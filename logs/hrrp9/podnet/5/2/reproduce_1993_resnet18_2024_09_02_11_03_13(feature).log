2024-09-02 11:03:13,947 [trainer.py] => config: ./exps/podnet.json
2024-09-02 11:03:13,947 [trainer.py] => prefix: reproduce
2024-09-02 11:03:13,947 [trainer.py] => dataset: hrrp9
2024-09-02 11:03:13,947 [trainer.py] => memory_size: 500
2024-09-02 11:03:13,947 [trainer.py] => memory_per_class: 20
2024-09-02 11:03:13,947 [trainer.py] => fixed_memory: False
2024-09-02 11:03:13,947 [trainer.py] => shuffle: True
2024-09-02 11:03:13,947 [trainer.py] => init_cls: 5
2024-09-02 11:03:13,947 [trainer.py] => increment: 2
2024-09-02 11:03:13,947 [trainer.py] => model_name: podnet
2024-09-02 11:03:13,948 [trainer.py] => convnet_type: resnet18
2024-09-02 11:03:13,948 [trainer.py] => init_train: True
2024-09-02 11:03:13,948 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-02 11:03:13,948 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-02 11:03:13,948 [trainer.py] => device: [device(type='cuda', index=7)]
2024-09-02 11:03:13,948 [trainer.py] => seed: 1993
2024-09-02 11:03:14,399 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-02 11:03:14,492 [trainer.py] => All params: 3843904
2024-09-02 11:03:14,492 [trainer.py] => Trainable params: 3843904
2024-09-02 11:03:14,492 [podnet.py] => Learning on 0-5
2024-09-02 11:03:14,527 [podnet.py] => Adaptive factor: 0
2024-09-02 11:03:17,681 [podnet.py] => Task 0, Epoch 1/300 (LR 0.10000) => LSC_loss 1.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 41.02, Test_acc 43.47
2024-09-02 11:03:19,602 [podnet.py] => Task 0, Epoch 2/300 (LR 0.09999) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.86, Test_acc 32.63
2024-09-02 11:03:21,469 [podnet.py] => Task 0, Epoch 3/300 (LR 0.09998) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.47, Test_acc 36.30
2024-09-02 11:03:23,356 [podnet.py] => Task 0, Epoch 4/300 (LR 0.09996) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.33, Test_acc 59.63
2024-09-02 11:03:25,600 [podnet.py] => Task 0, Epoch 5/300 (LR 0.09993) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.73, Test_acc 55.37
2024-09-02 11:03:27,908 [podnet.py] => Task 0, Epoch 6/300 (LR 0.09990) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.02, Test_acc 72.20
2024-09-02 11:03:29,852 [podnet.py] => Task 0, Epoch 7/300 (LR 0.09987) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.42, Test_acc 67.40
2024-09-02 11:03:32,670 [podnet.py] => Task 0, Epoch 8/300 (LR 0.09982) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.66, Test_acc 74.30
2024-09-02 11:03:35,462 [podnet.py] => Task 0, Epoch 9/300 (LR 0.09978) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.07, Test_acc 74.60
2024-09-02 11:03:36,928 [podnet.py] => Task 0, Epoch 10/300 (LR 0.09973) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.47, Test_acc 78.70
2024-09-02 11:03:38,757 [podnet.py] => Task 0, Epoch 11/300 (LR 0.09967) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 70.47
2024-09-02 11:03:40,707 [podnet.py] => Task 0, Epoch 12/300 (LR 0.09961) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.31, Test_acc 82.27
2024-09-02 11:03:42,139 [podnet.py] => Task 0, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.29, Test_acc 82.53
2024-09-02 11:03:45,138 [podnet.py] => Task 0, Epoch 14/300 (LR 0.09946) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 67.27
2024-09-02 11:03:47,771 [podnet.py] => Task 0, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.94, Test_acc 79.93
2024-09-02 11:03:50,773 [podnet.py] => Task 0, Epoch 16/300 (LR 0.09930) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.08, Test_acc 83.07
2024-09-02 11:03:53,627 [podnet.py] => Task 0, Epoch 17/300 (LR 0.09921) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.57, Test_acc 72.60
2024-09-02 11:03:56,694 [podnet.py] => Task 0, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.56, Test_acc 80.30
2024-09-02 11:03:59,302 [podnet.py] => Task 0, Epoch 19/300 (LR 0.09901) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 81.57
2024-09-02 11:04:02,017 [podnet.py] => Task 0, Epoch 20/300 (LR 0.09891) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 79.03
2024-09-02 11:04:04,349 [podnet.py] => Task 0, Epoch 21/300 (LR 0.09880) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 83.07
2024-09-02 11:04:07,064 [podnet.py] => Task 0, Epoch 22/300 (LR 0.09868) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.83, Test_acc 74.17
2024-09-02 11:04:09,363 [podnet.py] => Task 0, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 82.63
2024-09-02 11:04:11,607 [podnet.py] => Task 0, Epoch 24/300 (LR 0.09843) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 82.83
2024-09-02 11:04:14,079 [podnet.py] => Task 0, Epoch 25/300 (LR 0.09830) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.27, Test_acc 84.33
2024-09-02 11:04:16,598 [podnet.py] => Task 0, Epoch 26/300 (LR 0.09816) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.83, Test_acc 85.20
2024-09-02 11:04:19,109 [podnet.py] => Task 0, Epoch 27/300 (LR 0.09801) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 85.90
2024-09-02 11:04:21,679 [podnet.py] => Task 0, Epoch 28/300 (LR 0.09787) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.15, Test_acc 74.20
2024-09-02 11:04:24,418 [podnet.py] => Task 0, Epoch 29/300 (LR 0.09771) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 82.03
2024-09-02 11:04:27,161 [podnet.py] => Task 0, Epoch 30/300 (LR 0.09755) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 76.93
2024-09-02 11:04:29,705 [podnet.py] => Task 0, Epoch 31/300 (LR 0.09739) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.02, Test_acc 79.40
2024-09-02 11:04:32,495 [podnet.py] => Task 0, Epoch 32/300 (LR 0.09722) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.66, Test_acc 77.10
2024-09-02 11:04:35,211 [podnet.py] => Task 0, Epoch 33/300 (LR 0.09704) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.02, Test_acc 79.23
2024-09-02 11:04:38,274 [podnet.py] => Task 0, Epoch 34/300 (LR 0.09686) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.07, Test_acc 86.00
2024-09-02 11:04:41,001 [podnet.py] => Task 0, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 74.73
2024-09-02 11:04:42,878 [podnet.py] => Task 0, Epoch 36/300 (LR 0.09649) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.14, Test_acc 79.27
2024-09-02 11:04:45,548 [podnet.py] => Task 0, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 84.97
2024-09-02 11:04:48,474 [podnet.py] => Task 0, Epoch 38/300 (LR 0.09609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.08, Test_acc 84.70
2024-09-02 11:04:50,701 [podnet.py] => Task 0, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.69, Test_acc 82.83
2024-09-02 11:04:52,676 [podnet.py] => Task 0, Epoch 40/300 (LR 0.09568) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 75.70
2024-09-02 11:04:55,563 [podnet.py] => Task 0, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.97, Test_acc 83.57
2024-09-02 11:04:58,378 [podnet.py] => Task 0, Epoch 42/300 (LR 0.09524) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 82.43
2024-09-02 11:05:01,098 [podnet.py] => Task 0, Epoch 43/300 (LR 0.09502) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.89, Test_acc 86.70
2024-09-02 11:05:03,731 [podnet.py] => Task 0, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 71.70
2024-09-02 11:05:05,752 [podnet.py] => Task 0, Epoch 45/300 (LR 0.09455) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 84.30
2024-09-02 11:05:08,267 [podnet.py] => Task 0, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 80.70
2024-09-02 11:05:10,677 [podnet.py] => Task 0, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.17, Test_acc 84.67
2024-09-02 11:05:13,525 [podnet.py] => Task 0, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 83.63
2024-09-02 11:05:16,627 [podnet.py] => Task 0, Epoch 49/300 (LR 0.09356) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 85.03
2024-09-02 11:05:19,740 [podnet.py] => Task 0, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.65, Test_acc 82.57
2024-09-02 11:05:22,451 [podnet.py] => Task 0, Epoch 51/300 (LR 0.09304) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.39, Test_acc 88.17
2024-09-02 11:05:25,114 [podnet.py] => Task 0, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.86, Test_acc 80.73
2024-09-02 11:05:27,795 [podnet.py] => Task 0, Epoch 53/300 (LR 0.09249) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 78.07
2024-09-02 11:05:30,401 [podnet.py] => Task 0, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.67
2024-09-02 11:05:32,969 [podnet.py] => Task 0, Epoch 55/300 (LR 0.09193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.26, Test_acc 82.83
2024-09-02 11:05:35,058 [podnet.py] => Task 0, Epoch 56/300 (LR 0.09165) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 82.33
2024-09-02 11:05:37,894 [podnet.py] => Task 0, Epoch 57/300 (LR 0.09135) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.60, Test_acc 82.83
2024-09-02 11:05:40,358 [podnet.py] => Task 0, Epoch 58/300 (LR 0.09106) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.50, Test_acc 84.40
2024-09-02 11:05:42,971 [podnet.py] => Task 0, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 70.30
2024-09-02 11:05:45,079 [podnet.py] => Task 0, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 82.83
2024-09-02 11:05:47,038 [podnet.py] => Task 0, Epoch 61/300 (LR 0.09014) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.69, Test_acc 83.20
2024-09-02 11:05:49,286 [podnet.py] => Task 0, Epoch 62/300 (LR 0.08983) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.30, Test_acc 86.53
2024-09-02 11:05:51,784 [podnet.py] => Task 0, Epoch 63/300 (LR 0.08951) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.41, Test_acc 84.83
2024-09-02 11:05:53,980 [podnet.py] => Task 0, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 84.63
2024-09-02 11:05:56,285 [podnet.py] => Task 0, Epoch 65/300 (LR 0.08886) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 81.80
2024-09-02 11:05:58,650 [podnet.py] => Task 0, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 81.17
2024-09-02 11:06:01,300 [podnet.py] => Task 0, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 82.20
2024-09-02 11:06:04,011 [podnet.py] => Task 0, Epoch 68/300 (LR 0.08785) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.91, Test_acc 83.43
2024-09-02 11:06:06,864 [podnet.py] => Task 0, Epoch 69/300 (LR 0.08751) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.09, Test_acc 84.27
2024-09-02 11:06:09,863 [podnet.py] => Task 0, Epoch 70/300 (LR 0.08716) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.47, Test_acc 84.80
2024-09-02 11:06:12,947 [podnet.py] => Task 0, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 88.13
2024-09-02 11:06:15,904 [podnet.py] => Task 0, Epoch 72/300 (LR 0.08645) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 87.83
2024-09-02 11:06:17,879 [podnet.py] => Task 0, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.82, Test_acc 87.00
2024-09-02 11:06:20,517 [podnet.py] => Task 0, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 87.03
2024-09-02 11:06:22,682 [podnet.py] => Task 0, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 86.63
2024-09-02 11:06:25,464 [podnet.py] => Task 0, Epoch 76/300 (LR 0.08498) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.71, Test_acc 78.20
2024-09-02 11:06:28,371 [podnet.py] => Task 0, Epoch 77/300 (LR 0.08461) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 84.30
2024-09-02 11:06:31,550 [podnet.py] => Task 0, Epoch 78/300 (LR 0.08423) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 86.53
2024-09-02 11:06:33,916 [podnet.py] => Task 0, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 80.93
2024-09-02 11:06:36,471 [podnet.py] => Task 0, Epoch 80/300 (LR 0.08346) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.19, Test_acc 83.10
2024-09-02 11:06:38,446 [podnet.py] => Task 0, Epoch 81/300 (LR 0.08307) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.09, Test_acc 86.57
2024-09-02 11:06:41,427 [podnet.py] => Task 0, Epoch 82/300 (LR 0.08267) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 86.83
2024-09-02 11:06:44,141 [podnet.py] => Task 0, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.72, Test_acc 84.97
2024-09-02 11:06:45,702 [podnet.py] => Task 0, Epoch 84/300 (LR 0.08187) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.52, Test_acc 80.90
2024-09-02 11:06:48,120 [podnet.py] => Task 0, Epoch 85/300 (LR 0.08147) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.01, Test_acc 86.27
2024-09-02 11:06:50,167 [podnet.py] => Task 0, Epoch 86/300 (LR 0.08106) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.85, Test_acc 80.87
2024-09-02 11:06:52,947 [podnet.py] => Task 0, Epoch 87/300 (LR 0.08065) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.98, Test_acc 78.57
2024-09-02 11:06:55,864 [podnet.py] => Task 0, Epoch 88/300 (LR 0.08023) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.55, Test_acc 85.57
2024-09-02 11:06:57,767 [podnet.py] => Task 0, Epoch 89/300 (LR 0.07981) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 87.87
2024-09-02 11:06:59,691 [podnet.py] => Task 0, Epoch 90/300 (LR 0.07939) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.83
2024-09-02 11:07:02,644 [podnet.py] => Task 0, Epoch 91/300 (LR 0.07896) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.42, Test_acc 82.47
2024-09-02 11:07:05,126 [podnet.py] => Task 0, Epoch 92/300 (LR 0.07854) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.95, Test_acc 86.23
2024-09-02 11:07:08,210 [podnet.py] => Task 0, Epoch 93/300 (LR 0.07810) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 87.07
2024-09-02 11:07:10,427 [podnet.py] => Task 0, Epoch 94/300 (LR 0.07767) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 84.03
2024-09-02 11:07:12,956 [podnet.py] => Task 0, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 80.70
2024-09-02 11:07:15,143 [podnet.py] => Task 0, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 85.07
2024-09-02 11:07:18,034 [podnet.py] => Task 0, Epoch 97/300 (LR 0.07635) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 79.37
2024-09-02 11:07:20,569 [podnet.py] => Task 0, Epoch 98/300 (LR 0.07590) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 87.33
2024-09-02 11:07:23,720 [podnet.py] => Task 0, Epoch 99/300 (LR 0.07545) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.21, Test_acc 84.17
2024-09-02 11:07:26,957 [podnet.py] => Task 0, Epoch 100/300 (LR 0.07500) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 85.00
2024-09-02 11:07:29,901 [podnet.py] => Task 0, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.81, Test_acc 82.50
2024-09-02 11:07:32,780 [podnet.py] => Task 0, Epoch 102/300 (LR 0.07409) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.40
2024-09-02 11:07:35,628 [podnet.py] => Task 0, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.89, Test_acc 83.40
2024-09-02 11:07:37,806 [podnet.py] => Task 0, Epoch 104/300 (LR 0.07316) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 80.57
2024-09-02 11:07:40,542 [podnet.py] => Task 0, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.07, Test_acc 88.03
2024-09-02 11:07:43,177 [podnet.py] => Task 0, Epoch 106/300 (LR 0.07223) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 85.80
2024-09-02 11:07:45,959 [podnet.py] => Task 0, Epoch 107/300 (LR 0.07176) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.17, Test_acc 80.70
2024-09-02 11:07:49,141 [podnet.py] => Task 0, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 85.73
2024-09-02 11:07:51,140 [podnet.py] => Task 0, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.50
2024-09-02 11:07:53,366 [podnet.py] => Task 0, Epoch 110/300 (LR 0.07034) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 87.13
2024-09-02 11:07:56,070 [podnet.py] => Task 0, Epoch 111/300 (LR 0.06986) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.58, Test_acc 87.13
2024-09-02 11:07:59,011 [podnet.py] => Task 0, Epoch 112/300 (LR 0.06938) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.84, Test_acc 84.77
2024-09-02 11:08:02,015 [podnet.py] => Task 0, Epoch 113/300 (LR 0.06889) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.13, Test_acc 85.40
2024-09-02 11:08:04,248 [podnet.py] => Task 0, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 83.33
2024-09-02 11:08:06,265 [podnet.py] => Task 0, Epoch 115/300 (LR 0.06792) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 84.27
2024-09-02 11:08:08,209 [podnet.py] => Task 0, Epoch 116/300 (LR 0.06743) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.73
2024-09-02 11:08:11,241 [podnet.py] => Task 0, Epoch 117/300 (LR 0.06694) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.29, Test_acc 79.07
2024-09-02 11:08:13,405 [podnet.py] => Task 0, Epoch 118/300 (LR 0.06644) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 84.63
2024-09-02 11:08:15,701 [podnet.py] => Task 0, Epoch 119/300 (LR 0.06595) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 84.53
2024-09-02 11:08:17,470 [podnet.py] => Task 0, Epoch 120/300 (LR 0.06545) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 83.80
2024-09-02 11:08:20,322 [podnet.py] => Task 0, Epoch 121/300 (LR 0.06495) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.73, Test_acc 87.63
2024-09-02 11:08:23,247 [podnet.py] => Task 0, Epoch 122/300 (LR 0.06445) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 83.27
2024-09-02 11:08:25,811 [podnet.py] => Task 0, Epoch 123/300 (LR 0.06395) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 82.97
2024-09-02 11:08:28,696 [podnet.py] => Task 0, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 83.40
2024-09-02 11:08:30,790 [podnet.py] => Task 0, Epoch 125/300 (LR 0.06294) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.22, Test_acc 83.77
2024-09-02 11:08:33,362 [podnet.py] => Task 0, Epoch 126/300 (LR 0.06243) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 86.57
2024-09-02 11:08:36,201 [podnet.py] => Task 0, Epoch 127/300 (LR 0.06193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.36, Test_acc 86.00
2024-09-02 11:08:38,991 [podnet.py] => Task 0, Epoch 128/300 (LR 0.06142) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.84, Test_acc 84.60
2024-09-02 11:08:41,730 [podnet.py] => Task 0, Epoch 129/300 (LR 0.06091) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 87.97
2024-09-02 11:08:44,707 [podnet.py] => Task 0, Epoch 130/300 (LR 0.06040) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 82.23
2024-09-02 11:08:47,583 [podnet.py] => Task 0, Epoch 131/300 (LR 0.05988) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 86.90
2024-09-02 11:08:49,876 [podnet.py] => Task 0, Epoch 132/300 (LR 0.05937) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 89.73
2024-09-02 11:08:51,933 [podnet.py] => Task 0, Epoch 133/300 (LR 0.05885) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.57
2024-09-02 11:08:54,353 [podnet.py] => Task 0, Epoch 134/300 (LR 0.05834) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.87
2024-09-02 11:08:56,705 [podnet.py] => Task 0, Epoch 135/300 (LR 0.05782) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.44, Test_acc 85.53
2024-09-02 11:08:59,748 [podnet.py] => Task 0, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 79.13
2024-09-02 11:09:02,633 [podnet.py] => Task 0, Epoch 137/300 (LR 0.05679) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.71, Test_acc 88.00
2024-09-02 11:09:05,546 [podnet.py] => Task 0, Epoch 138/300 (LR 0.05627) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.33
2024-09-02 11:09:07,502 [podnet.py] => Task 0, Epoch 139/300 (LR 0.05575) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 88.17
2024-09-02 11:09:09,471 [podnet.py] => Task 0, Epoch 140/300 (LR 0.05523) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 82.47
2024-09-02 11:09:12,206 [podnet.py] => Task 0, Epoch 141/300 (LR 0.05471) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 84.93
2024-09-02 11:09:14,350 [podnet.py] => Task 0, Epoch 142/300 (LR 0.05418) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.70, Test_acc 84.13
2024-09-02 11:09:16,141 [podnet.py] => Task 0, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 84.60
2024-09-02 11:09:18,937 [podnet.py] => Task 0, Epoch 144/300 (LR 0.05314) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 87.83
2024-09-02 11:09:21,468 [podnet.py] => Task 0, Epoch 145/300 (LR 0.05262) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.45, Test_acc 86.60
2024-09-02 11:09:24,034 [podnet.py] => Task 0, Epoch 146/300 (LR 0.05209) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 81.50
2024-09-02 11:09:27,056 [podnet.py] => Task 0, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.53, Test_acc 86.77
2024-09-02 11:09:30,199 [podnet.py] => Task 0, Epoch 148/300 (LR 0.05105) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.37, Test_acc 84.77
2024-09-02 11:09:33,109 [podnet.py] => Task 0, Epoch 149/300 (LR 0.05052) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 85.70
2024-09-02 11:09:35,490 [podnet.py] => Task 0, Epoch 150/300 (LR 0.05000) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 86.57
2024-09-02 11:09:38,170 [podnet.py] => Task 0, Epoch 151/300 (LR 0.04948) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.81, Test_acc 84.43
2024-09-02 11:09:40,059 [podnet.py] => Task 0, Epoch 152/300 (LR 0.04895) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 88.60
2024-09-02 11:09:42,736 [podnet.py] => Task 0, Epoch 153/300 (LR 0.04843) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 87.07
2024-09-02 11:09:44,584 [podnet.py] => Task 0, Epoch 154/300 (LR 0.04791) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 87.57
2024-09-02 11:09:47,253 [podnet.py] => Task 0, Epoch 155/300 (LR 0.04738) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.14, Test_acc 81.10
2024-09-02 11:09:49,791 [podnet.py] => Task 0, Epoch 156/300 (LR 0.04686) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.67, Test_acc 88.10
2024-09-02 11:09:52,949 [podnet.py] => Task 0, Epoch 157/300 (LR 0.04634) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.87
2024-09-02 11:09:54,869 [podnet.py] => Task 0, Epoch 158/300 (LR 0.04582) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 88.53
2024-09-02 11:09:57,625 [podnet.py] => Task 0, Epoch 159/300 (LR 0.04529) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.43
2024-09-02 11:09:59,975 [podnet.py] => Task 0, Epoch 160/300 (LR 0.04477) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 86.20
2024-09-02 11:10:03,135 [podnet.py] => Task 0, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.68, Test_acc 84.87
2024-09-02 11:10:05,469 [podnet.py] => Task 0, Epoch 162/300 (LR 0.04373) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 88.27
2024-09-02 11:10:08,457 [podnet.py] => Task 0, Epoch 163/300 (LR 0.04321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 85.63
2024-09-02 11:10:11,076 [podnet.py] => Task 0, Epoch 164/300 (LR 0.04270) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 83.27
2024-09-02 11:10:13,710 [podnet.py] => Task 0, Epoch 165/300 (LR 0.04218) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 85.37
2024-09-02 11:10:16,143 [podnet.py] => Task 0, Epoch 166/300 (LR 0.04166) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 89.13
2024-09-02 11:10:18,541 [podnet.py] => Task 0, Epoch 167/300 (LR 0.04115) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.61, Test_acc 86.80
2024-09-02 11:10:21,233 [podnet.py] => Task 0, Epoch 168/300 (LR 0.04063) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.17
2024-09-02 11:10:24,019 [podnet.py] => Task 0, Epoch 169/300 (LR 0.04012) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.03
2024-09-02 11:10:27,051 [podnet.py] => Task 0, Epoch 170/300 (LR 0.03960) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 89.47
2024-09-02 11:10:30,265 [podnet.py] => Task 0, Epoch 171/300 (LR 0.03909) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.13
2024-09-02 11:10:32,302 [podnet.py] => Task 0, Epoch 172/300 (LR 0.03858) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.91, Test_acc 89.47
2024-09-02 11:10:34,206 [podnet.py] => Task 0, Epoch 173/300 (LR 0.03807) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 88.13
2024-09-02 11:10:36,376 [podnet.py] => Task 0, Epoch 174/300 (LR 0.03757) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 84.43
2024-09-02 11:10:38,852 [podnet.py] => Task 0, Epoch 175/300 (LR 0.03706) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.57, Test_acc 86.30
2024-09-02 11:10:40,808 [podnet.py] => Task 0, Epoch 176/300 (LR 0.03655) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 81.37
2024-09-02 11:10:43,820 [podnet.py] => Task 0, Epoch 177/300 (LR 0.03605) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.73, Test_acc 85.23
2024-09-02 11:10:46,336 [podnet.py] => Task 0, Epoch 178/300 (LR 0.03555) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 85.83
2024-09-02 11:10:49,399 [podnet.py] => Task 0, Epoch 179/300 (LR 0.03505) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.55, Test_acc 83.43
2024-09-02 11:10:51,466 [podnet.py] => Task 0, Epoch 180/300 (LR 0.03455) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 88.90
2024-09-02 11:10:53,353 [podnet.py] => Task 0, Epoch 181/300 (LR 0.03405) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 88.60
2024-09-02 11:10:55,280 [podnet.py] => Task 0, Epoch 182/300 (LR 0.03356) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.73
2024-09-02 11:10:57,707 [podnet.py] => Task 0, Epoch 183/300 (LR 0.03306) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.73
2024-09-02 11:11:00,166 [podnet.py] => Task 0, Epoch 184/300 (LR 0.03257) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.11, Test_acc 88.17
2024-09-02 11:11:02,191 [podnet.py] => Task 0, Epoch 185/300 (LR 0.03208) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 87.47
2024-09-02 11:11:04,887 [podnet.py] => Task 0, Epoch 186/300 (LR 0.03159) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 79.03
2024-09-02 11:11:06,743 [podnet.py] => Task 0, Epoch 187/300 (LR 0.03111) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.53, Test_acc 84.80
2024-09-02 11:11:08,847 [podnet.py] => Task 0, Epoch 188/300 (LR 0.03062) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.47, Test_acc 85.53
2024-09-02 11:11:11,691 [podnet.py] => Task 0, Epoch 189/300 (LR 0.03014) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.35, Test_acc 88.90
2024-09-02 11:11:13,620 [podnet.py] => Task 0, Epoch 190/300 (LR 0.02966) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 86.80
2024-09-02 11:11:16,593 [podnet.py] => Task 0, Epoch 191/300 (LR 0.02919) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.20
2024-09-02 11:11:19,394 [podnet.py] => Task 0, Epoch 192/300 (LR 0.02871) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 86.90
2024-09-02 11:11:22,098 [podnet.py] => Task 0, Epoch 193/300 (LR 0.02824) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 89.30
2024-09-02 11:11:24,530 [podnet.py] => Task 0, Epoch 194/300 (LR 0.02777) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.27
2024-09-02 11:11:27,229 [podnet.py] => Task 0, Epoch 195/300 (LR 0.02730) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.47
2024-09-02 11:11:29,933 [podnet.py] => Task 0, Epoch 196/300 (LR 0.02684) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.73
2024-09-02 11:11:32,799 [podnet.py] => Task 0, Epoch 197/300 (LR 0.02637) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.63
2024-09-02 11:11:34,906 [podnet.py] => Task 0, Epoch 198/300 (LR 0.02591) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.23
2024-09-02 11:11:37,492 [podnet.py] => Task 0, Epoch 199/300 (LR 0.02545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.60
2024-09-02 11:11:39,452 [podnet.py] => Task 0, Epoch 200/300 (LR 0.02500) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.67
2024-09-02 11:11:42,403 [podnet.py] => Task 0, Epoch 201/300 (LR 0.02455) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.67
2024-09-02 11:11:44,530 [podnet.py] => Task 0, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 88.40
2024-09-02 11:11:47,155 [podnet.py] => Task 0, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.02, Test_acc 88.30
2024-09-02 11:11:49,052 [podnet.py] => Task 0, Epoch 204/300 (LR 0.02321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 87.87
2024-09-02 11:11:51,015 [podnet.py] => Task 0, Epoch 205/300 (LR 0.02277) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 88.73
2024-09-02 11:11:54,000 [podnet.py] => Task 0, Epoch 206/300 (LR 0.02233) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.10
2024-09-02 11:11:56,931 [podnet.py] => Task 0, Epoch 207/300 (LR 0.02190) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.13
2024-09-02 11:11:59,718 [podnet.py] => Task 0, Epoch 208/300 (LR 0.02146) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 88.40
2024-09-02 11:12:01,882 [podnet.py] => Task 0, Epoch 209/300 (LR 0.02104) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 89.43
2024-09-02 11:12:04,238 [podnet.py] => Task 0, Epoch 210/300 (LR 0.02061) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.40
2024-09-02 11:12:06,059 [podnet.py] => Task 0, Epoch 211/300 (LR 0.02019) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 86.90
2024-09-02 11:12:08,539 [podnet.py] => Task 0, Epoch 212/300 (LR 0.01977) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 86.67
2024-09-02 11:12:10,628 [podnet.py] => Task 0, Epoch 213/300 (LR 0.01935) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.37
2024-09-02 11:12:13,536 [podnet.py] => Task 0, Epoch 214/300 (LR 0.01894) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 89.67
2024-09-02 11:12:16,216 [podnet.py] => Task 0, Epoch 215/300 (LR 0.01853) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 89.77
2024-09-02 11:12:18,764 [podnet.py] => Task 0, Epoch 216/300 (LR 0.01813) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.20
2024-09-02 11:12:21,019 [podnet.py] => Task 0, Epoch 217/300 (LR 0.01773) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.83
2024-09-02 11:12:23,379 [podnet.py] => Task 0, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.16, Test_acc 89.30
2024-09-02 11:12:26,032 [podnet.py] => Task 0, Epoch 219/300 (LR 0.01693) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 88.13
2024-09-02 11:12:28,739 [podnet.py] => Task 0, Epoch 220/300 (LR 0.01654) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.87, Test_acc 89.87
2024-09-02 11:12:30,219 [podnet.py] => Task 0, Epoch 221/300 (LR 0.01616) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.98, Test_acc 89.27
2024-09-02 11:12:32,239 [podnet.py] => Task 0, Epoch 222/300 (LR 0.01577) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 11:12:34,622 [podnet.py] => Task 0, Epoch 223/300 (LR 0.01539) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 11:12:37,297 [podnet.py] => Task 0, Epoch 224/300 (LR 0.01502) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 11:12:39,738 [podnet.py] => Task 0, Epoch 225/300 (LR 0.01464) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 11:12:42,786 [podnet.py] => Task 0, Epoch 226/300 (LR 0.01428) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 11:12:45,330 [podnet.py] => Task 0, Epoch 227/300 (LR 0.01391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 11:12:48,498 [podnet.py] => Task 0, Epoch 228/300 (LR 0.01355) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.33
2024-09-02 11:12:50,402 [podnet.py] => Task 0, Epoch 229/300 (LR 0.01320) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 11:12:53,028 [podnet.py] => Task 0, Epoch 230/300 (LR 0.01284) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.13
2024-09-02 11:12:55,707 [podnet.py] => Task 0, Epoch 231/300 (LR 0.01249) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.00
2024-09-02 11:12:58,429 [podnet.py] => Task 0, Epoch 232/300 (LR 0.01215) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.90
2024-09-02 11:13:00,318 [podnet.py] => Task 0, Epoch 233/300 (LR 0.01181) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.07
2024-09-02 11:13:03,079 [podnet.py] => Task 0, Epoch 234/300 (LR 0.01147) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.10
2024-09-02 11:13:05,058 [podnet.py] => Task 0, Epoch 235/300 (LR 0.01114) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.03
2024-09-02 11:13:06,922 [podnet.py] => Task 0, Epoch 236/300 (LR 0.01082) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 89.43
2024-09-02 11:13:08,804 [podnet.py] => Task 0, Epoch 237/300 (LR 0.01049) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 11:13:11,170 [podnet.py] => Task 0, Epoch 238/300 (LR 0.01017) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 11:13:13,972 [podnet.py] => Task 0, Epoch 239/300 (LR 0.00986) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 11:13:16,577 [podnet.py] => Task 0, Epoch 240/300 (LR 0.00955) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 11:13:18,000 [podnet.py] => Task 0, Epoch 241/300 (LR 0.00924) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 11:13:20,429 [podnet.py] => Task 0, Epoch 242/300 (LR 0.00894) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.33
2024-09-02 11:13:22,255 [podnet.py] => Task 0, Epoch 243/300 (LR 0.00865) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 11:13:25,048 [podnet.py] => Task 0, Epoch 244/300 (LR 0.00835) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 11:13:26,953 [podnet.py] => Task 0, Epoch 245/300 (LR 0.00807) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.73
2024-09-02 11:13:30,062 [podnet.py] => Task 0, Epoch 246/300 (LR 0.00778) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 11:13:32,831 [podnet.py] => Task 0, Epoch 247/300 (LR 0.00751) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 11:13:35,633 [podnet.py] => Task 0, Epoch 248/300 (LR 0.00723) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 11:13:37,743 [podnet.py] => Task 0, Epoch 249/300 (LR 0.00696) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 11:13:40,684 [podnet.py] => Task 0, Epoch 250/300 (LR 0.00670) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 11:13:42,852 [podnet.py] => Task 0, Epoch 251/300 (LR 0.00644) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 11:13:44,753 [podnet.py] => Task 0, Epoch 252/300 (LR 0.00618) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 11:13:47,297 [podnet.py] => Task 0, Epoch 253/300 (LR 0.00593) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 11:13:50,174 [podnet.py] => Task 0, Epoch 254/300 (LR 0.00569) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 11:13:52,644 [podnet.py] => Task 0, Epoch 255/300 (LR 0.00545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 11:13:55,393 [podnet.py] => Task 0, Epoch 256/300 (LR 0.00521) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 11:13:57,347 [podnet.py] => Task 0, Epoch 257/300 (LR 0.00498) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.57
2024-09-02 11:14:00,336 [podnet.py] => Task 0, Epoch 258/300 (LR 0.00476) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.87
2024-09-02 11:14:02,971 [podnet.py] => Task 0, Epoch 259/300 (LR 0.00454) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 11:14:05,756 [podnet.py] => Task 0, Epoch 260/300 (LR 0.00432) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.77
2024-09-02 11:14:08,285 [podnet.py] => Task 0, Epoch 261/300 (LR 0.00411) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 11:14:10,936 [podnet.py] => Task 0, Epoch 262/300 (LR 0.00391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 11:14:14,116 [podnet.py] => Task 0, Epoch 263/300 (LR 0.00371) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.80
2024-09-02 11:14:16,974 [podnet.py] => Task 0, Epoch 264/300 (LR 0.00351) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 11:14:19,647 [podnet.py] => Task 0, Epoch 265/300 (LR 0.00332) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 11:14:22,249 [podnet.py] => Task 0, Epoch 266/300 (LR 0.00314) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 11:14:25,038 [podnet.py] => Task 0, Epoch 267/300 (LR 0.00296) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 11:14:27,887 [podnet.py] => Task 0, Epoch 268/300 (LR 0.00278) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 11:14:30,066 [podnet.py] => Task 0, Epoch 269/300 (LR 0.00261) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 11:14:32,625 [podnet.py] => Task 0, Epoch 270/300 (LR 0.00245) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.63
2024-09-02 11:14:34,734 [podnet.py] => Task 0, Epoch 271/300 (LR 0.00229) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 11:14:37,407 [podnet.py] => Task 0, Epoch 272/300 (LR 0.00213) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 11:14:40,517 [podnet.py] => Task 0, Epoch 273/300 (LR 0.00199) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 11:14:42,169 [podnet.py] => Task 0, Epoch 274/300 (LR 0.00184) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 11:14:44,062 [podnet.py] => Task 0, Epoch 275/300 (LR 0.00170) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 11:14:46,536 [podnet.py] => Task 0, Epoch 276/300 (LR 0.00157) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 11:14:49,156 [podnet.py] => Task 0, Epoch 277/300 (LR 0.00144) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 11:14:51,440 [podnet.py] => Task 0, Epoch 278/300 (LR 0.00132) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.70
2024-09-02 11:14:53,985 [podnet.py] => Task 0, Epoch 279/300 (LR 0.00120) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 88.97
2024-09-02 11:14:56,659 [podnet.py] => Task 0, Epoch 280/300 (LR 0.00109) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 11:14:58,689 [podnet.py] => Task 0, Epoch 281/300 (LR 0.00099) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 11:15:01,219 [podnet.py] => Task 0, Epoch 282/300 (LR 0.00089) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 11:15:03,484 [podnet.py] => Task 0, Epoch 283/300 (LR 0.00079) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 11:15:05,432 [podnet.py] => Task 0, Epoch 284/300 (LR 0.00070) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 11:15:07,869 [podnet.py] => Task 0, Epoch 285/300 (LR 0.00062) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 11:15:10,656 [podnet.py] => Task 0, Epoch 286/300 (LR 0.00054) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 11:15:13,579 [podnet.py] => Task 0, Epoch 287/300 (LR 0.00046) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.17
2024-09-02 11:15:15,491 [podnet.py] => Task 0, Epoch 288/300 (LR 0.00039) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 11:15:17,579 [podnet.py] => Task 0, Epoch 289/300 (LR 0.00033) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 11:15:20,158 [podnet.py] => Task 0, Epoch 290/300 (LR 0.00027) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 11:15:22,627 [podnet.py] => Task 0, Epoch 291/300 (LR 0.00022) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 11:15:24,889 [podnet.py] => Task 0, Epoch 292/300 (LR 0.00018) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 11:15:27,575 [podnet.py] => Task 0, Epoch 293/300 (LR 0.00013) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.97
2024-09-02 11:15:29,856 [podnet.py] => Task 0, Epoch 294/300 (LR 0.00010) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 11:15:31,751 [podnet.py] => Task 0, Epoch 295/300 (LR 0.00007) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 11:15:34,161 [podnet.py] => Task 0, Epoch 296/300 (LR 0.00004) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.17
2024-09-02 11:15:36,966 [podnet.py] => Task 0, Epoch 297/300 (LR 0.00002) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.87
2024-09-02 11:15:39,506 [podnet.py] => Task 0, Epoch 298/300 (LR 0.00001) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 11:15:42,254 [podnet.py] => Task 0, Epoch 299/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 11:15:44,158 [podnet.py] => Task 0, Epoch 300/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.90
2024-09-02 11:15:44,158 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 11:15:44,159 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 11:15:49,390 [podnet.py] => Exemplar size: 500
2024-09-02 11:15:49,391 [trainer.py] => CNN: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 11:15:49,391 [trainer.py] => NME: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 11:15:49,391 [trainer.py] => CNN top1 curve: [88.9]
2024-09-02 11:15:49,391 [trainer.py] => CNN top5 curve: [100.0]
2024-09-02 11:15:49,391 [trainer.py] => NME top1 curve: [88.9]
2024-09-02 11:15:49,391 [trainer.py] => NME top5 curve: [100.0]

2024-09-02 11:15:49,391 [trainer.py] => Average Accuracy (CNN): 88.9
2024-09-02 11:15:49,391 [trainer.py] => Average Accuracy (NME): 88.9
2024-09-02 11:15:49,391 [trainer.py] => All params: 3869505
2024-09-02 11:15:49,391 [trainer.py] => Trainable params: 3869505
2024-09-02 11:15:49,392 [podnet.py] => Learning on 5-7
2024-09-02 11:15:49,406 [podnet.py] => Adaptive factor: 1.8708286933869707
2024-09-02 11:15:51,473 [podnet.py] => Task 1, Epoch 1/300 (LR 0.10000) => LSC_loss 1.11, Spatial_loss 0.23, Flat_loss 0.79, Train_acc 72.91, Test_acc 26.19
2024-09-02 11:15:53,189 [podnet.py] => Task 1, Epoch 2/300 (LR 0.09999) => LSC_loss 0.62, Spatial_loss 0.21, Flat_loss 0.59, Train_acc 83.98, Test_acc 19.90
2024-09-02 11:15:54,931 [podnet.py] => Task 1, Epoch 3/300 (LR 0.09998) => LSC_loss 0.47, Spatial_loss 0.20, Flat_loss 0.52, Train_acc 88.29, Test_acc 36.52
2024-09-02 11:15:57,021 [podnet.py] => Task 1, Epoch 4/300 (LR 0.09996) => LSC_loss 0.41, Spatial_loss 0.19, Flat_loss 0.49, Train_acc 89.36, Test_acc 30.17
2024-09-02 11:15:59,055 [podnet.py] => Task 1, Epoch 5/300 (LR 0.09993) => LSC_loss 0.31, Spatial_loss 0.18, Flat_loss 0.44, Train_acc 91.91, Test_acc 47.26
2024-09-02 11:16:01,070 [podnet.py] => Task 1, Epoch 6/300 (LR 0.09990) => LSC_loss 0.28, Spatial_loss 0.18, Flat_loss 0.42, Train_acc 92.96, Test_acc 44.86
2024-09-02 11:16:03,280 [podnet.py] => Task 1, Epoch 7/300 (LR 0.09987) => LSC_loss 0.23, Spatial_loss 0.17, Flat_loss 0.40, Train_acc 94.11, Test_acc 48.02
2024-09-02 11:16:05,137 [podnet.py] => Task 1, Epoch 8/300 (LR 0.09982) => LSC_loss 0.21, Spatial_loss 0.17, Flat_loss 0.39, Train_acc 94.69, Test_acc 51.21
2024-09-02 11:16:07,054 [podnet.py] => Task 1, Epoch 9/300 (LR 0.09978) => LSC_loss 0.20, Spatial_loss 0.17, Flat_loss 0.38, Train_acc 94.80, Test_acc 40.26
2024-09-02 11:16:08,781 [podnet.py] => Task 1, Epoch 10/300 (LR 0.09973) => LSC_loss 0.19, Spatial_loss 0.17, Flat_loss 0.37, Train_acc 95.51, Test_acc 54.67
2024-09-02 11:16:10,719 [podnet.py] => Task 1, Epoch 11/300 (LR 0.09967) => LSC_loss 0.14, Spatial_loss 0.16, Flat_loss 0.35, Train_acc 96.84, Test_acc 57.86
2024-09-02 11:16:12,544 [podnet.py] => Task 1, Epoch 12/300 (LR 0.09961) => LSC_loss 0.13, Spatial_loss 0.16, Flat_loss 0.34, Train_acc 97.16, Test_acc 50.00
2024-09-02 11:16:14,572 [podnet.py] => Task 1, Epoch 13/300 (LR 0.09954) => LSC_loss 0.12, Spatial_loss 0.16, Flat_loss 0.32, Train_acc 97.49, Test_acc 40.62
2024-09-02 11:16:16,581 [podnet.py] => Task 1, Epoch 14/300 (LR 0.09946) => LSC_loss 0.10, Spatial_loss 0.15, Flat_loss 0.30, Train_acc 98.36, Test_acc 57.33
2024-09-02 11:16:18,530 [podnet.py] => Task 1, Epoch 15/300 (LR 0.09938) => LSC_loss 0.11, Spatial_loss 0.15, Flat_loss 0.31, Train_acc 98.24, Test_acc 62.90
2024-09-02 11:16:20,528 [podnet.py] => Task 1, Epoch 16/300 (LR 0.09930) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.29, Train_acc 98.96, Test_acc 58.38
2024-09-02 11:16:22,870 [podnet.py] => Task 1, Epoch 17/300 (LR 0.09921) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 99.27, Test_acc 59.57
2024-09-02 11:16:24,978 [podnet.py] => Task 1, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.29, Train_acc 98.82, Test_acc 59.74
2024-09-02 11:16:27,181 [podnet.py] => Task 1, Epoch 19/300 (LR 0.09901) => LSC_loss 0.07, Spatial_loss 0.13, Flat_loss 0.27, Train_acc 99.47, Test_acc 63.95
2024-09-02 11:16:29,344 [podnet.py] => Task 1, Epoch 20/300 (LR 0.09891) => LSC_loss 0.08, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.18, Test_acc 60.29
2024-09-02 11:16:31,223 [podnet.py] => Task 1, Epoch 21/300 (LR 0.09880) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.28, Train_acc 98.91, Test_acc 52.62
2024-09-02 11:16:33,242 [podnet.py] => Task 1, Epoch 22/300 (LR 0.09868) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.31, Test_acc 65.71
2024-09-02 11:16:35,305 [podnet.py] => Task 1, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.51, Test_acc 60.00
2024-09-02 11:16:37,186 [podnet.py] => Task 1, Epoch 24/300 (LR 0.09843) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.71, Test_acc 54.60
2024-09-02 11:16:38,940 [podnet.py] => Task 1, Epoch 25/300 (LR 0.09830) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.60, Test_acc 61.14
2024-09-02 11:16:40,850 [podnet.py] => Task 1, Epoch 26/300 (LR 0.09816) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.23, Train_acc 99.76, Test_acc 64.81
2024-09-02 11:16:42,688 [podnet.py] => Task 1, Epoch 27/300 (LR 0.09801) => LSC_loss 0.14, Spatial_loss 0.14, Flat_loss 0.28, Train_acc 97.42, Test_acc 45.29
2024-09-02 11:16:44,563 [podnet.py] => Task 1, Epoch 28/300 (LR 0.09787) => LSC_loss 0.28, Spatial_loss 0.17, Flat_loss 0.40, Train_acc 92.42, Test_acc 49.67
2024-09-02 11:16:46,314 [podnet.py] => Task 1, Epoch 29/300 (LR 0.09771) => LSC_loss 0.19, Spatial_loss 0.17, Flat_loss 0.38, Train_acc 95.18, Test_acc 41.00
2024-09-02 11:16:48,403 [podnet.py] => Task 1, Epoch 30/300 (LR 0.09755) => LSC_loss 0.10, Spatial_loss 0.15, Flat_loss 0.32, Train_acc 97.82, Test_acc 61.57
2024-09-02 11:16:50,286 [podnet.py] => Task 1, Epoch 31/300 (LR 0.09739) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.33, Test_acc 63.67
2024-09-02 11:16:52,273 [podnet.py] => Task 1, Epoch 32/300 (LR 0.09722) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.82, Test_acc 66.00
2024-09-02 11:16:54,342 [podnet.py] => Task 1, Epoch 33/300 (LR 0.09704) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.28, Train_acc 98.64, Test_acc 53.90
2024-09-02 11:16:55,611 [podnet.py] => Task 1, Epoch 34/300 (LR 0.09686) => LSC_loss 0.12, Spatial_loss 0.15, Flat_loss 0.30, Train_acc 97.47, Test_acc 55.43
2024-09-02 11:16:57,565 [podnet.py] => Task 1, Epoch 35/300 (LR 0.09668) => LSC_loss 0.10, Spatial_loss 0.15, Flat_loss 0.30, Train_acc 97.91, Test_acc 59.57
2024-09-02 11:16:59,577 [podnet.py] => Task 1, Epoch 36/300 (LR 0.09649) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.56, Test_acc 62.62
2024-09-02 11:17:01,441 [podnet.py] => Task 1, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.78, Test_acc 65.02
2024-09-02 11:17:03,227 [podnet.py] => Task 1, Epoch 38/300 (LR 0.09609) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.87, Test_acc 67.14
2024-09-02 11:17:05,125 [podnet.py] => Task 1, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.82, Test_acc 67.05
2024-09-02 11:17:06,659 [podnet.py] => Task 1, Epoch 40/300 (LR 0.09568) => LSC_loss 0.06, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.80, Test_acc 64.45
2024-09-02 11:17:08,383 [podnet.py] => Task 1, Epoch 41/300 (LR 0.09546) => LSC_loss 0.06, Spatial_loss 0.11, Flat_loss 0.23, Train_acc 99.64, Test_acc 58.43
2024-09-02 11:17:10,585 [podnet.py] => Task 1, Epoch 42/300 (LR 0.09524) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.78, Test_acc 64.93
2024-09-02 11:17:12,692 [podnet.py] => Task 1, Epoch 43/300 (LR 0.09502) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.89, Test_acc 67.10
2024-09-02 11:17:14,691 [podnet.py] => Task 1, Epoch 44/300 (LR 0.09479) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.93, Test_acc 64.62
2024-09-02 11:17:16,867 [podnet.py] => Task 1, Epoch 45/300 (LR 0.09455) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.80, Test_acc 61.29
2024-09-02 11:17:18,852 [podnet.py] => Task 1, Epoch 46/300 (LR 0.09431) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.91, Test_acc 67.57
2024-09-02 11:17:20,765 [podnet.py] => Task 1, Epoch 47/300 (LR 0.09407) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.93, Test_acc 64.86
2024-09-02 11:17:22,581 [podnet.py] => Task 1, Epoch 48/300 (LR 0.09382) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 64.62
2024-09-02 11:17:24,260 [podnet.py] => Task 1, Epoch 49/300 (LR 0.09356) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.84, Test_acc 64.31
2024-09-02 11:17:26,270 [podnet.py] => Task 1, Epoch 50/300 (LR 0.09330) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.91, Test_acc 64.69
2024-09-02 11:17:28,248 [podnet.py] => Task 1, Epoch 51/300 (LR 0.09304) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.84, Test_acc 63.83
2024-09-02 11:17:30,237 [podnet.py] => Task 1, Epoch 52/300 (LR 0.09277) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 65.55
2024-09-02 11:17:32,271 [podnet.py] => Task 1, Epoch 53/300 (LR 0.09249) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 65.19
2024-09-02 11:17:34,406 [podnet.py] => Task 1, Epoch 54/300 (LR 0.09222) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.91, Test_acc 63.40
2024-09-02 11:17:36,485 [podnet.py] => Task 1, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.78, Test_acc 57.33
2024-09-02 11:17:38,400 [podnet.py] => Task 1, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.84, Test_acc 65.31
2024-09-02 11:17:40,348 [podnet.py] => Task 1, Epoch 57/300 (LR 0.09135) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.93, Test_acc 66.40
2024-09-02 11:17:42,215 [podnet.py] => Task 1, Epoch 58/300 (LR 0.09106) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.17, Train_acc 99.91, Test_acc 62.48
2024-09-02 11:17:44,251 [podnet.py] => Task 1, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.71, Test_acc 55.31
2024-09-02 11:17:46,264 [podnet.py] => Task 1, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.73, Test_acc 62.45
2024-09-02 11:17:48,345 [podnet.py] => Task 1, Epoch 61/300 (LR 0.09014) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.80, Test_acc 62.48
2024-09-02 11:17:50,329 [podnet.py] => Task 1, Epoch 62/300 (LR 0.08983) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.91, Test_acc 64.36
2024-09-02 11:17:52,406 [podnet.py] => Task 1, Epoch 63/300 (LR 0.08951) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.87, Test_acc 58.36
2024-09-02 11:17:54,573 [podnet.py] => Task 1, Epoch 64/300 (LR 0.08918) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.82, Test_acc 58.00
2024-09-02 11:17:55,763 [podnet.py] => Task 1, Epoch 65/300 (LR 0.08886) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.89, Test_acc 59.93
2024-09-02 11:17:57,567 [podnet.py] => Task 1, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.96, Test_acc 63.10
2024-09-02 11:17:59,506 [podnet.py] => Task 1, Epoch 67/300 (LR 0.08819) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.84, Test_acc 56.86
2024-09-02 11:18:01,542 [podnet.py] => Task 1, Epoch 68/300 (LR 0.08785) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.73, Test_acc 58.02
2024-09-02 11:18:03,457 [podnet.py] => Task 1, Epoch 69/300 (LR 0.08751) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.64, Test_acc 62.55
2024-09-02 11:18:05,253 [podnet.py] => Task 1, Epoch 70/300 (LR 0.08716) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.91, Test_acc 63.12
2024-09-02 11:18:06,614 [podnet.py] => Task 1, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.98, Test_acc 64.50
2024-09-02 11:18:08,360 [podnet.py] => Task 1, Epoch 72/300 (LR 0.08645) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.93, Test_acc 62.71
2024-09-02 11:18:09,791 [podnet.py] => Task 1, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.96, Test_acc 62.62
2024-09-02 11:18:11,690 [podnet.py] => Task 1, Epoch 74/300 (LR 0.08572) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.98, Test_acc 64.17
2024-09-02 11:18:13,447 [podnet.py] => Task 1, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.98, Test_acc 59.21
2024-09-02 11:18:15,248 [podnet.py] => Task 1, Epoch 76/300 (LR 0.08498) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.98, Test_acc 63.62
2024-09-02 11:18:17,248 [podnet.py] => Task 1, Epoch 77/300 (LR 0.08461) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 63.93
2024-09-02 11:18:19,281 [podnet.py] => Task 1, Epoch 78/300 (LR 0.08423) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.98, Test_acc 65.64
2024-09-02 11:18:21,230 [podnet.py] => Task 1, Epoch 79/300 (LR 0.08384) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 100.00, Test_acc 63.95
2024-09-02 11:18:23,200 [podnet.py] => Task 1, Epoch 80/300 (LR 0.08346) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.87, Test_acc 63.38
2024-09-02 11:18:24,969 [podnet.py] => Task 1, Epoch 81/300 (LR 0.08307) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.84, Test_acc 63.10
2024-09-02 11:18:26,904 [podnet.py] => Task 1, Epoch 82/300 (LR 0.08267) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.96, Test_acc 62.76
2024-09-02 11:18:28,969 [podnet.py] => Task 1, Epoch 83/300 (LR 0.08227) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.84, Test_acc 62.36
2024-09-02 11:18:31,171 [podnet.py] => Task 1, Epoch 84/300 (LR 0.08187) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.93, Test_acc 54.55
2024-09-02 11:18:33,040 [podnet.py] => Task 1, Epoch 85/300 (LR 0.08147) => LSC_loss 0.51, Spatial_loss 0.18, Flat_loss 0.46, Train_acc 87.73, Test_acc 32.86
2024-09-02 11:18:34,875 [podnet.py] => Task 1, Epoch 86/300 (LR 0.08106) => LSC_loss 0.45, Spatial_loss 0.20, Flat_loss 0.53, Train_acc 88.27, Test_acc 43.33
2024-09-02 11:18:36,698 [podnet.py] => Task 1, Epoch 87/300 (LR 0.08065) => LSC_loss 0.23, Spatial_loss 0.18, Flat_loss 0.42, Train_acc 93.84, Test_acc 44.88
2024-09-02 11:18:38,691 [podnet.py] => Task 1, Epoch 88/300 (LR 0.08023) => LSC_loss 0.20, Spatial_loss 0.17, Flat_loss 0.38, Train_acc 94.53, Test_acc 45.69
2024-09-02 11:18:40,378 [podnet.py] => Task 1, Epoch 89/300 (LR 0.07981) => LSC_loss 0.16, Spatial_loss 0.16, Flat_loss 0.34, Train_acc 95.89, Test_acc 56.00
2024-09-02 11:18:42,372 [podnet.py] => Task 1, Epoch 90/300 (LR 0.07939) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.29, Train_acc 98.13, Test_acc 60.52
2024-09-02 11:18:44,471 [podnet.py] => Task 1, Epoch 91/300 (LR 0.07896) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 99.07, Test_acc 57.48
2024-09-02 11:18:46,659 [podnet.py] => Task 1, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.25, Train_acc 99.71, Test_acc 63.36
2024-09-02 11:18:48,929 [podnet.py] => Task 1, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.22, Train_acc 99.82, Test_acc 64.07
2024-09-02 11:18:50,813 [podnet.py] => Task 1, Epoch 94/300 (LR 0.07767) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.82, Test_acc 64.24
2024-09-02 11:18:52,830 [podnet.py] => Task 1, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.84, Test_acc 65.24
2024-09-02 11:18:54,928 [podnet.py] => Task 1, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.84, Test_acc 63.83
2024-09-02 11:18:56,721 [podnet.py] => Task 1, Epoch 97/300 (LR 0.07635) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.96, Test_acc 66.07
2024-09-02 11:18:58,648 [podnet.py] => Task 1, Epoch 98/300 (LR 0.07590) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.84, Test_acc 64.14
2024-09-02 11:19:00,767 [podnet.py] => Task 1, Epoch 99/300 (LR 0.07545) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.84, Test_acc 68.00
2024-09-02 11:19:02,966 [podnet.py] => Task 1, Epoch 100/300 (LR 0.07500) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.89, Test_acc 63.57
2024-09-02 11:19:04,985 [podnet.py] => Task 1, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.87, Test_acc 63.19
2024-09-02 11:19:06,812 [podnet.py] => Task 1, Epoch 102/300 (LR 0.07409) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.91, Test_acc 63.19
2024-09-02 11:19:08,836 [podnet.py] => Task 1, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.78, Test_acc 64.19
2024-09-02 11:19:10,813 [podnet.py] => Task 1, Epoch 104/300 (LR 0.07316) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.93, Test_acc 64.69
2024-09-02 11:19:12,725 [podnet.py] => Task 1, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.93, Test_acc 62.43
2024-09-02 11:19:14,724 [podnet.py] => Task 1, Epoch 106/300 (LR 0.07223) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.98, Test_acc 64.05
2024-09-02 11:19:16,964 [podnet.py] => Task 1, Epoch 107/300 (LR 0.07176) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.87, Test_acc 66.07
2024-09-02 11:19:19,067 [podnet.py] => Task 1, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.91, Test_acc 63.29
2024-09-02 11:19:21,069 [podnet.py] => Task 1, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.91, Test_acc 67.52
2024-09-02 11:19:23,057 [podnet.py] => Task 1, Epoch 110/300 (LR 0.07034) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.96, Test_acc 63.26
2024-09-02 11:19:24,832 [podnet.py] => Task 1, Epoch 111/300 (LR 0.06986) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.93, Test_acc 63.95
2024-09-02 11:19:26,830 [podnet.py] => Task 1, Epoch 112/300 (LR 0.06938) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.98, Test_acc 63.02
2024-09-02 11:19:28,796 [podnet.py] => Task 1, Epoch 113/300 (LR 0.06889) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 100.00, Test_acc 67.55
2024-09-02 11:19:31,029 [podnet.py] => Task 1, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.81
2024-09-02 11:19:33,160 [podnet.py] => Task 1, Epoch 115/300 (LR 0.06792) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.38
2024-09-02 11:19:35,384 [podnet.py] => Task 1, Epoch 116/300 (LR 0.06743) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 63.29
2024-09-02 11:19:37,531 [podnet.py] => Task 1, Epoch 117/300 (LR 0.06694) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.98, Test_acc 62.71
2024-09-02 11:19:39,341 [podnet.py] => Task 1, Epoch 118/300 (LR 0.06644) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 63.05
2024-09-02 11:19:41,498 [podnet.py] => Task 1, Epoch 119/300 (LR 0.06595) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 64.43
2024-09-02 11:19:43,553 [podnet.py] => Task 1, Epoch 120/300 (LR 0.06545) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.13, Train_acc 100.00, Test_acc 64.12
2024-09-02 11:19:45,512 [podnet.py] => Task 1, Epoch 121/300 (LR 0.06495) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.13, Train_acc 99.96, Test_acc 66.24
2024-09-02 11:19:46,709 [podnet.py] => Task 1, Epoch 122/300 (LR 0.06445) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.98, Test_acc 64.69
2024-09-02 11:19:48,765 [podnet.py] => Task 1, Epoch 123/300 (LR 0.06395) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.13, Train_acc 99.98, Test_acc 67.83
2024-09-02 11:19:50,824 [podnet.py] => Task 1, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.06, Flat_loss 0.15, Train_acc 99.64, Test_acc 64.79
2024-09-02 11:19:52,775 [podnet.py] => Task 1, Epoch 125/300 (LR 0.06294) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.84, Test_acc 66.43
2024-09-02 11:19:54,701 [podnet.py] => Task 1, Epoch 126/300 (LR 0.06243) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 66.40
2024-09-02 11:19:56,613 [podnet.py] => Task 1, Epoch 127/300 (LR 0.06193) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.13, Train_acc 99.98, Test_acc 64.45
2024-09-02 11:19:58,289 [podnet.py] => Task 1, Epoch 128/300 (LR 0.06142) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 66.19
2024-09-02 11:20:00,319 [podnet.py] => Task 1, Epoch 129/300 (LR 0.06091) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 66.67
2024-09-02 11:20:02,358 [podnet.py] => Task 1, Epoch 130/300 (LR 0.06040) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 65.36
2024-09-02 11:20:04,137 [podnet.py] => Task 1, Epoch 131/300 (LR 0.05988) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 64.38
2024-09-02 11:20:05,919 [podnet.py] => Task 1, Epoch 132/300 (LR 0.05937) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.98, Test_acc 64.21
2024-09-02 11:20:07,741 [podnet.py] => Task 1, Epoch 133/300 (LR 0.05885) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.13, Train_acc 99.98, Test_acc 63.52
2024-09-02 11:20:09,769 [podnet.py] => Task 1, Epoch 134/300 (LR 0.05834) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 65.55
2024-09-02 11:20:11,954 [podnet.py] => Task 1, Epoch 135/300 (LR 0.05782) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 60.31
2024-09-02 11:20:14,057 [podnet.py] => Task 1, Epoch 136/300 (LR 0.05730) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 64.31
2024-09-02 11:20:15,924 [podnet.py] => Task 1, Epoch 137/300 (LR 0.05679) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.12, Train_acc 99.98, Test_acc 64.83
2024-09-02 11:20:17,937 [podnet.py] => Task 1, Epoch 138/300 (LR 0.05627) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.98, Test_acc 62.95
2024-09-02 11:20:19,315 [podnet.py] => Task 1, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.93, Test_acc 66.60
2024-09-02 11:20:21,395 [podnet.py] => Task 1, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.93, Test_acc 62.07
2024-09-02 11:20:22,837 [podnet.py] => Task 1, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.02
2024-09-02 11:20:24,772 [podnet.py] => Task 1, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.69
2024-09-02 11:20:26,608 [podnet.py] => Task 1, Epoch 143/300 (LR 0.05366) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 59.38
2024-09-02 11:20:28,610 [podnet.py] => Task 1, Epoch 144/300 (LR 0.05314) => LSC_loss 0.31, Spatial_loss 0.15, Flat_loss 0.34, Train_acc 92.62, Test_acc 32.76
2024-09-02 11:20:30,624 [podnet.py] => Task 1, Epoch 145/300 (LR 0.05262) => LSC_loss 0.45, Spatial_loss 0.20, Flat_loss 0.50, Train_acc 88.40, Test_acc 21.19
2024-09-02 11:20:32,641 [podnet.py] => Task 1, Epoch 146/300 (LR 0.05209) => LSC_loss 0.27, Spatial_loss 0.18, Flat_loss 0.43, Train_acc 92.73, Test_acc 46.55
2024-09-02 11:20:34,554 [podnet.py] => Task 1, Epoch 147/300 (LR 0.05157) => LSC_loss 0.15, Spatial_loss 0.16, Flat_loss 0.34, Train_acc 96.49, Test_acc 55.29
2024-09-02 11:20:36,577 [podnet.py] => Task 1, Epoch 148/300 (LR 0.05105) => LSC_loss 0.11, Spatial_loss 0.15, Flat_loss 0.32, Train_acc 97.67, Test_acc 57.64
2024-09-02 11:20:38,072 [podnet.py] => Task 1, Epoch 149/300 (LR 0.05052) => LSC_loss 0.10, Spatial_loss 0.14, Flat_loss 0.29, Train_acc 97.76, Test_acc 55.19
2024-09-02 11:20:40,009 [podnet.py] => Task 1, Epoch 150/300 (LR 0.05000) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.33, Test_acc 64.69
2024-09-02 11:20:41,939 [podnet.py] => Task 1, Epoch 151/300 (LR 0.04948) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.71, Test_acc 66.79
2024-09-02 11:20:43,743 [podnet.py] => Task 1, Epoch 152/300 (LR 0.04895) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.20, Train_acc 99.91, Test_acc 61.55
2024-09-02 11:20:45,896 [podnet.py] => Task 1, Epoch 153/300 (LR 0.04843) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.89, Test_acc 63.33
2024-09-02 11:20:48,066 [podnet.py] => Task 1, Epoch 154/300 (LR 0.04791) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.96, Test_acc 63.90
2024-09-02 11:20:50,096 [podnet.py] => Task 1, Epoch 155/300 (LR 0.04738) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.89, Test_acc 62.12
2024-09-02 11:20:52,147 [podnet.py] => Task 1, Epoch 156/300 (LR 0.04686) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.93, Test_acc 63.36
2024-09-02 11:20:54,229 [podnet.py] => Task 1, Epoch 157/300 (LR 0.04634) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.91, Test_acc 65.12
2024-09-02 11:20:56,246 [podnet.py] => Task 1, Epoch 158/300 (LR 0.04582) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.84, Test_acc 63.74
2024-09-02 11:20:58,316 [podnet.py] => Task 1, Epoch 159/300 (LR 0.04529) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.87, Test_acc 64.21
2024-09-02 11:21:00,447 [podnet.py] => Task 1, Epoch 160/300 (LR 0.04477) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.96, Test_acc 62.98
2024-09-02 11:21:02,383 [podnet.py] => Task 1, Epoch 161/300 (LR 0.04425) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 100.00, Test_acc 64.07
2024-09-02 11:21:04,236 [podnet.py] => Task 1, Epoch 162/300 (LR 0.04373) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 100.00, Test_acc 64.64
2024-09-02 11:21:05,968 [podnet.py] => Task 1, Epoch 163/300 (LR 0.04321) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 100.00, Test_acc 64.67
2024-09-02 11:21:07,957 [podnet.py] => Task 1, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.06, Flat_loss 0.15, Train_acc 99.93, Test_acc 61.86
2024-09-02 11:21:09,964 [podnet.py] => Task 1, Epoch 165/300 (LR 0.04218) => LSC_loss 0.17, Spatial_loss 0.15, Flat_loss 0.32, Train_acc 95.49, Test_acc 51.21
2024-09-02 11:21:12,190 [podnet.py] => Task 1, Epoch 166/300 (LR 0.04166) => LSC_loss 0.09, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 98.44, Test_acc 59.95
2024-09-02 11:21:14,468 [podnet.py] => Task 1, Epoch 167/300 (LR 0.04115) => LSC_loss 0.08, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.07, Test_acc 49.74
2024-09-02 11:21:16,569 [podnet.py] => Task 1, Epoch 168/300 (LR 0.04063) => LSC_loss 0.10, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 98.18, Test_acc 56.21
2024-09-02 11:21:18,146 [podnet.py] => Task 1, Epoch 169/300 (LR 0.04012) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.64, Test_acc 60.90
2024-09-02 11:21:19,889 [podnet.py] => Task 1, Epoch 170/300 (LR 0.03960) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.76, Test_acc 62.00
2024-09-02 11:21:22,257 [podnet.py] => Task 1, Epoch 171/300 (LR 0.03909) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 65.12
2024-09-02 11:21:24,629 [podnet.py] => Task 1, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.96, Test_acc 65.33
2024-09-02 11:21:26,609 [podnet.py] => Task 1, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.91, Test_acc 64.19
2024-09-02 11:21:28,457 [podnet.py] => Task 1, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.91, Test_acc 64.69
2024-09-02 11:21:30,322 [podnet.py] => Task 1, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 99.98, Test_acc 62.98
2024-09-02 11:21:32,358 [podnet.py] => Task 1, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.98, Test_acc 65.69
2024-09-02 11:21:34,377 [podnet.py] => Task 1, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 100.00, Test_acc 65.74
2024-09-02 11:21:36,423 [podnet.py] => Task 1, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.98, Test_acc 65.19
2024-09-02 11:21:38,472 [podnet.py] => Task 1, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.15, Train_acc 99.98, Test_acc 66.93
2024-09-02 11:21:40,628 [podnet.py] => Task 1, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 100.00, Test_acc 65.95
2024-09-02 11:21:42,647 [podnet.py] => Task 1, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.98, Test_acc 64.81
2024-09-02 11:21:44,635 [podnet.py] => Task 1, Epoch 182/300 (LR 0.03356) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.14, Train_acc 99.96, Test_acc 64.67
2024-09-02 11:21:46,663 [podnet.py] => Task 1, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.98, Test_acc 65.79
2024-09-02 11:21:48,729 [podnet.py] => Task 1, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 65.93
2024-09-02 11:21:50,774 [podnet.py] => Task 1, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 65.38
2024-09-02 11:21:52,982 [podnet.py] => Task 1, Epoch 186/300 (LR 0.03159) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.98, Test_acc 65.98
2024-09-02 11:21:54,987 [podnet.py] => Task 1, Epoch 187/300 (LR 0.03111) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.93, Test_acc 64.71
2024-09-02 11:21:56,260 [podnet.py] => Task 1, Epoch 188/300 (LR 0.03062) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 66.45
2024-09-02 11:21:58,172 [podnet.py] => Task 1, Epoch 189/300 (LR 0.03014) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 65.24
2024-09-02 11:22:00,482 [podnet.py] => Task 1, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 65.02
2024-09-02 11:22:02,618 [podnet.py] => Task 1, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.15, Train_acc 99.87, Test_acc 62.62
2024-09-02 11:22:04,640 [podnet.py] => Task 1, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.93, Test_acc 66.45
2024-09-02 11:22:06,641 [podnet.py] => Task 1, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 66.02
2024-09-02 11:22:08,075 [podnet.py] => Task 1, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.31
2024-09-02 11:22:10,024 [podnet.py] => Task 1, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 65.88
2024-09-02 11:22:12,228 [podnet.py] => Task 1, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 64.81
2024-09-02 11:22:14,218 [podnet.py] => Task 1, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 64.38
2024-09-02 11:22:16,144 [podnet.py] => Task 1, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 100.00, Test_acc 65.90
2024-09-02 11:22:18,047 [podnet.py] => Task 1, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.71
2024-09-02 11:22:20,183 [podnet.py] => Task 1, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.67
2024-09-02 11:22:22,406 [podnet.py] => Task 1, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.29
2024-09-02 11:22:24,171 [podnet.py] => Task 1, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.19
2024-09-02 11:22:26,149 [podnet.py] => Task 1, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.07
2024-09-02 11:22:28,257 [podnet.py] => Task 1, Epoch 204/300 (LR 0.02321) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.86
2024-09-02 11:22:30,199 [podnet.py] => Task 1, Epoch 205/300 (LR 0.02277) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 99.96, Test_acc 63.38
2024-09-02 11:22:32,227 [podnet.py] => Task 1, Epoch 206/300 (LR 0.02233) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.21
2024-09-02 11:22:34,011 [podnet.py] => Task 1, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.12
2024-09-02 11:22:36,112 [podnet.py] => Task 1, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.83
2024-09-02 11:22:38,057 [podnet.py] => Task 1, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.93
2024-09-02 11:22:40,052 [podnet.py] => Task 1, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.52
2024-09-02 11:22:42,073 [podnet.py] => Task 1, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 99.98, Test_acc 66.79
2024-09-02 11:22:44,168 [podnet.py] => Task 1, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.62
2024-09-02 11:22:46,098 [podnet.py] => Task 1, Epoch 213/300 (LR 0.01935) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.29
2024-09-02 11:22:47,919 [podnet.py] => Task 1, Epoch 214/300 (LR 0.01894) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 99.98, Test_acc 66.88
2024-09-02 11:22:49,946 [podnet.py] => Task 1, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 99.98, Test_acc 65.38
2024-09-02 11:22:51,967 [podnet.py] => Task 1, Epoch 216/300 (LR 0.01813) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.13, Train_acc 99.96, Test_acc 67.45
2024-09-02 11:22:54,014 [podnet.py] => Task 1, Epoch 217/300 (LR 0.01773) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.43
2024-09-02 11:22:56,049 [podnet.py] => Task 1, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.76
2024-09-02 11:22:58,133 [podnet.py] => Task 1, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.86
2024-09-02 11:22:59,653 [podnet.py] => Task 1, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.21
2024-09-02 11:23:01,715 [podnet.py] => Task 1, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 66.60
2024-09-02 11:23:03,702 [podnet.py] => Task 1, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.62
2024-09-02 11:23:05,110 [podnet.py] => Task 1, Epoch 223/300 (LR 0.01539) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.43
2024-09-02 11:23:07,060 [podnet.py] => Task 1, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.43
2024-09-02 11:23:09,115 [podnet.py] => Task 1, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.21
2024-09-02 11:23:10,797 [podnet.py] => Task 1, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.83
2024-09-02 11:23:12,739 [podnet.py] => Task 1, Epoch 227/300 (LR 0.01391) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.12
2024-09-02 11:23:14,731 [podnet.py] => Task 1, Epoch 228/300 (LR 0.01355) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.50
2024-09-02 11:23:16,137 [podnet.py] => Task 1, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.52
2024-09-02 11:23:18,222 [podnet.py] => Task 1, Epoch 230/300 (LR 0.01284) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.24
2024-09-02 11:23:19,906 [podnet.py] => Task 1, Epoch 231/300 (LR 0.01249) => LSC_loss 0.03, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.71
2024-09-02 11:23:21,818 [podnet.py] => Task 1, Epoch 232/300 (LR 0.01215) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.17
2024-09-02 11:23:23,236 [podnet.py] => Task 1, Epoch 233/300 (LR 0.01181) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.05
2024-09-02 11:23:25,171 [podnet.py] => Task 1, Epoch 234/300 (LR 0.01147) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.33
2024-09-02 11:23:27,079 [podnet.py] => Task 1, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.38
2024-09-02 11:23:29,098 [podnet.py] => Task 1, Epoch 236/300 (LR 0.01082) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.64
2024-09-02 11:23:30,924 [podnet.py] => Task 1, Epoch 237/300 (LR 0.01049) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.40
2024-09-02 11:23:32,617 [podnet.py] => Task 1, Epoch 238/300 (LR 0.01017) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.38
2024-09-02 11:23:34,645 [podnet.py] => Task 1, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.57
2024-09-02 11:23:36,697 [podnet.py] => Task 1, Epoch 240/300 (LR 0.00955) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.76
2024-09-02 11:23:38,938 [podnet.py] => Task 1, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.40
2024-09-02 11:23:40,971 [podnet.py] => Task 1, Epoch 242/300 (LR 0.00894) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.90
2024-09-02 11:23:43,108 [podnet.py] => Task 1, Epoch 243/300 (LR 0.00865) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.02
2024-09-02 11:23:45,047 [podnet.py] => Task 1, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.00
2024-09-02 11:23:47,118 [podnet.py] => Task 1, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.02
2024-09-02 11:23:48,977 [podnet.py] => Task 1, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.88
2024-09-02 11:23:51,049 [podnet.py] => Task 1, Epoch 247/300 (LR 0.00751) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.86
2024-09-02 11:23:52,969 [podnet.py] => Task 1, Epoch 248/300 (LR 0.00723) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.24
2024-09-02 11:23:54,903 [podnet.py] => Task 1, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.26
2024-09-02 11:23:56,867 [podnet.py] => Task 1, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.05
2024-09-02 11:23:58,904 [podnet.py] => Task 1, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.14
2024-09-02 11:24:01,099 [podnet.py] => Task 1, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.05
2024-09-02 11:24:02,999 [podnet.py] => Task 1, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.36
2024-09-02 11:24:04,892 [podnet.py] => Task 1, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 66.98
2024-09-02 11:24:06,566 [podnet.py] => Task 1, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.40
2024-09-02 11:24:08,485 [podnet.py] => Task 1, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.71
2024-09-02 11:24:10,407 [podnet.py] => Task 1, Epoch 257/300 (LR 0.00498) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.05
2024-09-02 11:24:12,449 [podnet.py] => Task 1, Epoch 258/300 (LR 0.00476) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.10
2024-09-02 11:24:14,346 [podnet.py] => Task 1, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 67.98
2024-09-02 11:24:16,481 [podnet.py] => Task 1, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.90
2024-09-02 11:24:18,495 [podnet.py] => Task 1, Epoch 261/300 (LR 0.00411) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.52
2024-09-02 11:24:20,511 [podnet.py] => Task 1, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.00
2024-09-02 11:24:22,693 [podnet.py] => Task 1, Epoch 263/300 (LR 0.00371) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.19
2024-09-02 11:24:24,527 [podnet.py] => Task 1, Epoch 264/300 (LR 0.00351) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.69
2024-09-02 11:24:26,576 [podnet.py] => Task 1, Epoch 265/300 (LR 0.00332) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.55
2024-09-02 11:24:28,460 [podnet.py] => Task 1, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.05
2024-09-02 11:24:30,387 [podnet.py] => Task 1, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.67
2024-09-02 11:24:32,140 [podnet.py] => Task 1, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.10
2024-09-02 11:24:33,879 [podnet.py] => Task 1, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.43
2024-09-02 11:24:35,663 [podnet.py] => Task 1, Epoch 270/300 (LR 0.00245) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.26
2024-09-02 11:24:37,593 [podnet.py] => Task 1, Epoch 271/300 (LR 0.00229) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.88
2024-09-02 11:24:39,543 [podnet.py] => Task 1, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.02
2024-09-02 11:24:41,385 [podnet.py] => Task 1, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.64
2024-09-02 11:24:42,639 [podnet.py] => Task 1, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.95
2024-09-02 11:24:44,581 [podnet.py] => Task 1, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.07
2024-09-02 11:24:46,539 [podnet.py] => Task 1, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.29
2024-09-02 11:24:48,448 [podnet.py] => Task 1, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.40
2024-09-02 11:24:50,526 [podnet.py] => Task 1, Epoch 278/300 (LR 0.00132) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.19
2024-09-02 11:24:52,142 [podnet.py] => Task 1, Epoch 279/300 (LR 0.00120) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.31
2024-09-02 11:24:54,119 [podnet.py] => Task 1, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.38
2024-09-02 11:24:56,145 [podnet.py] => Task 1, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.90
2024-09-02 11:24:58,166 [podnet.py] => Task 1, Epoch 282/300 (LR 0.00089) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.50
2024-09-02 11:25:00,165 [podnet.py] => Task 1, Epoch 283/300 (LR 0.00079) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.55
2024-09-02 11:25:02,295 [podnet.py] => Task 1, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.45
2024-09-02 11:25:03,974 [podnet.py] => Task 1, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.98
2024-09-02 11:25:05,691 [podnet.py] => Task 1, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.29
2024-09-02 11:25:07,660 [podnet.py] => Task 1, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.14
2024-09-02 11:25:09,535 [podnet.py] => Task 1, Epoch 288/300 (LR 0.00039) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.93
2024-09-02 11:25:11,429 [podnet.py] => Task 1, Epoch 289/300 (LR 0.00033) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.07
2024-09-02 11:25:13,142 [podnet.py] => Task 1, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 67.86
2024-09-02 11:25:15,217 [podnet.py] => Task 1, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.02
2024-09-02 11:25:17,246 [podnet.py] => Task 1, Epoch 292/300 (LR 0.00018) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.12
2024-09-02 11:25:19,342 [podnet.py] => Task 1, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.19
2024-09-02 11:25:21,447 [podnet.py] => Task 1, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.38
2024-09-02 11:25:23,581 [podnet.py] => Task 1, Epoch 295/300 (LR 0.00007) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.36
2024-09-02 11:25:25,573 [podnet.py] => Task 1, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.24
2024-09-02 11:25:27,760 [podnet.py] => Task 1, Epoch 297/300 (LR 0.00002) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.24
2024-09-02 11:25:29,734 [podnet.py] => Task 1, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.12
2024-09-02 11:25:31,863 [podnet.py] => Task 1, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.17
2024-09-02 11:25:33,859 [podnet.py] => Task 1, Epoch 300/300 (LR 0.00000) => LSC_loss 0.03, Spatial_loss 0.03, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.36
2024-09-02 11:25:33,860 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 11:25:33,860 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 11:25:34,887 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 11:25:36,804 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 11:25:37,869 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 11:25:40,422 [podnet.py] => Exemplar size: 497
2024-09-02 11:25:40,422 [trainer.py] => CNN: {'total': 68.36, '00-04': 56.97, '05-06': 96.83, 'old': 56.97, 'new': 96.83}
2024-09-02 11:25:40,422 [trainer.py] => NME: {'total': 73.69, '00-04': 73.27, '05-06': 74.75, 'old': 73.27, 'new': 74.75}
2024-09-02 11:25:40,422 [trainer.py] => CNN top1 curve: [88.9, 68.36]
2024-09-02 11:25:40,422 [trainer.py] => CNN top5 curve: [100.0, 97.1]
2024-09-02 11:25:40,422 [trainer.py] => NME top1 curve: [88.9, 73.69]
2024-09-02 11:25:40,422 [trainer.py] => NME top5 curve: [100.0, 97.17]

2024-09-02 11:25:40,422 [trainer.py] => Average Accuracy (CNN): 78.63
2024-09-02 11:25:40,422 [trainer.py] => Average Accuracy (NME): 81.295
2024-09-02 11:25:40,423 [trainer.py] => All params: 3879745
2024-09-02 11:25:40,423 [trainer.py] => Trainable params: 3879745
2024-09-02 11:25:40,424 [podnet.py] => Learning on 7-9
2024-09-02 11:25:40,444 [podnet.py] => Adaptive factor: 2.1213203435596424
2024-09-02 11:25:42,912 [podnet.py] => Task 2, Epoch 1/300 (LR 0.10000) => LSC_loss 1.55, Spatial_loss 0.26, Flat_loss 1.02, Train_acc 76.52, Test_acc 11.30
2024-09-02 11:25:45,040 [podnet.py] => Task 2, Epoch 2/300 (LR 0.09999) => LSC_loss 0.74, Spatial_loss 0.23, Flat_loss 0.80, Train_acc 86.52, Test_acc 28.24
2024-09-02 11:25:47,179 [podnet.py] => Task 2, Epoch 3/300 (LR 0.09998) => LSC_loss 0.63, Spatial_loss 0.22, Flat_loss 0.68, Train_acc 88.08, Test_acc 28.37
2024-09-02 11:25:49,357 [podnet.py] => Task 2, Epoch 4/300 (LR 0.09996) => LSC_loss 0.58, Spatial_loss 0.20, Flat_loss 0.62, Train_acc 88.64, Test_acc 35.56
2024-09-02 11:25:51,483 [podnet.py] => Task 2, Epoch 5/300 (LR 0.09993) => LSC_loss 0.51, Spatial_loss 0.20, Flat_loss 0.58, Train_acc 89.82, Test_acc 25.52
2024-09-02 11:25:53,703 [podnet.py] => Task 2, Epoch 6/300 (LR 0.09990) => LSC_loss 0.49, Spatial_loss 0.20, Flat_loss 0.55, Train_acc 89.88, Test_acc 28.06
2024-09-02 11:25:55,748 [podnet.py] => Task 2, Epoch 7/300 (LR 0.09987) => LSC_loss 0.44, Spatial_loss 0.19, Flat_loss 0.53, Train_acc 90.97, Test_acc 44.33
2024-09-02 11:25:57,771 [podnet.py] => Task 2, Epoch 8/300 (LR 0.09982) => LSC_loss 0.36, Spatial_loss 0.18, Flat_loss 0.49, Train_acc 92.08, Test_acc 39.87
2024-09-02 11:25:59,866 [podnet.py] => Task 2, Epoch 9/300 (LR 0.09978) => LSC_loss 0.32, Spatial_loss 0.18, Flat_loss 0.48, Train_acc 93.22, Test_acc 45.39
2024-09-02 11:26:02,154 [podnet.py] => Task 2, Epoch 10/300 (LR 0.09973) => LSC_loss 0.26, Spatial_loss 0.17, Flat_loss 0.46, Train_acc 94.55, Test_acc 44.35
2024-09-02 11:26:04,332 [podnet.py] => Task 2, Epoch 11/300 (LR 0.09967) => LSC_loss 0.24, Spatial_loss 0.17, Flat_loss 0.45, Train_acc 95.31, Test_acc 39.02
2024-09-02 11:26:06,460 [podnet.py] => Task 2, Epoch 12/300 (LR 0.09961) => LSC_loss 0.40, Spatial_loss 0.19, Flat_loss 0.51, Train_acc 91.39, Test_acc 40.85
2024-09-02 11:26:08,542 [podnet.py] => Task 2, Epoch 13/300 (LR 0.09954) => LSC_loss 0.32, Spatial_loss 0.19, Flat_loss 0.47, Train_acc 92.84, Test_acc 41.69
2024-09-02 11:26:10,534 [podnet.py] => Task 2, Epoch 14/300 (LR 0.09946) => LSC_loss 0.22, Spatial_loss 0.17, Flat_loss 0.44, Train_acc 95.69, Test_acc 53.00
2024-09-02 11:26:12,398 [podnet.py] => Task 2, Epoch 15/300 (LR 0.09938) => LSC_loss 0.22, Spatial_loss 0.17, Flat_loss 0.44, Train_acc 95.53, Test_acc 35.22
2024-09-02 11:26:14,207 [podnet.py] => Task 2, Epoch 16/300 (LR 0.09930) => LSC_loss 0.26, Spatial_loss 0.17, Flat_loss 0.45, Train_acc 94.29, Test_acc 49.00
2024-09-02 11:26:16,331 [podnet.py] => Task 2, Epoch 17/300 (LR 0.09921) => LSC_loss 0.17, Spatial_loss 0.17, Flat_loss 0.42, Train_acc 96.93, Test_acc 49.48
2024-09-02 11:26:18,381 [podnet.py] => Task 2, Epoch 18/300 (LR 0.09911) => LSC_loss 0.13, Spatial_loss 0.16, Flat_loss 0.40, Train_acc 97.87, Test_acc 51.07
2024-09-02 11:26:20,617 [podnet.py] => Task 2, Epoch 19/300 (LR 0.09901) => LSC_loss 0.11, Spatial_loss 0.16, Flat_loss 0.38, Train_acc 98.69, Test_acc 52.41
2024-09-02 11:26:22,829 [podnet.py] => Task 2, Epoch 20/300 (LR 0.09891) => LSC_loss 0.11, Spatial_loss 0.15, Flat_loss 0.37, Train_acc 99.27, Test_acc 55.33
2024-09-02 11:26:24,913 [podnet.py] => Task 2, Epoch 21/300 (LR 0.09880) => LSC_loss 0.22, Spatial_loss 0.17, Flat_loss 0.43, Train_acc 95.26, Test_acc 42.69
2024-09-02 11:26:26,873 [podnet.py] => Task 2, Epoch 22/300 (LR 0.09868) => LSC_loss 0.13, Spatial_loss 0.16, Flat_loss 0.40, Train_acc 97.64, Test_acc 51.74
2024-09-02 11:26:28,828 [podnet.py] => Task 2, Epoch 23/300 (LR 0.09856) => LSC_loss 0.12, Spatial_loss 0.16, Flat_loss 0.39, Train_acc 97.87, Test_acc 49.98
2024-09-02 11:26:30,899 [podnet.py] => Task 2, Epoch 24/300 (LR 0.09843) => LSC_loss 0.08, Spatial_loss 0.15, Flat_loss 0.36, Train_acc 99.36, Test_acc 53.41
2024-09-02 11:26:33,001 [podnet.py] => Task 2, Epoch 25/300 (LR 0.09830) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.36, Train_acc 99.04, Test_acc 54.41
2024-09-02 11:26:34,719 [podnet.py] => Task 2, Epoch 26/300 (LR 0.09816) => LSC_loss 0.06, Spatial_loss 0.14, Flat_loss 0.34, Train_acc 99.89, Test_acc 56.04
2024-09-02 11:26:36,515 [podnet.py] => Task 2, Epoch 27/300 (LR 0.09801) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.33, Train_acc 99.93, Test_acc 55.98
2024-09-02 11:26:38,750 [podnet.py] => Task 2, Epoch 28/300 (LR 0.09787) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.32, Train_acc 99.82, Test_acc 56.96
2024-09-02 11:26:39,986 [podnet.py] => Task 2, Epoch 29/300 (LR 0.09771) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 100.00, Test_acc 56.22
2024-09-02 11:26:41,896 [podnet.py] => Task 2, Epoch 30/300 (LR 0.09755) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 99.91, Test_acc 55.46
2024-09-02 11:26:43,766 [podnet.py] => Task 2, Epoch 31/300 (LR 0.09739) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.91, Test_acc 55.76
2024-09-02 11:26:45,968 [podnet.py] => Task 2, Epoch 32/300 (LR 0.09722) => LSC_loss 0.07, Spatial_loss 0.13, Flat_loss 0.32, Train_acc 99.64, Test_acc 56.81
2024-09-02 11:26:47,923 [podnet.py] => Task 2, Epoch 33/300 (LR 0.09704) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 99.87, Test_acc 55.67
2024-09-02 11:26:50,012 [podnet.py] => Task 2, Epoch 34/300 (LR 0.09686) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.30, Train_acc 99.96, Test_acc 54.35
2024-09-02 11:26:52,160 [podnet.py] => Task 2, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.80, Test_acc 55.57
2024-09-02 11:26:54,237 [podnet.py] => Task 2, Epoch 36/300 (LR 0.09649) => LSC_loss 0.07, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 99.51, Test_acc 54.30
2024-09-02 11:26:56,175 [podnet.py] => Task 2, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.84, Test_acc 56.52
2024-09-02 11:26:58,312 [podnet.py] => Task 2, Epoch 38/300 (LR 0.09609) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.28, Train_acc 99.96, Test_acc 54.61
2024-09-02 11:27:00,386 [podnet.py] => Task 2, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.28, Train_acc 99.96, Test_acc 55.04
2024-09-02 11:27:02,656 [podnet.py] => Task 2, Epoch 40/300 (LR 0.09568) => LSC_loss 0.07, Spatial_loss 0.11, Flat_loss 0.30, Train_acc 99.44, Test_acc 50.91
2024-09-02 11:27:04,556 [podnet.py] => Task 2, Epoch 41/300 (LR 0.09546) => LSC_loss 0.08, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 99.02, Test_acc 49.61
2024-09-02 11:27:06,338 [podnet.py] => Task 2, Epoch 42/300 (LR 0.09524) => LSC_loss 0.08, Spatial_loss 0.13, Flat_loss 0.32, Train_acc 99.04, Test_acc 31.46
2024-09-02 11:27:08,426 [podnet.py] => Task 2, Epoch 43/300 (LR 0.09502) => LSC_loss 0.62, Spatial_loss 0.20, Flat_loss 0.53, Train_acc 87.95, Test_acc 18.44
2024-09-02 11:27:09,694 [podnet.py] => Task 2, Epoch 44/300 (LR 0.09479) => LSC_loss 0.39, Spatial_loss 0.19, Flat_loss 0.46, Train_acc 91.71, Test_acc 37.67
2024-09-02 11:27:11,539 [podnet.py] => Task 2, Epoch 45/300 (LR 0.09455) => LSC_loss 0.22, Spatial_loss 0.17, Flat_loss 0.41, Train_acc 95.24, Test_acc 40.69
2024-09-02 11:27:13,869 [podnet.py] => Task 2, Epoch 46/300 (LR 0.09431) => LSC_loss 0.26, Spatial_loss 0.18, Flat_loss 0.43, Train_acc 94.49, Test_acc 43.46
2024-09-02 11:27:15,236 [podnet.py] => Task 2, Epoch 47/300 (LR 0.09407) => LSC_loss 0.20, Spatial_loss 0.17, Flat_loss 0.41, Train_acc 95.95, Test_acc 48.30
2024-09-02 11:27:17,521 [podnet.py] => Task 2, Epoch 48/300 (LR 0.09382) => LSC_loss 0.14, Spatial_loss 0.16, Flat_loss 0.38, Train_acc 97.55, Test_acc 53.80
2024-09-02 11:27:19,612 [podnet.py] => Task 2, Epoch 49/300 (LR 0.09356) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.35, Train_acc 98.98, Test_acc 54.93
2024-09-02 11:27:21,745 [podnet.py] => Task 2, Epoch 50/300 (LR 0.09330) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.33, Train_acc 99.58, Test_acc 57.17
2024-09-02 11:27:23,876 [podnet.py] => Task 2, Epoch 51/300 (LR 0.09304) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.32, Train_acc 99.87, Test_acc 55.65
2024-09-02 11:27:25,965 [podnet.py] => Task 2, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.98, Test_acc 58.17
2024-09-02 11:27:28,035 [podnet.py] => Task 2, Epoch 53/300 (LR 0.09249) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.98, Test_acc 55.02
2024-09-02 11:27:29,975 [podnet.py] => Task 2, Epoch 54/300 (LR 0.09222) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.93, Test_acc 57.46
2024-09-02 11:27:31,831 [podnet.py] => Task 2, Epoch 55/300 (LR 0.09193) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.96, Test_acc 56.52
2024-09-02 11:27:34,073 [podnet.py] => Task 2, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 100.00, Test_acc 58.02
2024-09-02 11:27:36,034 [podnet.py] => Task 2, Epoch 57/300 (LR 0.09135) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 99.96, Test_acc 57.07
2024-09-02 11:27:37,999 [podnet.py] => Task 2, Epoch 58/300 (LR 0.09106) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.27, Train_acc 99.98, Test_acc 58.19
2024-09-02 11:27:39,725 [podnet.py] => Task 2, Epoch 59/300 (LR 0.09076) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 99.98, Test_acc 58.00
2024-09-02 11:27:41,907 [podnet.py] => Task 2, Epoch 60/300 (LR 0.09045) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 100.00, Test_acc 59.74
2024-09-02 11:27:43,993 [podnet.py] => Task 2, Epoch 61/300 (LR 0.09014) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.26, Train_acc 100.00, Test_acc 57.63
2024-09-02 11:27:45,705 [podnet.py] => Task 2, Epoch 62/300 (LR 0.08983) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 100.00, Test_acc 57.50
2024-09-02 11:27:47,831 [podnet.py] => Task 2, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.96, Test_acc 57.30
2024-09-02 11:27:49,817 [podnet.py] => Task 2, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.96, Test_acc 57.31
2024-09-02 11:27:51,893 [podnet.py] => Task 2, Epoch 65/300 (LR 0.08886) => LSC_loss 0.06, Spatial_loss 0.10, Flat_loss 0.27, Train_acc 99.84, Test_acc 55.96
2024-09-02 11:27:53,946 [podnet.py] => Task 2, Epoch 66/300 (LR 0.08853) => LSC_loss 0.06, Spatial_loss 0.11, Flat_loss 0.28, Train_acc 99.69, Test_acc 55.52
2024-09-02 11:27:55,800 [podnet.py] => Task 2, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 99.93, Test_acc 56.93
2024-09-02 11:27:57,964 [podnet.py] => Task 2, Epoch 68/300 (LR 0.08785) => LSC_loss 0.06, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.91, Test_acc 49.48
2024-09-02 11:28:00,201 [podnet.py] => Task 2, Epoch 69/300 (LR 0.08751) => LSC_loss 0.40, Spatial_loss 0.18, Flat_loss 0.44, Train_acc 91.39, Test_acc 22.87
2024-09-02 11:28:02,216 [podnet.py] => Task 2, Epoch 70/300 (LR 0.08716) => LSC_loss 0.42, Spatial_loss 0.19, Flat_loss 0.46, Train_acc 90.91, Test_acc 33.94
2024-09-02 11:28:04,178 [podnet.py] => Task 2, Epoch 71/300 (LR 0.08680) => LSC_loss 0.24, Spatial_loss 0.17, Flat_loss 0.41, Train_acc 94.77, Test_acc 42.70
2024-09-02 11:28:06,292 [podnet.py] => Task 2, Epoch 72/300 (LR 0.08645) => LSC_loss 0.14, Spatial_loss 0.16, Flat_loss 0.38, Train_acc 97.02, Test_acc 52.63
2024-09-02 11:28:08,275 [podnet.py] => Task 2, Epoch 73/300 (LR 0.08609) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.34, Train_acc 98.91, Test_acc 52.44
2024-09-02 11:28:09,851 [podnet.py] => Task 2, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.31, Train_acc 99.80, Test_acc 54.87
2024-09-02 11:28:11,810 [podnet.py] => Task 2, Epoch 75/300 (LR 0.08536) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.89, Test_acc 58.31
2024-09-02 11:28:13,826 [podnet.py] => Task 2, Epoch 76/300 (LR 0.08498) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.28, Train_acc 99.89, Test_acc 57.89
2024-09-02 11:28:15,890 [podnet.py] => Task 2, Epoch 77/300 (LR 0.08461) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 99.91, Test_acc 56.24
2024-09-02 11:28:17,851 [podnet.py] => Task 2, Epoch 78/300 (LR 0.08423) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 100.00, Test_acc 58.15
2024-09-02 11:28:19,799 [podnet.py] => Task 2, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 100.00, Test_acc 56.43
2024-09-02 11:28:21,866 [podnet.py] => Task 2, Epoch 80/300 (LR 0.08346) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.27, Train_acc 99.98, Test_acc 58.07
2024-09-02 11:28:24,145 [podnet.py] => Task 2, Epoch 81/300 (LR 0.08307) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 99.98, Test_acc 58.04
2024-09-02 11:28:26,021 [podnet.py] => Task 2, Epoch 82/300 (LR 0.08267) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 100.00, Test_acc 58.30
2024-09-02 11:28:27,962 [podnet.py] => Task 2, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.96, Test_acc 56.61
2024-09-02 11:28:30,170 [podnet.py] => Task 2, Epoch 84/300 (LR 0.08187) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 100.00, Test_acc 59.30
2024-09-02 11:28:32,058 [podnet.py] => Task 2, Epoch 85/300 (LR 0.08147) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.46
2024-09-02 11:28:34,413 [podnet.py] => Task 2, Epoch 86/300 (LR 0.08106) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.98, Test_acc 56.22
2024-09-02 11:28:36,587 [podnet.py] => Task 2, Epoch 87/300 (LR 0.08065) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.26, Train_acc 99.87, Test_acc 56.30
2024-09-02 11:28:38,818 [podnet.py] => Task 2, Epoch 88/300 (LR 0.08023) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.98, Test_acc 59.28
2024-09-02 11:28:40,910 [podnet.py] => Task 2, Epoch 89/300 (LR 0.07981) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.24, Train_acc 99.93, Test_acc 59.89
2024-09-02 11:28:43,094 [podnet.py] => Task 2, Epoch 90/300 (LR 0.07939) => LSC_loss 0.06, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.49, Test_acc 56.80
2024-09-02 11:28:44,413 [podnet.py] => Task 2, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.98, Test_acc 57.78
2024-09-02 11:28:46,629 [podnet.py] => Task 2, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.41
2024-09-02 11:28:48,846 [podnet.py] => Task 2, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 99.98, Test_acc 50.63
2024-09-02 11:28:50,789 [podnet.py] => Task 2, Epoch 94/300 (LR 0.07767) => LSC_loss 0.11, Spatial_loss 0.12, Flat_loss 0.31, Train_acc 98.49, Test_acc 37.20
2024-09-02 11:28:52,519 [podnet.py] => Task 2, Epoch 95/300 (LR 0.07723) => LSC_loss 0.45, Spatial_loss 0.19, Flat_loss 0.47, Train_acc 91.22, Test_acc 21.54
2024-09-02 11:28:54,772 [podnet.py] => Task 2, Epoch 96/300 (LR 0.07679) => LSC_loss 0.31, Spatial_loss 0.17, Flat_loss 0.43, Train_acc 93.55, Test_acc 32.06
2024-09-02 11:28:56,738 [podnet.py] => Task 2, Epoch 97/300 (LR 0.07635) => LSC_loss 0.41, Spatial_loss 0.19, Flat_loss 0.48, Train_acc 91.15, Test_acc 47.44
2024-09-02 11:28:58,691 [podnet.py] => Task 2, Epoch 98/300 (LR 0.07590) => LSC_loss 0.19, Spatial_loss 0.16, Flat_loss 0.39, Train_acc 96.42, Test_acc 55.83
2024-09-02 11:29:00,585 [podnet.py] => Task 2, Epoch 99/300 (LR 0.07545) => LSC_loss 0.15, Spatial_loss 0.16, Flat_loss 0.37, Train_acc 97.44, Test_acc 44.54
2024-09-02 11:29:02,645 [podnet.py] => Task 2, Epoch 100/300 (LR 0.07500) => LSC_loss 0.16, Spatial_loss 0.16, Flat_loss 0.37, Train_acc 96.46, Test_acc 48.31
2024-09-02 11:29:04,827 [podnet.py] => Task 2, Epoch 101/300 (LR 0.07455) => LSC_loss 0.16, Spatial_loss 0.16, Flat_loss 0.37, Train_acc 97.09, Test_acc 42.67
2024-09-02 11:29:06,807 [podnet.py] => Task 2, Epoch 102/300 (LR 0.07409) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.33, Train_acc 99.24, Test_acc 57.52
2024-09-02 11:29:08,793 [podnet.py] => Task 2, Epoch 103/300 (LR 0.07363) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.31, Train_acc 99.73, Test_acc 57.37
2024-09-02 11:29:10,782 [podnet.py] => Task 2, Epoch 104/300 (LR 0.07316) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.91, Test_acc 58.17
2024-09-02 11:29:13,007 [podnet.py] => Task 2, Epoch 105/300 (LR 0.07270) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.93, Test_acc 57.56
2024-09-02 11:29:15,261 [podnet.py] => Task 2, Epoch 106/300 (LR 0.07223) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 99.93, Test_acc 57.56
2024-09-02 11:29:17,502 [podnet.py] => Task 2, Epoch 107/300 (LR 0.07176) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.30, Train_acc 99.73, Test_acc 56.44
2024-09-02 11:29:19,715 [podnet.py] => Task 2, Epoch 108/300 (LR 0.07129) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 99.91, Test_acc 57.39
2024-09-02 11:29:22,034 [podnet.py] => Task 2, Epoch 109/300 (LR 0.07081) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 100.00, Test_acc 57.78
2024-09-02 11:29:23,840 [podnet.py] => Task 2, Epoch 110/300 (LR 0.07034) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 100.00, Test_acc 56.87
2024-09-02 11:29:25,985 [podnet.py] => Task 2, Epoch 111/300 (LR 0.06986) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 100.00, Test_acc 57.52
2024-09-02 11:29:28,104 [podnet.py] => Task 2, Epoch 112/300 (LR 0.06938) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.26, Train_acc 99.96, Test_acc 56.59
2024-09-02 11:29:30,192 [podnet.py] => Task 2, Epoch 113/300 (LR 0.06889) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.98, Test_acc 57.20
2024-09-02 11:29:32,356 [podnet.py] => Task 2, Epoch 114/300 (LR 0.06841) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 100.00, Test_acc 57.96
2024-09-02 11:29:34,616 [podnet.py] => Task 2, Epoch 115/300 (LR 0.06792) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.25, Train_acc 99.96, Test_acc 58.02
2024-09-02 11:29:36,876 [podnet.py] => Task 2, Epoch 116/300 (LR 0.06743) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.93
2024-09-02 11:29:39,050 [podnet.py] => Task 2, Epoch 117/300 (LR 0.06694) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 99.96, Test_acc 57.30
2024-09-02 11:29:41,266 [podnet.py] => Task 2, Epoch 118/300 (LR 0.06644) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.81
2024-09-02 11:29:43,532 [podnet.py] => Task 2, Epoch 119/300 (LR 0.06595) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.33
2024-09-02 11:29:45,700 [podnet.py] => Task 2, Epoch 120/300 (LR 0.06545) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.23, Train_acc 99.98, Test_acc 57.69
2024-09-02 11:29:47,966 [podnet.py] => Task 2, Epoch 121/300 (LR 0.06495) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.39
2024-09-02 11:29:50,233 [podnet.py] => Task 2, Epoch 122/300 (LR 0.06445) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 99.96, Test_acc 55.98
2024-09-02 11:29:52,313 [podnet.py] => Task 2, Epoch 123/300 (LR 0.06395) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 99.98, Test_acc 57.52
2024-09-02 11:29:54,630 [podnet.py] => Task 2, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.23, Train_acc 100.00, Test_acc 56.30
2024-09-02 11:29:56,906 [podnet.py] => Task 2, Epoch 125/300 (LR 0.06294) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.23, Train_acc 100.00, Test_acc 57.43
2024-09-02 11:29:59,233 [podnet.py] => Task 2, Epoch 126/300 (LR 0.06243) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 100.00, Test_acc 56.44
2024-09-02 11:30:01,510 [podnet.py] => Task 2, Epoch 127/300 (LR 0.06193) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.33
2024-09-02 11:30:03,599 [podnet.py] => Task 2, Epoch 128/300 (LR 0.06142) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 99.98, Test_acc 56.85
2024-09-02 11:30:05,417 [podnet.py] => Task 2, Epoch 129/300 (LR 0.06091) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.43
2024-09-02 11:30:07,614 [podnet.py] => Task 2, Epoch 130/300 (LR 0.06040) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.85
2024-09-02 11:30:09,777 [podnet.py] => Task 2, Epoch 131/300 (LR 0.05988) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 99.98, Test_acc 56.31
2024-09-02 11:30:11,868 [podnet.py] => Task 2, Epoch 132/300 (LR 0.05937) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 100.00, Test_acc 56.48
2024-09-02 11:30:14,068 [podnet.py] => Task 2, Epoch 133/300 (LR 0.05885) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 100.00, Test_acc 56.80
2024-09-02 11:30:16,135 [podnet.py] => Task 2, Epoch 134/300 (LR 0.05834) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 56.63
2024-09-02 11:30:18,347 [podnet.py] => Task 2, Epoch 135/300 (LR 0.05782) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.59
2024-09-02 11:30:20,476 [podnet.py] => Task 2, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.23, Train_acc 99.93, Test_acc 54.28
2024-09-02 11:30:22,750 [podnet.py] => Task 2, Epoch 137/300 (LR 0.05679) => LSC_loss 0.05, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 99.98, Test_acc 56.89
2024-09-02 11:30:24,927 [podnet.py] => Task 2, Epoch 138/300 (LR 0.05627) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.28
2024-09-02 11:30:27,132 [podnet.py] => Task 2, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.22
2024-09-02 11:30:29,122 [podnet.py] => Task 2, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 57.06
2024-09-02 11:30:31,369 [podnet.py] => Task 2, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 99.98, Test_acc 57.91
2024-09-02 11:30:33,660 [podnet.py] => Task 2, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.15
2024-09-02 11:30:35,759 [podnet.py] => Task 2, Epoch 143/300 (LR 0.05366) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 100.00, Test_acc 55.91
2024-09-02 11:30:38,087 [podnet.py] => Task 2, Epoch 144/300 (LR 0.05314) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.04
2024-09-02 11:30:40,097 [podnet.py] => Task 2, Epoch 145/300 (LR 0.05262) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.70
2024-09-02 11:30:42,321 [podnet.py] => Task 2, Epoch 146/300 (LR 0.05209) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 57.11
2024-09-02 11:30:44,569 [podnet.py] => Task 2, Epoch 147/300 (LR 0.05157) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 99.98, Test_acc 58.04
2024-09-02 11:30:46,896 [podnet.py] => Task 2, Epoch 148/300 (LR 0.05105) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 56.24
2024-09-02 11:30:49,112 [podnet.py] => Task 2, Epoch 149/300 (LR 0.05052) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 57.91
2024-09-02 11:30:51,371 [podnet.py] => Task 2, Epoch 150/300 (LR 0.05000) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 57.54
2024-09-02 11:30:53,570 [podnet.py] => Task 2, Epoch 151/300 (LR 0.04948) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.48
2024-09-02 11:30:55,652 [podnet.py] => Task 2, Epoch 152/300 (LR 0.04895) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 56.15
2024-09-02 11:30:57,921 [podnet.py] => Task 2, Epoch 153/300 (LR 0.04843) => LSC_loss 0.05, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 99.98, Test_acc 54.70
2024-09-02 11:31:00,057 [podnet.py] => Task 2, Epoch 154/300 (LR 0.04791) => LSC_loss 0.08, Spatial_loss 0.11, Flat_loss 0.28, Train_acc 99.22, Test_acc 42.46
2024-09-02 11:31:01,855 [podnet.py] => Task 2, Epoch 155/300 (LR 0.04738) => LSC_loss 0.21, Spatial_loss 0.14, Flat_loss 0.35, Train_acc 95.46, Test_acc 43.19
2024-09-02 11:31:04,108 [podnet.py] => Task 2, Epoch 156/300 (LR 0.04686) => LSC_loss 0.23, Spatial_loss 0.16, Flat_loss 0.39, Train_acc 94.84, Test_acc 52.59
2024-09-02 11:31:06,246 [podnet.py] => Task 2, Epoch 157/300 (LR 0.04634) => LSC_loss 0.14, Spatial_loss 0.15, Flat_loss 0.36, Train_acc 97.24, Test_acc 48.26
2024-09-02 11:31:08,471 [podnet.py] => Task 2, Epoch 158/300 (LR 0.04582) => LSC_loss 0.07, Spatial_loss 0.13, Flat_loss 0.32, Train_acc 99.18, Test_acc 55.61
2024-09-02 11:31:10,590 [podnet.py] => Task 2, Epoch 159/300 (LR 0.04529) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.29, Train_acc 99.58, Test_acc 56.48
2024-09-02 11:31:12,884 [podnet.py] => Task 2, Epoch 160/300 (LR 0.04477) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.27, Train_acc 100.00, Test_acc 57.44
2024-09-02 11:31:15,209 [podnet.py] => Task 2, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.25, Train_acc 99.93, Test_acc 58.87
2024-09-02 11:31:17,417 [podnet.py] => Task 2, Epoch 162/300 (LR 0.04373) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.24, Train_acc 100.00, Test_acc 57.69
2024-09-02 11:31:19,539 [podnet.py] => Task 2, Epoch 163/300 (LR 0.04321) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 99.98, Test_acc 58.11
2024-09-02 11:31:21,722 [podnet.py] => Task 2, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.08, Flat_loss 0.23, Train_acc 99.98, Test_acc 57.09
2024-09-02 11:31:23,979 [podnet.py] => Task 2, Epoch 165/300 (LR 0.04218) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.24, Train_acc 99.91, Test_acc 57.33
2024-09-02 11:31:26,225 [podnet.py] => Task 2, Epoch 166/300 (LR 0.04166) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.24, Train_acc 100.00, Test_acc 59.07
2024-09-02 11:31:27,659 [podnet.py] => Task 2, Epoch 167/300 (LR 0.04115) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 100.00, Test_acc 58.11
2024-09-02 11:31:29,748 [podnet.py] => Task 2, Epoch 168/300 (LR 0.04063) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.94
2024-09-02 11:31:31,828 [podnet.py] => Task 2, Epoch 169/300 (LR 0.04012) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.91
2024-09-02 11:31:34,172 [podnet.py] => Task 2, Epoch 170/300 (LR 0.03960) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.28
2024-09-02 11:31:36,579 [podnet.py] => Task 2, Epoch 171/300 (LR 0.03909) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.46
2024-09-02 11:31:39,100 [podnet.py] => Task 2, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 100.00, Test_acc 58.67
2024-09-02 11:31:41,581 [podnet.py] => Task 2, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.22, Train_acc 99.98, Test_acc 57.76
2024-09-02 11:31:44,010 [podnet.py] => Task 2, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 99.98, Test_acc 57.70
2024-09-02 11:31:46,397 [podnet.py] => Task 2, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.56
2024-09-02 11:31:48,823 [podnet.py] => Task 2, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.04
2024-09-02 11:31:51,134 [podnet.py] => Task 2, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.63
2024-09-02 11:31:53,273 [podnet.py] => Task 2, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.33
2024-09-02 11:31:55,504 [podnet.py] => Task 2, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.52
2024-09-02 11:31:57,759 [podnet.py] => Task 2, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.33
2024-09-02 11:31:59,864 [podnet.py] => Task 2, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 59.04
2024-09-02 11:32:02,128 [podnet.py] => Task 2, Epoch 182/300 (LR 0.03356) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.74
2024-09-02 11:32:04,230 [podnet.py] => Task 2, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:32:06,337 [podnet.py] => Task 2, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.78
2024-09-02 11:32:08,452 [podnet.py] => Task 2, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 59.20
2024-09-02 11:32:10,679 [podnet.py] => Task 2, Epoch 186/300 (LR 0.03159) => LSC_loss 0.05, Spatial_loss 0.06, Flat_loss 0.20, Train_acc 99.98, Test_acc 58.26
2024-09-02 11:32:12,797 [podnet.py] => Task 2, Epoch 187/300 (LR 0.03111) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.23, Train_acc 100.00, Test_acc 58.04
2024-09-02 11:32:15,050 [podnet.py] => Task 2, Epoch 188/300 (LR 0.03062) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.48
2024-09-02 11:32:17,286 [podnet.py] => Task 2, Epoch 189/300 (LR 0.03014) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.28
2024-09-02 11:32:19,548 [podnet.py] => Task 2, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.54
2024-09-02 11:32:21,574 [podnet.py] => Task 2, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 57.91
2024-09-02 11:32:23,787 [podnet.py] => Task 2, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 57.44
2024-09-02 11:32:25,866 [podnet.py] => Task 2, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.67
2024-09-02 11:32:27,982 [podnet.py] => Task 2, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.89
2024-09-02 11:32:30,204 [podnet.py] => Task 2, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.83
2024-09-02 11:32:32,435 [podnet.py] => Task 2, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.50
2024-09-02 11:32:34,749 [podnet.py] => Task 2, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.39
2024-09-02 11:32:37,017 [podnet.py] => Task 2, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.52
2024-09-02 11:32:39,160 [podnet.py] => Task 2, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.19
2024-09-02 11:32:41,395 [podnet.py] => Task 2, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 99.98, Test_acc 57.93
2024-09-02 11:32:43,611 [podnet.py] => Task 2, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.39
2024-09-02 11:32:45,960 [podnet.py] => Task 2, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.41
2024-09-02 11:32:48,183 [podnet.py] => Task 2, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.20
2024-09-02 11:32:50,395 [podnet.py] => Task 2, Epoch 204/300 (LR 0.02321) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.83
2024-09-02 11:32:52,619 [podnet.py] => Task 2, Epoch 205/300 (LR 0.02277) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.72
2024-09-02 11:32:54,811 [podnet.py] => Task 2, Epoch 206/300 (LR 0.02233) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 57.87
2024-09-02 11:32:57,091 [podnet.py] => Task 2, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.46
2024-09-02 11:32:59,300 [podnet.py] => Task 2, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.78
2024-09-02 11:33:01,215 [podnet.py] => Task 2, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.39
2024-09-02 11:33:03,182 [podnet.py] => Task 2, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.81
2024-09-02 11:33:05,404 [podnet.py] => Task 2, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.22
2024-09-02 11:33:07,669 [podnet.py] => Task 2, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.13
2024-09-02 11:33:09,798 [podnet.py] => Task 2, Epoch 213/300 (LR 0.01935) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.46
2024-09-02 11:33:11,831 [podnet.py] => Task 2, Epoch 214/300 (LR 0.01894) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 99.98, Test_acc 58.83
2024-09-02 11:33:14,158 [podnet.py] => Task 2, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.56
2024-09-02 11:33:16,468 [podnet.py] => Task 2, Epoch 216/300 (LR 0.01813) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.59
2024-09-02 11:33:18,723 [podnet.py] => Task 2, Epoch 217/300 (LR 0.01773) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.15
2024-09-02 11:33:20,868 [podnet.py] => Task 2, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.15
2024-09-02 11:33:23,163 [podnet.py] => Task 2, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.15
2024-09-02 11:33:25,318 [podnet.py] => Task 2, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.87
2024-09-02 11:33:27,545 [podnet.py] => Task 2, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.80
2024-09-02 11:33:29,622 [podnet.py] => Task 2, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.81
2024-09-02 11:33:31,854 [podnet.py] => Task 2, Epoch 223/300 (LR 0.01539) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.69
2024-09-02 11:33:34,085 [podnet.py] => Task 2, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.63
2024-09-02 11:33:36,314 [podnet.py] => Task 2, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.26
2024-09-02 11:33:38,394 [podnet.py] => Task 2, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.11
2024-09-02 11:33:40,507 [podnet.py] => Task 2, Epoch 227/300 (LR 0.01391) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:33:42,731 [podnet.py] => Task 2, Epoch 228/300 (LR 0.01355) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.76
2024-09-02 11:33:44,851 [podnet.py] => Task 2, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.15
2024-09-02 11:33:47,118 [podnet.py] => Task 2, Epoch 230/300 (LR 0.01284) => LSC_loss 0.06, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 99.93, Test_acc 56.30
2024-09-02 11:33:49,204 [podnet.py] => Task 2, Epoch 231/300 (LR 0.01249) => LSC_loss 0.06, Spatial_loss 0.09, Flat_loss 0.27, Train_acc 99.49, Test_acc 55.59
2024-09-02 11:33:51,466 [podnet.py] => Task 2, Epoch 232/300 (LR 0.01215) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.22, Train_acc 99.98, Test_acc 58.63
2024-09-02 11:33:53,725 [podnet.py] => Task 2, Epoch 233/300 (LR 0.01181) => LSC_loss 0.04, Spatial_loss 0.06, Flat_loss 0.21, Train_acc 100.00, Test_acc 58.61
2024-09-02 11:33:56,077 [podnet.py] => Task 2, Epoch 234/300 (LR 0.01147) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 57.98
2024-09-02 11:33:58,190 [podnet.py] => Task 2, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.02
2024-09-02 11:34:00,173 [podnet.py] => Task 2, Epoch 236/300 (LR 0.01082) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.02
2024-09-02 11:34:02,290 [podnet.py] => Task 2, Epoch 237/300 (LR 0.01049) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.26
2024-09-02 11:34:04,399 [podnet.py] => Task 2, Epoch 238/300 (LR 0.01017) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.30
2024-09-02 11:34:06,476 [podnet.py] => Task 2, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.04
2024-09-02 11:34:08,608 [podnet.py] => Task 2, Epoch 240/300 (LR 0.00955) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.20, Train_acc 100.00, Test_acc 58.41
2024-09-02 11:34:10,613 [podnet.py] => Task 2, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.05, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.41
2024-09-02 11:34:12,937 [podnet.py] => Task 2, Epoch 242/300 (LR 0.00894) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.07
2024-09-02 11:34:15,121 [podnet.py] => Task 2, Epoch 243/300 (LR 0.00865) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.67
2024-09-02 11:34:17,325 [podnet.py] => Task 2, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.13
2024-09-02 11:34:19,445 [podnet.py] => Task 2, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:34:21,738 [podnet.py] => Task 2, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.85
2024-09-02 11:34:24,061 [podnet.py] => Task 2, Epoch 247/300 (LR 0.00751) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 99.98, Test_acc 58.11
2024-09-02 11:34:26,302 [podnet.py] => Task 2, Epoch 248/300 (LR 0.00723) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.22
2024-09-02 11:34:28,641 [podnet.py] => Task 2, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.37
2024-09-02 11:34:30,971 [podnet.py] => Task 2, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.13
2024-09-02 11:34:33,271 [podnet.py] => Task 2, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.81
2024-09-02 11:34:35,581 [podnet.py] => Task 2, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.15
2024-09-02 11:34:37,715 [podnet.py] => Task 2, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.98
2024-09-02 11:34:39,637 [podnet.py] => Task 2, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.52
2024-09-02 11:34:41,895 [podnet.py] => Task 2, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.07
2024-09-02 11:34:44,049 [podnet.py] => Task 2, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.28
2024-09-02 11:34:46,165 [podnet.py] => Task 2, Epoch 257/300 (LR 0.00498) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.13
2024-09-02 11:34:48,292 [podnet.py] => Task 2, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.17
2024-09-02 11:34:50,202 [podnet.py] => Task 2, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.06
2024-09-02 11:34:52,315 [podnet.py] => Task 2, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.39
2024-09-02 11:34:54,186 [podnet.py] => Task 2, Epoch 261/300 (LR 0.00411) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.04
2024-09-02 11:34:56,245 [podnet.py] => Task 2, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.19
2024-09-02 11:34:58,244 [podnet.py] => Task 2, Epoch 263/300 (LR 0.00371) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.41
2024-09-02 11:35:00,355 [podnet.py] => Task 2, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.33
2024-09-02 11:35:02,453 [podnet.py] => Task 2, Epoch 265/300 (LR 0.00332) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.89
2024-09-02 11:35:04,572 [podnet.py] => Task 2, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.98
2024-09-02 11:35:06,570 [podnet.py] => Task 2, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.44
2024-09-02 11:35:08,683 [podnet.py] => Task 2, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.48
2024-09-02 11:35:10,868 [podnet.py] => Task 2, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.43
2024-09-02 11:35:13,167 [podnet.py] => Task 2, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.37
2024-09-02 11:35:15,320 [podnet.py] => Task 2, Epoch 271/300 (LR 0.00229) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.13
2024-09-02 11:35:17,287 [podnet.py] => Task 2, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:35:19,485 [podnet.py] => Task 2, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.17
2024-09-02 11:35:20,946 [podnet.py] => Task 2, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.24
2024-09-02 11:35:23,122 [podnet.py] => Task 2, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:35:25,509 [podnet.py] => Task 2, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 57.98
2024-09-02 11:35:27,680 [podnet.py] => Task 2, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.26
2024-09-02 11:35:29,861 [podnet.py] => Task 2, Epoch 278/300 (LR 0.00132) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.46
2024-09-02 11:35:32,087 [podnet.py] => Task 2, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:35:34,367 [podnet.py] => Task 2, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.31
2024-09-02 11:35:36,394 [podnet.py] => Task 2, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.17
2024-09-02 11:35:38,596 [podnet.py] => Task 2, Epoch 282/300 (LR 0.00089) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.17
2024-09-02 11:35:40,756 [podnet.py] => Task 2, Epoch 283/300 (LR 0.00079) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.28
2024-09-02 11:35:42,987 [podnet.py] => Task 2, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.85
2024-09-02 11:35:45,310 [podnet.py] => Task 2, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.70
2024-09-02 11:35:47,592 [podnet.py] => Task 2, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.43
2024-09-02 11:35:49,950 [podnet.py] => Task 2, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.63
2024-09-02 11:35:52,186 [podnet.py] => Task 2, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.31
2024-09-02 11:35:54,461 [podnet.py] => Task 2, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.52
2024-09-02 11:35:56,462 [podnet.py] => Task 2, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.30
2024-09-02 11:35:58,518 [podnet.py] => Task 2, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.19, Train_acc 100.00, Test_acc 58.54
2024-09-02 11:36:00,655 [podnet.py] => Task 2, Epoch 292/300 (LR 0.00018) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.41
2024-09-02 11:36:02,832 [podnet.py] => Task 2, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.20
2024-09-02 11:36:04,445 [podnet.py] => Task 2, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.30
2024-09-02 11:36:06,322 [podnet.py] => Task 2, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.35
2024-09-02 11:36:07,760 [podnet.py] => Task 2, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.50
2024-09-02 11:36:09,868 [podnet.py] => Task 2, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.46
2024-09-02 11:36:11,878 [podnet.py] => Task 2, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.50
2024-09-02 11:36:14,098 [podnet.py] => Task 2, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.93
2024-09-02 11:36:16,238 [podnet.py] => Task 2, Epoch 300/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.04, Flat_loss 0.18, Train_acc 100.00, Test_acc 58.56
2024-09-02 11:36:16,239 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 11:36:16,239 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 11:36:17,585 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 11:36:19,289 [base.py] => Reducing exemplars...(55 per classes)
2024-09-02 11:36:20,762 [base.py] => Constructing exemplars...(55 per classes)
2024-09-02 11:36:23,294 [podnet.py] => Exemplar size: 495
2024-09-02 11:36:23,294 [trainer.py] => CNN: {'total': 58.56, '00-04': 47.2, '05-06': 47.92, '07-08': 97.58, 'old': 47.4, 'new': 97.58}
2024-09-02 11:36:23,295 [trainer.py] => NME: {'total': 61.44, '00-04': 61.73, '05-06': 40.58, '07-08': 81.58, 'old': 55.69, 'new': 81.58}
2024-09-02 11:36:23,295 [trainer.py] => CNN top1 curve: [88.9, 68.36, 58.56]
2024-09-02 11:36:23,295 [trainer.py] => CNN top5 curve: [100.0, 97.1, 89.02]
2024-09-02 11:36:23,295 [trainer.py] => NME top1 curve: [88.9, 73.69, 61.44]
2024-09-02 11:36:23,295 [trainer.py] => NME top5 curve: [100.0, 97.17, 92.15]

2024-09-02 11:36:23,295 [trainer.py] => Average Accuracy (CNN): 71.94
2024-09-02 11:36:23,295 [trainer.py] => Average Accuracy (NME): 74.67666666666666
2024-09-02 11:36:23,296 [trainer.py] => Forgetting (CNN): 45.305
