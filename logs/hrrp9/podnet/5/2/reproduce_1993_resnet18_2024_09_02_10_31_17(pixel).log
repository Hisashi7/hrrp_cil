2024-09-02 10:31:17,638 [trainer.py] => config: ./exps/podnet.json
2024-09-02 10:31:17,638 [trainer.py] => prefix: reproduce
2024-09-02 10:31:17,638 [trainer.py] => dataset: hrrp9
2024-09-02 10:31:17,638 [trainer.py] => memory_size: 500
2024-09-02 10:31:17,638 [trainer.py] => memory_per_class: 20
2024-09-02 10:31:17,638 [trainer.py] => fixed_memory: False
2024-09-02 10:31:17,638 [trainer.py] => shuffle: True
2024-09-02 10:31:17,638 [trainer.py] => init_cls: 5
2024-09-02 10:31:17,638 [trainer.py] => increment: 2
2024-09-02 10:31:17,638 [trainer.py] => model_name: podnet
2024-09-02 10:31:17,639 [trainer.py] => convnet_type: resnet18
2024-09-02 10:31:17,639 [trainer.py] => init_train: True
2024-09-02 10:31:17,639 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-02 10:31:17,639 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-02 10:31:17,639 [trainer.py] => device: [device(type='cuda', index=6)]
2024-09-02 10:31:17,639 [trainer.py] => seed: 1993
2024-09-02 10:31:18,112 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-02 10:31:18,212 [trainer.py] => All params: 3843904
2024-09-02 10:31:18,212 [trainer.py] => Trainable params: 3843904
2024-09-02 10:31:18,213 [podnet.py] => Learning on 0-5
2024-09-02 10:31:18,248 [podnet.py] => Adaptive factor: 0
2024-09-02 10:31:21,044 [podnet.py] => Task 0, Epoch 1/300 (LR 0.10000) => LSC_loss 1.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 41.02, Test_acc 43.47
2024-09-02 10:31:23,769 [podnet.py] => Task 0, Epoch 2/300 (LR 0.09999) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.86, Test_acc 32.63
2024-09-02 10:31:26,554 [podnet.py] => Task 0, Epoch 3/300 (LR 0.09998) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.47, Test_acc 36.30
2024-09-02 10:31:29,090 [podnet.py] => Task 0, Epoch 4/300 (LR 0.09996) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.33, Test_acc 59.63
2024-09-02 10:31:31,751 [podnet.py] => Task 0, Epoch 5/300 (LR 0.09993) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.73, Test_acc 55.37
2024-09-02 10:31:33,719 [podnet.py] => Task 0, Epoch 6/300 (LR 0.09990) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.02, Test_acc 72.20
2024-09-02 10:31:36,539 [podnet.py] => Task 0, Epoch 7/300 (LR 0.09987) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.42, Test_acc 67.40
2024-09-02 10:31:38,485 [podnet.py] => Task 0, Epoch 8/300 (LR 0.09982) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.66, Test_acc 74.30
2024-09-02 10:31:41,211 [podnet.py] => Task 0, Epoch 9/300 (LR 0.09978) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.07, Test_acc 74.60
2024-09-02 10:31:43,403 [podnet.py] => Task 0, Epoch 10/300 (LR 0.09973) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.47, Test_acc 78.70
2024-09-02 10:31:45,314 [podnet.py] => Task 0, Epoch 11/300 (LR 0.09967) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 70.47
2024-09-02 10:31:47,361 [podnet.py] => Task 0, Epoch 12/300 (LR 0.09961) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.31, Test_acc 82.27
2024-09-02 10:31:50,167 [podnet.py] => Task 0, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.29, Test_acc 82.53
2024-09-02 10:31:52,086 [podnet.py] => Task 0, Epoch 14/300 (LR 0.09946) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 67.27
2024-09-02 10:31:54,677 [podnet.py] => Task 0, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.94, Test_acc 79.93
2024-09-02 10:31:57,046 [podnet.py] => Task 0, Epoch 16/300 (LR 0.09930) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.08, Test_acc 83.07
2024-09-02 10:32:00,062 [podnet.py] => Task 0, Epoch 17/300 (LR 0.09921) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.57, Test_acc 72.60
2024-09-02 10:32:02,570 [podnet.py] => Task 0, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.56, Test_acc 80.30
2024-09-02 10:32:05,413 [podnet.py] => Task 0, Epoch 19/300 (LR 0.09901) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 81.57
2024-09-02 10:32:08,217 [podnet.py] => Task 0, Epoch 20/300 (LR 0.09891) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 79.03
2024-09-02 10:32:10,522 [podnet.py] => Task 0, Epoch 21/300 (LR 0.09880) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 83.07
2024-09-02 10:32:12,778 [podnet.py] => Task 0, Epoch 22/300 (LR 0.09868) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.83, Test_acc 74.17
2024-09-02 10:32:14,602 [podnet.py] => Task 0, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 82.63
2024-09-02 10:32:17,125 [podnet.py] => Task 0, Epoch 24/300 (LR 0.09843) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 82.83
2024-09-02 10:32:19,411 [podnet.py] => Task 0, Epoch 25/300 (LR 0.09830) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.27, Test_acc 84.33
2024-09-02 10:32:21,582 [podnet.py] => Task 0, Epoch 26/300 (LR 0.09816) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.83, Test_acc 85.20
2024-09-02 10:32:24,184 [podnet.py] => Task 0, Epoch 27/300 (LR 0.09801) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 85.90
2024-09-02 10:32:26,834 [podnet.py] => Task 0, Epoch 28/300 (LR 0.09787) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.15, Test_acc 74.20
2024-09-02 10:32:29,364 [podnet.py] => Task 0, Epoch 29/300 (LR 0.09771) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 82.03
2024-09-02 10:32:31,628 [podnet.py] => Task 0, Epoch 30/300 (LR 0.09755) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 76.93
2024-09-02 10:32:33,785 [podnet.py] => Task 0, Epoch 31/300 (LR 0.09739) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.02, Test_acc 79.40
2024-09-02 10:32:36,072 [podnet.py] => Task 0, Epoch 32/300 (LR 0.09722) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.66, Test_acc 77.10
2024-09-02 10:32:38,251 [podnet.py] => Task 0, Epoch 33/300 (LR 0.09704) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.02, Test_acc 79.23
2024-09-02 10:32:40,712 [podnet.py] => Task 0, Epoch 34/300 (LR 0.09686) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.07, Test_acc 86.00
2024-09-02 10:32:43,415 [podnet.py] => Task 0, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 74.73
2024-09-02 10:32:45,636 [podnet.py] => Task 0, Epoch 36/300 (LR 0.09649) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.14, Test_acc 79.27
2024-09-02 10:32:47,532 [podnet.py] => Task 0, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 84.97
2024-09-02 10:32:50,227 [podnet.py] => Task 0, Epoch 38/300 (LR 0.09609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.08, Test_acc 84.70
2024-09-02 10:32:53,147 [podnet.py] => Task 0, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.69, Test_acc 82.83
2024-09-02 10:32:55,282 [podnet.py] => Task 0, Epoch 40/300 (LR 0.09568) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 75.70
2024-09-02 10:32:57,863 [podnet.py] => Task 0, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.97, Test_acc 83.57
2024-09-02 10:33:00,685 [podnet.py] => Task 0, Epoch 42/300 (LR 0.09524) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 82.43
2024-09-02 10:33:02,939 [podnet.py] => Task 0, Epoch 43/300 (LR 0.09502) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.89, Test_acc 86.70
2024-09-02 10:33:04,800 [podnet.py] => Task 0, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 71.70
2024-09-02 10:33:06,638 [podnet.py] => Task 0, Epoch 45/300 (LR 0.09455) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 84.30
2024-09-02 10:33:08,479 [podnet.py] => Task 0, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 80.70
2024-09-02 10:33:10,438 [podnet.py] => Task 0, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.17, Test_acc 84.67
2024-09-02 10:33:12,683 [podnet.py] => Task 0, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 83.63
2024-09-02 10:33:14,644 [podnet.py] => Task 0, Epoch 49/300 (LR 0.09356) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 85.03
2024-09-02 10:33:16,729 [podnet.py] => Task 0, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.65, Test_acc 82.57
2024-09-02 10:33:19,418 [podnet.py] => Task 0, Epoch 51/300 (LR 0.09304) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.39, Test_acc 88.17
2024-09-02 10:33:21,358 [podnet.py] => Task 0, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.86, Test_acc 80.73
2024-09-02 10:33:23,231 [podnet.py] => Task 0, Epoch 53/300 (LR 0.09249) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 78.07
2024-09-02 10:33:25,722 [podnet.py] => Task 0, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.67
2024-09-02 10:33:27,700 [podnet.py] => Task 0, Epoch 55/300 (LR 0.09193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.26, Test_acc 82.83
2024-09-02 10:33:30,372 [podnet.py] => Task 0, Epoch 56/300 (LR 0.09165) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 82.33
2024-09-02 10:33:33,026 [podnet.py] => Task 0, Epoch 57/300 (LR 0.09135) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.60, Test_acc 82.83
2024-09-02 10:33:34,884 [podnet.py] => Task 0, Epoch 58/300 (LR 0.09106) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.50, Test_acc 84.40
2024-09-02 10:33:37,780 [podnet.py] => Task 0, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 70.30
2024-09-02 10:33:39,701 [podnet.py] => Task 0, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 82.83
2024-09-02 10:33:42,038 [podnet.py] => Task 0, Epoch 61/300 (LR 0.09014) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.69, Test_acc 83.20
2024-09-02 10:33:44,762 [podnet.py] => Task 0, Epoch 62/300 (LR 0.08983) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.30, Test_acc 86.53
2024-09-02 10:33:47,167 [podnet.py] => Task 0, Epoch 63/300 (LR 0.08951) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.41, Test_acc 84.83
2024-09-02 10:33:49,727 [podnet.py] => Task 0, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 84.63
2024-09-02 10:33:52,482 [podnet.py] => Task 0, Epoch 65/300 (LR 0.08886) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 81.80
2024-09-02 10:33:55,303 [podnet.py] => Task 0, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 81.17
2024-09-02 10:33:58,327 [podnet.py] => Task 0, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 82.20
2024-09-02 10:34:00,738 [podnet.py] => Task 0, Epoch 68/300 (LR 0.08785) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.91, Test_acc 83.43
2024-09-02 10:34:03,304 [podnet.py] => Task 0, Epoch 69/300 (LR 0.08751) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.09, Test_acc 84.27
2024-09-02 10:34:05,118 [podnet.py] => Task 0, Epoch 70/300 (LR 0.08716) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.47, Test_acc 84.80
2024-09-02 10:34:06,953 [podnet.py] => Task 0, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 88.13
2024-09-02 10:34:09,385 [podnet.py] => Task 0, Epoch 72/300 (LR 0.08645) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 87.83
2024-09-02 10:34:11,774 [podnet.py] => Task 0, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.82, Test_acc 87.00
2024-09-02 10:34:14,647 [podnet.py] => Task 0, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 87.03
2024-09-02 10:34:16,063 [podnet.py] => Task 0, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 86.63
2024-09-02 10:34:18,932 [podnet.py] => Task 0, Epoch 76/300 (LR 0.08498) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.71, Test_acc 78.20
2024-09-02 10:34:20,885 [podnet.py] => Task 0, Epoch 77/300 (LR 0.08461) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 84.30
2024-09-02 10:34:22,736 [podnet.py] => Task 0, Epoch 78/300 (LR 0.08423) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 86.53
2024-09-02 10:34:25,725 [podnet.py] => Task 0, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 80.93
2024-09-02 10:34:28,432 [podnet.py] => Task 0, Epoch 80/300 (LR 0.08346) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.19, Test_acc 83.10
2024-09-02 10:34:31,205 [podnet.py] => Task 0, Epoch 81/300 (LR 0.08307) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.09, Test_acc 86.57
2024-09-02 10:34:33,700 [podnet.py] => Task 0, Epoch 82/300 (LR 0.08267) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 86.83
2024-09-02 10:34:35,970 [podnet.py] => Task 0, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.72, Test_acc 84.97
2024-09-02 10:34:37,922 [podnet.py] => Task 0, Epoch 84/300 (LR 0.08187) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.52, Test_acc 80.90
2024-09-02 10:34:39,800 [podnet.py] => Task 0, Epoch 85/300 (LR 0.08147) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.01, Test_acc 86.27
2024-09-02 10:34:41,679 [podnet.py] => Task 0, Epoch 86/300 (LR 0.08106) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.85, Test_acc 80.87
2024-09-02 10:34:44,319 [podnet.py] => Task 0, Epoch 87/300 (LR 0.08065) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.98, Test_acc 78.57
2024-09-02 10:34:46,472 [podnet.py] => Task 0, Epoch 88/300 (LR 0.08023) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.55, Test_acc 85.57
2024-09-02 10:34:48,722 [podnet.py] => Task 0, Epoch 89/300 (LR 0.07981) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 87.87
2024-09-02 10:34:51,181 [podnet.py] => Task 0, Epoch 90/300 (LR 0.07939) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.83
2024-09-02 10:34:53,796 [podnet.py] => Task 0, Epoch 91/300 (LR 0.07896) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.42, Test_acc 82.47
2024-09-02 10:34:56,584 [podnet.py] => Task 0, Epoch 92/300 (LR 0.07854) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.95, Test_acc 86.23
2024-09-02 10:34:59,069 [podnet.py] => Task 0, Epoch 93/300 (LR 0.07810) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 87.07
2024-09-02 10:35:01,709 [podnet.py] => Task 0, Epoch 94/300 (LR 0.07767) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 84.03
2024-09-02 10:35:03,701 [podnet.py] => Task 0, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 80.70
2024-09-02 10:35:06,053 [podnet.py] => Task 0, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 85.07
2024-09-02 10:35:08,368 [podnet.py] => Task 0, Epoch 97/300 (LR 0.07635) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 79.37
2024-09-02 10:35:10,445 [podnet.py] => Task 0, Epoch 98/300 (LR 0.07590) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 87.33
2024-09-02 10:35:12,364 [podnet.py] => Task 0, Epoch 99/300 (LR 0.07545) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.21, Test_acc 84.17
2024-09-02 10:35:14,842 [podnet.py] => Task 0, Epoch 100/300 (LR 0.07500) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 85.00
2024-09-02 10:35:16,307 [podnet.py] => Task 0, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.81, Test_acc 82.50
2024-09-02 10:35:18,197 [podnet.py] => Task 0, Epoch 102/300 (LR 0.07409) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.40
2024-09-02 10:35:20,217 [podnet.py] => Task 0, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.89, Test_acc 83.40
2024-09-02 10:35:22,939 [podnet.py] => Task 0, Epoch 104/300 (LR 0.07316) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 80.57
2024-09-02 10:35:25,775 [podnet.py] => Task 0, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.07, Test_acc 88.03
2024-09-02 10:35:28,356 [podnet.py] => Task 0, Epoch 106/300 (LR 0.07223) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 85.80
2024-09-02 10:35:30,880 [podnet.py] => Task 0, Epoch 107/300 (LR 0.07176) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.17, Test_acc 80.70
2024-09-02 10:35:33,649 [podnet.py] => Task 0, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 85.73
2024-09-02 10:35:35,477 [podnet.py] => Task 0, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.50
2024-09-02 10:35:38,079 [podnet.py] => Task 0, Epoch 110/300 (LR 0.07034) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 87.13
2024-09-02 10:35:40,433 [podnet.py] => Task 0, Epoch 111/300 (LR 0.06986) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.58, Test_acc 87.13
2024-09-02 10:35:43,144 [podnet.py] => Task 0, Epoch 112/300 (LR 0.06938) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.84, Test_acc 84.77
2024-09-02 10:35:45,020 [podnet.py] => Task 0, Epoch 113/300 (LR 0.06889) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.13, Test_acc 85.40
2024-09-02 10:35:47,377 [podnet.py] => Task 0, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 83.33
2024-09-02 10:35:50,163 [podnet.py] => Task 0, Epoch 115/300 (LR 0.06792) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 84.27
2024-09-02 10:35:52,436 [podnet.py] => Task 0, Epoch 116/300 (LR 0.06743) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.73
2024-09-02 10:35:55,249 [podnet.py] => Task 0, Epoch 117/300 (LR 0.06694) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.29, Test_acc 79.07
2024-09-02 10:35:58,245 [podnet.py] => Task 0, Epoch 118/300 (LR 0.06644) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 84.63
2024-09-02 10:36:01,179 [podnet.py] => Task 0, Epoch 119/300 (LR 0.06595) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 84.53
2024-09-02 10:36:03,843 [podnet.py] => Task 0, Epoch 120/300 (LR 0.06545) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 83.80
2024-09-02 10:36:06,138 [podnet.py] => Task 0, Epoch 121/300 (LR 0.06495) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.73, Test_acc 87.63
2024-09-02 10:36:07,913 [podnet.py] => Task 0, Epoch 122/300 (LR 0.06445) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 83.27
2024-09-02 10:36:10,849 [podnet.py] => Task 0, Epoch 123/300 (LR 0.06395) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 82.97
2024-09-02 10:36:13,495 [podnet.py] => Task 0, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 83.40
2024-09-02 10:36:14,942 [podnet.py] => Task 0, Epoch 125/300 (LR 0.06294) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.22, Test_acc 83.77
2024-09-02 10:36:17,844 [podnet.py] => Task 0, Epoch 126/300 (LR 0.06243) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 86.57
2024-09-02 10:36:20,892 [podnet.py] => Task 0, Epoch 127/300 (LR 0.06193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.36, Test_acc 86.00
2024-09-02 10:36:23,356 [podnet.py] => Task 0, Epoch 128/300 (LR 0.06142) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.84, Test_acc 84.60
2024-09-02 10:36:25,982 [podnet.py] => Task 0, Epoch 129/300 (LR 0.06091) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 87.97
2024-09-02 10:36:28,840 [podnet.py] => Task 0, Epoch 130/300 (LR 0.06040) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 82.23
2024-09-02 10:36:31,641 [podnet.py] => Task 0, Epoch 131/300 (LR 0.05988) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 86.90
2024-09-02 10:36:33,570 [podnet.py] => Task 0, Epoch 132/300 (LR 0.05937) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 89.73
2024-09-02 10:36:35,132 [podnet.py] => Task 0, Epoch 133/300 (LR 0.05885) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.57
2024-09-02 10:36:38,131 [podnet.py] => Task 0, Epoch 134/300 (LR 0.05834) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.87
2024-09-02 10:36:41,236 [podnet.py] => Task 0, Epoch 135/300 (LR 0.05782) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.44, Test_acc 85.53
2024-09-02 10:36:42,895 [podnet.py] => Task 0, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 79.13
2024-09-02 10:36:45,646 [podnet.py] => Task 0, Epoch 137/300 (LR 0.05679) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.71, Test_acc 88.00
2024-09-02 10:36:47,909 [podnet.py] => Task 0, Epoch 138/300 (LR 0.05627) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.33
2024-09-02 10:36:49,870 [podnet.py] => Task 0, Epoch 139/300 (LR 0.05575) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 88.17
2024-09-02 10:36:52,633 [podnet.py] => Task 0, Epoch 140/300 (LR 0.05523) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 82.47
2024-09-02 10:36:55,024 [podnet.py] => Task 0, Epoch 141/300 (LR 0.05471) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 84.93
2024-09-02 10:36:58,012 [podnet.py] => Task 0, Epoch 142/300 (LR 0.05418) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.70, Test_acc 84.13
2024-09-02 10:37:01,019 [podnet.py] => Task 0, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 84.60
2024-09-02 10:37:03,764 [podnet.py] => Task 0, Epoch 144/300 (LR 0.05314) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 87.83
2024-09-02 10:37:05,779 [podnet.py] => Task 0, Epoch 145/300 (LR 0.05262) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.45, Test_acc 86.60
2024-09-02 10:37:08,393 [podnet.py] => Task 0, Epoch 146/300 (LR 0.05209) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 81.50
2024-09-02 10:37:11,393 [podnet.py] => Task 0, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.53, Test_acc 86.77
2024-09-02 10:37:13,989 [podnet.py] => Task 0, Epoch 148/300 (LR 0.05105) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.37, Test_acc 84.77
2024-09-02 10:37:16,042 [podnet.py] => Task 0, Epoch 149/300 (LR 0.05052) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 85.70
2024-09-02 10:37:18,074 [podnet.py] => Task 0, Epoch 150/300 (LR 0.05000) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 86.57
2024-09-02 10:37:20,549 [podnet.py] => Task 0, Epoch 151/300 (LR 0.04948) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.81, Test_acc 84.43
2024-09-02 10:37:23,341 [podnet.py] => Task 0, Epoch 152/300 (LR 0.04895) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 88.60
2024-09-02 10:37:26,021 [podnet.py] => Task 0, Epoch 153/300 (LR 0.04843) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 87.07
2024-09-02 10:37:28,987 [podnet.py] => Task 0, Epoch 154/300 (LR 0.04791) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 87.57
2024-09-02 10:37:31,661 [podnet.py] => Task 0, Epoch 155/300 (LR 0.04738) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.14, Test_acc 81.10
2024-09-02 10:37:33,081 [podnet.py] => Task 0, Epoch 156/300 (LR 0.04686) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.67, Test_acc 88.10
2024-09-02 10:37:35,694 [podnet.py] => Task 0, Epoch 157/300 (LR 0.04634) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.87
2024-09-02 10:37:37,982 [podnet.py] => Task 0, Epoch 158/300 (LR 0.04582) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 88.53
2024-09-02 10:37:40,653 [podnet.py] => Task 0, Epoch 159/300 (LR 0.04529) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.43
2024-09-02 10:37:43,181 [podnet.py] => Task 0, Epoch 160/300 (LR 0.04477) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 86.20
2024-09-02 10:37:45,087 [podnet.py] => Task 0, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.68, Test_acc 84.87
2024-09-02 10:37:47,928 [podnet.py] => Task 0, Epoch 162/300 (LR 0.04373) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 88.27
2024-09-02 10:37:50,182 [podnet.py] => Task 0, Epoch 163/300 (LR 0.04321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 85.63
2024-09-02 10:37:52,924 [podnet.py] => Task 0, Epoch 164/300 (LR 0.04270) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 83.27
2024-09-02 10:37:54,847 [podnet.py] => Task 0, Epoch 165/300 (LR 0.04218) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 85.37
2024-09-02 10:37:57,991 [podnet.py] => Task 0, Epoch 166/300 (LR 0.04166) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 89.13
2024-09-02 10:38:00,520 [podnet.py] => Task 0, Epoch 167/300 (LR 0.04115) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.61, Test_acc 86.80
2024-09-02 10:38:02,861 [podnet.py] => Task 0, Epoch 168/300 (LR 0.04063) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.17
2024-09-02 10:38:05,136 [podnet.py] => Task 0, Epoch 169/300 (LR 0.04012) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.03
2024-09-02 10:38:07,300 [podnet.py] => Task 0, Epoch 170/300 (LR 0.03960) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 89.47
2024-09-02 10:38:09,417 [podnet.py] => Task 0, Epoch 171/300 (LR 0.03909) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.13
2024-09-02 10:38:10,825 [podnet.py] => Task 0, Epoch 172/300 (LR 0.03858) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.91, Test_acc 89.47
2024-09-02 10:38:12,862 [podnet.py] => Task 0, Epoch 173/300 (LR 0.03807) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 88.13
2024-09-02 10:38:15,497 [podnet.py] => Task 0, Epoch 174/300 (LR 0.03757) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 84.43
2024-09-02 10:38:17,681 [podnet.py] => Task 0, Epoch 175/300 (LR 0.03706) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.57, Test_acc 86.30
2024-09-02 10:38:20,059 [podnet.py] => Task 0, Epoch 176/300 (LR 0.03655) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 81.37
2024-09-02 10:38:22,735 [podnet.py] => Task 0, Epoch 177/300 (LR 0.03605) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.73, Test_acc 85.23
2024-09-02 10:38:24,462 [podnet.py] => Task 0, Epoch 178/300 (LR 0.03555) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 85.83
2024-09-02 10:38:27,242 [podnet.py] => Task 0, Epoch 179/300 (LR 0.03505) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.55, Test_acc 83.43
2024-09-02 10:38:29,784 [podnet.py] => Task 0, Epoch 180/300 (LR 0.03455) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 88.90
2024-09-02 10:38:31,852 [podnet.py] => Task 0, Epoch 181/300 (LR 0.03405) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 88.60
2024-09-02 10:38:34,758 [podnet.py] => Task 0, Epoch 182/300 (LR 0.03356) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.73
2024-09-02 10:38:37,687 [podnet.py] => Task 0, Epoch 183/300 (LR 0.03306) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.73
2024-09-02 10:38:40,726 [podnet.py] => Task 0, Epoch 184/300 (LR 0.03257) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.11, Test_acc 88.17
2024-09-02 10:38:43,441 [podnet.py] => Task 0, Epoch 185/300 (LR 0.03208) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 87.47
2024-09-02 10:38:46,224 [podnet.py] => Task 0, Epoch 186/300 (LR 0.03159) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 79.03
2024-09-02 10:38:49,036 [podnet.py] => Task 0, Epoch 187/300 (LR 0.03111) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.53, Test_acc 84.80
2024-09-02 10:38:51,825 [podnet.py] => Task 0, Epoch 188/300 (LR 0.03062) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.47, Test_acc 85.53
2024-09-02 10:38:54,877 [podnet.py] => Task 0, Epoch 189/300 (LR 0.03014) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.35, Test_acc 88.90
2024-09-02 10:38:57,472 [podnet.py] => Task 0, Epoch 190/300 (LR 0.02966) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 86.80
2024-09-02 10:38:59,703 [podnet.py] => Task 0, Epoch 191/300 (LR 0.02919) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.20
2024-09-02 10:39:02,271 [podnet.py] => Task 0, Epoch 192/300 (LR 0.02871) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 86.90
2024-09-02 10:39:05,119 [podnet.py] => Task 0, Epoch 193/300 (LR 0.02824) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 89.30
2024-09-02 10:39:07,052 [podnet.py] => Task 0, Epoch 194/300 (LR 0.02777) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.27
2024-09-02 10:39:09,036 [podnet.py] => Task 0, Epoch 195/300 (LR 0.02730) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.47
2024-09-02 10:39:10,937 [podnet.py] => Task 0, Epoch 196/300 (LR 0.02684) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.73
2024-09-02 10:39:13,666 [podnet.py] => Task 0, Epoch 197/300 (LR 0.02637) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.63
2024-09-02 10:39:16,446 [podnet.py] => Task 0, Epoch 198/300 (LR 0.02591) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.23
2024-09-02 10:39:19,262 [podnet.py] => Task 0, Epoch 199/300 (LR 0.02545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.60
2024-09-02 10:39:21,708 [podnet.py] => Task 0, Epoch 200/300 (LR 0.02500) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.67
2024-09-02 10:39:23,124 [podnet.py] => Task 0, Epoch 201/300 (LR 0.02455) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.67
2024-09-02 10:39:25,847 [podnet.py] => Task 0, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 88.40
2024-09-02 10:39:28,438 [podnet.py] => Task 0, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.02, Test_acc 88.30
2024-09-02 10:39:30,800 [podnet.py] => Task 0, Epoch 204/300 (LR 0.02321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 87.87
2024-09-02 10:39:33,214 [podnet.py] => Task 0, Epoch 205/300 (LR 0.02277) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 88.73
2024-09-02 10:39:36,109 [podnet.py] => Task 0, Epoch 206/300 (LR 0.02233) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.10
2024-09-02 10:39:38,615 [podnet.py] => Task 0, Epoch 207/300 (LR 0.02190) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.13
2024-09-02 10:39:41,095 [podnet.py] => Task 0, Epoch 208/300 (LR 0.02146) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 88.40
2024-09-02 10:39:43,847 [podnet.py] => Task 0, Epoch 209/300 (LR 0.02104) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 89.43
2024-09-02 10:39:46,233 [podnet.py] => Task 0, Epoch 210/300 (LR 0.02061) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.40
2024-09-02 10:39:48,837 [podnet.py] => Task 0, Epoch 211/300 (LR 0.02019) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 86.90
2024-09-02 10:39:50,244 [podnet.py] => Task 0, Epoch 212/300 (LR 0.01977) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 86.67
2024-09-02 10:39:52,647 [podnet.py] => Task 0, Epoch 213/300 (LR 0.01935) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.37
2024-09-02 10:39:54,492 [podnet.py] => Task 0, Epoch 214/300 (LR 0.01894) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 89.67
2024-09-02 10:39:57,123 [podnet.py] => Task 0, Epoch 215/300 (LR 0.01853) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 89.77
2024-09-02 10:40:00,154 [podnet.py] => Task 0, Epoch 216/300 (LR 0.01813) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.20
2024-09-02 10:40:03,051 [podnet.py] => Task 0, Epoch 217/300 (LR 0.01773) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.83
2024-09-02 10:40:05,690 [podnet.py] => Task 0, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.16, Test_acc 89.30
2024-09-02 10:40:07,916 [podnet.py] => Task 0, Epoch 219/300 (LR 0.01693) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 88.13
2024-09-02 10:40:09,791 [podnet.py] => Task 0, Epoch 220/300 (LR 0.01654) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.87, Test_acc 89.87
2024-09-02 10:40:12,079 [podnet.py] => Task 0, Epoch 221/300 (LR 0.01616) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.98, Test_acc 89.27
2024-09-02 10:40:14,937 [podnet.py] => Task 0, Epoch 222/300 (LR 0.01577) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 10:40:16,854 [podnet.py] => Task 0, Epoch 223/300 (LR 0.01539) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 10:40:19,593 [podnet.py] => Task 0, Epoch 224/300 (LR 0.01502) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 10:40:22,079 [podnet.py] => Task 0, Epoch 225/300 (LR 0.01464) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 10:40:25,116 [podnet.py] => Task 0, Epoch 226/300 (LR 0.01428) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 10:40:27,464 [podnet.py] => Task 0, Epoch 227/300 (LR 0.01391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 10:40:30,084 [podnet.py] => Task 0, Epoch 228/300 (LR 0.01355) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.33
2024-09-02 10:40:33,010 [podnet.py] => Task 0, Epoch 229/300 (LR 0.01320) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 10:40:36,062 [podnet.py] => Task 0, Epoch 230/300 (LR 0.01284) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.13
2024-09-02 10:40:38,459 [podnet.py] => Task 0, Epoch 231/300 (LR 0.01249) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.00
2024-09-02 10:40:41,271 [podnet.py] => Task 0, Epoch 232/300 (LR 0.01215) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.90
2024-09-02 10:40:43,960 [podnet.py] => Task 0, Epoch 233/300 (LR 0.01181) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.07
2024-09-02 10:40:46,836 [podnet.py] => Task 0, Epoch 234/300 (LR 0.01147) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.10
2024-09-02 10:40:49,205 [podnet.py] => Task 0, Epoch 235/300 (LR 0.01114) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.03
2024-09-02 10:40:52,184 [podnet.py] => Task 0, Epoch 236/300 (LR 0.01082) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 89.43
2024-09-02 10:40:53,815 [podnet.py] => Task 0, Epoch 237/300 (LR 0.01049) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 10:40:56,757 [podnet.py] => Task 0, Epoch 238/300 (LR 0.01017) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 10:40:59,497 [podnet.py] => Task 0, Epoch 239/300 (LR 0.00986) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 10:41:02,534 [podnet.py] => Task 0, Epoch 240/300 (LR 0.00955) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 10:41:05,153 [podnet.py] => Task 0, Epoch 241/300 (LR 0.00924) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 10:41:07,684 [podnet.py] => Task 0, Epoch 242/300 (LR 0.00894) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.33
2024-09-02 10:41:10,499 [podnet.py] => Task 0, Epoch 243/300 (LR 0.00865) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 10:41:13,239 [podnet.py] => Task 0, Epoch 244/300 (LR 0.00835) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 10:41:15,347 [podnet.py] => Task 0, Epoch 245/300 (LR 0.00807) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.73
2024-09-02 10:41:17,958 [podnet.py] => Task 0, Epoch 246/300 (LR 0.00778) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 10:41:21,119 [podnet.py] => Task 0, Epoch 247/300 (LR 0.00751) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 10:41:23,936 [podnet.py] => Task 0, Epoch 248/300 (LR 0.00723) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 10:41:26,492 [podnet.py] => Task 0, Epoch 249/300 (LR 0.00696) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 10:41:29,423 [podnet.py] => Task 0, Epoch 250/300 (LR 0.00670) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 10:41:31,370 [podnet.py] => Task 0, Epoch 251/300 (LR 0.00644) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 10:41:33,207 [podnet.py] => Task 0, Epoch 252/300 (LR 0.00618) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 10:41:35,055 [podnet.py] => Task 0, Epoch 253/300 (LR 0.00593) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 10:41:37,471 [podnet.py] => Task 0, Epoch 254/300 (LR 0.00569) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 10:41:40,435 [podnet.py] => Task 0, Epoch 255/300 (LR 0.00545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 10:41:43,226 [podnet.py] => Task 0, Epoch 256/300 (LR 0.00521) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 10:41:45,149 [podnet.py] => Task 0, Epoch 257/300 (LR 0.00498) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.57
2024-09-02 10:41:47,710 [podnet.py] => Task 0, Epoch 258/300 (LR 0.00476) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.87
2024-09-02 10:41:49,171 [podnet.py] => Task 0, Epoch 259/300 (LR 0.00454) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 10:41:51,756 [podnet.py] => Task 0, Epoch 260/300 (LR 0.00432) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.77
2024-09-02 10:41:53,665 [podnet.py] => Task 0, Epoch 261/300 (LR 0.00411) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 10:41:55,531 [podnet.py] => Task 0, Epoch 262/300 (LR 0.00391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 10:41:57,338 [podnet.py] => Task 0, Epoch 263/300 (LR 0.00371) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.80
2024-09-02 10:41:59,998 [podnet.py] => Task 0, Epoch 264/300 (LR 0.00351) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 10:42:02,444 [podnet.py] => Task 0, Epoch 265/300 (LR 0.00332) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 10:42:05,281 [podnet.py] => Task 0, Epoch 266/300 (LR 0.00314) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 10:42:07,145 [podnet.py] => Task 0, Epoch 267/300 (LR 0.00296) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 10:42:09,571 [podnet.py] => Task 0, Epoch 268/300 (LR 0.00278) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 10:42:11,160 [podnet.py] => Task 0, Epoch 269/300 (LR 0.00261) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 10:42:13,756 [podnet.py] => Task 0, Epoch 270/300 (LR 0.00245) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.63
2024-09-02 10:42:16,567 [podnet.py] => Task 0, Epoch 271/300 (LR 0.00229) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 10:42:18,550 [podnet.py] => Task 0, Epoch 272/300 (LR 0.00213) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 10:42:21,564 [podnet.py] => Task 0, Epoch 273/300 (LR 0.00199) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 10:42:23,636 [podnet.py] => Task 0, Epoch 274/300 (LR 0.00184) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 10:42:25,589 [podnet.py] => Task 0, Epoch 275/300 (LR 0.00170) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 10:42:28,088 [podnet.py] => Task 0, Epoch 276/300 (LR 0.00157) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 10:42:30,099 [podnet.py] => Task 0, Epoch 277/300 (LR 0.00144) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 10:42:32,889 [podnet.py] => Task 0, Epoch 278/300 (LR 0.00132) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.70
2024-09-02 10:42:35,048 [podnet.py] => Task 0, Epoch 279/300 (LR 0.00120) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 88.97
2024-09-02 10:42:37,682 [podnet.py] => Task 0, Epoch 280/300 (LR 0.00109) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 10:42:40,699 [podnet.py] => Task 0, Epoch 281/300 (LR 0.00099) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 10:42:42,201 [podnet.py] => Task 0, Epoch 282/300 (LR 0.00089) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 10:42:44,893 [podnet.py] => Task 0, Epoch 283/300 (LR 0.00079) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 10:42:46,816 [podnet.py] => Task 0, Epoch 284/300 (LR 0.00070) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 10:42:48,675 [podnet.py] => Task 0, Epoch 285/300 (LR 0.00062) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 10:42:50,617 [podnet.py] => Task 0, Epoch 286/300 (LR 0.00054) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 10:42:52,992 [podnet.py] => Task 0, Epoch 287/300 (LR 0.00046) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.17
2024-09-02 10:42:55,816 [podnet.py] => Task 0, Epoch 288/300 (LR 0.00039) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 10:42:58,414 [podnet.py] => Task 0, Epoch 289/300 (LR 0.00033) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 10:43:00,522 [podnet.py] => Task 0, Epoch 290/300 (LR 0.00027) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 10:43:02,456 [podnet.py] => Task 0, Epoch 291/300 (LR 0.00022) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 10:43:04,388 [podnet.py] => Task 0, Epoch 292/300 (LR 0.00018) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 10:43:06,541 [podnet.py] => Task 0, Epoch 293/300 (LR 0.00013) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.97
2024-09-02 10:43:08,609 [podnet.py] => Task 0, Epoch 294/300 (LR 0.00010) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 10:43:11,326 [podnet.py] => Task 0, Epoch 295/300 (LR 0.00007) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 10:43:14,322 [podnet.py] => Task 0, Epoch 296/300 (LR 0.00004) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.17
2024-09-02 10:43:16,694 [podnet.py] => Task 0, Epoch 297/300 (LR 0.00002) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.87
2024-09-02 10:43:18,922 [podnet.py] => Task 0, Epoch 298/300 (LR 0.00001) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 10:43:21,843 [podnet.py] => Task 0, Epoch 299/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 10:43:24,763 [podnet.py] => Task 0, Epoch 300/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.90
2024-09-02 10:43:24,764 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 10:43:24,764 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 10:43:29,741 [podnet.py] => Exemplar size: 500
2024-09-02 10:43:29,742 [trainer.py] => CNN: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 10:43:29,742 [trainer.py] => NME: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 10:43:29,742 [trainer.py] => CNN top1 curve: [88.9]
2024-09-02 10:43:29,742 [trainer.py] => CNN top5 curve: [100.0]
2024-09-02 10:43:29,742 [trainer.py] => NME top1 curve: [88.9]
2024-09-02 10:43:29,742 [trainer.py] => NME top5 curve: [100.0]

2024-09-02 10:43:29,742 [trainer.py] => Average Accuracy (CNN): 88.9
2024-09-02 10:43:29,742 [trainer.py] => Average Accuracy (NME): 88.9
2024-09-02 10:43:29,742 [trainer.py] => All params: 3869505
2024-09-02 10:43:29,742 [trainer.py] => Trainable params: 3869505
2024-09-02 10:43:29,743 [podnet.py] => Learning on 5-7
2024-09-02 10:43:29,757 [podnet.py] => Adaptive factor: 1.8708286933869707
2024-09-02 10:43:32,058 [podnet.py] => Task 1, Epoch 1/300 (LR 0.10000) => LSC_loss 1.13, Spatial_loss 0.31, Flat_loss 0.81, Train_acc 72.49, Test_acc 27.50
2024-09-02 10:43:34,199 [podnet.py] => Task 1, Epoch 2/300 (LR 0.09999) => LSC_loss 0.55, Spatial_loss 0.27, Flat_loss 0.59, Train_acc 86.64, Test_acc 44.10
2024-09-02 10:43:36,222 [podnet.py] => Task 1, Epoch 3/300 (LR 0.09998) => LSC_loss 0.42, Spatial_loss 0.25, Flat_loss 0.51, Train_acc 89.71, Test_acc 41.57
2024-09-02 10:43:38,251 [podnet.py] => Task 1, Epoch 4/300 (LR 0.09996) => LSC_loss 0.39, Spatial_loss 0.26, Flat_loss 0.48, Train_acc 89.98, Test_acc 35.31
2024-09-02 10:43:40,489 [podnet.py] => Task 1, Epoch 5/300 (LR 0.09993) => LSC_loss 0.30, Spatial_loss 0.25, Flat_loss 0.44, Train_acc 92.73, Test_acc 50.14
2024-09-02 10:43:42,672 [podnet.py] => Task 1, Epoch 6/300 (LR 0.09990) => LSC_loss 0.23, Spatial_loss 0.21, Flat_loss 0.40, Train_acc 94.51, Test_acc 53.07
2024-09-02 10:43:44,668 [podnet.py] => Task 1, Epoch 7/300 (LR 0.09987) => LSC_loss 0.19, Spatial_loss 0.20, Flat_loss 0.37, Train_acc 95.27, Test_acc 60.26
2024-09-02 10:43:46,702 [podnet.py] => Task 1, Epoch 8/300 (LR 0.09982) => LSC_loss 0.16, Spatial_loss 0.19, Flat_loss 0.35, Train_acc 95.89, Test_acc 56.93
2024-09-02 10:43:48,789 [podnet.py] => Task 1, Epoch 9/300 (LR 0.09978) => LSC_loss 0.14, Spatial_loss 0.17, Flat_loss 0.35, Train_acc 96.67, Test_acc 57.57
2024-09-02 10:43:50,976 [podnet.py] => Task 1, Epoch 10/300 (LR 0.09973) => LSC_loss 0.11, Spatial_loss 0.16, Flat_loss 0.32, Train_acc 97.89, Test_acc 58.71
2024-09-02 10:43:53,269 [podnet.py] => Task 1, Epoch 11/300 (LR 0.09967) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.31, Train_acc 98.64, Test_acc 60.79
2024-09-02 10:43:54,429 [podnet.py] => Task 1, Epoch 12/300 (LR 0.09961) => LSC_loss 0.09, Spatial_loss 0.14, Flat_loss 0.30, Train_acc 98.60, Test_acc 62.31
2024-09-02 10:43:56,455 [podnet.py] => Task 1, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.30, Train_acc 98.64, Test_acc 61.88
2024-09-02 10:43:58,547 [podnet.py] => Task 1, Epoch 14/300 (LR 0.09946) => LSC_loss 0.07, Spatial_loss 0.13, Flat_loss 0.27, Train_acc 99.47, Test_acc 61.21
2024-09-02 10:43:59,743 [podnet.py] => Task 1, Epoch 15/300 (LR 0.09938) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.28, Train_acc 99.20, Test_acc 63.88
2024-09-02 10:44:02,021 [podnet.py] => Task 1, Epoch 16/300 (LR 0.09930) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.27, Train_acc 99.71, Test_acc 65.02
2024-09-02 10:44:03,816 [podnet.py] => Task 1, Epoch 17/300 (LR 0.09921) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.26, Train_acc 99.64, Test_acc 62.36
2024-09-02 10:44:05,693 [podnet.py] => Task 1, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 99.04, Test_acc 61.14
2024-09-02 10:44:07,562 [podnet.py] => Task 1, Epoch 19/300 (LR 0.09901) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.28, Train_acc 99.18, Test_acc 62.62
2024-09-02 10:44:09,914 [podnet.py] => Task 1, Epoch 20/300 (LR 0.09891) => LSC_loss 0.08, Spatial_loss 0.15, Flat_loss 0.29, Train_acc 98.53, Test_acc 59.86
2024-09-02 10:44:11,943 [podnet.py] => Task 1, Epoch 21/300 (LR 0.09880) => LSC_loss 0.19, Spatial_loss 0.22, Flat_loss 0.36, Train_acc 94.80, Test_acc 47.90
2024-09-02 10:44:14,072 [podnet.py] => Task 1, Epoch 22/300 (LR 0.09868) => LSC_loss 0.14, Spatial_loss 0.21, Flat_loss 0.34, Train_acc 96.87, Test_acc 58.90
2024-09-02 10:44:15,886 [podnet.py] => Task 1, Epoch 23/300 (LR 0.09856) => LSC_loss 0.09, Spatial_loss 0.18, Flat_loss 0.31, Train_acc 98.09, Test_acc 60.88
2024-09-02 10:44:17,848 [podnet.py] => Task 1, Epoch 24/300 (LR 0.09843) => LSC_loss 0.07, Spatial_loss 0.15, Flat_loss 0.29, Train_acc 98.96, Test_acc 59.36
2024-09-02 10:44:19,949 [podnet.py] => Task 1, Epoch 25/300 (LR 0.09830) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 99.58, Test_acc 64.83
2024-09-02 10:44:21,955 [podnet.py] => Task 1, Epoch 26/300 (LR 0.09816) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.91, Test_acc 66.60
2024-09-02 10:44:24,072 [podnet.py] => Task 1, Epoch 27/300 (LR 0.09801) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.33, Test_acc 55.90
2024-09-02 10:44:26,022 [podnet.py] => Task 1, Epoch 28/300 (LR 0.09787) => LSC_loss 0.09, Spatial_loss 0.16, Flat_loss 0.31, Train_acc 98.38, Test_acc 48.86
2024-09-02 10:44:28,235 [podnet.py] => Task 1, Epoch 29/300 (LR 0.09771) => LSC_loss 0.33, Spatial_loss 0.28, Flat_loss 0.43, Train_acc 92.36, Test_acc 41.38
2024-09-02 10:44:30,533 [podnet.py] => Task 1, Epoch 30/300 (LR 0.09755) => LSC_loss 0.21, Spatial_loss 0.26, Flat_loss 0.41, Train_acc 93.96, Test_acc 58.45
2024-09-02 10:44:32,623 [podnet.py] => Task 1, Epoch 31/300 (LR 0.09739) => LSC_loss 0.10, Spatial_loss 0.20, Flat_loss 0.33, Train_acc 98.20, Test_acc 64.07
2024-09-02 10:44:34,525 [podnet.py] => Task 1, Epoch 32/300 (LR 0.09722) => LSC_loss 0.06, Spatial_loss 0.16, Flat_loss 0.30, Train_acc 99.31, Test_acc 61.93
2024-09-02 10:44:36,739 [podnet.py] => Task 1, Epoch 33/300 (LR 0.09704) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.26, Train_acc 99.93, Test_acc 63.38
2024-09-02 10:44:38,787 [podnet.py] => Task 1, Epoch 34/300 (LR 0.09686) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.87, Test_acc 66.98
2024-09-02 10:44:40,995 [podnet.py] => Task 1, Epoch 35/300 (LR 0.09668) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.93, Test_acc 64.50
2024-09-02 10:44:43,015 [podnet.py] => Task 1, Epoch 36/300 (LR 0.09649) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.93, Test_acc 67.02
2024-09-02 10:44:45,373 [podnet.py] => Task 1, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.60, Test_acc 66.29
2024-09-02 10:44:47,381 [podnet.py] => Task 1, Epoch 38/300 (LR 0.09609) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.25, Train_acc 99.62, Test_acc 67.79
2024-09-02 10:44:49,292 [podnet.py] => Task 1, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.80, Test_acc 68.33
2024-09-02 10:44:51,333 [podnet.py] => Task 1, Epoch 40/300 (LR 0.09568) => LSC_loss 0.06, Spatial_loss 0.11, Flat_loss 0.23, Train_acc 99.76, Test_acc 56.60
2024-09-02 10:44:53,567 [podnet.py] => Task 1, Epoch 41/300 (LR 0.09546) => LSC_loss 0.09, Spatial_loss 0.17, Flat_loss 0.29, Train_acc 98.31, Test_acc 53.64
2024-09-02 10:44:55,718 [podnet.py] => Task 1, Epoch 42/300 (LR 0.09524) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.27, Train_acc 99.51, Test_acc 59.02
2024-09-02 10:44:57,837 [podnet.py] => Task 1, Epoch 43/300 (LR 0.09502) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.24, Train_acc 99.78, Test_acc 66.93
2024-09-02 10:44:59,960 [podnet.py] => Task 1, Epoch 44/300 (LR 0.09479) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.89, Test_acc 66.26
2024-09-02 10:45:02,092 [podnet.py] => Task 1, Epoch 45/300 (LR 0.09455) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.89, Test_acc 64.71
2024-09-02 10:45:04,275 [podnet.py] => Task 1, Epoch 46/300 (LR 0.09431) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.87, Test_acc 67.62
2024-09-02 10:45:06,405 [podnet.py] => Task 1, Epoch 47/300 (LR 0.09407) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.93, Test_acc 67.38
2024-09-02 10:45:08,696 [podnet.py] => Task 1, Epoch 48/300 (LR 0.09382) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.96, Test_acc 62.26
2024-09-02 10:45:10,717 [podnet.py] => Task 1, Epoch 49/300 (LR 0.09356) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.96, Test_acc 70.19
2024-09-02 10:45:12,943 [podnet.py] => Task 1, Epoch 50/300 (LR 0.09330) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.91, Test_acc 66.86
2024-09-02 10:45:14,922 [podnet.py] => Task 1, Epoch 51/300 (LR 0.09304) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 65.43
2024-09-02 10:45:17,046 [podnet.py] => Task 1, Epoch 52/300 (LR 0.09277) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.93, Test_acc 67.31
2024-09-02 10:45:19,235 [podnet.py] => Task 1, Epoch 53/300 (LR 0.09249) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.20, Train_acc 99.84, Test_acc 69.00
2024-09-02 10:45:21,511 [podnet.py] => Task 1, Epoch 54/300 (LR 0.09222) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.96, Test_acc 70.07
2024-09-02 10:45:23,421 [podnet.py] => Task 1, Epoch 55/300 (LR 0.09193) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.91, Test_acc 64.26
2024-09-02 10:45:25,611 [podnet.py] => Task 1, Epoch 56/300 (LR 0.09165) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.91, Test_acc 69.52
2024-09-02 10:45:27,552 [podnet.py] => Task 1, Epoch 57/300 (LR 0.09135) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 65.64
2024-09-02 10:45:29,567 [podnet.py] => Task 1, Epoch 58/300 (LR 0.09106) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 68.40
2024-09-02 10:45:31,501 [podnet.py] => Task 1, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 65.05
2024-09-02 10:45:33,547 [podnet.py] => Task 1, Epoch 60/300 (LR 0.09045) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.24, Train_acc 98.69, Test_acc 48.98
2024-09-02 10:45:35,623 [podnet.py] => Task 1, Epoch 61/300 (LR 0.09014) => LSC_loss 0.28, Spatial_loss 0.23, Flat_loss 0.39, Train_acc 92.73, Test_acc 20.19
2024-09-02 10:45:37,670 [podnet.py] => Task 1, Epoch 62/300 (LR 0.08983) => LSC_loss 0.38, Spatial_loss 0.33, Flat_loss 0.48, Train_acc 89.91, Test_acc 43.38
2024-09-02 10:45:39,675 [podnet.py] => Task 1, Epoch 63/300 (LR 0.08951) => LSC_loss 0.14, Spatial_loss 0.24, Flat_loss 0.36, Train_acc 96.29, Test_acc 57.38
2024-09-02 10:45:41,750 [podnet.py] => Task 1, Epoch 64/300 (LR 0.08918) => LSC_loss 0.07, Spatial_loss 0.18, Flat_loss 0.30, Train_acc 98.87, Test_acc 66.93
2024-09-02 10:45:43,617 [podnet.py] => Task 1, Epoch 65/300 (LR 0.08886) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.26, Train_acc 99.62, Test_acc 63.86
2024-09-02 10:45:45,379 [podnet.py] => Task 1, Epoch 66/300 (LR 0.08853) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.73, Test_acc 64.62
2024-09-02 10:45:47,338 [podnet.py] => Task 1, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.84, Test_acc 62.93
2024-09-02 10:45:49,174 [podnet.py] => Task 1, Epoch 68/300 (LR 0.08785) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.21, Train_acc 99.98, Test_acc 65.55
2024-09-02 10:45:51,214 [podnet.py] => Task 1, Epoch 69/300 (LR 0.08751) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.87, Test_acc 65.86
2024-09-02 10:45:53,265 [podnet.py] => Task 1, Epoch 70/300 (LR 0.08716) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.20, Train_acc 99.96, Test_acc 68.02
2024-09-02 10:45:55,310 [podnet.py] => Task 1, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.89, Test_acc 66.21
2024-09-02 10:45:57,497 [podnet.py] => Task 1, Epoch 72/300 (LR 0.08645) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.91, Test_acc 66.07
2024-09-02 10:45:59,532 [podnet.py] => Task 1, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 100.00, Test_acc 69.02
2024-09-02 10:46:01,788 [podnet.py] => Task 1, Epoch 74/300 (LR 0.08572) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.18, Train_acc 99.91, Test_acc 64.69
2024-09-02 10:46:03,900 [podnet.py] => Task 1, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.91, Test_acc 64.60
2024-09-02 10:46:05,890 [podnet.py] => Task 1, Epoch 76/300 (LR 0.08498) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.93, Test_acc 64.67
2024-09-02 10:46:07,599 [podnet.py] => Task 1, Epoch 77/300 (LR 0.08461) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.93, Test_acc 64.45
2024-09-02 10:46:09,210 [podnet.py] => Task 1, Epoch 78/300 (LR 0.08423) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.23, Train_acc 99.29, Test_acc 61.98
2024-09-02 10:46:11,328 [podnet.py] => Task 1, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.91, Test_acc 67.79
2024-09-02 10:46:13,410 [podnet.py] => Task 1, Epoch 80/300 (LR 0.08346) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.93, Test_acc 66.40
2024-09-02 10:46:15,460 [podnet.py] => Task 1, Epoch 81/300 (LR 0.08307) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 100.00, Test_acc 69.36
2024-09-02 10:46:17,447 [podnet.py] => Task 1, Epoch 82/300 (LR 0.08267) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.87, Test_acc 67.19
2024-09-02 10:46:19,576 [podnet.py] => Task 1, Epoch 83/300 (LR 0.08227) => LSC_loss 0.08, Spatial_loss 0.13, Flat_loss 0.27, Train_acc 98.27, Test_acc 33.88
2024-09-02 10:46:21,706 [podnet.py] => Task 1, Epoch 84/300 (LR 0.08187) => LSC_loss 0.44, Spatial_loss 0.26, Flat_loss 0.49, Train_acc 89.44, Test_acc 45.60
2024-09-02 10:46:23,942 [podnet.py] => Task 1, Epoch 85/300 (LR 0.08147) => LSC_loss 0.31, Spatial_loss 0.29, Flat_loss 0.45, Train_acc 91.76, Test_acc 52.60
2024-09-02 10:46:25,408 [podnet.py] => Task 1, Epoch 86/300 (LR 0.08106) => LSC_loss 0.14, Spatial_loss 0.24, Flat_loss 0.39, Train_acc 96.29, Test_acc 59.29
2024-09-02 10:46:27,705 [podnet.py] => Task 1, Epoch 87/300 (LR 0.08065) => LSC_loss 0.07, Spatial_loss 0.19, Flat_loss 0.32, Train_acc 98.80, Test_acc 57.43
2024-09-02 10:46:29,722 [podnet.py] => Task 1, Epoch 88/300 (LR 0.08023) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.28, Train_acc 99.76, Test_acc 61.31
2024-09-02 10:46:31,896 [podnet.py] => Task 1, Epoch 89/300 (LR 0.07981) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.26, Train_acc 99.93, Test_acc 63.52
2024-09-02 10:46:33,982 [podnet.py] => Task 1, Epoch 90/300 (LR 0.07939) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.91, Test_acc 65.36
2024-09-02 10:46:35,849 [podnet.py] => Task 1, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.96, Test_acc 68.24
2024-09-02 10:46:38,072 [podnet.py] => Task 1, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.73, Test_acc 66.52
2024-09-02 10:46:40,132 [podnet.py] => Task 1, Epoch 93/300 (LR 0.07810) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.87, Test_acc 64.79
2024-09-02 10:46:41,932 [podnet.py] => Task 1, Epoch 94/300 (LR 0.07767) => LSC_loss 0.09, Spatial_loss 0.17, Flat_loss 0.32, Train_acc 98.18, Test_acc 61.71
2024-09-02 10:46:43,829 [podnet.py] => Task 1, Epoch 95/300 (LR 0.07723) => LSC_loss 0.06, Spatial_loss 0.16, Flat_loss 0.29, Train_acc 99.11, Test_acc 59.48
2024-09-02 10:46:45,807 [podnet.py] => Task 1, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.25, Train_acc 99.73, Test_acc 60.81
2024-09-02 10:46:47,977 [podnet.py] => Task 1, Epoch 97/300 (LR 0.07635) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.23, Train_acc 99.87, Test_acc 66.02
2024-09-02 10:46:49,898 [podnet.py] => Task 1, Epoch 98/300 (LR 0.07590) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.93, Test_acc 64.95
2024-09-02 10:46:52,066 [podnet.py] => Task 1, Epoch 99/300 (LR 0.07545) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.84, Test_acc 67.64
2024-09-02 10:46:54,055 [podnet.py] => Task 1, Epoch 100/300 (LR 0.07500) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.93, Test_acc 47.29
2024-09-02 10:46:56,107 [podnet.py] => Task 1, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.23, Train_acc 99.89, Test_acc 63.45
2024-09-02 10:46:58,238 [podnet.py] => Task 1, Epoch 102/300 (LR 0.07409) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.96, Test_acc 67.14
2024-09-02 10:47:00,277 [podnet.py] => Task 1, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.93, Test_acc 66.12
2024-09-02 10:47:02,301 [podnet.py] => Task 1, Epoch 104/300 (LR 0.07316) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.96, Test_acc 68.21
2024-09-02 10:47:04,469 [podnet.py] => Task 1, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 100.00, Test_acc 67.14
2024-09-02 10:47:06,756 [podnet.py] => Task 1, Epoch 106/300 (LR 0.07223) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.87, Test_acc 66.60
2024-09-02 10:47:08,664 [podnet.py] => Task 1, Epoch 107/300 (LR 0.07176) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.91, Test_acc 67.14
2024-09-02 10:47:10,467 [podnet.py] => Task 1, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.91, Test_acc 66.83
2024-09-02 10:47:12,685 [podnet.py] => Task 1, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.82, Test_acc 65.52
2024-09-02 10:47:14,783 [podnet.py] => Task 1, Epoch 110/300 (LR 0.07034) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.82, Test_acc 64.95
2024-09-02 10:47:16,794 [podnet.py] => Task 1, Epoch 111/300 (LR 0.06986) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.20, Train_acc 99.84, Test_acc 66.76
2024-09-02 10:47:18,905 [podnet.py] => Task 1, Epoch 112/300 (LR 0.06938) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 100.00, Test_acc 68.74
2024-09-02 10:47:21,226 [podnet.py] => Task 1, Epoch 113/300 (LR 0.06889) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 70.12
2024-09-02 10:47:23,398 [podnet.py] => Task 1, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.93, Test_acc 74.17
2024-09-02 10:47:25,468 [podnet.py] => Task 1, Epoch 115/300 (LR 0.06792) => LSC_loss 0.06, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.07, Test_acc 67.29
2024-09-02 10:47:27,655 [podnet.py] => Task 1, Epoch 116/300 (LR 0.06743) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.91, Test_acc 66.64
2024-09-02 10:47:29,766 [podnet.py] => Task 1, Epoch 117/300 (LR 0.06694) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 67.52
2024-09-02 10:47:31,787 [podnet.py] => Task 1, Epoch 118/300 (LR 0.06644) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 67.55
2024-09-02 10:47:33,776 [podnet.py] => Task 1, Epoch 119/300 (LR 0.06595) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 68.02
2024-09-02 10:47:35,937 [podnet.py] => Task 1, Epoch 120/300 (LR 0.06545) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 66.33
2024-09-02 10:47:38,124 [podnet.py] => Task 1, Epoch 121/300 (LR 0.06495) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 71.10
2024-09-02 10:47:40,365 [podnet.py] => Task 1, Epoch 122/300 (LR 0.06445) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.50
2024-09-02 10:47:42,486 [podnet.py] => Task 1, Epoch 123/300 (LR 0.06395) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.91, Test_acc 68.60
2024-09-02 10:47:44,504 [podnet.py] => Task 1, Epoch 124/300 (LR 0.06345) => LSC_loss 0.06, Spatial_loss 0.11, Flat_loss 0.23, Train_acc 99.31, Test_acc 68.98
2024-09-02 10:47:46,705 [podnet.py] => Task 1, Epoch 125/300 (LR 0.06294) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.89, Test_acc 64.98
2024-09-02 10:47:48,854 [podnet.py] => Task 1, Epoch 126/300 (LR 0.06243) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.20, Train_acc 99.91, Test_acc 65.29
2024-09-02 10:47:50,992 [podnet.py] => Task 1, Epoch 127/300 (LR 0.06193) => LSC_loss 0.12, Spatial_loss 0.17, Flat_loss 0.29, Train_acc 97.47, Test_acc 35.69
2024-09-02 10:47:53,015 [podnet.py] => Task 1, Epoch 128/300 (LR 0.06142) => LSC_loss 0.32, Spatial_loss 0.27, Flat_loss 0.42, Train_acc 91.84, Test_acc 43.71
2024-09-02 10:47:55,282 [podnet.py] => Task 1, Epoch 129/300 (LR 0.06091) => LSC_loss 0.20, Spatial_loss 0.24, Flat_loss 0.39, Train_acc 94.51, Test_acc 47.52
2024-09-02 10:47:57,297 [podnet.py] => Task 1, Epoch 130/300 (LR 0.06040) => LSC_loss 0.13, Spatial_loss 0.22, Flat_loss 0.35, Train_acc 96.84, Test_acc 60.38
2024-09-02 10:47:59,219 [podnet.py] => Task 1, Epoch 131/300 (LR 0.05988) => LSC_loss 0.08, Spatial_loss 0.18, Flat_loss 0.31, Train_acc 98.36, Test_acc 61.40
2024-09-02 10:48:01,219 [podnet.py] => Task 1, Epoch 132/300 (LR 0.05937) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.27, Train_acc 99.49, Test_acc 45.88
2024-09-02 10:48:03,346 [podnet.py] => Task 1, Epoch 133/300 (LR 0.05885) => LSC_loss 0.08, Spatial_loss 0.19, Flat_loss 0.30, Train_acc 98.56, Test_acc 61.62
2024-09-02 10:48:05,580 [podnet.py] => Task 1, Epoch 134/300 (LR 0.05834) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.26, Train_acc 99.84, Test_acc 69.07
2024-09-02 10:48:07,684 [podnet.py] => Task 1, Epoch 135/300 (LR 0.05782) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.23, Train_acc 99.91, Test_acc 66.10
2024-09-02 10:48:09,679 [podnet.py] => Task 1, Epoch 136/300 (LR 0.05730) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.22, Train_acc 99.96, Test_acc 67.95
2024-09-02 10:48:11,366 [podnet.py] => Task 1, Epoch 137/300 (LR 0.05679) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 100.00, Test_acc 66.45
2024-09-02 10:48:13,525 [podnet.py] => Task 1, Epoch 138/300 (LR 0.05627) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.96, Test_acc 68.24
2024-09-02 10:48:15,485 [podnet.py] => Task 1, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.20, Train_acc 99.96, Test_acc 67.71
2024-09-02 10:48:17,595 [podnet.py] => Task 1, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.20, Train_acc 99.91, Test_acc 66.40
2024-09-02 10:48:19,790 [podnet.py] => Task 1, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.93, Test_acc 68.12
2024-09-02 10:48:21,996 [podnet.py] => Task 1, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.98, Test_acc 67.00
2024-09-02 10:48:24,226 [podnet.py] => Task 1, Epoch 143/300 (LR 0.05366) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.96, Test_acc 69.40
2024-09-02 10:48:26,050 [podnet.py] => Task 1, Epoch 144/300 (LR 0.05314) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 99.98, Test_acc 68.43
2024-09-02 10:48:28,058 [podnet.py] => Task 1, Epoch 145/300 (LR 0.05262) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.18, Train_acc 99.96, Test_acc 68.45
2024-09-02 10:48:30,081 [podnet.py] => Task 1, Epoch 146/300 (LR 0.05209) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 100.00, Test_acc 69.36
2024-09-02 10:48:31,727 [podnet.py] => Task 1, Epoch 147/300 (LR 0.05157) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 66.31
2024-09-02 10:48:33,830 [podnet.py] => Task 1, Epoch 148/300 (LR 0.05105) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 100.00, Test_acc 68.57
2024-09-02 10:48:35,499 [podnet.py] => Task 1, Epoch 149/300 (LR 0.05052) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 30.29
2024-09-02 10:48:37,422 [podnet.py] => Task 1, Epoch 150/300 (LR 0.05000) => LSC_loss 0.07, Spatial_loss 0.14, Flat_loss 0.29, Train_acc 98.73, Test_acc 60.05
2024-09-02 10:48:39,338 [podnet.py] => Task 1, Epoch 151/300 (LR 0.04948) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.26, Train_acc 99.58, Test_acc 66.76
2024-09-02 10:48:41,416 [podnet.py] => Task 1, Epoch 152/300 (LR 0.04895) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.84, Test_acc 65.57
2024-09-02 10:48:43,244 [podnet.py] => Task 1, Epoch 153/300 (LR 0.04843) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.22, Train_acc 99.84, Test_acc 64.62
2024-09-02 10:48:45,158 [podnet.py] => Task 1, Epoch 154/300 (LR 0.04791) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.96, Test_acc 67.38
2024-09-02 10:48:47,311 [podnet.py] => Task 1, Epoch 155/300 (LR 0.04738) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.93, Test_acc 68.31
2024-09-02 10:48:49,314 [podnet.py] => Task 1, Epoch 156/300 (LR 0.04686) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 100.00, Test_acc 67.05
2024-09-02 10:48:51,587 [podnet.py] => Task 1, Epoch 157/300 (LR 0.04634) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.98, Test_acc 67.36
2024-09-02 10:48:52,735 [podnet.py] => Task 1, Epoch 158/300 (LR 0.04582) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.19, Train_acc 100.00, Test_acc 67.79
2024-09-02 10:48:54,816 [podnet.py] => Task 1, Epoch 159/300 (LR 0.04529) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 100.00, Test_acc 66.83
2024-09-02 10:48:56,899 [podnet.py] => Task 1, Epoch 160/300 (LR 0.04477) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 67.00
2024-09-02 10:48:58,120 [podnet.py] => Task 1, Epoch 161/300 (LR 0.04425) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 100.00, Test_acc 67.31
2024-09-02 10:49:00,224 [podnet.py] => Task 1, Epoch 162/300 (LR 0.04373) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 100.00, Test_acc 68.40
2024-09-02 10:49:02,281 [podnet.py] => Task 1, Epoch 163/300 (LR 0.04321) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 66.14
2024-09-02 10:49:04,330 [podnet.py] => Task 1, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 63.31
2024-09-02 10:49:06,529 [podnet.py] => Task 1, Epoch 165/300 (LR 0.04218) => LSC_loss 0.10, Spatial_loss 0.16, Flat_loss 0.31, Train_acc 97.76, Test_acc 59.02
2024-09-02 10:49:07,994 [podnet.py] => Task 1, Epoch 166/300 (LR 0.04166) => LSC_loss 0.07, Spatial_loss 0.15, Flat_loss 0.28, Train_acc 98.31, Test_acc 62.26
2024-09-02 10:49:10,043 [podnet.py] => Task 1, Epoch 167/300 (LR 0.04115) => LSC_loss 0.10, Spatial_loss 0.15, Flat_loss 0.28, Train_acc 98.71, Test_acc 53.48
2024-09-02 10:49:12,088 [podnet.py] => Task 1, Epoch 168/300 (LR 0.04063) => LSC_loss 0.09, Spatial_loss 0.17, Flat_loss 0.29, Train_acc 98.20, Test_acc 64.33
2024-09-02 10:49:13,985 [podnet.py] => Task 1, Epoch 169/300 (LR 0.04012) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.24, Train_acc 99.82, Test_acc 63.00
2024-09-02 10:49:16,123 [podnet.py] => Task 1, Epoch 170/300 (LR 0.03960) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.91, Test_acc 64.95
2024-09-02 10:49:18,034 [podnet.py] => Task 1, Epoch 171/300 (LR 0.03909) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 100.00, Test_acc 66.48
2024-09-02 10:49:20,121 [podnet.py] => Task 1, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.98, Test_acc 68.52
2024-09-02 10:49:22,335 [podnet.py] => Task 1, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.98, Test_acc 68.57
2024-09-02 10:49:24,384 [podnet.py] => Task 1, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.96, Test_acc 67.40
2024-09-02 10:49:25,696 [podnet.py] => Task 1, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.20, Train_acc 99.96, Test_acc 69.69
2024-09-02 10:49:27,544 [podnet.py] => Task 1, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.87, Test_acc 69.93
2024-09-02 10:49:29,795 [podnet.py] => Task 1, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 67.90
2024-09-02 10:49:31,936 [podnet.py] => Task 1, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 68.71
2024-09-02 10:49:34,017 [podnet.py] => Task 1, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 68.55
2024-09-02 10:49:36,268 [podnet.py] => Task 1, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.52
2024-09-02 10:49:37,505 [podnet.py] => Task 1, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.96, Test_acc 68.14
2024-09-02 10:49:39,664 [podnet.py] => Task 1, Epoch 182/300 (LR 0.03356) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 67.26
2024-09-02 10:49:41,945 [podnet.py] => Task 1, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.10
2024-09-02 10:49:44,018 [podnet.py] => Task 1, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.86
2024-09-02 10:49:46,217 [podnet.py] => Task 1, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.24
2024-09-02 10:49:48,525 [podnet.py] => Task 1, Epoch 186/300 (LR 0.03159) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.55
2024-09-02 10:49:50,755 [podnet.py] => Task 1, Epoch 187/300 (LR 0.03111) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.96, Test_acc 67.19
2024-09-02 10:49:52,947 [podnet.py] => Task 1, Epoch 188/300 (LR 0.03062) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.21, Train_acc 99.80, Test_acc 66.67
2024-09-02 10:49:55,110 [podnet.py] => Task 1, Epoch 189/300 (LR 0.03014) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.20, Train_acc 99.84, Test_acc 67.38
2024-09-02 10:49:56,983 [podnet.py] => Task 1, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.98, Test_acc 67.10
2024-09-02 10:49:59,205 [podnet.py] => Task 1, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.96, Test_acc 66.86
2024-09-02 10:50:01,461 [podnet.py] => Task 1, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 68.43
2024-09-02 10:50:03,415 [podnet.py] => Task 1, Epoch 193/300 (LR 0.02824) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.10
2024-09-02 10:50:05,363 [podnet.py] => Task 1, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.12
2024-09-02 10:50:07,592 [podnet.py] => Task 1, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.18, Train_acc 99.98, Test_acc 67.40
2024-09-02 10:50:09,833 [podnet.py] => Task 1, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 67.48
2024-09-02 10:50:12,118 [podnet.py] => Task 1, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.07
2024-09-02 10:50:14,244 [podnet.py] => Task 1, Epoch 198/300 (LR 0.02591) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.79
2024-09-02 10:50:16,350 [podnet.py] => Task 1, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.86
2024-09-02 10:50:18,610 [podnet.py] => Task 1, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.81
2024-09-02 10:50:20,793 [podnet.py] => Task 1, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 69.19
2024-09-02 10:50:22,974 [podnet.py] => Task 1, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 68.79
2024-09-02 10:50:25,007 [podnet.py] => Task 1, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.69
2024-09-02 10:50:26,948 [podnet.py] => Task 1, Epoch 204/300 (LR 0.02321) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 69.33
2024-09-02 10:50:28,772 [podnet.py] => Task 1, Epoch 205/300 (LR 0.02277) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.50
2024-09-02 10:50:30,666 [podnet.py] => Task 1, Epoch 206/300 (LR 0.02233) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.98, Test_acc 69.40
2024-09-02 10:50:33,012 [podnet.py] => Task 1, Epoch 207/300 (LR 0.02190) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.81
2024-09-02 10:50:35,052 [podnet.py] => Task 1, Epoch 208/300 (LR 0.02146) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.07
2024-09-02 10:50:37,067 [podnet.py] => Task 1, Epoch 209/300 (LR 0.02104) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.60
2024-09-02 10:50:39,061 [podnet.py] => Task 1, Epoch 210/300 (LR 0.02061) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.52
2024-09-02 10:50:41,179 [podnet.py] => Task 1, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.96, Test_acc 70.29
2024-09-02 10:50:43,257 [podnet.py] => Task 1, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.76
2024-09-02 10:50:45,322 [podnet.py] => Task 1, Epoch 213/300 (LR 0.01935) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.93
2024-09-02 10:50:46,934 [podnet.py] => Task 1, Epoch 214/300 (LR 0.01894) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.98, Test_acc 68.71
2024-09-02 10:50:48,944 [podnet.py] => Task 1, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 99.98, Test_acc 68.24
2024-09-02 10:50:51,105 [podnet.py] => Task 1, Epoch 216/300 (LR 0.01813) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.91, Test_acc 70.74
2024-09-02 10:50:53,449 [podnet.py] => Task 1, Epoch 217/300 (LR 0.01773) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 67.86
2024-09-02 10:50:55,845 [podnet.py] => Task 1, Epoch 218/300 (LR 0.01733) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.57
2024-09-02 10:50:57,876 [podnet.py] => Task 1, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.76
2024-09-02 10:50:59,930 [podnet.py] => Task 1, Epoch 220/300 (LR 0.01654) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 68.57
2024-09-02 10:51:02,070 [podnet.py] => Task 1, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.96, Test_acc 69.19
2024-09-02 10:51:03,850 [podnet.py] => Task 1, Epoch 222/300 (LR 0.01577) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 68.62
2024-09-02 10:51:05,588 [podnet.py] => Task 1, Epoch 223/300 (LR 0.01539) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.62
2024-09-02 10:51:07,628 [podnet.py] => Task 1, Epoch 224/300 (LR 0.01502) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 56.60
2024-09-02 10:51:09,795 [podnet.py] => Task 1, Epoch 225/300 (LR 0.01464) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.19, Train_acc 99.98, Test_acc 67.98
2024-09-02 10:51:10,987 [podnet.py] => Task 1, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.52
2024-09-02 10:51:13,213 [podnet.py] => Task 1, Epoch 227/300 (LR 0.01391) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 68.43
2024-09-02 10:51:15,222 [podnet.py] => Task 1, Epoch 228/300 (LR 0.01355) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.23, Train_acc 99.64, Test_acc 60.98
2024-09-02 10:51:17,279 [podnet.py] => Task 1, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.21, Train_acc 99.91, Test_acc 68.21
2024-09-02 10:51:19,371 [podnet.py] => Task 1, Epoch 230/300 (LR 0.01284) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.19, Train_acc 99.98, Test_acc 68.88
2024-09-02 10:51:21,405 [podnet.py] => Task 1, Epoch 231/300 (LR 0.01249) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.19, Train_acc 100.00, Test_acc 68.55
2024-09-02 10:51:23,438 [podnet.py] => Task 1, Epoch 232/300 (LR 0.01215) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.19, Train_acc 99.98, Test_acc 70.88
2024-09-02 10:51:25,540 [podnet.py] => Task 1, Epoch 233/300 (LR 0.01181) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.82, Test_acc 71.29
2024-09-02 10:51:27,033 [podnet.py] => Task 1, Epoch 234/300 (LR 0.01147) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 69.52
2024-09-02 10:51:29,184 [podnet.py] => Task 1, Epoch 235/300 (LR 0.01114) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.36
2024-09-02 10:51:31,142 [podnet.py] => Task 1, Epoch 236/300 (LR 0.01082) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.17, Train_acc 99.98, Test_acc 70.40
2024-09-02 10:51:33,027 [podnet.py] => Task 1, Epoch 237/300 (LR 0.01049) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.12
2024-09-02 10:51:35,066 [podnet.py] => Task 1, Epoch 238/300 (LR 0.01017) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.02
2024-09-02 10:51:37,130 [podnet.py] => Task 1, Epoch 239/300 (LR 0.00986) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.74
2024-09-02 10:51:39,272 [podnet.py] => Task 1, Epoch 240/300 (LR 0.00955) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.71
2024-09-02 10:51:41,532 [podnet.py] => Task 1, Epoch 241/300 (LR 0.00924) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.98, Test_acc 69.45
2024-09-02 10:51:43,680 [podnet.py] => Task 1, Epoch 242/300 (LR 0.00894) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.29
2024-09-02 10:51:45,880 [podnet.py] => Task 1, Epoch 243/300 (LR 0.00865) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.90
2024-09-02 10:51:47,877 [podnet.py] => Task 1, Epoch 244/300 (LR 0.00835) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 71.02
2024-09-02 10:51:49,954 [podnet.py] => Task 1, Epoch 245/300 (LR 0.00807) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.40
2024-09-02 10:51:52,058 [podnet.py] => Task 1, Epoch 246/300 (LR 0.00778) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.86
2024-09-02 10:51:54,141 [podnet.py] => Task 1, Epoch 247/300 (LR 0.00751) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.52
2024-09-02 10:51:56,339 [podnet.py] => Task 1, Epoch 248/300 (LR 0.00723) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.12
2024-09-02 10:51:58,626 [podnet.py] => Task 1, Epoch 249/300 (LR 0.00696) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.95
2024-09-02 10:52:00,531 [podnet.py] => Task 1, Epoch 250/300 (LR 0.00670) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.98, Test_acc 39.60
2024-09-02 10:52:02,611 [podnet.py] => Task 1, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.21, Train_acc 100.00, Test_acc 67.93
2024-09-02 10:52:04,490 [podnet.py] => Task 1, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 99.98, Test_acc 69.55
2024-09-02 10:52:06,622 [podnet.py] => Task 1, Epoch 253/300 (LR 0.00593) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 70.14
2024-09-02 10:52:08,106 [podnet.py] => Task 1, Epoch 254/300 (LR 0.00569) => LSC_loss 0.03, Spatial_loss 0.08, Flat_loss 0.18, Train_acc 100.00, Test_acc 69.81
2024-09-02 10:52:10,202 [podnet.py] => Task 1, Epoch 255/300 (LR 0.00545) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.14
2024-09-02 10:52:12,416 [podnet.py] => Task 1, Epoch 256/300 (LR 0.00521) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.19
2024-09-02 10:52:14,650 [podnet.py] => Task 1, Epoch 257/300 (LR 0.00498) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.33
2024-09-02 10:52:16,855 [podnet.py] => Task 1, Epoch 258/300 (LR 0.00476) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.36
2024-09-02 10:52:18,939 [podnet.py] => Task 1, Epoch 259/300 (LR 0.00454) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 71.00
2024-09-02 10:52:21,240 [podnet.py] => Task 1, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.98, Test_acc 70.60
2024-09-02 10:52:23,329 [podnet.py] => Task 1, Epoch 261/300 (LR 0.00411) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.98, Test_acc 70.36
2024-09-02 10:52:25,113 [podnet.py] => Task 1, Epoch 262/300 (LR 0.00391) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.21
2024-09-02 10:52:27,063 [podnet.py] => Task 1, Epoch 263/300 (LR 0.00371) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.83
2024-09-02 10:52:28,366 [podnet.py] => Task 1, Epoch 264/300 (LR 0.00351) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.38
2024-09-02 10:52:29,997 [podnet.py] => Task 1, Epoch 265/300 (LR 0.00332) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.31
2024-09-02 10:52:31,695 [podnet.py] => Task 1, Epoch 266/300 (LR 0.00314) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.93
2024-09-02 10:52:33,511 [podnet.py] => Task 1, Epoch 267/300 (LR 0.00296) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.26
2024-09-02 10:52:35,278 [podnet.py] => Task 1, Epoch 268/300 (LR 0.00278) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.21
2024-09-02 10:52:36,738 [podnet.py] => Task 1, Epoch 269/300 (LR 0.00261) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.50
2024-09-02 10:52:38,545 [podnet.py] => Task 1, Epoch 270/300 (LR 0.00245) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.50
2024-09-02 10:52:40,253 [podnet.py] => Task 1, Epoch 271/300 (LR 0.00229) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.36
2024-09-02 10:52:42,000 [podnet.py] => Task 1, Epoch 272/300 (LR 0.00213) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.36
2024-09-02 10:52:43,514 [podnet.py] => Task 1, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 99.98, Test_acc 69.74
2024-09-02 10:52:44,993 [podnet.py] => Task 1, Epoch 274/300 (LR 0.00184) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.86
2024-09-02 10:52:47,034 [podnet.py] => Task 1, Epoch 275/300 (LR 0.00170) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.17, Train_acc 100.00, Test_acc 70.14
2024-09-02 10:52:48,733 [podnet.py] => Task 1, Epoch 276/300 (LR 0.00157) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.52
2024-09-02 10:52:50,444 [podnet.py] => Task 1, Epoch 277/300 (LR 0.00144) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.60
2024-09-02 10:52:52,200 [podnet.py] => Task 1, Epoch 278/300 (LR 0.00132) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.24
2024-09-02 10:52:53,728 [podnet.py] => Task 1, Epoch 279/300 (LR 0.00120) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.50
2024-09-02 10:52:55,402 [podnet.py] => Task 1, Epoch 280/300 (LR 0.00109) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.31
2024-09-02 10:52:57,182 [podnet.py] => Task 1, Epoch 281/300 (LR 0.00099) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.38
2024-09-02 10:52:58,873 [podnet.py] => Task 1, Epoch 282/300 (LR 0.00089) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.40
2024-09-02 10:53:00,730 [podnet.py] => Task 1, Epoch 283/300 (LR 0.00079) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.76
2024-09-02 10:53:02,445 [podnet.py] => Task 1, Epoch 284/300 (LR 0.00070) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.74
2024-09-02 10:53:04,228 [podnet.py] => Task 1, Epoch 285/300 (LR 0.00062) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.24
2024-09-02 10:53:06,071 [podnet.py] => Task 1, Epoch 286/300 (LR 0.00054) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.67
2024-09-02 10:53:08,186 [podnet.py] => Task 1, Epoch 287/300 (LR 0.00046) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.45
2024-09-02 10:53:09,872 [podnet.py] => Task 1, Epoch 288/300 (LR 0.00039) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.69
2024-09-02 10:53:11,817 [podnet.py] => Task 1, Epoch 289/300 (LR 0.00033) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 69.62
2024-09-02 10:53:13,403 [podnet.py] => Task 1, Epoch 290/300 (LR 0.00027) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.00
2024-09-02 10:53:15,398 [podnet.py] => Task 1, Epoch 291/300 (LR 0.00022) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.17, Train_acc 100.00, Test_acc 69.83
2024-09-02 10:53:17,274 [podnet.py] => Task 1, Epoch 292/300 (LR 0.00018) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.36
2024-09-02 10:53:18,744 [podnet.py] => Task 1, Epoch 293/300 (LR 0.00013) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.12
2024-09-02 10:53:20,157 [podnet.py] => Task 1, Epoch 294/300 (LR 0.00010) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.55
2024-09-02 10:53:21,800 [podnet.py] => Task 1, Epoch 295/300 (LR 0.00007) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.36
2024-09-02 10:53:23,519 [podnet.py] => Task 1, Epoch 296/300 (LR 0.00004) => LSC_loss 0.03, Spatial_loss 0.07, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.74
2024-09-02 10:53:25,065 [podnet.py] => Task 1, Epoch 297/300 (LR 0.00002) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.57
2024-09-02 10:53:26,654 [podnet.py] => Task 1, Epoch 298/300 (LR 0.00001) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.33
2024-09-02 10:53:28,216 [podnet.py] => Task 1, Epoch 299/300 (LR 0.00000) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.02
2024-09-02 10:53:29,665 [podnet.py] => Task 1, Epoch 300/300 (LR 0.00000) => LSC_loss 0.03, Spatial_loss 0.06, Flat_loss 0.16, Train_acc 100.00, Test_acc 70.43
2024-09-02 10:53:29,665 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 10:53:29,665 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 10:53:30,677 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 10:53:32,555 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 10:53:33,559 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 10:53:35,960 [podnet.py] => Exemplar size: 497
2024-09-02 10:53:35,960 [trainer.py] => CNN: {'total': 70.43, '00-04': 60.53, '05-06': 95.17, 'old': 60.53, 'new': 95.17}
2024-09-02 10:53:35,960 [trainer.py] => NME: {'total': 73.81, '00-04': 73.97, '05-06': 73.42, 'old': 73.97, 'new': 73.42}
2024-09-02 10:53:35,960 [trainer.py] => CNN top1 curve: [88.9, 70.43]
2024-09-02 10:53:35,960 [trainer.py] => CNN top5 curve: [100.0, 98.02]
2024-09-02 10:53:35,960 [trainer.py] => NME top1 curve: [88.9, 73.81]
2024-09-02 10:53:35,960 [trainer.py] => NME top5 curve: [100.0, 98.05]

2024-09-02 10:53:35,960 [trainer.py] => Average Accuracy (CNN): 79.665
2024-09-02 10:53:35,961 [trainer.py] => Average Accuracy (NME): 81.355
2024-09-02 10:53:35,961 [trainer.py] => All params: 3879745
2024-09-02 10:53:35,961 [trainer.py] => Trainable params: 3879745
2024-09-02 10:53:35,962 [podnet.py] => Learning on 7-9
2024-09-02 10:53:35,980 [podnet.py] => Adaptive factor: 2.1213203435596424
2024-09-02 10:53:38,150 [podnet.py] => Task 2, Epoch 1/300 (LR 0.10000) => LSC_loss 1.53, Spatial_loss 0.32, Flat_loss 1.29, Train_acc 76.10, Test_acc 19.35
2024-09-02 10:53:39,978 [podnet.py] => Task 2, Epoch 2/300 (LR 0.09999) => LSC_loss 0.75, Spatial_loss 0.28, Flat_loss 1.09, Train_acc 87.37, Test_acc 21.06
2024-09-02 10:53:41,409 [podnet.py] => Task 2, Epoch 3/300 (LR 0.09998) => LSC_loss 0.61, Spatial_loss 0.27, Flat_loss 0.93, Train_acc 87.66, Test_acc 24.22
2024-09-02 10:53:43,477 [podnet.py] => Task 2, Epoch 4/300 (LR 0.09996) => LSC_loss 0.52, Spatial_loss 0.26, Flat_loss 0.82, Train_acc 88.93, Test_acc 29.96
2024-09-02 10:53:45,745 [podnet.py] => Task 2, Epoch 5/300 (LR 0.09993) => LSC_loss 0.44, Spatial_loss 0.27, Flat_loss 0.75, Train_acc 90.04, Test_acc 37.56
2024-09-02 10:53:47,460 [podnet.py] => Task 2, Epoch 6/300 (LR 0.09990) => LSC_loss 0.46, Spatial_loss 0.27, Flat_loss 0.73, Train_acc 89.53, Test_acc 22.13
2024-09-02 10:53:49,618 [podnet.py] => Task 2, Epoch 7/300 (LR 0.09987) => LSC_loss 0.41, Spatial_loss 0.27, Flat_loss 0.71, Train_acc 90.91, Test_acc 44.67
2024-09-02 10:53:51,704 [podnet.py] => Task 2, Epoch 8/300 (LR 0.09982) => LSC_loss 0.32, Spatial_loss 0.25, Flat_loss 0.65, Train_acc 92.35, Test_acc 37.02
2024-09-02 10:53:53,030 [podnet.py] => Task 2, Epoch 9/300 (LR 0.09978) => LSC_loss 0.29, Spatial_loss 0.23, Flat_loss 0.62, Train_acc 93.60, Test_acc 38.74
2024-09-02 10:53:54,853 [podnet.py] => Task 2, Epoch 10/300 (LR 0.09973) => LSC_loss 0.28, Spatial_loss 0.24, Flat_loss 0.61, Train_acc 93.11, Test_acc 44.54
2024-09-02 10:53:56,396 [podnet.py] => Task 2, Epoch 11/300 (LR 0.09967) => LSC_loss 0.23, Spatial_loss 0.22, Flat_loss 0.58, Train_acc 95.15, Test_acc 30.02
2024-09-02 10:53:57,952 [podnet.py] => Task 2, Epoch 12/300 (LR 0.09961) => LSC_loss 0.44, Spatial_loss 0.31, Flat_loss 0.66, Train_acc 89.95, Test_acc 38.15
2024-09-02 10:53:59,602 [podnet.py] => Task 2, Epoch 13/300 (LR 0.09954) => LSC_loss 0.30, Spatial_loss 0.27, Flat_loss 0.61, Train_acc 92.62, Test_acc 43.06
2024-09-02 10:54:01,166 [podnet.py] => Task 2, Epoch 14/300 (LR 0.09946) => LSC_loss 0.19, Spatial_loss 0.22, Flat_loss 0.56, Train_acc 95.95, Test_acc 46.31
2024-09-02 10:54:02,818 [podnet.py] => Task 2, Epoch 15/300 (LR 0.09938) => LSC_loss 0.22, Spatial_loss 0.22, Flat_loss 0.57, Train_acc 95.64, Test_acc 49.35
2024-09-02 10:54:04,842 [podnet.py] => Task 2, Epoch 16/300 (LR 0.09930) => LSC_loss 0.20, Spatial_loss 0.23, Flat_loss 0.56, Train_acc 95.20, Test_acc 48.31
2024-09-02 10:54:06,782 [podnet.py] => Task 2, Epoch 17/300 (LR 0.09921) => LSC_loss 0.15, Spatial_loss 0.21, Flat_loss 0.53, Train_acc 96.71, Test_acc 47.52
2024-09-02 10:54:08,862 [podnet.py] => Task 2, Epoch 18/300 (LR 0.09911) => LSC_loss 0.15, Spatial_loss 0.21, Flat_loss 0.53, Train_acc 96.80, Test_acc 53.72
2024-09-02 10:54:11,017 [podnet.py] => Task 2, Epoch 19/300 (LR 0.09901) => LSC_loss 0.14, Spatial_loss 0.20, Flat_loss 0.52, Train_acc 97.53, Test_acc 52.78
2024-09-02 10:54:13,021 [podnet.py] => Task 2, Epoch 20/300 (LR 0.09891) => LSC_loss 0.11, Spatial_loss 0.19, Flat_loss 0.51, Train_acc 98.20, Test_acc 58.67
2024-09-02 10:54:15,149 [podnet.py] => Task 2, Epoch 21/300 (LR 0.09880) => LSC_loss 0.09, Spatial_loss 0.17, Flat_loss 0.48, Train_acc 99.04, Test_acc 54.39
2024-09-02 10:54:17,221 [podnet.py] => Task 2, Epoch 22/300 (LR 0.09868) => LSC_loss 0.07, Spatial_loss 0.16, Flat_loss 0.46, Train_acc 99.49, Test_acc 57.28
2024-09-02 10:54:19,212 [podnet.py] => Task 2, Epoch 23/300 (LR 0.09856) => LSC_loss 0.08, Spatial_loss 0.16, Flat_loss 0.46, Train_acc 99.20, Test_acc 60.11
2024-09-02 10:54:21,099 [podnet.py] => Task 2, Epoch 24/300 (LR 0.09843) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.45, Train_acc 99.62, Test_acc 58.13
2024-09-02 10:54:23,396 [podnet.py] => Task 2, Epoch 25/300 (LR 0.09830) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.43, Train_acc 99.76, Test_acc 57.28
2024-09-02 10:54:25,229 [podnet.py] => Task 2, Epoch 26/300 (LR 0.09816) => LSC_loss 0.07, Spatial_loss 0.15, Flat_loss 0.44, Train_acc 99.51, Test_acc 55.44
2024-09-02 10:54:27,427 [podnet.py] => Task 2, Epoch 27/300 (LR 0.09801) => LSC_loss 0.21, Spatial_loss 0.22, Flat_loss 0.53, Train_acc 95.33, Test_acc 41.52
2024-09-02 10:54:29,158 [podnet.py] => Task 2, Epoch 28/300 (LR 0.09787) => LSC_loss 0.22, Spatial_loss 0.24, Flat_loss 0.54, Train_acc 94.89, Test_acc 38.06
2024-09-02 10:54:31,491 [podnet.py] => Task 2, Epoch 29/300 (LR 0.09771) => LSC_loss 0.22, Spatial_loss 0.25, Flat_loss 0.55, Train_acc 94.97, Test_acc 51.17
2024-09-02 10:54:33,530 [podnet.py] => Task 2, Epoch 30/300 (LR 0.09755) => LSC_loss 0.11, Spatial_loss 0.20, Flat_loss 0.49, Train_acc 97.73, Test_acc 51.37
2024-09-02 10:54:35,729 [podnet.py] => Task 2, Epoch 31/300 (LR 0.09739) => LSC_loss 0.07, Spatial_loss 0.17, Flat_loss 0.46, Train_acc 99.33, Test_acc 54.65
2024-09-02 10:54:37,867 [podnet.py] => Task 2, Epoch 32/300 (LR 0.09722) => LSC_loss 0.06, Spatial_loss 0.16, Flat_loss 0.44, Train_acc 99.71, Test_acc 62.11
2024-09-02 10:54:39,703 [podnet.py] => Task 2, Epoch 33/300 (LR 0.09704) => LSC_loss 0.07, Spatial_loss 0.15, Flat_loss 0.45, Train_acc 99.24, Test_acc 31.78
2024-09-02 10:54:41,624 [podnet.py] => Task 2, Epoch 34/300 (LR 0.09686) => LSC_loss 0.08, Spatial_loss 0.16, Flat_loss 0.48, Train_acc 99.00, Test_acc 55.00
2024-09-02 10:54:43,771 [podnet.py] => Task 2, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.43, Train_acc 99.60, Test_acc 60.46
2024-09-02 10:54:45,863 [podnet.py] => Task 2, Epoch 36/300 (LR 0.09649) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.42, Train_acc 99.89, Test_acc 61.11
2024-09-02 10:54:47,763 [podnet.py] => Task 2, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.41, Train_acc 99.82, Test_acc 61.67
2024-09-02 10:54:49,759 [podnet.py] => Task 2, Epoch 38/300 (LR 0.09609) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.40, Train_acc 99.96, Test_acc 59.46
2024-09-02 10:54:51,928 [podnet.py] => Task 2, Epoch 39/300 (LR 0.09589) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.91, Test_acc 60.46
2024-09-02 10:54:53,694 [podnet.py] => Task 2, Epoch 40/300 (LR 0.09568) => LSC_loss 0.13, Spatial_loss 0.17, Flat_loss 0.47, Train_acc 97.38, Test_acc 41.43
2024-09-02 10:54:55,704 [podnet.py] => Task 2, Epoch 41/300 (LR 0.09546) => LSC_loss 0.30, Spatial_loss 0.26, Flat_loss 0.55, Train_acc 93.33, Test_acc 35.41
2024-09-02 10:54:57,862 [podnet.py] => Task 2, Epoch 42/300 (LR 0.09524) => LSC_loss 0.21, Spatial_loss 0.25, Flat_loss 0.53, Train_acc 95.20, Test_acc 47.41
2024-09-02 10:54:59,820 [podnet.py] => Task 2, Epoch 43/300 (LR 0.09502) => LSC_loss 0.13, Spatial_loss 0.21, Flat_loss 0.48, Train_acc 97.13, Test_acc 52.17
2024-09-02 10:55:01,759 [podnet.py] => Task 2, Epoch 44/300 (LR 0.09479) => LSC_loss 0.08, Spatial_loss 0.19, Flat_loss 0.45, Train_acc 98.69, Test_acc 60.59
2024-09-02 10:55:03,599 [podnet.py] => Task 2, Epoch 45/300 (LR 0.09455) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.42, Train_acc 99.56, Test_acc 58.76
2024-09-02 10:55:05,021 [podnet.py] => Task 2, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.40, Train_acc 99.84, Test_acc 60.44
2024-09-02 10:55:07,149 [podnet.py] => Task 2, Epoch 47/300 (LR 0.09407) => LSC_loss 0.09, Spatial_loss 0.18, Flat_loss 0.46, Train_acc 98.69, Test_acc 47.76
2024-09-02 10:55:09,245 [podnet.py] => Task 2, Epoch 48/300 (LR 0.09382) => LSC_loss 0.14, Spatial_loss 0.21, Flat_loss 0.50, Train_acc 97.06, Test_acc 50.20
2024-09-02 10:55:11,288 [podnet.py] => Task 2, Epoch 49/300 (LR 0.09356) => LSC_loss 0.09, Spatial_loss 0.18, Flat_loss 0.47, Train_acc 98.29, Test_acc 54.22
2024-09-02 10:55:13,209 [podnet.py] => Task 2, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.43, Train_acc 99.78, Test_acc 60.69
2024-09-02 10:55:15,182 [podnet.py] => Task 2, Epoch 51/300 (LR 0.09304) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.41, Train_acc 99.87, Test_acc 61.91
2024-09-02 10:55:16,593 [podnet.py] => Task 2, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 100.00, Test_acc 61.15
2024-09-02 10:55:18,240 [podnet.py] => Task 2, Epoch 53/300 (LR 0.09249) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.96, Test_acc 59.41
2024-09-02 10:55:19,746 [podnet.py] => Task 2, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.98, Test_acc 60.81
2024-09-02 10:55:21,303 [podnet.py] => Task 2, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.98, Test_acc 59.78
2024-09-02 10:55:22,925 [podnet.py] => Task 2, Epoch 56/300 (LR 0.09165) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 99.96, Test_acc 61.70
2024-09-02 10:55:24,335 [podnet.py] => Task 2, Epoch 57/300 (LR 0.09135) => LSC_loss 0.16, Spatial_loss 0.19, Flat_loss 0.52, Train_acc 96.20, Test_acc 35.11
2024-09-02 10:55:25,991 [podnet.py] => Task 2, Epoch 58/300 (LR 0.09106) => LSC_loss 0.18, Spatial_loss 0.23, Flat_loss 0.53, Train_acc 96.22, Test_acc 40.70
2024-09-02 10:55:27,530 [podnet.py] => Task 2, Epoch 59/300 (LR 0.09076) => LSC_loss 0.10, Spatial_loss 0.21, Flat_loss 0.49, Train_acc 98.18, Test_acc 55.39
2024-09-02 10:55:29,130 [podnet.py] => Task 2, Epoch 60/300 (LR 0.09045) => LSC_loss 0.10, Spatial_loss 0.20, Flat_loss 0.48, Train_acc 98.35, Test_acc 57.17
2024-09-02 10:55:30,895 [podnet.py] => Task 2, Epoch 61/300 (LR 0.09014) => LSC_loss 0.06, Spatial_loss 0.17, Flat_loss 0.44, Train_acc 99.56, Test_acc 60.07
2024-09-02 10:55:32,885 [podnet.py] => Task 2, Epoch 62/300 (LR 0.08983) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.42, Train_acc 99.91, Test_acc 60.61
2024-09-02 10:55:34,657 [podnet.py] => Task 2, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.41, Train_acc 99.93, Test_acc 61.06
2024-09-02 10:55:36,531 [podnet.py] => Task 2, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.40, Train_acc 99.89, Test_acc 59.98
2024-09-02 10:55:38,097 [podnet.py] => Task 2, Epoch 65/300 (LR 0.08886) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 99.80, Test_acc 59.46
2024-09-02 10:55:39,818 [podnet.py] => Task 2, Epoch 66/300 (LR 0.08853) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 99.96, Test_acc 56.87
2024-09-02 10:55:41,826 [podnet.py] => Task 2, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.38, Train_acc 99.93, Test_acc 59.41
2024-09-02 10:55:43,579 [podnet.py] => Task 2, Epoch 68/300 (LR 0.08785) => LSC_loss 0.07, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.91, Test_acc 18.70
2024-09-02 10:55:45,327 [podnet.py] => Task 2, Epoch 69/300 (LR 0.08751) => LSC_loss 0.61, Spatial_loss 0.34, Flat_loss 0.68, Train_acc 87.55, Test_acc 32.00
2024-09-02 10:55:46,846 [podnet.py] => Task 2, Epoch 70/300 (LR 0.08716) => LSC_loss 0.43, Spatial_loss 0.32, Flat_loss 0.61, Train_acc 91.11, Test_acc 44.00
2024-09-02 10:55:48,648 [podnet.py] => Task 2, Epoch 71/300 (LR 0.08680) => LSC_loss 0.28, Spatial_loss 0.29, Flat_loss 0.56, Train_acc 93.11, Test_acc 43.59
2024-09-02 10:55:50,564 [podnet.py] => Task 2, Epoch 72/300 (LR 0.08645) => LSC_loss 0.14, Spatial_loss 0.24, Flat_loss 0.51, Train_acc 96.89, Test_acc 47.11
2024-09-02 10:55:52,709 [podnet.py] => Task 2, Epoch 73/300 (LR 0.08609) => LSC_loss 0.20, Spatial_loss 0.26, Flat_loss 0.53, Train_acc 95.60, Test_acc 40.24
2024-09-02 10:55:54,299 [podnet.py] => Task 2, Epoch 74/300 (LR 0.08572) => LSC_loss 0.19, Spatial_loss 0.24, Flat_loss 0.53, Train_acc 95.44, Test_acc 49.37
2024-09-02 10:55:56,300 [podnet.py] => Task 2, Epoch 75/300 (LR 0.08536) => LSC_loss 0.08, Spatial_loss 0.20, Flat_loss 0.47, Train_acc 99.00, Test_acc 56.17
2024-09-02 10:55:57,715 [podnet.py] => Task 2, Epoch 76/300 (LR 0.08498) => LSC_loss 0.07, Spatial_loss 0.19, Flat_loss 0.46, Train_acc 99.42, Test_acc 59.19
2024-09-02 10:55:59,173 [podnet.py] => Task 2, Epoch 77/300 (LR 0.08461) => LSC_loss 0.06, Spatial_loss 0.17, Flat_loss 0.43, Train_acc 99.80, Test_acc 59.00
2024-09-02 10:56:00,717 [podnet.py] => Task 2, Epoch 78/300 (LR 0.08423) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.42, Train_acc 99.93, Test_acc 60.28
2024-09-02 10:56:02,322 [podnet.py] => Task 2, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.41, Train_acc 99.82, Test_acc 58.30
2024-09-02 10:56:03,877 [podnet.py] => Task 2, Epoch 80/300 (LR 0.08346) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.41, Train_acc 99.78, Test_acc 58.30
2024-09-02 10:56:05,437 [podnet.py] => Task 2, Epoch 81/300 (LR 0.08307) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.40, Train_acc 99.91, Test_acc 59.61
2024-09-02 10:56:07,524 [podnet.py] => Task 2, Epoch 82/300 (LR 0.08267) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.96, Test_acc 60.63
2024-09-02 10:56:09,397 [podnet.py] => Task 2, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.38, Train_acc 100.00, Test_acc 60.13
2024-09-02 10:56:11,344 [podnet.py] => Task 2, Epoch 84/300 (LR 0.08187) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.38, Train_acc 100.00, Test_acc 62.06
2024-09-02 10:56:12,596 [podnet.py] => Task 2, Epoch 85/300 (LR 0.08147) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.38, Train_acc 100.00, Test_acc 61.43
2024-09-02 10:56:14,529 [podnet.py] => Task 2, Epoch 86/300 (LR 0.08106) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.38, Train_acc 99.96, Test_acc 61.46
2024-09-02 10:56:16,205 [podnet.py] => Task 2, Epoch 87/300 (LR 0.08065) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.87, Test_acc 60.24
2024-09-02 10:56:17,804 [podnet.py] => Task 2, Epoch 88/300 (LR 0.08023) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.89, Test_acc 61.39
2024-09-02 10:56:19,466 [podnet.py] => Task 2, Epoch 89/300 (LR 0.07981) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.36, Train_acc 99.93, Test_acc 62.46
2024-09-02 10:56:20,954 [podnet.py] => Task 2, Epoch 90/300 (LR 0.07939) => LSC_loss 0.06, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.38, Test_acc 61.17
2024-09-02 10:56:22,616 [podnet.py] => Task 2, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.73, Test_acc 60.31
2024-09-02 10:56:24,437 [podnet.py] => Task 2, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.93, Test_acc 62.59
2024-09-02 10:56:26,079 [podnet.py] => Task 2, Epoch 93/300 (LR 0.07810) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 99.98, Test_acc 62.50
2024-09-02 10:56:27,626 [podnet.py] => Task 2, Epoch 94/300 (LR 0.07767) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 100.00, Test_acc 62.52
2024-09-02 10:56:29,370 [podnet.py] => Task 2, Epoch 95/300 (LR 0.07723) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.35, Train_acc 100.00, Test_acc 62.13
2024-09-02 10:56:31,145 [podnet.py] => Task 2, Epoch 96/300 (LR 0.07679) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 100.00, Test_acc 62.19
2024-09-02 10:56:32,739 [podnet.py] => Task 2, Epoch 97/300 (LR 0.07635) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 100.00, Test_acc 61.59
2024-09-02 10:56:34,438 [podnet.py] => Task 2, Epoch 98/300 (LR 0.07590) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 100.00, Test_acc 61.87
2024-09-02 10:56:36,186 [podnet.py] => Task 2, Epoch 99/300 (LR 0.07545) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 99.98, Test_acc 61.15
2024-09-02 10:56:37,745 [podnet.py] => Task 2, Epoch 100/300 (LR 0.07500) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 99.96, Test_acc 62.00
2024-09-02 10:56:40,011 [podnet.py] => Task 2, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.33, Train_acc 100.00, Test_acc 63.54
2024-09-02 10:56:42,044 [podnet.py] => Task 2, Epoch 102/300 (LR 0.07409) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 99.96, Test_acc 61.48
2024-09-02 10:56:43,988 [podnet.py] => Task 2, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.34, Train_acc 100.00, Test_acc 62.00
2024-09-02 10:56:46,088 [podnet.py] => Task 2, Epoch 104/300 (LR 0.07316) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.33, Train_acc 99.96, Test_acc 62.06
2024-09-02 10:56:47,815 [podnet.py] => Task 2, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.34, Train_acc 99.91, Test_acc 60.80
2024-09-02 10:56:49,330 [podnet.py] => Task 2, Epoch 106/300 (LR 0.07223) => LSC_loss 0.09, Spatial_loss 0.15, Flat_loss 0.39, Train_acc 98.69, Test_acc 25.22
2024-09-02 10:56:51,278 [podnet.py] => Task 2, Epoch 107/300 (LR 0.07176) => LSC_loss 0.48, Spatial_loss 0.32, Flat_loss 0.63, Train_acc 89.93, Test_acc 25.67
2024-09-02 10:56:53,439 [podnet.py] => Task 2, Epoch 108/300 (LR 0.07129) => LSC_loss 0.32, Spatial_loss 0.28, Flat_loss 0.57, Train_acc 92.08, Test_acc 42.31
2024-09-02 10:56:55,503 [podnet.py] => Task 2, Epoch 109/300 (LR 0.07081) => LSC_loss 0.22, Spatial_loss 0.26, Flat_loss 0.52, Train_acc 94.91, Test_acc 37.67
2024-09-02 10:56:57,545 [podnet.py] => Task 2, Epoch 110/300 (LR 0.07034) => LSC_loss 0.46, Spatial_loss 0.35, Flat_loss 0.62, Train_acc 90.86, Test_acc 22.13
2024-09-02 10:56:59,499 [podnet.py] => Task 2, Epoch 111/300 (LR 0.06986) => LSC_loss 0.34, Spatial_loss 0.30, Flat_loss 0.57, Train_acc 92.35, Test_acc 48.87
2024-09-02 10:57:01,483 [podnet.py] => Task 2, Epoch 112/300 (LR 0.06938) => LSC_loss 0.21, Spatial_loss 0.27, Flat_loss 0.54, Train_acc 95.29, Test_acc 50.87
2024-09-02 10:57:03,259 [podnet.py] => Task 2, Epoch 113/300 (LR 0.06889) => LSC_loss 0.22, Spatial_loss 0.26, Flat_loss 0.53, Train_acc 95.17, Test_acc 51.31
2024-09-02 10:57:05,154 [podnet.py] => Task 2, Epoch 114/300 (LR 0.06841) => LSC_loss 0.10, Spatial_loss 0.22, Flat_loss 0.48, Train_acc 98.20, Test_acc 58.33
2024-09-02 10:57:06,839 [podnet.py] => Task 2, Epoch 115/300 (LR 0.06792) => LSC_loss 0.10, Spatial_loss 0.20, Flat_loss 0.46, Train_acc 98.47, Test_acc 57.94
2024-09-02 10:57:08,365 [podnet.py] => Task 2, Epoch 116/300 (LR 0.06743) => LSC_loss 0.07, Spatial_loss 0.18, Flat_loss 0.43, Train_acc 99.49, Test_acc 59.96
2024-09-02 10:57:09,905 [podnet.py] => Task 2, Epoch 117/300 (LR 0.06694) => LSC_loss 0.07, Spatial_loss 0.17, Flat_loss 0.43, Train_acc 99.40, Test_acc 60.63
2024-09-02 10:57:11,536 [podnet.py] => Task 2, Epoch 118/300 (LR 0.06644) => LSC_loss 0.06, Spatial_loss 0.16, Flat_loss 0.41, Train_acc 99.82, Test_acc 60.24
2024-09-02 10:57:13,035 [podnet.py] => Task 2, Epoch 119/300 (LR 0.06595) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.40, Train_acc 99.96, Test_acc 61.48
2024-09-02 10:57:14,580 [podnet.py] => Task 2, Epoch 120/300 (LR 0.06545) => LSC_loss 0.20, Spatial_loss 0.23, Flat_loss 0.56, Train_acc 95.46, Test_acc 51.91
2024-09-02 10:57:16,450 [podnet.py] => Task 2, Epoch 121/300 (LR 0.06495) => LSC_loss 0.10, Spatial_loss 0.21, Flat_loss 0.49, Train_acc 98.18, Test_acc 56.85
2024-09-02 10:57:18,134 [podnet.py] => Task 2, Epoch 122/300 (LR 0.06445) => LSC_loss 0.08, Spatial_loss 0.18, Flat_loss 0.46, Train_acc 98.91, Test_acc 55.96
2024-09-02 10:57:20,126 [podnet.py] => Task 2, Epoch 123/300 (LR 0.06395) => LSC_loss 0.07, Spatial_loss 0.17, Flat_loss 0.45, Train_acc 99.29, Test_acc 58.02
2024-09-02 10:57:22,057 [podnet.py] => Task 2, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.43, Train_acc 99.87, Test_acc 58.52
2024-09-02 10:57:23,779 [podnet.py] => Task 2, Epoch 125/300 (LR 0.06294) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.42, Train_acc 99.89, Test_acc 60.94
2024-09-02 10:57:25,579 [podnet.py] => Task 2, Epoch 126/300 (LR 0.06243) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.41, Train_acc 99.91, Test_acc 59.15
2024-09-02 10:57:27,469 [podnet.py] => Task 2, Epoch 127/300 (LR 0.06193) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 99.98, Test_acc 59.11
2024-09-02 10:57:28,999 [podnet.py] => Task 2, Epoch 128/300 (LR 0.06142) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.42, Train_acc 99.82, Test_acc 59.96
2024-09-02 10:57:31,020 [podnet.py] => Task 2, Epoch 129/300 (LR 0.06091) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.42, Train_acc 99.58, Test_acc 61.28
2024-09-02 10:57:32,714 [podnet.py] => Task 2, Epoch 130/300 (LR 0.06040) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 99.91, Test_acc 58.57
2024-09-02 10:57:34,367 [podnet.py] => Task 2, Epoch 131/300 (LR 0.05988) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.96, Test_acc 58.89
2024-09-02 10:57:35,993 [podnet.py] => Task 2, Epoch 132/300 (LR 0.05937) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 58.69
2024-09-02 10:57:37,716 [podnet.py] => Task 2, Epoch 133/300 (LR 0.05885) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 60.67
2024-09-02 10:57:39,528 [podnet.py] => Task 2, Epoch 134/300 (LR 0.05834) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.52
2024-09-02 10:57:41,604 [podnet.py] => Task 2, Epoch 135/300 (LR 0.05782) => LSC_loss 0.06, Spatial_loss 0.15, Flat_loss 0.39, Train_acc 99.56, Test_acc 38.31
2024-09-02 10:57:43,992 [podnet.py] => Task 2, Epoch 136/300 (LR 0.05730) => LSC_loss 0.08, Spatial_loss 0.17, Flat_loss 0.44, Train_acc 98.91, Test_acc 53.15
2024-09-02 10:57:46,319 [podnet.py] => Task 2, Epoch 137/300 (LR 0.05679) => LSC_loss 0.06, Spatial_loss 0.16, Flat_loss 0.41, Train_acc 99.56, Test_acc 59.57
2024-09-02 10:57:47,593 [podnet.py] => Task 2, Epoch 138/300 (LR 0.05627) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.89, Test_acc 60.78
2024-09-02 10:57:49,142 [podnet.py] => Task 2, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 60.50
2024-09-02 10:57:50,632 [podnet.py] => Task 2, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.94
2024-09-02 10:57:52,070 [podnet.py] => Task 2, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.96, Test_acc 59.89
2024-09-02 10:57:53,524 [podnet.py] => Task 2, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.85
2024-09-02 10:57:55,127 [podnet.py] => Task 2, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.91, Test_acc 44.56
2024-09-02 10:57:57,134 [podnet.py] => Task 2, Epoch 144/300 (LR 0.05314) => LSC_loss 0.27, Spatial_loss 0.29, Flat_loss 0.53, Train_acc 94.13, Test_acc 34.22
2024-09-02 10:57:59,308 [podnet.py] => Task 2, Epoch 145/300 (LR 0.05262) => LSC_loss 0.24, Spatial_loss 0.25, Flat_loss 0.53, Train_acc 94.71, Test_acc 43.63
2024-09-02 10:58:01,171 [podnet.py] => Task 2, Epoch 146/300 (LR 0.05209) => LSC_loss 0.14, Spatial_loss 0.23, Flat_loss 0.49, Train_acc 97.26, Test_acc 53.87
2024-09-02 10:58:03,169 [podnet.py] => Task 2, Epoch 147/300 (LR 0.05157) => LSC_loss 0.07, Spatial_loss 0.18, Flat_loss 0.45, Train_acc 99.02, Test_acc 58.13
2024-09-02 10:58:05,223 [podnet.py] => Task 2, Epoch 148/300 (LR 0.05105) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.41, Train_acc 99.84, Test_acc 54.17
2024-09-02 10:58:07,431 [podnet.py] => Task 2, Epoch 149/300 (LR 0.05052) => LSC_loss 0.08, Spatial_loss 0.17, Flat_loss 0.45, Train_acc 98.95, Test_acc 54.65
2024-09-02 10:58:09,549 [podnet.py] => Task 2, Epoch 150/300 (LR 0.05000) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.42, Train_acc 99.71, Test_acc 61.76
2024-09-02 10:58:11,485 [podnet.py] => Task 2, Epoch 151/300 (LR 0.04948) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 100.00, Test_acc 60.61
2024-09-02 10:58:12,891 [podnet.py] => Task 2, Epoch 152/300 (LR 0.04895) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.40, Train_acc 99.96, Test_acc 57.83
2024-09-02 10:58:14,412 [podnet.py] => Task 2, Epoch 153/300 (LR 0.04843) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 61.81
2024-09-02 10:58:16,257 [podnet.py] => Task 2, Epoch 154/300 (LR 0.04791) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 60.15
2024-09-02 10:58:17,925 [podnet.py] => Task 2, Epoch 155/300 (LR 0.04738) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.96, Test_acc 60.61
2024-09-02 10:58:20,100 [podnet.py] => Task 2, Epoch 156/300 (LR 0.04686) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.98, Test_acc 59.15
2024-09-02 10:58:22,214 [podnet.py] => Task 2, Epoch 157/300 (LR 0.04634) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 100.00, Test_acc 61.26
2024-09-02 10:58:24,091 [podnet.py] => Task 2, Epoch 158/300 (LR 0.04582) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 99.98, Test_acc 46.72
2024-09-02 10:58:26,411 [podnet.py] => Task 2, Epoch 159/300 (LR 0.04529) => LSC_loss 0.41, Spatial_loss 0.28, Flat_loss 0.59, Train_acc 91.35, Test_acc 38.33
2024-09-02 10:58:28,592 [podnet.py] => Task 2, Epoch 160/300 (LR 0.04477) => LSC_loss 0.17, Spatial_loss 0.24, Flat_loss 0.53, Train_acc 96.06, Test_acc 40.35
2024-09-02 10:58:30,506 [podnet.py] => Task 2, Epoch 161/300 (LR 0.04425) => LSC_loss 0.07, Spatial_loss 0.19, Flat_loss 0.46, Train_acc 98.91, Test_acc 59.93
2024-09-02 10:58:32,857 [podnet.py] => Task 2, Epoch 162/300 (LR 0.04373) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.43, Train_acc 99.69, Test_acc 60.24
2024-09-02 10:58:35,281 [podnet.py] => Task 2, Epoch 163/300 (LR 0.04321) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.41, Train_acc 99.89, Test_acc 60.59
2024-09-02 10:58:36,752 [podnet.py] => Task 2, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.40, Train_acc 99.82, Test_acc 60.28
2024-09-02 10:58:38,247 [podnet.py] => Task 2, Epoch 165/300 (LR 0.04218) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.98, Test_acc 60.30
2024-09-02 10:58:39,631 [podnet.py] => Task 2, Epoch 166/300 (LR 0.04166) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.98, Test_acc 62.11
2024-09-02 10:58:41,215 [podnet.py] => Task 2, Epoch 167/300 (LR 0.04115) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 61.02
2024-09-02 10:58:42,947 [podnet.py] => Task 2, Epoch 168/300 (LR 0.04063) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.96, Test_acc 61.80
2024-09-02 10:58:44,728 [podnet.py] => Task 2, Epoch 169/300 (LR 0.04012) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.96, Test_acc 58.04
2024-09-02 10:58:46,404 [podnet.py] => Task 2, Epoch 170/300 (LR 0.03960) => LSC_loss 0.06, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.56, Test_acc 60.20
2024-09-02 10:58:48,324 [podnet.py] => Task 2, Epoch 171/300 (LR 0.03909) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.38, Train_acc 99.98, Test_acc 60.76
2024-09-02 10:58:49,650 [podnet.py] => Task 2, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.37, Train_acc 99.98, Test_acc 59.74
2024-09-02 10:58:51,800 [podnet.py] => Task 2, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.98, Test_acc 60.15
2024-09-02 10:58:53,399 [podnet.py] => Task 2, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.76
2024-09-02 10:58:54,792 [podnet.py] => Task 2, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 100.00, Test_acc 61.74
2024-09-02 10:58:56,412 [podnet.py] => Task 2, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.35, Train_acc 100.00, Test_acc 59.17
2024-09-02 10:58:57,798 [podnet.py] => Task 2, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 100.00, Test_acc 61.91
2024-09-02 10:58:59,284 [podnet.py] => Task 2, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.36, Train_acc 99.98, Test_acc 60.30
2024-09-02 10:59:01,277 [podnet.py] => Task 2, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 100.00, Test_acc 60.50
2024-09-02 10:59:03,256 [podnet.py] => Task 2, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 99.98, Test_acc 59.74
2024-09-02 10:59:05,059 [podnet.py] => Task 2, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 99.98, Test_acc 60.78
2024-09-02 10:59:07,045 [podnet.py] => Task 2, Epoch 182/300 (LR 0.03356) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.67, Test_acc 56.76
2024-09-02 10:59:09,228 [podnet.py] => Task 2, Epoch 183/300 (LR 0.03306) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.87, Test_acc 59.98
2024-09-02 10:59:11,340 [podnet.py] => Task 2, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.96, Test_acc 59.70
2024-09-02 10:59:13,326 [podnet.py] => Task 2, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 99.96, Test_acc 60.52
2024-09-02 10:59:15,080 [podnet.py] => Task 2, Epoch 186/300 (LR 0.03159) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.38, Train_acc 99.91, Test_acc 58.41
2024-09-02 10:59:16,707 [podnet.py] => Task 2, Epoch 187/300 (LR 0.03111) => LSC_loss 0.06, Spatial_loss 0.13, Flat_loss 0.40, Train_acc 99.62, Test_acc 57.48
2024-09-02 10:59:18,205 [podnet.py] => Task 2, Epoch 188/300 (LR 0.03062) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.39, Train_acc 99.80, Test_acc 61.56
2024-09-02 10:59:20,028 [podnet.py] => Task 2, Epoch 189/300 (LR 0.03014) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.38, Train_acc 99.76, Test_acc 59.74
2024-09-02 10:59:21,778 [podnet.py] => Task 2, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.98, Test_acc 60.30
2024-09-02 10:59:23,983 [podnet.py] => Task 2, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 99.98, Test_acc 60.87
2024-09-02 10:59:25,597 [podnet.py] => Task 2, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.57
2024-09-02 10:59:27,426 [podnet.py] => Task 2, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 100.00, Test_acc 61.26
2024-09-02 10:59:29,726 [podnet.py] => Task 2, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 100.00, Test_acc 61.13
2024-09-02 10:59:31,590 [podnet.py] => Task 2, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 100.00, Test_acc 60.76
2024-09-02 10:59:33,279 [podnet.py] => Task 2, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.35, Train_acc 99.98, Test_acc 60.39
2024-09-02 10:59:34,991 [podnet.py] => Task 2, Epoch 197/300 (LR 0.02637) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.78, Test_acc 49.89
2024-09-02 10:59:37,017 [podnet.py] => Task 2, Epoch 198/300 (LR 0.02591) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.40, Train_acc 99.78, Test_acc 60.17
2024-09-02 10:59:39,122 [podnet.py] => Task 2, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.93, Test_acc 60.61
2024-09-02 10:59:41,017 [podnet.py] => Task 2, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.48
2024-09-02 10:59:42,728 [podnet.py] => Task 2, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 100.00, Test_acc 61.02
2024-09-02 10:59:44,554 [podnet.py] => Task 2, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.83
2024-09-02 10:59:46,268 [podnet.py] => Task 2, Epoch 203/300 (LR 0.02365) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.35, Train_acc 99.93, Test_acc 61.59
2024-09-02 10:59:48,069 [podnet.py] => Task 2, Epoch 204/300 (LR 0.02321) => LSC_loss 0.05, Spatial_loss 0.11, Flat_loss 0.40, Train_acc 99.71, Test_acc 59.54
2024-09-02 10:59:49,656 [podnet.py] => Task 2, Epoch 205/300 (LR 0.02277) => LSC_loss 0.06, Spatial_loss 0.12, Flat_loss 0.40, Train_acc 99.53, Test_acc 50.35
2024-09-02 10:59:51,829 [podnet.py] => Task 2, Epoch 206/300 (LR 0.02233) => LSC_loss 0.06, Spatial_loss 0.14, Flat_loss 0.42, Train_acc 99.53, Test_acc 60.74
2024-09-02 10:59:53,755 [podnet.py] => Task 2, Epoch 207/300 (LR 0.02190) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.40, Train_acc 99.76, Test_acc 59.13
2024-09-02 10:59:55,707 [podnet.py] => Task 2, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.38, Train_acc 100.00, Test_acc 61.31
2024-09-02 10:59:57,726 [podnet.py] => Task 2, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.37, Train_acc 100.00, Test_acc 61.19
2024-09-02 10:59:59,336 [podnet.py] => Task 2, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 62.07
2024-09-02 11:00:01,228 [podnet.py] => Task 2, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 62.28
2024-09-02 11:00:03,325 [podnet.py] => Task 2, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 58.85
2024-09-02 11:00:05,116 [podnet.py] => Task 2, Epoch 213/300 (LR 0.01935) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 62.00
2024-09-02 11:00:06,857 [podnet.py] => Task 2, Epoch 214/300 (LR 0.01894) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 62.22
2024-09-02 11:00:08,305 [podnet.py] => Task 2, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 99.98, Test_acc 62.09
2024-09-02 11:00:09,838 [podnet.py] => Task 2, Epoch 216/300 (LR 0.01813) => LSC_loss 0.05, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 99.96, Test_acc 55.02
2024-09-02 11:00:11,506 [podnet.py] => Task 2, Epoch 217/300 (LR 0.01773) => LSC_loss 0.07, Spatial_loss 0.15, Flat_loss 0.43, Train_acc 99.33, Test_acc 57.35
2024-09-02 11:00:12,742 [podnet.py] => Task 2, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.39, Train_acc 99.91, Test_acc 60.13
2024-09-02 11:00:14,813 [podnet.py] => Task 2, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.80
2024-09-02 11:00:16,747 [podnet.py] => Task 2, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.33
2024-09-02 11:00:18,891 [podnet.py] => Task 2, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.38, Train_acc 99.93, Test_acc 59.46
2024-09-02 11:00:20,944 [podnet.py] => Task 2, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.39, Train_acc 99.98, Test_acc 61.70
2024-09-02 11:00:23,196 [podnet.py] => Task 2, Epoch 223/300 (LR 0.01539) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 99.98, Test_acc 60.02
2024-09-02 11:00:24,855 [podnet.py] => Task 2, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.69
2024-09-02 11:00:26,923 [podnet.py] => Task 2, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 61.06
2024-09-02 11:00:28,989 [podnet.py] => Task 2, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.17
2024-09-02 11:00:30,809 [podnet.py] => Task 2, Epoch 227/300 (LR 0.01391) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 99.98, Test_acc 60.07
2024-09-02 11:00:32,473 [podnet.py] => Task 2, Epoch 228/300 (LR 0.01355) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.37, Train_acc 99.69, Test_acc 60.22
2024-09-02 11:00:34,217 [podnet.py] => Task 2, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 99.96, Test_acc 60.63
2024-09-02 11:00:36,224 [podnet.py] => Task 2, Epoch 230/300 (LR 0.01284) => LSC_loss 0.10, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 99.80, Test_acc 59.33
2024-09-02 11:00:37,830 [podnet.py] => Task 2, Epoch 231/300 (LR 0.01249) => LSC_loss 0.10, Spatial_loss 0.15, Flat_loss 0.47, Train_acc 98.20, Test_acc 55.98
2024-09-02 11:00:39,493 [podnet.py] => Task 2, Epoch 232/300 (LR 0.01215) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.41, Train_acc 99.84, Test_acc 53.13
2024-09-02 11:00:41,347 [podnet.py] => Task 2, Epoch 233/300 (LR 0.01181) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.41, Train_acc 99.82, Test_acc 58.28
2024-09-02 11:00:42,982 [podnet.py] => Task 2, Epoch 234/300 (LR 0.01147) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.38, Train_acc 100.00, Test_acc 59.24
2024-09-02 11:00:44,797 [podnet.py] => Task 2, Epoch 235/300 (LR 0.01114) => LSC_loss 0.05, Spatial_loss 0.12, Flat_loss 0.39, Train_acc 99.73, Test_acc 36.83
2024-09-02 11:00:46,731 [podnet.py] => Task 2, Epoch 236/300 (LR 0.01082) => LSC_loss 0.06, Spatial_loss 0.14, Flat_loss 0.43, Train_acc 99.31, Test_acc 57.69
2024-09-02 11:00:48,443 [podnet.py] => Task 2, Epoch 237/300 (LR 0.01049) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.40, Train_acc 99.91, Test_acc 57.57
2024-09-02 11:00:50,292 [podnet.py] => Task 2, Epoch 238/300 (LR 0.01017) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.39, Train_acc 99.96, Test_acc 56.52
2024-09-02 11:00:52,115 [podnet.py] => Task 2, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.39, Train_acc 99.84, Test_acc 58.72
2024-09-02 11:00:53,964 [podnet.py] => Task 2, Epoch 240/300 (LR 0.00955) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.38, Train_acc 100.00, Test_acc 58.61
2024-09-02 11:00:56,166 [podnet.py] => Task 2, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 58.54
2024-09-02 11:00:58,289 [podnet.py] => Task 2, Epoch 242/300 (LR 0.00894) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 58.63
2024-09-02 11:01:00,523 [podnet.py] => Task 2, Epoch 243/300 (LR 0.00865) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 99.98, Test_acc 59.80
2024-09-02 11:01:02,636 [podnet.py] => Task 2, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.19
2024-09-02 11:01:04,448 [podnet.py] => Task 2, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.26
2024-09-02 11:01:06,010 [podnet.py] => Task 2, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.35
2024-09-02 11:01:07,977 [podnet.py] => Task 2, Epoch 247/300 (LR 0.00751) => LSC_loss 0.05, Spatial_loss 0.14, Flat_loss 0.39, Train_acc 99.69, Test_acc 52.28
2024-09-02 11:01:09,572 [podnet.py] => Task 2, Epoch 248/300 (LR 0.00723) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.40, Train_acc 99.82, Test_acc 58.20
2024-09-02 11:01:11,002 [podnet.py] => Task 2, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.39, Train_acc 99.84, Test_acc 59.98
2024-09-02 11:01:12,442 [podnet.py] => Task 2, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.38, Train_acc 99.98, Test_acc 59.63
2024-09-02 11:01:13,944 [podnet.py] => Task 2, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.40, Train_acc 99.91, Test_acc 36.54
2024-09-02 11:01:15,628 [podnet.py] => Task 2, Epoch 252/300 (LR 0.00618) => LSC_loss 0.05, Spatial_loss 0.13, Flat_loss 0.43, Train_acc 99.64, Test_acc 58.37
2024-09-02 11:01:17,193 [podnet.py] => Task 2, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.41, Train_acc 100.00, Test_acc 59.56
2024-09-02 11:01:18,489 [podnet.py] => Task 2, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.39, Train_acc 100.00, Test_acc 59.43
2024-09-02 11:01:20,383 [podnet.py] => Task 2, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.39, Train_acc 100.00, Test_acc 59.56
2024-09-02 11:01:21,957 [podnet.py] => Task 2, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.38, Train_acc 100.00, Test_acc 59.52
2024-09-02 11:01:23,451 [podnet.py] => Task 2, Epoch 257/300 (LR 0.00498) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.38, Train_acc 100.00, Test_acc 60.46
2024-09-02 11:01:25,265 [podnet.py] => Task 2, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.38, Train_acc 100.00, Test_acc 60.24
2024-09-02 11:01:26,899 [podnet.py] => Task 2, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.70
2024-09-02 11:01:28,574 [podnet.py] => Task 2, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.06
2024-09-02 11:01:30,598 [podnet.py] => Task 2, Epoch 261/300 (LR 0.00411) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.67
2024-09-02 11:01:32,239 [podnet.py] => Task 2, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 99.98, Test_acc 60.59
2024-09-02 11:01:34,308 [podnet.py] => Task 2, Epoch 263/300 (LR 0.00371) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.38, Train_acc 100.00, Test_acc 60.28
2024-09-02 11:01:36,199 [podnet.py] => Task 2, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.38, Train_acc 100.00, Test_acc 60.04
2024-09-02 11:01:37,800 [podnet.py] => Task 2, Epoch 265/300 (LR 0.00332) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.07
2024-09-02 11:01:39,556 [podnet.py] => Task 2, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 99.98, Test_acc 59.81
2024-09-02 11:01:41,090 [podnet.py] => Task 2, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.85
2024-09-02 11:01:42,739 [podnet.py] => Task 2, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.37
2024-09-02 11:01:44,434 [podnet.py] => Task 2, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.24
2024-09-02 11:01:46,073 [podnet.py] => Task 2, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.24
2024-09-02 11:01:47,658 [podnet.py] => Task 2, Epoch 271/300 (LR 0.00229) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.91
2024-09-02 11:01:49,664 [podnet.py] => Task 2, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.02
2024-09-02 11:01:51,333 [podnet.py] => Task 2, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.57
2024-09-02 11:01:53,385 [podnet.py] => Task 2, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.46
2024-09-02 11:01:55,147 [podnet.py] => Task 2, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.22
2024-09-02 11:01:57,003 [podnet.py] => Task 2, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.93
2024-09-02 11:01:58,584 [podnet.py] => Task 2, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 59.98
2024-09-02 11:02:00,730 [podnet.py] => Task 2, Epoch 278/300 (LR 0.00132) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.56
2024-09-02 11:02:02,980 [podnet.py] => Task 2, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.15
2024-09-02 11:02:05,295 [podnet.py] => Task 2, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.39
2024-09-02 11:02:07,670 [podnet.py] => Task 2, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 59.52
2024-09-02 11:02:10,099 [podnet.py] => Task 2, Epoch 282/300 (LR 0.00089) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.24
2024-09-02 11:02:12,516 [podnet.py] => Task 2, Epoch 283/300 (LR 0.00079) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.63
2024-09-02 11:02:14,968 [podnet.py] => Task 2, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.36, Train_acc 100.00, Test_acc 61.00
2024-09-02 11:02:17,151 [podnet.py] => Task 2, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.57
2024-09-02 11:02:19,355 [podnet.py] => Task 2, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.85
2024-09-02 11:02:21,530 [podnet.py] => Task 2, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.35
2024-09-02 11:02:23,740 [podnet.py] => Task 2, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.37, Train_acc 100.00, Test_acc 60.41
2024-09-02 11:02:25,619 [podnet.py] => Task 2, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.56
2024-09-02 11:02:27,625 [podnet.py] => Task 2, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.46
2024-09-02 11:02:29,866 [podnet.py] => Task 2, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.30
2024-09-02 11:02:31,979 [podnet.py] => Task 2, Epoch 292/300 (LR 0.00018) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.46
2024-09-02 11:02:34,211 [podnet.py] => Task 2, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 59.80
2024-09-02 11:02:36,341 [podnet.py] => Task 2, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.13
2024-09-02 11:02:38,434 [podnet.py] => Task 2, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.13
2024-09-02 11:02:40,731 [podnet.py] => Task 2, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.07
2024-09-02 11:02:42,756 [podnet.py] => Task 2, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.39
2024-09-02 11:02:44,980 [podnet.py] => Task 2, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.15
2024-09-02 11:02:47,188 [podnet.py] => Task 2, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 100.00, Test_acc 60.61
2024-09-02 11:02:49,389 [podnet.py] => Task 2, Epoch 300/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.36, Train_acc 99.98, Test_acc 60.31
2024-09-02 11:02:49,390 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 11:02:49,390 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 11:02:50,713 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 11:02:52,286 [base.py] => Reducing exemplars...(55 per classes)
2024-09-02 11:02:53,477 [base.py] => Constructing exemplars...(55 per classes)
2024-09-02 11:02:55,740 [podnet.py] => Exemplar size: 495
2024-09-02 11:02:55,740 [trainer.py] => CNN: {'total': 60.31, '00-04': 51.27, '05-06': 47.17, '07-08': 96.08, 'old': 50.1, 'new': 96.08}
2024-09-02 11:02:55,740 [trainer.py] => NME: {'total': 61.54, '00-04': 63.17, '05-06': 47.5, '07-08': 71.5, 'old': 58.69, 'new': 71.5}
2024-09-02 11:02:55,740 [trainer.py] => CNN top1 curve: [88.9, 70.43, 60.31]
2024-09-02 11:02:55,740 [trainer.py] => CNN top5 curve: [100.0, 98.02, 88.67]
2024-09-02 11:02:55,740 [trainer.py] => NME top1 curve: [88.9, 73.81, 61.54]
2024-09-02 11:02:55,740 [trainer.py] => NME top5 curve: [100.0, 98.05, 91.85]

2024-09-02 11:02:55,740 [trainer.py] => Average Accuracy (CNN): 73.21333333333334
2024-09-02 11:02:55,741 [trainer.py] => Average Accuracy (NME): 74.75
2024-09-02 11:02:55,741 [trainer.py] => Forgetting (CNN): 42.815
