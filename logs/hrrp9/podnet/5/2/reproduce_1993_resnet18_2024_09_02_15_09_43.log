2024-09-02 15:09:43,700 [trainer.py] => config: ./exps/podnet.json
2024-09-02 15:09:43,700 [trainer.py] => prefix: reproduce
2024-09-02 15:09:43,700 [trainer.py] => dataset: hrrp9
2024-09-02 15:09:43,700 [trainer.py] => memory_size: 500
2024-09-02 15:09:43,700 [trainer.py] => memory_per_class: 20
2024-09-02 15:09:43,700 [trainer.py] => fixed_memory: False
2024-09-02 15:09:43,700 [trainer.py] => shuffle: True
2024-09-02 15:09:43,700 [trainer.py] => init_cls: 5
2024-09-02 15:09:43,700 [trainer.py] => increment: 2
2024-09-02 15:09:43,700 [trainer.py] => model_name: podnet
2024-09-02 15:09:43,700 [trainer.py] => convnet_type: resnet18
2024-09-02 15:09:43,700 [trainer.py] => init_train: True
2024-09-02 15:09:43,700 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-02 15:09:43,700 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-02 15:09:43,701 [trainer.py] => device: [device(type='cuda', index=6)]
2024-09-02 15:09:43,701 [trainer.py] => seed: 1993
2024-09-02 15:09:44,182 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-02 15:09:44,279 [trainer.py] => All params: 3843904
2024-09-02 15:09:44,279 [trainer.py] => Trainable params: 3843904
2024-09-02 15:09:44,280 [podnet.py] => Learning on 0-5
2024-09-02 15:09:44,316 [podnet.py] => Adaptive factor: 0
2024-09-02 15:09:47,140 [podnet.py] => Task 0, Epoch 1/300 (LR 0.10000) => LSC_loss 1.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 41.02, Test_acc 43.47
2024-09-02 15:09:48,931 [podnet.py] => Task 0, Epoch 2/300 (LR 0.09999) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.86, Test_acc 32.63
2024-09-02 15:09:50,764 [podnet.py] => Task 0, Epoch 3/300 (LR 0.09998) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.47, Test_acc 36.30
2024-09-02 15:09:52,252 [podnet.py] => Task 0, Epoch 4/300 (LR 0.09996) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.33, Test_acc 59.63
2024-09-02 15:09:53,898 [podnet.py] => Task 0, Epoch 5/300 (LR 0.09993) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.73, Test_acc 55.37
2024-09-02 15:09:55,847 [podnet.py] => Task 0, Epoch 6/300 (LR 0.09990) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.02, Test_acc 72.20
2024-09-02 15:09:57,501 [podnet.py] => Task 0, Epoch 7/300 (LR 0.09987) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.42, Test_acc 67.40
2024-09-02 15:09:59,293 [podnet.py] => Task 0, Epoch 8/300 (LR 0.09982) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.66, Test_acc 74.30
2024-09-02 15:10:01,029 [podnet.py] => Task 0, Epoch 9/300 (LR 0.09978) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.07, Test_acc 74.60
2024-09-02 15:10:02,755 [podnet.py] => Task 0, Epoch 10/300 (LR 0.09973) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.47, Test_acc 78.70
2024-09-02 15:10:04,315 [podnet.py] => Task 0, Epoch 11/300 (LR 0.09967) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 70.47
2024-09-02 15:10:06,543 [podnet.py] => Task 0, Epoch 12/300 (LR 0.09961) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.31, Test_acc 82.27
2024-09-02 15:10:08,583 [podnet.py] => Task 0, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.29, Test_acc 82.53
2024-09-02 15:10:10,531 [podnet.py] => Task 0, Epoch 14/300 (LR 0.09946) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 67.27
2024-09-02 15:10:12,718 [podnet.py] => Task 0, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.94, Test_acc 79.93
2024-09-02 15:10:14,610 [podnet.py] => Task 0, Epoch 16/300 (LR 0.09930) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.08, Test_acc 83.07
2024-09-02 15:10:16,738 [podnet.py] => Task 0, Epoch 17/300 (LR 0.09921) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.57, Test_acc 72.60
2024-09-02 15:10:18,315 [podnet.py] => Task 0, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.56, Test_acc 80.30
2024-09-02 15:10:20,530 [podnet.py] => Task 0, Epoch 19/300 (LR 0.09901) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 81.57
2024-09-02 15:10:22,424 [podnet.py] => Task 0, Epoch 20/300 (LR 0.09891) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 79.03
2024-09-02 15:10:24,607 [podnet.py] => Task 0, Epoch 21/300 (LR 0.09880) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 83.07
2024-09-02 15:10:26,380 [podnet.py] => Task 0, Epoch 22/300 (LR 0.09868) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.83, Test_acc 74.17
2024-09-02 15:10:28,227 [podnet.py] => Task 0, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 82.63
2024-09-02 15:10:30,066 [podnet.py] => Task 0, Epoch 24/300 (LR 0.09843) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 82.83
2024-09-02 15:10:31,756 [podnet.py] => Task 0, Epoch 25/300 (LR 0.09830) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.27, Test_acc 84.33
2024-09-02 15:10:33,452 [podnet.py] => Task 0, Epoch 26/300 (LR 0.09816) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.83, Test_acc 85.20
2024-09-02 15:10:35,050 [podnet.py] => Task 0, Epoch 27/300 (LR 0.09801) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 85.90
2024-09-02 15:10:36,706 [podnet.py] => Task 0, Epoch 28/300 (LR 0.09787) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.15, Test_acc 74.20
2024-09-02 15:10:38,346 [podnet.py] => Task 0, Epoch 29/300 (LR 0.09771) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 82.03
2024-09-02 15:10:40,056 [podnet.py] => Task 0, Epoch 30/300 (LR 0.09755) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 76.93
2024-09-02 15:10:41,823 [podnet.py] => Task 0, Epoch 31/300 (LR 0.09739) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.02, Test_acc 79.40
2024-09-02 15:10:43,642 [podnet.py] => Task 0, Epoch 32/300 (LR 0.09722) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.66, Test_acc 77.10
2024-09-02 15:10:45,469 [podnet.py] => Task 0, Epoch 33/300 (LR 0.09704) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.02, Test_acc 79.23
2024-09-02 15:10:47,113 [podnet.py] => Task 0, Epoch 34/300 (LR 0.09686) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.07, Test_acc 86.00
2024-09-02 15:10:48,999 [podnet.py] => Task 0, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 74.73
2024-09-02 15:10:50,864 [podnet.py] => Task 0, Epoch 36/300 (LR 0.09649) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.14, Test_acc 79.27
2024-09-02 15:10:52,593 [podnet.py] => Task 0, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 84.97
2024-09-02 15:10:54,400 [podnet.py] => Task 0, Epoch 38/300 (LR 0.09609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.08, Test_acc 84.70
2024-09-02 15:10:56,200 [podnet.py] => Task 0, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.69, Test_acc 82.83
2024-09-02 15:10:58,017 [podnet.py] => Task 0, Epoch 40/300 (LR 0.09568) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 75.70
2024-09-02 15:10:59,788 [podnet.py] => Task 0, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.97, Test_acc 83.57
2024-09-02 15:11:01,588 [podnet.py] => Task 0, Epoch 42/300 (LR 0.09524) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 82.43
2024-09-02 15:11:03,598 [podnet.py] => Task 0, Epoch 43/300 (LR 0.09502) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.89, Test_acc 86.70
2024-09-02 15:11:05,476 [podnet.py] => Task 0, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 71.70
2024-09-02 15:11:07,174 [podnet.py] => Task 0, Epoch 45/300 (LR 0.09455) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 84.30
2024-09-02 15:11:08,902 [podnet.py] => Task 0, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 80.70
2024-09-02 15:11:10,662 [podnet.py] => Task 0, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.17, Test_acc 84.67
2024-09-02 15:11:12,419 [podnet.py] => Task 0, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 83.63
2024-09-02 15:11:14,006 [podnet.py] => Task 0, Epoch 49/300 (LR 0.09356) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 85.03
2024-09-02 15:11:15,708 [podnet.py] => Task 0, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.65, Test_acc 82.57
2024-09-02 15:11:17,160 [podnet.py] => Task 0, Epoch 51/300 (LR 0.09304) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.39, Test_acc 88.17
2024-09-02 15:11:19,005 [podnet.py] => Task 0, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.86, Test_acc 80.73
2024-09-02 15:11:20,780 [podnet.py] => Task 0, Epoch 53/300 (LR 0.09249) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 78.07
2024-09-02 15:11:22,747 [podnet.py] => Task 0, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.67
2024-09-02 15:11:24,747 [podnet.py] => Task 0, Epoch 55/300 (LR 0.09193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.26, Test_acc 82.83
2024-09-02 15:11:26,981 [podnet.py] => Task 0, Epoch 56/300 (LR 0.09165) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 82.33
2024-09-02 15:11:29,196 [podnet.py] => Task 0, Epoch 57/300 (LR 0.09135) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.60, Test_acc 82.83
2024-09-02 15:11:30,718 [podnet.py] => Task 0, Epoch 58/300 (LR 0.09106) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.50, Test_acc 84.40
2024-09-02 15:11:32,410 [podnet.py] => Task 0, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 70.30
2024-09-02 15:11:34,121 [podnet.py] => Task 0, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 82.83
2024-09-02 15:11:35,737 [podnet.py] => Task 0, Epoch 61/300 (LR 0.09014) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.69, Test_acc 83.20
2024-09-02 15:11:37,555 [podnet.py] => Task 0, Epoch 62/300 (LR 0.08983) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.30, Test_acc 86.53
2024-09-02 15:11:39,321 [podnet.py] => Task 0, Epoch 63/300 (LR 0.08951) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.41, Test_acc 84.83
2024-09-02 15:11:41,421 [podnet.py] => Task 0, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 84.63
2024-09-02 15:11:43,244 [podnet.py] => Task 0, Epoch 65/300 (LR 0.08886) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 81.80
2024-09-02 15:11:44,943 [podnet.py] => Task 0, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 81.17
2024-09-02 15:11:46,807 [podnet.py] => Task 0, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 82.20
2024-09-02 15:11:48,703 [podnet.py] => Task 0, Epoch 68/300 (LR 0.08785) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.91, Test_acc 83.43
2024-09-02 15:11:50,646 [podnet.py] => Task 0, Epoch 69/300 (LR 0.08751) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.09, Test_acc 84.27
2024-09-02 15:11:52,323 [podnet.py] => Task 0, Epoch 70/300 (LR 0.08716) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.47, Test_acc 84.80
2024-09-02 15:11:54,469 [podnet.py] => Task 0, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 88.13
2024-09-02 15:11:56,474 [podnet.py] => Task 0, Epoch 72/300 (LR 0.08645) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 87.83
2024-09-02 15:11:58,295 [podnet.py] => Task 0, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.82, Test_acc 87.00
2024-09-02 15:12:00,103 [podnet.py] => Task 0, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 87.03
2024-09-02 15:12:01,513 [podnet.py] => Task 0, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 86.63
2024-09-02 15:12:03,253 [podnet.py] => Task 0, Epoch 76/300 (LR 0.08498) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.71, Test_acc 78.20
2024-09-02 15:12:04,700 [podnet.py] => Task 0, Epoch 77/300 (LR 0.08461) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 84.30
2024-09-02 15:12:06,395 [podnet.py] => Task 0, Epoch 78/300 (LR 0.08423) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 86.53
2024-09-02 15:12:08,094 [podnet.py] => Task 0, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 80.93
2024-09-02 15:12:09,952 [podnet.py] => Task 0, Epoch 80/300 (LR 0.08346) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.19, Test_acc 83.10
2024-09-02 15:12:11,629 [podnet.py] => Task 0, Epoch 81/300 (LR 0.08307) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.09, Test_acc 86.57
2024-09-02 15:12:13,141 [podnet.py] => Task 0, Epoch 82/300 (LR 0.08267) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 86.83
2024-09-02 15:12:15,046 [podnet.py] => Task 0, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.72, Test_acc 84.97
2024-09-02 15:12:16,787 [podnet.py] => Task 0, Epoch 84/300 (LR 0.08187) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.52, Test_acc 80.90
2024-09-02 15:12:18,307 [podnet.py] => Task 0, Epoch 85/300 (LR 0.08147) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.01, Test_acc 86.27
2024-09-02 15:12:20,038 [podnet.py] => Task 0, Epoch 86/300 (LR 0.08106) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.85, Test_acc 80.87
2024-09-02 15:12:21,594 [podnet.py] => Task 0, Epoch 87/300 (LR 0.08065) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.98, Test_acc 78.57
2024-09-02 15:12:23,130 [podnet.py] => Task 0, Epoch 88/300 (LR 0.08023) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.55, Test_acc 85.57
2024-09-02 15:12:24,830 [podnet.py] => Task 0, Epoch 89/300 (LR 0.07981) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 87.87
2024-09-02 15:12:26,513 [podnet.py] => Task 0, Epoch 90/300 (LR 0.07939) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.83
2024-09-02 15:12:28,226 [podnet.py] => Task 0, Epoch 91/300 (LR 0.07896) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.42, Test_acc 82.47
2024-09-02 15:12:29,714 [podnet.py] => Task 0, Epoch 92/300 (LR 0.07854) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.95, Test_acc 86.23
2024-09-02 15:12:31,331 [podnet.py] => Task 0, Epoch 93/300 (LR 0.07810) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 87.07
2024-09-02 15:12:32,904 [podnet.py] => Task 0, Epoch 94/300 (LR 0.07767) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 84.03
2024-09-02 15:12:34,513 [podnet.py] => Task 0, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 80.70
2024-09-02 15:12:36,224 [podnet.py] => Task 0, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 85.07
2024-09-02 15:12:37,992 [podnet.py] => Task 0, Epoch 97/300 (LR 0.07635) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 79.37
2024-09-02 15:12:39,983 [podnet.py] => Task 0, Epoch 98/300 (LR 0.07590) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 87.33
2024-09-02 15:12:42,399 [podnet.py] => Task 0, Epoch 99/300 (LR 0.07545) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.21, Test_acc 84.17
2024-09-02 15:12:44,183 [podnet.py] => Task 0, Epoch 100/300 (LR 0.07500) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 85.00
2024-09-02 15:12:45,983 [podnet.py] => Task 0, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.81, Test_acc 82.50
2024-09-02 15:12:47,895 [podnet.py] => Task 0, Epoch 102/300 (LR 0.07409) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.40
2024-09-02 15:12:49,843 [podnet.py] => Task 0, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.89, Test_acc 83.40
2024-09-02 15:12:51,986 [podnet.py] => Task 0, Epoch 104/300 (LR 0.07316) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 80.57
2024-09-02 15:12:54,055 [podnet.py] => Task 0, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.07, Test_acc 88.03
2024-09-02 15:12:56,163 [podnet.py] => Task 0, Epoch 106/300 (LR 0.07223) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 85.80
2024-09-02 15:12:57,887 [podnet.py] => Task 0, Epoch 107/300 (LR 0.07176) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.17, Test_acc 80.70
2024-09-02 15:12:59,527 [podnet.py] => Task 0, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 85.73
2024-09-02 15:13:01,286 [podnet.py] => Task 0, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.50
2024-09-02 15:13:02,756 [podnet.py] => Task 0, Epoch 110/300 (LR 0.07034) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 87.13
2024-09-02 15:13:04,698 [podnet.py] => Task 0, Epoch 111/300 (LR 0.06986) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.58, Test_acc 87.13
2024-09-02 15:13:06,649 [podnet.py] => Task 0, Epoch 112/300 (LR 0.06938) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.84, Test_acc 84.77
2024-09-02 15:13:08,361 [podnet.py] => Task 0, Epoch 113/300 (LR 0.06889) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.13, Test_acc 85.40
2024-09-02 15:13:09,950 [podnet.py] => Task 0, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 83.33
2024-09-02 15:13:11,665 [podnet.py] => Task 0, Epoch 115/300 (LR 0.06792) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 84.27
2024-09-02 15:13:13,267 [podnet.py] => Task 0, Epoch 116/300 (LR 0.06743) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.73
2024-09-02 15:13:14,913 [podnet.py] => Task 0, Epoch 117/300 (LR 0.06694) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.29, Test_acc 79.07
2024-09-02 15:13:16,689 [podnet.py] => Task 0, Epoch 118/300 (LR 0.06644) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 84.63
2024-09-02 15:13:18,647 [podnet.py] => Task 0, Epoch 119/300 (LR 0.06595) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 84.53
2024-09-02 15:13:20,607 [podnet.py] => Task 0, Epoch 120/300 (LR 0.06545) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 83.80
2024-09-02 15:13:22,442 [podnet.py] => Task 0, Epoch 121/300 (LR 0.06495) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.73, Test_acc 87.63
2024-09-02 15:13:24,350 [podnet.py] => Task 0, Epoch 122/300 (LR 0.06445) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 83.27
2024-09-02 15:13:26,167 [podnet.py] => Task 0, Epoch 123/300 (LR 0.06395) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 82.97
2024-09-02 15:13:28,389 [podnet.py] => Task 0, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 83.40
2024-09-02 15:13:30,195 [podnet.py] => Task 0, Epoch 125/300 (LR 0.06294) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.22, Test_acc 83.77
2024-09-02 15:13:31,958 [podnet.py] => Task 0, Epoch 126/300 (LR 0.06243) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 86.57
2024-09-02 15:13:33,925 [podnet.py] => Task 0, Epoch 127/300 (LR 0.06193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.36, Test_acc 86.00
2024-09-02 15:13:36,096 [podnet.py] => Task 0, Epoch 128/300 (LR 0.06142) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.84, Test_acc 84.60
2024-09-02 15:13:37,853 [podnet.py] => Task 0, Epoch 129/300 (LR 0.06091) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 87.97
2024-09-02 15:13:39,743 [podnet.py] => Task 0, Epoch 130/300 (LR 0.06040) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 82.23
2024-09-02 15:13:41,525 [podnet.py] => Task 0, Epoch 131/300 (LR 0.05988) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 86.90
2024-09-02 15:13:43,281 [podnet.py] => Task 0, Epoch 132/300 (LR 0.05937) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 89.73
2024-09-02 15:13:45,008 [podnet.py] => Task 0, Epoch 133/300 (LR 0.05885) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.57
2024-09-02 15:13:46,547 [podnet.py] => Task 0, Epoch 134/300 (LR 0.05834) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.87
2024-09-02 15:13:48,253 [podnet.py] => Task 0, Epoch 135/300 (LR 0.05782) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.44, Test_acc 85.53
2024-09-02 15:13:50,160 [podnet.py] => Task 0, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 79.13
2024-09-02 15:13:51,959 [podnet.py] => Task 0, Epoch 137/300 (LR 0.05679) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.71, Test_acc 88.00
2024-09-02 15:13:53,771 [podnet.py] => Task 0, Epoch 138/300 (LR 0.05627) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.33
2024-09-02 15:13:55,828 [podnet.py] => Task 0, Epoch 139/300 (LR 0.05575) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 88.17
2024-09-02 15:13:57,746 [podnet.py] => Task 0, Epoch 140/300 (LR 0.05523) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 82.47
2024-09-02 15:13:59,446 [podnet.py] => Task 0, Epoch 141/300 (LR 0.05471) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 84.93
2024-09-02 15:14:01,101 [podnet.py] => Task 0, Epoch 142/300 (LR 0.05418) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.70, Test_acc 84.13
2024-09-02 15:14:03,086 [podnet.py] => Task 0, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 84.60
2024-09-02 15:14:04,734 [podnet.py] => Task 0, Epoch 144/300 (LR 0.05314) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 87.83
2024-09-02 15:14:06,346 [podnet.py] => Task 0, Epoch 145/300 (LR 0.05262) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.45, Test_acc 86.60
2024-09-02 15:14:08,081 [podnet.py] => Task 0, Epoch 146/300 (LR 0.05209) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 81.50
2024-09-02 15:14:09,652 [podnet.py] => Task 0, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.53, Test_acc 86.77
2024-09-02 15:14:11,430 [podnet.py] => Task 0, Epoch 148/300 (LR 0.05105) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.37, Test_acc 84.77
2024-09-02 15:14:13,285 [podnet.py] => Task 0, Epoch 149/300 (LR 0.05052) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 85.70
2024-09-02 15:14:15,240 [podnet.py] => Task 0, Epoch 150/300 (LR 0.05000) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 86.57
2024-09-02 15:14:16,985 [podnet.py] => Task 0, Epoch 151/300 (LR 0.04948) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.81, Test_acc 84.43
2024-09-02 15:14:18,737 [podnet.py] => Task 0, Epoch 152/300 (LR 0.04895) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 88.60
2024-09-02 15:14:20,614 [podnet.py] => Task 0, Epoch 153/300 (LR 0.04843) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 87.07
2024-09-02 15:14:22,274 [podnet.py] => Task 0, Epoch 154/300 (LR 0.04791) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 87.57
2024-09-02 15:14:23,846 [podnet.py] => Task 0, Epoch 155/300 (LR 0.04738) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.14, Test_acc 81.10
2024-09-02 15:14:25,876 [podnet.py] => Task 0, Epoch 156/300 (LR 0.04686) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.67, Test_acc 88.10
2024-09-02 15:14:27,598 [podnet.py] => Task 0, Epoch 157/300 (LR 0.04634) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.87
2024-09-02 15:14:29,688 [podnet.py] => Task 0, Epoch 158/300 (LR 0.04582) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 88.53
2024-09-02 15:14:31,430 [podnet.py] => Task 0, Epoch 159/300 (LR 0.04529) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.43
2024-09-02 15:14:33,278 [podnet.py] => Task 0, Epoch 160/300 (LR 0.04477) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 86.20
2024-09-02 15:14:35,057 [podnet.py] => Task 0, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.68, Test_acc 84.87
2024-09-02 15:14:36,763 [podnet.py] => Task 0, Epoch 162/300 (LR 0.04373) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 88.27
2024-09-02 15:14:38,285 [podnet.py] => Task 0, Epoch 163/300 (LR 0.04321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 85.63
2024-09-02 15:14:40,315 [podnet.py] => Task 0, Epoch 164/300 (LR 0.04270) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 83.27
2024-09-02 15:14:42,184 [podnet.py] => Task 0, Epoch 165/300 (LR 0.04218) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 85.37
2024-09-02 15:14:43,942 [podnet.py] => Task 0, Epoch 166/300 (LR 0.04166) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 89.13
2024-09-02 15:14:45,726 [podnet.py] => Task 0, Epoch 167/300 (LR 0.04115) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.61, Test_acc 86.80
2024-09-02 15:14:47,628 [podnet.py] => Task 0, Epoch 168/300 (LR 0.04063) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.17
2024-09-02 15:14:49,412 [podnet.py] => Task 0, Epoch 169/300 (LR 0.04012) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.03
2024-09-02 15:14:51,369 [podnet.py] => Task 0, Epoch 170/300 (LR 0.03960) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 89.47
2024-09-02 15:14:53,854 [podnet.py] => Task 0, Epoch 171/300 (LR 0.03909) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.13
2024-09-02 15:14:55,592 [podnet.py] => Task 0, Epoch 172/300 (LR 0.03858) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.91, Test_acc 89.47
2024-09-02 15:14:57,353 [podnet.py] => Task 0, Epoch 173/300 (LR 0.03807) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 88.13
2024-09-02 15:14:59,036 [podnet.py] => Task 0, Epoch 174/300 (LR 0.03757) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 84.43
2024-09-02 15:15:00,759 [podnet.py] => Task 0, Epoch 175/300 (LR 0.03706) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.57, Test_acc 86.30
2024-09-02 15:15:02,536 [podnet.py] => Task 0, Epoch 176/300 (LR 0.03655) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 81.37
2024-09-02 15:15:04,191 [podnet.py] => Task 0, Epoch 177/300 (LR 0.03605) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.73, Test_acc 85.23
2024-09-02 15:15:05,947 [podnet.py] => Task 0, Epoch 178/300 (LR 0.03555) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 85.83
2024-09-02 15:15:07,630 [podnet.py] => Task 0, Epoch 179/300 (LR 0.03505) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.55, Test_acc 83.43
2024-09-02 15:15:09,418 [podnet.py] => Task 0, Epoch 180/300 (LR 0.03455) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 88.90
2024-09-02 15:15:11,163 [podnet.py] => Task 0, Epoch 181/300 (LR 0.03405) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 88.60
2024-09-02 15:15:12,969 [podnet.py] => Task 0, Epoch 182/300 (LR 0.03356) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.73
2024-09-02 15:15:14,811 [podnet.py] => Task 0, Epoch 183/300 (LR 0.03306) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.73
2024-09-02 15:15:16,494 [podnet.py] => Task 0, Epoch 184/300 (LR 0.03257) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.11, Test_acc 88.17
2024-09-02 15:15:18,168 [podnet.py] => Task 0, Epoch 185/300 (LR 0.03208) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 87.47
2024-09-02 15:15:19,945 [podnet.py] => Task 0, Epoch 186/300 (LR 0.03159) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 79.03
2024-09-02 15:15:22,144 [podnet.py] => Task 0, Epoch 187/300 (LR 0.03111) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.53, Test_acc 84.80
2024-09-02 15:15:24,105 [podnet.py] => Task 0, Epoch 188/300 (LR 0.03062) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.47, Test_acc 85.53
2024-09-02 15:15:25,982 [podnet.py] => Task 0, Epoch 189/300 (LR 0.03014) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.35, Test_acc 88.90
2024-09-02 15:15:27,696 [podnet.py] => Task 0, Epoch 190/300 (LR 0.02966) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 86.80
2024-09-02 15:15:29,496 [podnet.py] => Task 0, Epoch 191/300 (LR 0.02919) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.20
2024-09-02 15:15:31,252 [podnet.py] => Task 0, Epoch 192/300 (LR 0.02871) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 86.90
2024-09-02 15:15:33,141 [podnet.py] => Task 0, Epoch 193/300 (LR 0.02824) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 89.30
2024-09-02 15:15:34,700 [podnet.py] => Task 0, Epoch 194/300 (LR 0.02777) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.27
2024-09-02 15:15:36,537 [podnet.py] => Task 0, Epoch 195/300 (LR 0.02730) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.47
2024-09-02 15:15:38,316 [podnet.py] => Task 0, Epoch 196/300 (LR 0.02684) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.73
2024-09-02 15:15:40,148 [podnet.py] => Task 0, Epoch 197/300 (LR 0.02637) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.63
2024-09-02 15:15:41,995 [podnet.py] => Task 0, Epoch 198/300 (LR 0.02591) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.23
2024-09-02 15:15:43,860 [podnet.py] => Task 0, Epoch 199/300 (LR 0.02545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.60
2024-09-02 15:15:45,481 [podnet.py] => Task 0, Epoch 200/300 (LR 0.02500) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.67
2024-09-02 15:15:47,504 [podnet.py] => Task 0, Epoch 201/300 (LR 0.02455) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.67
2024-09-02 15:15:49,722 [podnet.py] => Task 0, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 88.40
2024-09-02 15:15:51,653 [podnet.py] => Task 0, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.02, Test_acc 88.30
2024-09-02 15:15:53,366 [podnet.py] => Task 0, Epoch 204/300 (LR 0.02321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 87.87
2024-09-02 15:15:55,315 [podnet.py] => Task 0, Epoch 205/300 (LR 0.02277) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 88.73
2024-09-02 15:15:57,296 [podnet.py] => Task 0, Epoch 206/300 (LR 0.02233) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.10
2024-09-02 15:15:59,258 [podnet.py] => Task 0, Epoch 207/300 (LR 0.02190) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.13
2024-09-02 15:16:01,309 [podnet.py] => Task 0, Epoch 208/300 (LR 0.02146) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 88.40
2024-09-02 15:16:03,235 [podnet.py] => Task 0, Epoch 209/300 (LR 0.02104) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 89.43
2024-09-02 15:16:05,081 [podnet.py] => Task 0, Epoch 210/300 (LR 0.02061) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.40
2024-09-02 15:16:06,944 [podnet.py] => Task 0, Epoch 211/300 (LR 0.02019) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 86.90
2024-09-02 15:16:08,589 [podnet.py] => Task 0, Epoch 212/300 (LR 0.01977) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 86.67
2024-09-02 15:16:10,587 [podnet.py] => Task 0, Epoch 213/300 (LR 0.01935) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.37
2024-09-02 15:16:12,687 [podnet.py] => Task 0, Epoch 214/300 (LR 0.01894) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 89.67
2024-09-02 15:16:14,560 [podnet.py] => Task 0, Epoch 215/300 (LR 0.01853) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 89.77
2024-09-02 15:16:16,373 [podnet.py] => Task 0, Epoch 216/300 (LR 0.01813) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.20
2024-09-02 15:16:18,077 [podnet.py] => Task 0, Epoch 217/300 (LR 0.01773) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.83
2024-09-02 15:16:19,975 [podnet.py] => Task 0, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.16, Test_acc 89.30
2024-09-02 15:16:21,660 [podnet.py] => Task 0, Epoch 219/300 (LR 0.01693) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 88.13
2024-09-02 15:16:23,886 [podnet.py] => Task 0, Epoch 220/300 (LR 0.01654) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.87, Test_acc 89.87
2024-09-02 15:16:25,732 [podnet.py] => Task 0, Epoch 221/300 (LR 0.01616) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.98, Test_acc 89.27
2024-09-02 15:16:27,746 [podnet.py] => Task 0, Epoch 222/300 (LR 0.01577) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:16:29,276 [podnet.py] => Task 0, Epoch 223/300 (LR 0.01539) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 15:16:30,974 [podnet.py] => Task 0, Epoch 224/300 (LR 0.01502) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:16:32,804 [podnet.py] => Task 0, Epoch 225/300 (LR 0.01464) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:16:34,774 [podnet.py] => Task 0, Epoch 226/300 (LR 0.01428) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:16:36,532 [podnet.py] => Task 0, Epoch 227/300 (LR 0.01391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 15:16:38,372 [podnet.py] => Task 0, Epoch 228/300 (LR 0.01355) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.33
2024-09-02 15:16:40,531 [podnet.py] => Task 0, Epoch 229/300 (LR 0.01320) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:16:42,440 [podnet.py] => Task 0, Epoch 230/300 (LR 0.01284) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.13
2024-09-02 15:16:44,211 [podnet.py] => Task 0, Epoch 231/300 (LR 0.01249) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.00
2024-09-02 15:16:46,034 [podnet.py] => Task 0, Epoch 232/300 (LR 0.01215) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.90
2024-09-02 15:16:47,779 [podnet.py] => Task 0, Epoch 233/300 (LR 0.01181) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.07
2024-09-02 15:16:49,417 [podnet.py] => Task 0, Epoch 234/300 (LR 0.01147) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.10
2024-09-02 15:16:51,282 [podnet.py] => Task 0, Epoch 235/300 (LR 0.01114) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.03
2024-09-02 15:16:53,088 [podnet.py] => Task 0, Epoch 236/300 (LR 0.01082) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 89.43
2024-09-02 15:16:54,944 [podnet.py] => Task 0, Epoch 237/300 (LR 0.01049) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 15:16:56,739 [podnet.py] => Task 0, Epoch 238/300 (LR 0.01017) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:16:58,621 [podnet.py] => Task 0, Epoch 239/300 (LR 0.00986) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:17:00,770 [podnet.py] => Task 0, Epoch 240/300 (LR 0.00955) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:17:02,703 [podnet.py] => Task 0, Epoch 241/300 (LR 0.00924) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 15:17:04,452 [podnet.py] => Task 0, Epoch 242/300 (LR 0.00894) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.33
2024-09-02 15:17:06,357 [podnet.py] => Task 0, Epoch 243/300 (LR 0.00865) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 15:17:08,310 [podnet.py] => Task 0, Epoch 244/300 (LR 0.00835) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:17:10,002 [podnet.py] => Task 0, Epoch 245/300 (LR 0.00807) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.73
2024-09-02 15:17:11,885 [podnet.py] => Task 0, Epoch 246/300 (LR 0.00778) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 15:17:13,963 [podnet.py] => Task 0, Epoch 247/300 (LR 0.00751) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:17:16,056 [podnet.py] => Task 0, Epoch 248/300 (LR 0.00723) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 15:17:17,786 [podnet.py] => Task 0, Epoch 249/300 (LR 0.00696) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 15:17:19,794 [podnet.py] => Task 0, Epoch 250/300 (LR 0.00670) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:17:21,630 [podnet.py] => Task 0, Epoch 251/300 (LR 0.00644) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 15:17:23,384 [podnet.py] => Task 0, Epoch 252/300 (LR 0.00618) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:17:25,410 [podnet.py] => Task 0, Epoch 253/300 (LR 0.00593) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:17:27,301 [podnet.py] => Task 0, Epoch 254/300 (LR 0.00569) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:17:29,157 [podnet.py] => Task 0, Epoch 255/300 (LR 0.00545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 15:17:31,107 [podnet.py] => Task 0, Epoch 256/300 (LR 0.00521) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 15:17:32,679 [podnet.py] => Task 0, Epoch 257/300 (LR 0.00498) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.57
2024-09-02 15:17:34,804 [podnet.py] => Task 0, Epoch 258/300 (LR 0.00476) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.87
2024-09-02 15:17:37,055 [podnet.py] => Task 0, Epoch 259/300 (LR 0.00454) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 15:17:39,247 [podnet.py] => Task 0, Epoch 260/300 (LR 0.00432) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.77
2024-09-02 15:17:41,420 [podnet.py] => Task 0, Epoch 261/300 (LR 0.00411) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 15:17:43,855 [podnet.py] => Task 0, Epoch 262/300 (LR 0.00391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:17:46,158 [podnet.py] => Task 0, Epoch 263/300 (LR 0.00371) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.80
2024-09-02 15:17:48,123 [podnet.py] => Task 0, Epoch 264/300 (LR 0.00351) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 15:17:50,164 [podnet.py] => Task 0, Epoch 265/300 (LR 0.00332) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 15:17:52,429 [podnet.py] => Task 0, Epoch 266/300 (LR 0.00314) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 15:17:54,880 [podnet.py] => Task 0, Epoch 267/300 (LR 0.00296) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:17:56,946 [podnet.py] => Task 0, Epoch 268/300 (LR 0.00278) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:17:59,065 [podnet.py] => Task 0, Epoch 269/300 (LR 0.00261) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:18:01,490 [podnet.py] => Task 0, Epoch 270/300 (LR 0.00245) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.63
2024-09-02 15:18:03,698 [podnet.py] => Task 0, Epoch 271/300 (LR 0.00229) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:18:05,912 [podnet.py] => Task 0, Epoch 272/300 (LR 0.00213) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:18:08,340 [podnet.py] => Task 0, Epoch 273/300 (LR 0.00199) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:18:10,882 [podnet.py] => Task 0, Epoch 274/300 (LR 0.00184) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:18:13,553 [podnet.py] => Task 0, Epoch 275/300 (LR 0.00170) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:18:15,860 [podnet.py] => Task 0, Epoch 276/300 (LR 0.00157) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:18:18,388 [podnet.py] => Task 0, Epoch 277/300 (LR 0.00144) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:18:20,648 [podnet.py] => Task 0, Epoch 278/300 (LR 0.00132) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.70
2024-09-02 15:18:23,662 [podnet.py] => Task 0, Epoch 279/300 (LR 0.00120) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 88.97
2024-09-02 15:18:25,906 [podnet.py] => Task 0, Epoch 280/300 (LR 0.00109) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:18:28,134 [podnet.py] => Task 0, Epoch 281/300 (LR 0.00099) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 15:18:30,896 [podnet.py] => Task 0, Epoch 282/300 (LR 0.00089) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 15:18:33,440 [podnet.py] => Task 0, Epoch 283/300 (LR 0.00079) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 15:18:35,460 [podnet.py] => Task 0, Epoch 284/300 (LR 0.00070) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 15:18:37,544 [podnet.py] => Task 0, Epoch 285/300 (LR 0.00062) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 15:18:39,785 [podnet.py] => Task 0, Epoch 286/300 (LR 0.00054) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:18:41,839 [podnet.py] => Task 0, Epoch 287/300 (LR 0.00046) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.17
2024-09-02 15:18:43,726 [podnet.py] => Task 0, Epoch 288/300 (LR 0.00039) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:18:45,561 [podnet.py] => Task 0, Epoch 289/300 (LR 0.00033) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 15:18:48,007 [podnet.py] => Task 0, Epoch 290/300 (LR 0.00027) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:18:50,140 [podnet.py] => Task 0, Epoch 291/300 (LR 0.00022) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:18:52,360 [podnet.py] => Task 0, Epoch 292/300 (LR 0.00018) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:18:55,234 [podnet.py] => Task 0, Epoch 293/300 (LR 0.00013) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.97
2024-09-02 15:18:58,041 [podnet.py] => Task 0, Epoch 294/300 (LR 0.00010) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:19:00,680 [podnet.py] => Task 0, Epoch 295/300 (LR 0.00007) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:19:03,252 [podnet.py] => Task 0, Epoch 296/300 (LR 0.00004) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.17
2024-09-02 15:19:05,440 [podnet.py] => Task 0, Epoch 297/300 (LR 0.00002) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.87
2024-09-02 15:19:08,121 [podnet.py] => Task 0, Epoch 298/300 (LR 0.00001) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:19:10,279 [podnet.py] => Task 0, Epoch 299/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:19:12,590 [podnet.py] => Task 0, Epoch 300/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.90
2024-09-02 15:19:12,591 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 15:19:12,591 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 15:19:18,197 [podnet.py] => Exemplar size: 500
2024-09-02 15:19:18,197 [trainer.py] => CNN: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 15:19:18,197 [trainer.py] => NME: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 15:19:18,197 [trainer.py] => CNN top1 curve: [88.9]
2024-09-02 15:19:18,197 [trainer.py] => CNN top5 curve: [100.0]
2024-09-02 15:19:18,197 [trainer.py] => NME top1 curve: [88.9]
2024-09-02 15:19:18,197 [trainer.py] => NME top5 curve: [100.0]

2024-09-02 15:19:18,197 [trainer.py] => Average Accuracy (CNN): 88.9
2024-09-02 15:19:18,197 [trainer.py] => Average Accuracy (NME): 88.9
2024-09-02 15:19:18,198 [trainer.py] => All params: 3869505
2024-09-02 15:19:18,198 [trainer.py] => Trainable params: 3869505
2024-09-02 15:19:18,199 [podnet.py] => Learning on 5-7
2024-09-02 15:19:18,212 [podnet.py] => Adaptive factor: 1.8708286933869707
2024-09-02 15:19:19,846 [podnet.py] => Task 1, Epoch 1/300 (LR 0.10000) => LSC_loss 1.11, Spatial_loss 0.70, Flat_loss 0.75, Train_acc 73.13, Test_acc 17.43
2024-09-02 15:19:21,515 [podnet.py] => Task 1, Epoch 2/300 (LR 0.09999) => LSC_loss 0.51, Spatial_loss 0.58, Flat_loss 0.53, Train_acc 87.60, Test_acc 19.67
2024-09-02 15:19:23,522 [podnet.py] => Task 1, Epoch 3/300 (LR 0.09998) => LSC_loss 0.44, Spatial_loss 0.55, Flat_loss 0.47, Train_acc 89.09, Test_acc 36.31
2024-09-02 15:19:25,436 [podnet.py] => Task 1, Epoch 4/300 (LR 0.09996) => LSC_loss 0.41, Spatial_loss 0.55, Flat_loss 0.45, Train_acc 89.49, Test_acc 36.17
2024-09-02 15:19:27,381 [podnet.py] => Task 1, Epoch 5/300 (LR 0.09993) => LSC_loss 0.27, Spatial_loss 0.47, Flat_loss 0.38, Train_acc 93.56, Test_acc 45.81
2024-09-02 15:19:29,388 [podnet.py] => Task 1, Epoch 6/300 (LR 0.09990) => LSC_loss 0.22, Spatial_loss 0.45, Flat_loss 0.35, Train_acc 94.80, Test_acc 49.24
2024-09-02 15:19:31,505 [podnet.py] => Task 1, Epoch 7/300 (LR 0.09987) => LSC_loss 0.18, Spatial_loss 0.41, Flat_loss 0.32, Train_acc 95.98, Test_acc 55.83
2024-09-02 15:19:33,507 [podnet.py] => Task 1, Epoch 8/300 (LR 0.09982) => LSC_loss 0.14, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 96.91, Test_acc 58.45
2024-09-02 15:19:35,026 [podnet.py] => Task 1, Epoch 9/300 (LR 0.09978) => LSC_loss 0.12, Spatial_loss 0.35, Flat_loss 0.27, Train_acc 97.89, Test_acc 59.45
2024-09-02 15:19:37,102 [podnet.py] => Task 1, Epoch 10/300 (LR 0.09973) => LSC_loss 0.11, Spatial_loss 0.34, Flat_loss 0.26, Train_acc 98.40, Test_acc 60.26
2024-09-02 15:19:39,333 [podnet.py] => Task 1, Epoch 11/300 (LR 0.09967) => LSC_loss 0.11, Spatial_loss 0.33, Flat_loss 0.25, Train_acc 98.38, Test_acc 61.57
2024-09-02 15:19:41,116 [podnet.py] => Task 1, Epoch 12/300 (LR 0.09961) => LSC_loss 0.12, Spatial_loss 0.36, Flat_loss 0.27, Train_acc 97.56, Test_acc 60.10
2024-09-02 15:19:43,049 [podnet.py] => Task 1, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.33, Flat_loss 0.25, Train_acc 98.53, Test_acc 61.50
2024-09-02 15:19:44,943 [podnet.py] => Task 1, Epoch 14/300 (LR 0.09946) => LSC_loss 0.08, Spatial_loss 0.30, Flat_loss 0.23, Train_acc 99.27, Test_acc 56.81
2024-09-02 15:19:47,076 [podnet.py] => Task 1, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.30, Flat_loss 0.22, Train_acc 99.47, Test_acc 60.79
2024-09-02 15:19:49,170 [podnet.py] => Task 1, Epoch 16/300 (LR 0.09930) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.22, Train_acc 99.40, Test_acc 65.21
2024-09-02 15:19:51,343 [podnet.py] => Task 1, Epoch 17/300 (LR 0.09921) => LSC_loss 0.07, Spatial_loss 0.27, Flat_loss 0.21, Train_acc 99.60, Test_acc 58.52
2024-09-02 15:19:53,397 [podnet.py] => Task 1, Epoch 18/300 (LR 0.09911) => LSC_loss 0.19, Spatial_loss 0.39, Flat_loss 0.29, Train_acc 95.44, Test_acc 42.57
2024-09-02 15:19:55,401 [podnet.py] => Task 1, Epoch 19/300 (LR 0.09901) => LSC_loss 0.22, Spatial_loss 0.46, Flat_loss 0.34, Train_acc 93.93, Test_acc 47.67
2024-09-02 15:19:57,454 [podnet.py] => Task 1, Epoch 20/300 (LR 0.09891) => LSC_loss 0.13, Spatial_loss 0.41, Flat_loss 0.30, Train_acc 96.98, Test_acc 52.05
2024-09-02 15:19:59,417 [podnet.py] => Task 1, Epoch 21/300 (LR 0.09880) => LSC_loss 0.11, Spatial_loss 0.38, Flat_loss 0.28, Train_acc 97.73, Test_acc 63.12
2024-09-02 15:20:01,561 [podnet.py] => Task 1, Epoch 22/300 (LR 0.09868) => LSC_loss 0.07, Spatial_loss 0.31, Flat_loss 0.23, Train_acc 99.47, Test_acc 65.62
2024-09-02 15:20:03,554 [podnet.py] => Task 1, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.28, Flat_loss 0.21, Train_acc 99.76, Test_acc 68.90
2024-09-02 15:20:05,140 [podnet.py] => Task 1, Epoch 24/300 (LR 0.09843) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.82, Test_acc 62.52
2024-09-02 15:20:07,294 [podnet.py] => Task 1, Epoch 25/300 (LR 0.09830) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.87, Test_acc 62.10
2024-09-02 15:20:09,030 [podnet.py] => Task 1, Epoch 26/300 (LR 0.09816) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.19, Train_acc 99.73, Test_acc 64.43
2024-09-02 15:20:10,608 [podnet.py] => Task 1, Epoch 27/300 (LR 0.09801) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.71, Test_acc 61.33
2024-09-02 15:20:12,590 [podnet.py] => Task 1, Epoch 28/300 (LR 0.09787) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.19, Train_acc 99.73, Test_acc 65.40
2024-09-02 15:20:15,063 [podnet.py] => Task 1, Epoch 29/300 (LR 0.09771) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.89, Test_acc 66.14
2024-09-02 15:20:17,167 [podnet.py] => Task 1, Epoch 30/300 (LR 0.09755) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.82, Test_acc 65.55
2024-09-02 15:20:19,274 [podnet.py] => Task 1, Epoch 31/300 (LR 0.09739) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.82, Test_acc 66.74
2024-09-02 15:20:21,399 [podnet.py] => Task 1, Epoch 32/300 (LR 0.09722) => LSC_loss 0.06, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.80, Test_acc 60.52
2024-09-02 15:20:23,285 [podnet.py] => Task 1, Epoch 33/300 (LR 0.09704) => LSC_loss 0.26, Spatial_loss 0.47, Flat_loss 0.34, Train_acc 92.71, Test_acc 45.52
2024-09-02 15:20:25,160 [podnet.py] => Task 1, Epoch 34/300 (LR 0.09686) => LSC_loss 0.30, Spatial_loss 0.51, Flat_loss 0.38, Train_acc 92.00, Test_acc 50.07
2024-09-02 15:20:26,866 [podnet.py] => Task 1, Epoch 35/300 (LR 0.09668) => LSC_loss 0.14, Spatial_loss 0.43, Flat_loss 0.32, Train_acc 96.64, Test_acc 57.95
2024-09-02 15:20:28,629 [podnet.py] => Task 1, Epoch 36/300 (LR 0.09649) => LSC_loss 0.08, Spatial_loss 0.36, Flat_loss 0.27, Train_acc 98.56, Test_acc 61.05
2024-09-02 15:20:30,519 [podnet.py] => Task 1, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.23, Train_acc 99.56, Test_acc 61.71
2024-09-02 15:20:32,740 [podnet.py] => Task 1, Epoch 38/300 (LR 0.09609) => LSC_loss 0.06, Spatial_loss 0.28, Flat_loss 0.20, Train_acc 99.78, Test_acc 69.83
2024-09-02 15:20:34,773 [podnet.py] => Task 1, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.91, Test_acc 66.43
2024-09-02 15:20:36,698 [podnet.py] => Task 1, Epoch 40/300 (LR 0.09568) => LSC_loss 0.07, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.71, Test_acc 61.48
2024-09-02 15:20:38,750 [podnet.py] => Task 1, Epoch 41/300 (LR 0.09546) => LSC_loss 0.09, Spatial_loss 0.32, Flat_loss 0.24, Train_acc 98.76, Test_acc 63.26
2024-09-02 15:20:40,703 [podnet.py] => Task 1, Epoch 42/300 (LR 0.09524) => LSC_loss 0.08, Spatial_loss 0.33, Flat_loss 0.23, Train_acc 98.84, Test_acc 62.50
2024-09-02 15:20:42,481 [podnet.py] => Task 1, Epoch 43/300 (LR 0.09502) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.73, Test_acc 69.36
2024-09-02 15:20:44,301 [podnet.py] => Task 1, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.87, Test_acc 63.31
2024-09-02 15:20:46,103 [podnet.py] => Task 1, Epoch 45/300 (LR 0.09455) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.84, Test_acc 67.83
2024-09-02 15:20:48,327 [podnet.py] => Task 1, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.80, Test_acc 68.64
2024-09-02 15:20:50,573 [podnet.py] => Task 1, Epoch 47/300 (LR 0.09407) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.87, Test_acc 69.48
2024-09-02 15:20:52,543 [podnet.py] => Task 1, Epoch 48/300 (LR 0.09382) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.17, Train_acc 99.87, Test_acc 65.90
2024-09-02 15:20:54,361 [podnet.py] => Task 1, Epoch 49/300 (LR 0.09356) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.89, Test_acc 67.79
2024-09-02 15:20:56,115 [podnet.py] => Task 1, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.93, Test_acc 68.31
2024-09-02 15:20:57,861 [podnet.py] => Task 1, Epoch 51/300 (LR 0.09304) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.89, Test_acc 67.17
2024-09-02 15:20:59,864 [podnet.py] => Task 1, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.93, Test_acc 66.26
2024-09-02 15:21:01,901 [podnet.py] => Task 1, Epoch 53/300 (LR 0.09249) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.80, Test_acc 66.24
2024-09-02 15:21:03,877 [podnet.py] => Task 1, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.71, Test_acc 67.02
2024-09-02 15:21:06,004 [podnet.py] => Task 1, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.80, Test_acc 67.81
2024-09-02 15:21:08,073 [podnet.py] => Task 1, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.87, Test_acc 69.31
2024-09-02 15:21:10,079 [podnet.py] => Task 1, Epoch 57/300 (LR 0.09135) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.91, Test_acc 64.83
2024-09-02 15:21:12,279 [podnet.py] => Task 1, Epoch 58/300 (LR 0.09106) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 100.00, Test_acc 70.02
2024-09-02 15:21:14,403 [podnet.py] => Task 1, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 68.48
2024-09-02 15:21:16,385 [podnet.py] => Task 1, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.98, Test_acc 67.12
2024-09-02 15:21:18,630 [podnet.py] => Task 1, Epoch 61/300 (LR 0.09014) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.15, Train_acc 99.89, Test_acc 71.19
2024-09-02 15:21:20,682 [podnet.py] => Task 1, Epoch 62/300 (LR 0.08983) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 68.19
2024-09-02 15:21:22,888 [podnet.py] => Task 1, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.73, Test_acc 69.69
2024-09-02 15:21:25,042 [podnet.py] => Task 1, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.87, Test_acc 68.55
2024-09-02 15:21:27,091 [podnet.py] => Task 1, Epoch 65/300 (LR 0.08886) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.84, Test_acc 64.36
2024-09-02 15:21:28,596 [podnet.py] => Task 1, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.87, Test_acc 64.36
2024-09-02 15:21:30,362 [podnet.py] => Task 1, Epoch 67/300 (LR 0.08819) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 67.29
2024-09-02 15:21:32,162 [podnet.py] => Task 1, Epoch 68/300 (LR 0.08785) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.07
2024-09-02 15:21:33,933 [podnet.py] => Task 1, Epoch 69/300 (LR 0.08751) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 100.00, Test_acc 65.86
2024-09-02 15:21:35,875 [podnet.py] => Task 1, Epoch 70/300 (LR 0.08716) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 100.00, Test_acc 70.05
2024-09-02 15:21:38,083 [podnet.py] => Task 1, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.98, Test_acc 65.07
2024-09-02 15:21:40,292 [podnet.py] => Task 1, Epoch 72/300 (LR 0.08645) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.80, Test_acc 65.19
2024-09-02 15:21:42,248 [podnet.py] => Task 1, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.91, Test_acc 66.52
2024-09-02 15:21:44,188 [podnet.py] => Task 1, Epoch 74/300 (LR 0.08572) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 59.93
2024-09-02 15:21:46,129 [podnet.py] => Task 1, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.38
2024-09-02 15:21:48,023 [podnet.py] => Task 1, Epoch 76/300 (LR 0.08498) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 67.55
2024-09-02 15:21:50,002 [podnet.py] => Task 1, Epoch 77/300 (LR 0.08461) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.96, Test_acc 64.86
2024-09-02 15:21:51,714 [podnet.py] => Task 1, Epoch 78/300 (LR 0.08423) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.91, Test_acc 67.17
2024-09-02 15:21:53,348 [podnet.py] => Task 1, Epoch 79/300 (LR 0.08384) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.93, Test_acc 65.81
2024-09-02 15:21:55,202 [podnet.py] => Task 1, Epoch 80/300 (LR 0.08346) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.87, Test_acc 63.69
2024-09-02 15:21:57,451 [podnet.py] => Task 1, Epoch 81/300 (LR 0.08307) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 64.31
2024-09-02 15:21:59,633 [podnet.py] => Task 1, Epoch 82/300 (LR 0.08267) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 59.52
2024-09-02 15:22:01,775 [podnet.py] => Task 1, Epoch 83/300 (LR 0.08227) => LSC_loss 0.22, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 94.60, Test_acc 32.24
2024-09-02 15:22:04,080 [podnet.py] => Task 1, Epoch 84/300 (LR 0.08187) => LSC_loss 0.38, Spatial_loss 0.54, Flat_loss 0.41, Train_acc 90.98, Test_acc 36.19
2024-09-02 15:22:06,514 [podnet.py] => Task 1, Epoch 85/300 (LR 0.08147) => LSC_loss 0.25, Spatial_loss 0.50, Flat_loss 0.38, Train_acc 93.18, Test_acc 47.79
2024-09-02 15:22:08,813 [podnet.py] => Task 1, Epoch 86/300 (LR 0.08106) => LSC_loss 0.14, Spatial_loss 0.43, Flat_loss 0.32, Train_acc 96.09, Test_acc 63.69
2024-09-02 15:22:11,230 [podnet.py] => Task 1, Epoch 87/300 (LR 0.08065) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.25, Train_acc 98.71, Test_acc 60.52
2024-09-02 15:22:13,381 [podnet.py] => Task 1, Epoch 88/300 (LR 0.08023) => LSC_loss 0.06, Spatial_loss 0.30, Flat_loss 0.22, Train_acc 99.67, Test_acc 64.12
2024-09-02 15:22:15,361 [podnet.py] => Task 1, Epoch 89/300 (LR 0.07981) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.82, Test_acc 67.83
2024-09-02 15:22:16,982 [podnet.py] => Task 1, Epoch 90/300 (LR 0.07939) => LSC_loss 0.06, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.69, Test_acc 63.36
2024-09-02 15:22:18,847 [podnet.py] => Task 1, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.91, Test_acc 66.74
2024-09-02 15:22:20,855 [podnet.py] => Task 1, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.16, Train_acc 99.91, Test_acc 69.33
2024-09-02 15:22:22,932 [podnet.py] => Task 1, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.98, Test_acc 64.29
2024-09-02 15:22:24,986 [podnet.py] => Task 1, Epoch 94/300 (LR 0.07767) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.89, Test_acc 65.64
2024-09-02 15:22:27,289 [podnet.py] => Task 1, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.93, Test_acc 64.86
2024-09-02 15:22:29,573 [podnet.py] => Task 1, Epoch 96/300 (LR 0.07679) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.14, Train_acc 99.96, Test_acc 66.55
2024-09-02 15:22:31,657 [podnet.py] => Task 1, Epoch 97/300 (LR 0.07635) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.96, Test_acc 70.07
2024-09-02 15:22:33,702 [podnet.py] => Task 1, Epoch 98/300 (LR 0.07590) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.91, Test_acc 68.76
2024-09-02 15:22:35,802 [podnet.py] => Task 1, Epoch 99/300 (LR 0.07545) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 70.50
2024-09-02 15:22:37,901 [podnet.py] => Task 1, Epoch 100/300 (LR 0.07500) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.98, Test_acc 67.00
2024-09-02 15:22:40,101 [podnet.py] => Task 1, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.84, Test_acc 65.88
2024-09-02 15:22:42,135 [podnet.py] => Task 1, Epoch 102/300 (LR 0.07409) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.98, Test_acc 70.05
2024-09-02 15:22:44,291 [podnet.py] => Task 1, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 68.57
2024-09-02 15:22:46,559 [podnet.py] => Task 1, Epoch 104/300 (LR 0.07316) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 69.48
2024-09-02 15:22:49,065 [podnet.py] => Task 1, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 69.48
2024-09-02 15:22:51,348 [podnet.py] => Task 1, Epoch 106/300 (LR 0.07223) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 70.33
2024-09-02 15:22:53,376 [podnet.py] => Task 1, Epoch 107/300 (LR 0.07176) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.91, Test_acc 70.14
2024-09-02 15:22:55,243 [podnet.py] => Task 1, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 66.95
2024-09-02 15:22:57,642 [podnet.py] => Task 1, Epoch 109/300 (LR 0.07081) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.73, Test_acc 61.26
2024-09-02 15:23:00,231 [podnet.py] => Task 1, Epoch 110/300 (LR 0.07034) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 65.57
2024-09-02 15:23:02,433 [podnet.py] => Task 1, Epoch 111/300 (LR 0.06986) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 67.67
2024-09-02 15:23:04,283 [podnet.py] => Task 1, Epoch 112/300 (LR 0.06938) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 100.00, Test_acc 68.57
2024-09-02 15:23:06,463 [podnet.py] => Task 1, Epoch 113/300 (LR 0.06889) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.89, Test_acc 70.24
2024-09-02 15:23:08,667 [podnet.py] => Task 1, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 71.79
2024-09-02 15:23:10,717 [podnet.py] => Task 1, Epoch 115/300 (LR 0.06792) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.78, Test_acc 66.36
2024-09-02 15:23:12,804 [podnet.py] => Task 1, Epoch 116/300 (LR 0.06743) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.12, Train_acc 99.98, Test_acc 68.00
2024-09-02 15:23:14,860 [podnet.py] => Task 1, Epoch 117/300 (LR 0.06694) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 63.48
2024-09-02 15:23:17,023 [podnet.py] => Task 1, Epoch 118/300 (LR 0.06644) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.12, Train_acc 99.96, Test_acc 67.43
2024-09-02 15:23:18,948 [podnet.py] => Task 1, Epoch 119/300 (LR 0.06595) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 67.10
2024-09-02 15:23:20,946 [podnet.py] => Task 1, Epoch 120/300 (LR 0.06545) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 69.05
2024-09-02 15:23:22,789 [podnet.py] => Task 1, Epoch 121/300 (LR 0.06495) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.24
2024-09-02 15:23:24,819 [podnet.py] => Task 1, Epoch 122/300 (LR 0.06445) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.96, Test_acc 69.12
2024-09-02 15:23:27,092 [podnet.py] => Task 1, Epoch 123/300 (LR 0.06395) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.93, Test_acc 61.50
2024-09-02 15:23:29,321 [podnet.py] => Task 1, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.80, Test_acc 64.60
2024-09-02 15:23:31,398 [podnet.py] => Task 1, Epoch 125/300 (LR 0.06294) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 63.71
2024-09-02 15:23:33,155 [podnet.py] => Task 1, Epoch 126/300 (LR 0.06243) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.87, Test_acc 68.52
2024-09-02 15:23:35,418 [podnet.py] => Task 1, Epoch 127/300 (LR 0.06193) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.57
2024-09-02 15:23:37,827 [podnet.py] => Task 1, Epoch 128/300 (LR 0.06142) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.96, Test_acc 68.93
2024-09-02 15:23:40,260 [podnet.py] => Task 1, Epoch 129/300 (LR 0.06091) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.36
2024-09-02 15:23:42,323 [podnet.py] => Task 1, Epoch 130/300 (LR 0.06040) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.93, Test_acc 63.10
2024-09-02 15:23:44,132 [podnet.py] => Task 1, Epoch 131/300 (LR 0.05988) => LSC_loss 0.12, Spatial_loss 0.33, Flat_loss 0.23, Train_acc 97.33, Test_acc 47.31
2024-09-02 15:23:45,970 [podnet.py] => Task 1, Epoch 132/300 (LR 0.05937) => LSC_loss 0.19, Spatial_loss 0.39, Flat_loss 0.30, Train_acc 95.13, Test_acc 47.17
2024-09-02 15:23:47,982 [podnet.py] => Task 1, Epoch 133/300 (LR 0.05885) => LSC_loss 0.19, Spatial_loss 0.44, Flat_loss 0.33, Train_acc 95.04, Test_acc 53.31
2024-09-02 15:23:50,011 [podnet.py] => Task 1, Epoch 134/300 (LR 0.05834) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.25, Train_acc 98.49, Test_acc 67.88
2024-09-02 15:23:51,950 [podnet.py] => Task 1, Epoch 135/300 (LR 0.05782) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.71, Test_acc 65.43
2024-09-02 15:23:53,726 [podnet.py] => Task 1, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.82, Test_acc 67.48
2024-09-02 15:23:55,708 [podnet.py] => Task 1, Epoch 137/300 (LR 0.05679) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.82, Test_acc 68.38
2024-09-02 15:23:57,860 [podnet.py] => Task 1, Epoch 138/300 (LR 0.05627) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.91, Test_acc 66.64
2024-09-02 15:23:59,927 [podnet.py] => Task 1, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.87, Test_acc 70.02
2024-09-02 15:24:01,891 [podnet.py] => Task 1, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.93, Test_acc 68.95
2024-09-02 15:24:03,911 [podnet.py] => Task 1, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:24:05,947 [podnet.py] => Task 1, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 68.55
2024-09-02 15:24:08,119 [podnet.py] => Task 1, Epoch 143/300 (LR 0.05366) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.91, Test_acc 64.21
2024-09-02 15:24:10,355 [podnet.py] => Task 1, Epoch 144/300 (LR 0.05314) => LSC_loss 0.07, Spatial_loss 0.30, Flat_loss 0.21, Train_acc 98.96, Test_acc 64.36
2024-09-02 15:24:12,474 [podnet.py] => Task 1, Epoch 145/300 (LR 0.05262) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.82, Test_acc 67.62
2024-09-02 15:24:14,296 [podnet.py] => Task 1, Epoch 146/300 (LR 0.05209) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 68.48
2024-09-02 15:24:16,279 [podnet.py] => Task 1, Epoch 147/300 (LR 0.05157) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.96, Test_acc 69.50
2024-09-02 15:24:18,327 [podnet.py] => Task 1, Epoch 148/300 (LR 0.05105) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.93, Test_acc 68.07
2024-09-02 15:24:20,449 [podnet.py] => Task 1, Epoch 149/300 (LR 0.05052) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 70.19
2024-09-02 15:24:22,693 [podnet.py] => Task 1, Epoch 150/300 (LR 0.05000) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.88
2024-09-02 15:24:24,873 [podnet.py] => Task 1, Epoch 151/300 (LR 0.04948) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 69.02
2024-09-02 15:24:26,998 [podnet.py] => Task 1, Epoch 152/300 (LR 0.04895) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 68.83
2024-09-02 15:24:28,846 [podnet.py] => Task 1, Epoch 153/300 (LR 0.04843) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.93, Test_acc 70.79
2024-09-02 15:24:30,921 [podnet.py] => Task 1, Epoch 154/300 (LR 0.04791) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.52
2024-09-02 15:24:33,090 [podnet.py] => Task 1, Epoch 155/300 (LR 0.04738) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 69.67
2024-09-02 15:24:34,963 [podnet.py] => Task 1, Epoch 156/300 (LR 0.04686) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 70.93
2024-09-02 15:24:36,970 [podnet.py] => Task 1, Epoch 157/300 (LR 0.04634) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 70.93
2024-09-02 15:24:38,905 [podnet.py] => Task 1, Epoch 158/300 (LR 0.04582) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.74
2024-09-02 15:24:40,870 [podnet.py] => Task 1, Epoch 159/300 (LR 0.04529) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.33
2024-09-02 15:24:43,019 [podnet.py] => Task 1, Epoch 160/300 (LR 0.04477) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.05
2024-09-02 15:24:45,152 [podnet.py] => Task 1, Epoch 161/300 (LR 0.04425) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 68.21
2024-09-02 15:24:47,188 [podnet.py] => Task 1, Epoch 162/300 (LR 0.04373) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.38
2024-09-02 15:24:49,133 [podnet.py] => Task 1, Epoch 163/300 (LR 0.04321) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 70.31
2024-09-02 15:24:51,149 [podnet.py] => Task 1, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.91, Test_acc 62.19
2024-09-02 15:24:53,249 [podnet.py] => Task 1, Epoch 165/300 (LR 0.04218) => LSC_loss 0.11, Spatial_loss 0.36, Flat_loss 0.26, Train_acc 97.00, Test_acc 50.14
2024-09-02 15:24:55,257 [podnet.py] => Task 1, Epoch 166/300 (LR 0.04166) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.20, Train_acc 99.53, Test_acc 68.24
2024-09-02 15:24:57,468 [podnet.py] => Task 1, Epoch 167/300 (LR 0.04115) => LSC_loss 0.06, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.82, Test_acc 62.26
2024-09-02 15:24:59,759 [podnet.py] => Task 1, Epoch 168/300 (LR 0.04063) => LSC_loss 0.06, Spatial_loss 0.25, Flat_loss 0.19, Train_acc 99.36, Test_acc 68.95
2024-09-02 15:25:01,697 [podnet.py] => Task 1, Epoch 169/300 (LR 0.04012) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.82, Test_acc 66.83
2024-09-02 15:25:03,554 [podnet.py] => Task 1, Epoch 170/300 (LR 0.03960) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 100.00, Test_acc 69.31
2024-09-02 15:25:05,568 [podnet.py] => Task 1, Epoch 171/300 (LR 0.03909) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 68.74
2024-09-02 15:25:07,501 [podnet.py] => Task 1, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.13, Train_acc 99.93, Test_acc 69.52
2024-09-02 15:25:09,557 [podnet.py] => Task 1, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.48
2024-09-02 15:25:11,505 [podnet.py] => Task 1, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.45
2024-09-02 15:25:13,464 [podnet.py] => Task 1, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 100.00, Test_acc 69.52
2024-09-02 15:25:15,487 [podnet.py] => Task 1, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 72.50
2024-09-02 15:25:17,420 [podnet.py] => Task 1, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.64
2024-09-02 15:25:19,512 [podnet.py] => Task 1, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.76
2024-09-02 15:25:21,585 [podnet.py] => Task 1, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 71.62
2024-09-02 15:25:23,477 [podnet.py] => Task 1, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.07
2024-09-02 15:25:25,539 [podnet.py] => Task 1, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.45
2024-09-02 15:25:27,630 [podnet.py] => Task 1, Epoch 182/300 (LR 0.03356) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.38
2024-09-02 15:25:29,613 [podnet.py] => Task 1, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.07
2024-09-02 15:25:31,715 [podnet.py] => Task 1, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.11, Train_acc 99.98, Test_acc 69.21
2024-09-02 15:25:33,755 [podnet.py] => Task 1, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:25:35,668 [podnet.py] => Task 1, Epoch 186/300 (LR 0.03159) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:25:37,725 [podnet.py] => Task 1, Epoch 187/300 (LR 0.03111) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.14
2024-09-02 15:25:39,923 [podnet.py] => Task 1, Epoch 188/300 (LR 0.03062) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.45
2024-09-02 15:25:41,870 [podnet.py] => Task 1, Epoch 189/300 (LR 0.03014) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:25:43,914 [podnet.py] => Task 1, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.19
2024-09-02 15:25:45,887 [podnet.py] => Task 1, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.10
2024-09-02 15:25:47,608 [podnet.py] => Task 1, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.36
2024-09-02 15:25:49,691 [podnet.py] => Task 1, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.88
2024-09-02 15:25:51,652 [podnet.py] => Task 1, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.00
2024-09-02 15:25:53,425 [podnet.py] => Task 1, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.26
2024-09-02 15:25:55,386 [podnet.py] => Task 1, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 68.55
2024-09-02 15:25:57,335 [podnet.py] => Task 1, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.52
2024-09-02 15:25:59,298 [podnet.py] => Task 1, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:26:01,306 [podnet.py] => Task 1, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.86
2024-09-02 15:26:03,190 [podnet.py] => Task 1, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.52
2024-09-02 15:26:05,107 [podnet.py] => Task 1, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.45
2024-09-02 15:26:07,003 [podnet.py] => Task 1, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 69.00
2024-09-02 15:26:08,972 [podnet.py] => Task 1, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.48
2024-09-02 15:26:11,037 [podnet.py] => Task 1, Epoch 204/300 (LR 0.02321) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.67
2024-09-02 15:26:12,974 [podnet.py] => Task 1, Epoch 205/300 (LR 0.02277) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.05
2024-09-02 15:26:14,922 [podnet.py] => Task 1, Epoch 206/300 (LR 0.02233) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 99.98, Test_acc 72.21
2024-09-02 15:26:16,699 [podnet.py] => Task 1, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:26:18,789 [podnet.py] => Task 1, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:26:20,582 [podnet.py] => Task 1, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.62
2024-09-02 15:26:22,550 [podnet.py] => Task 1, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.40
2024-09-02 15:26:24,621 [podnet.py] => Task 1, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.98
2024-09-02 15:26:26,675 [podnet.py] => Task 1, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:26:28,734 [podnet.py] => Task 1, Epoch 213/300 (LR 0.01935) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.52
2024-09-02 15:26:30,688 [podnet.py] => Task 1, Epoch 214/300 (LR 0.01894) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.95
2024-09-02 15:26:32,744 [podnet.py] => Task 1, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 99.96, Test_acc 67.86
2024-09-02 15:26:34,702 [podnet.py] => Task 1, Epoch 216/300 (LR 0.01813) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.12, Train_acc 99.93, Test_acc 69.69
2024-09-02 15:26:36,639 [podnet.py] => Task 1, Epoch 217/300 (LR 0.01773) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.90
2024-09-02 15:26:38,568 [podnet.py] => Task 1, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:26:40,487 [podnet.py] => Task 1, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.00
2024-09-02 15:26:42,588 [podnet.py] => Task 1, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:26:44,538 [podnet.py] => Task 1, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.64
2024-09-02 15:26:46,543 [podnet.py] => Task 1, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:26:48,568 [podnet.py] => Task 1, Epoch 223/300 (LR 0.01539) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.00
2024-09-02 15:26:50,367 [podnet.py] => Task 1, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.71
2024-09-02 15:26:52,470 [podnet.py] => Task 1, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.64
2024-09-02 15:26:54,629 [podnet.py] => Task 1, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.29
2024-09-02 15:26:56,753 [podnet.py] => Task 1, Epoch 227/300 (LR 0.01391) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.64
2024-09-02 15:26:58,893 [podnet.py] => Task 1, Epoch 228/300 (LR 0.01355) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.57
2024-09-02 15:27:00,834 [podnet.py] => Task 1, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:27:02,728 [podnet.py] => Task 1, Epoch 230/300 (LR 0.01284) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.00
2024-09-02 15:27:04,718 [podnet.py] => Task 1, Epoch 231/300 (LR 0.01249) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.50
2024-09-02 15:27:06,868 [podnet.py] => Task 1, Epoch 232/300 (LR 0.01215) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:27:09,275 [podnet.py] => Task 1, Epoch 233/300 (LR 0.01181) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.10
2024-09-02 15:27:11,578 [podnet.py] => Task 1, Epoch 234/300 (LR 0.01147) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.74
2024-09-02 15:27:13,798 [podnet.py] => Task 1, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.57
2024-09-02 15:27:15,856 [podnet.py] => Task 1, Epoch 236/300 (LR 0.01082) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:27:17,830 [podnet.py] => Task 1, Epoch 237/300 (LR 0.01049) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.26
2024-09-02 15:27:19,677 [podnet.py] => Task 1, Epoch 238/300 (LR 0.01017) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.71
2024-09-02 15:27:21,664 [podnet.py] => Task 1, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.43
2024-09-02 15:27:23,689 [podnet.py] => Task 1, Epoch 240/300 (LR 0.00955) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.48
2024-09-02 15:27:25,751 [podnet.py] => Task 1, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.90
2024-09-02 15:27:27,745 [podnet.py] => Task 1, Epoch 242/300 (LR 0.00894) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:27:29,589 [podnet.py] => Task 1, Epoch 243/300 (LR 0.00865) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.71
2024-09-02 15:27:31,497 [podnet.py] => Task 1, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.81
2024-09-02 15:27:33,589 [podnet.py] => Task 1, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:27:35,616 [podnet.py] => Task 1, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:27:37,539 [podnet.py] => Task 1, Epoch 247/300 (LR 0.00751) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:27:39,566 [podnet.py] => Task 1, Epoch 248/300 (LR 0.00723) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.12
2024-09-02 15:27:41,518 [podnet.py] => Task 1, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.83
2024-09-02 15:27:43,478 [podnet.py] => Task 1, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:27:45,520 [podnet.py] => Task 1, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.50
2024-09-02 15:27:47,654 [podnet.py] => Task 1, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.74
2024-09-02 15:27:49,685 [podnet.py] => Task 1, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.69
2024-09-02 15:27:51,714 [podnet.py] => Task 1, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.57
2024-09-02 15:27:53,617 [podnet.py] => Task 1, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.79
2024-09-02 15:27:55,641 [podnet.py] => Task 1, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:27:57,686 [podnet.py] => Task 1, Epoch 257/300 (LR 0.00498) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:27:59,819 [podnet.py] => Task 1, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.60
2024-09-02 15:28:01,884 [podnet.py] => Task 1, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.50
2024-09-02 15:28:03,835 [podnet.py] => Task 1, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.81
2024-09-02 15:28:05,818 [podnet.py] => Task 1, Epoch 261/300 (LR 0.00411) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.36
2024-09-02 15:28:07,623 [podnet.py] => Task 1, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.88
2024-09-02 15:28:09,615 [podnet.py] => Task 1, Epoch 263/300 (LR 0.00371) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.10
2024-09-02 15:28:11,755 [podnet.py] => Task 1, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.31
2024-09-02 15:28:13,937 [podnet.py] => Task 1, Epoch 265/300 (LR 0.00332) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.45
2024-09-02 15:28:15,931 [podnet.py] => Task 1, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.19
2024-09-02 15:28:17,934 [podnet.py] => Task 1, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.24
2024-09-02 15:28:19,967 [podnet.py] => Task 1, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.98
2024-09-02 15:28:21,845 [podnet.py] => Task 1, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:28:24,018 [podnet.py] => Task 1, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:28:25,991 [podnet.py] => Task 1, Epoch 271/300 (LR 0.00229) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.36
2024-09-02 15:28:27,920 [podnet.py] => Task 1, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.74
2024-09-02 15:28:30,027 [podnet.py] => Task 1, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 99.98, Test_acc 70.38
2024-09-02 15:28:31,984 [podnet.py] => Task 1, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.19
2024-09-02 15:28:33,875 [podnet.py] => Task 1, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.26
2024-09-02 15:28:35,708 [podnet.py] => Task 1, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.93
2024-09-02 15:28:37,837 [podnet.py] => Task 1, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:28:39,831 [podnet.py] => Task 1, Epoch 278/300 (LR 0.00132) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.90
2024-09-02 15:28:41,840 [podnet.py] => Task 1, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:28:43,777 [podnet.py] => Task 1, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:28:45,694 [podnet.py] => Task 1, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.83
2024-09-02 15:28:47,761 [podnet.py] => Task 1, Epoch 282/300 (LR 0.00089) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:28:49,756 [podnet.py] => Task 1, Epoch 283/300 (LR 0.00079) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:28:51,881 [podnet.py] => Task 1, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:28:53,725 [podnet.py] => Task 1, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.81
2024-09-02 15:28:55,781 [podnet.py] => Task 1, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:28:57,828 [podnet.py] => Task 1, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.62
2024-09-02 15:28:59,905 [podnet.py] => Task 1, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.69
2024-09-02 15:29:01,881 [podnet.py] => Task 1, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:29:03,744 [podnet.py] => Task 1, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:29:05,631 [podnet.py] => Task 1, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.50
2024-09-02 15:29:07,745 [podnet.py] => Task 1, Epoch 292/300 (LR 0.00018) => LSC_loss 0.03, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.83
2024-09-02 15:29:09,883 [podnet.py] => Task 1, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.71
2024-09-02 15:29:11,869 [podnet.py] => Task 1, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.95
2024-09-02 15:29:13,968 [podnet.py] => Task 1, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.09, Train_acc 100.00, Test_acc 72.21
2024-09-02 15:29:15,860 [podnet.py] => Task 1, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:29:17,838 [podnet.py] => Task 1, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.76
2024-09-02 15:29:19,484 [podnet.py] => Task 1, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:29:21,043 [podnet.py] => Task 1, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.60
2024-09-02 15:29:22,773 [podnet.py] => Task 1, Epoch 300/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.17
2024-09-02 15:29:22,773 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 15:29:22,774 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 15:29:23,790 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 15:29:25,733 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 15:29:26,824 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 15:29:29,381 [podnet.py] => Exemplar size: 497
2024-09-02 15:29:29,381 [trainer.py] => CNN: {'total': 72.17, '00-04': 62.63, '05-06': 96.0, 'old': 62.63, 'new': 96.0}
2024-09-02 15:29:29,381 [trainer.py] => NME: {'total': 76.4, '00-04': 78.03, '05-06': 72.33, 'old': 78.03, 'new': 72.33}
2024-09-02 15:29:29,381 [trainer.py] => CNN top1 curve: [88.9, 72.17]
2024-09-02 15:29:29,382 [trainer.py] => CNN top5 curve: [100.0, 98.02]
2024-09-02 15:29:29,382 [trainer.py] => NME top1 curve: [88.9, 76.4]
2024-09-02 15:29:29,382 [trainer.py] => NME top5 curve: [100.0, 98.05]

2024-09-02 15:29:29,382 [trainer.py] => Average Accuracy (CNN): 80.535
2024-09-02 15:29:29,382 [trainer.py] => Average Accuracy (NME): 82.65
2024-09-02 15:29:29,382 [trainer.py] => All params: 3879745
2024-09-02 15:29:29,382 [trainer.py] => Trainable params: 3879745
2024-09-02 15:29:29,383 [podnet.py] => Learning on 7-9
2024-09-02 15:29:29,402 [podnet.py] => Adaptive factor: 2.1213203435596424
2024-09-02 15:29:31,562 [podnet.py] => Task 2, Epoch 1/300 (LR 0.10000) => LSC_loss 1.68, Spatial_loss 0.83, Flat_loss 1.06, Train_acc 76.30, Test_acc 21.80
2024-09-02 15:29:33,394 [podnet.py] => Task 2, Epoch 2/300 (LR 0.09999) => LSC_loss 0.89, Spatial_loss 0.68, Flat_loss 0.86, Train_acc 87.53, Test_acc 21.50
2024-09-02 15:29:35,203 [podnet.py] => Task 2, Epoch 3/300 (LR 0.09998) => LSC_loss 0.75, Spatial_loss 0.66, Flat_loss 0.74, Train_acc 87.19, Test_acc 20.15
2024-09-02 15:29:37,015 [podnet.py] => Task 2, Epoch 4/300 (LR 0.09996) => LSC_loss 0.59, Spatial_loss 0.62, Flat_loss 0.66, Train_acc 89.08, Test_acc 32.67
2024-09-02 15:29:38,857 [podnet.py] => Task 2, Epoch 5/300 (LR 0.09993) => LSC_loss 0.51, Spatial_loss 0.61, Flat_loss 0.60, Train_acc 89.70, Test_acc 31.13
2024-09-02 15:29:40,772 [podnet.py] => Task 2, Epoch 6/300 (LR 0.09990) => LSC_loss 0.44, Spatial_loss 0.58, Flat_loss 0.56, Train_acc 90.53, Test_acc 36.02
2024-09-02 15:29:42,894 [podnet.py] => Task 2, Epoch 7/300 (LR 0.09987) => LSC_loss 0.41, Spatial_loss 0.58, Flat_loss 0.55, Train_acc 91.59, Test_acc 32.91
2024-09-02 15:29:44,876 [podnet.py] => Task 2, Epoch 8/300 (LR 0.09982) => LSC_loss 0.32, Spatial_loss 0.56, Flat_loss 0.51, Train_acc 92.93, Test_acc 46.43
2024-09-02 15:29:46,815 [podnet.py] => Task 2, Epoch 9/300 (LR 0.09978) => LSC_loss 0.25, Spatial_loss 0.52, Flat_loss 0.48, Train_acc 94.71, Test_acc 46.11
2024-09-02 15:29:48,664 [podnet.py] => Task 2, Epoch 10/300 (LR 0.09973) => LSC_loss 0.27, Spatial_loss 0.55, Flat_loss 0.49, Train_acc 94.00, Test_acc 31.54
2024-09-02 15:29:50,407 [podnet.py] => Task 2, Epoch 11/300 (LR 0.09967) => LSC_loss 0.22, Spatial_loss 0.53, Flat_loss 0.47, Train_acc 95.73, Test_acc 49.39
2024-09-02 15:29:52,313 [podnet.py] => Task 2, Epoch 12/300 (LR 0.09961) => LSC_loss 0.21, Spatial_loss 0.53, Flat_loss 0.47, Train_acc 95.71, Test_acc 48.07
2024-09-02 15:29:54,270 [podnet.py] => Task 2, Epoch 13/300 (LR 0.09954) => LSC_loss 0.22, Spatial_loss 0.54, Flat_loss 0.46, Train_acc 95.00, Test_acc 53.07
2024-09-02 15:29:56,396 [podnet.py] => Task 2, Epoch 14/300 (LR 0.09946) => LSC_loss 0.17, Spatial_loss 0.49, Flat_loss 0.44, Train_acc 96.95, Test_acc 42.11
2024-09-02 15:29:58,330 [podnet.py] => Task 2, Epoch 15/300 (LR 0.09938) => LSC_loss 0.24, Spatial_loss 0.56, Flat_loss 0.47, Train_acc 94.53, Test_acc 32.94
2024-09-02 15:30:00,218 [podnet.py] => Task 2, Epoch 16/300 (LR 0.09930) => LSC_loss 0.28, Spatial_loss 0.60, Flat_loss 0.48, Train_acc 93.71, Test_acc 47.70
2024-09-02 15:30:01,950 [podnet.py] => Task 2, Epoch 17/300 (LR 0.09921) => LSC_loss 0.18, Spatial_loss 0.53, Flat_loss 0.44, Train_acc 96.51, Test_acc 52.46
2024-09-02 15:30:03,938 [podnet.py] => Task 2, Epoch 18/300 (LR 0.09911) => LSC_loss 0.13, Spatial_loss 0.50, Flat_loss 0.42, Train_acc 97.80, Test_acc 54.22
2024-09-02 15:30:06,012 [podnet.py] => Task 2, Epoch 19/300 (LR 0.09901) => LSC_loss 0.10, Spatial_loss 0.46, Flat_loss 0.40, Train_acc 98.87, Test_acc 55.61
2024-09-02 15:30:08,190 [podnet.py] => Task 2, Epoch 20/300 (LR 0.09891) => LSC_loss 0.08, Spatial_loss 0.43, Flat_loss 0.38, Train_acc 99.51, Test_acc 61.56
2024-09-02 15:30:10,080 [podnet.py] => Task 2, Epoch 21/300 (LR 0.09880) => LSC_loss 0.07, Spatial_loss 0.41, Flat_loss 0.36, Train_acc 99.53, Test_acc 55.89
2024-09-02 15:30:11,741 [podnet.py] => Task 2, Epoch 22/300 (LR 0.09868) => LSC_loss 0.07, Spatial_loss 0.40, Flat_loss 0.35, Train_acc 99.80, Test_acc 60.96
2024-09-02 15:30:13,611 [podnet.py] => Task 2, Epoch 23/300 (LR 0.09856) => LSC_loss 0.07, Spatial_loss 0.39, Flat_loss 0.34, Train_acc 99.87, Test_acc 62.85
2024-09-02 15:30:15,469 [podnet.py] => Task 2, Epoch 24/300 (LR 0.09843) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.34, Train_acc 99.84, Test_acc 59.28
2024-09-02 15:30:17,618 [podnet.py] => Task 2, Epoch 25/300 (LR 0.09830) => LSC_loss 0.06, Spatial_loss 0.37, Flat_loss 0.33, Train_acc 99.89, Test_acc 59.44
2024-09-02 15:30:19,676 [podnet.py] => Task 2, Epoch 26/300 (LR 0.09816) => LSC_loss 0.07, Spatial_loss 0.36, Flat_loss 0.32, Train_acc 99.87, Test_acc 61.61
2024-09-02 15:30:21,886 [podnet.py] => Task 2, Epoch 27/300 (LR 0.09801) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.32, Train_acc 99.71, Test_acc 55.81
2024-09-02 15:30:23,601 [podnet.py] => Task 2, Epoch 28/300 (LR 0.09787) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.31, Train_acc 99.80, Test_acc 56.78
2024-09-02 15:30:25,267 [podnet.py] => Task 2, Epoch 29/300 (LR 0.09771) => LSC_loss 0.10, Spatial_loss 0.41, Flat_loss 0.35, Train_acc 98.64, Test_acc 42.72
2024-09-02 15:30:27,231 [podnet.py] => Task 2, Epoch 30/300 (LR 0.09755) => LSC_loss 0.12, Spatial_loss 0.46, Flat_loss 0.37, Train_acc 97.73, Test_acc 46.33
2024-09-02 15:30:28,993 [podnet.py] => Task 2, Epoch 31/300 (LR 0.09739) => LSC_loss 0.11, Spatial_loss 0.44, Flat_loss 0.36, Train_acc 98.18, Test_acc 56.85
2024-09-02 15:30:30,619 [podnet.py] => Task 2, Epoch 32/300 (LR 0.09722) => LSC_loss 0.08, Spatial_loss 0.42, Flat_loss 0.35, Train_acc 98.84, Test_acc 54.04
2024-09-02 15:30:32,421 [podnet.py] => Task 2, Epoch 33/300 (LR 0.09704) => LSC_loss 0.06, Spatial_loss 0.37, Flat_loss 0.32, Train_acc 99.71, Test_acc 60.11
2024-09-02 15:30:34,117 [podnet.py] => Task 2, Epoch 34/300 (LR 0.09686) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.30, Train_acc 99.93, Test_acc 62.43
2024-09-02 15:30:35,745 [podnet.py] => Task 2, Epoch 35/300 (LR 0.09668) => LSC_loss 0.05, Spatial_loss 0.34, Flat_loss 0.30, Train_acc 99.91, Test_acc 62.93
2024-09-02 15:30:37,531 [podnet.py] => Task 2, Epoch 36/300 (LR 0.09649) => LSC_loss 0.05, Spatial_loss 0.33, Flat_loss 0.29, Train_acc 99.98, Test_acc 62.17
2024-09-02 15:30:39,216 [podnet.py] => Task 2, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.28, Train_acc 99.91, Test_acc 61.41
2024-09-02 15:30:41,014 [podnet.py] => Task 2, Epoch 38/300 (LR 0.09609) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.28, Train_acc 99.98, Test_acc 62.72
2024-09-02 15:30:42,725 [podnet.py] => Task 2, Epoch 39/300 (LR 0.09589) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.28, Train_acc 99.89, Test_acc 55.00
2024-09-02 15:30:44,478 [podnet.py] => Task 2, Epoch 40/300 (LR 0.09568) => LSC_loss 0.12, Spatial_loss 0.42, Flat_loss 0.35, Train_acc 97.93, Test_acc 56.28
2024-09-02 15:30:46,220 [podnet.py] => Task 2, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.43, Flat_loss 0.35, Train_acc 98.11, Test_acc 49.87
2024-09-02 15:30:48,239 [podnet.py] => Task 2, Epoch 42/300 (LR 0.09524) => LSC_loss 0.09, Spatial_loss 0.41, Flat_loss 0.34, Train_acc 98.58, Test_acc 48.02
2024-09-02 15:30:50,176 [podnet.py] => Task 2, Epoch 43/300 (LR 0.09502) => LSC_loss 0.19, Spatial_loss 0.49, Flat_loss 0.39, Train_acc 96.15, Test_acc 46.19
2024-09-02 15:30:52,068 [podnet.py] => Task 2, Epoch 44/300 (LR 0.09479) => LSC_loss 0.20, Spatial_loss 0.53, Flat_loss 0.40, Train_acc 95.15, Test_acc 51.85
2024-09-02 15:30:54,011 [podnet.py] => Task 2, Epoch 45/300 (LR 0.09455) => LSC_loss 0.09, Spatial_loss 0.43, Flat_loss 0.34, Train_acc 98.82, Test_acc 61.39
2024-09-02 15:30:56,070 [podnet.py] => Task 2, Epoch 46/300 (LR 0.09431) => LSC_loss 0.06, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.84, Test_acc 61.85
2024-09-02 15:30:57,865 [podnet.py] => Task 2, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.29, Train_acc 99.91, Test_acc 62.13
2024-09-02 15:30:59,639 [podnet.py] => Task 2, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.28, Train_acc 99.87, Test_acc 64.28
2024-09-02 15:31:01,418 [podnet.py] => Task 2, Epoch 49/300 (LR 0.09356) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.27, Train_acc 99.91, Test_acc 61.74
2024-09-02 15:31:03,108 [podnet.py] => Task 2, Epoch 50/300 (LR 0.09330) => LSC_loss 0.06, Spatial_loss 0.32, Flat_loss 0.26, Train_acc 99.96, Test_acc 64.07
2024-09-02 15:31:04,726 [podnet.py] => Task 2, Epoch 51/300 (LR 0.09304) => LSC_loss 0.07, Spatial_loss 0.37, Flat_loss 0.29, Train_acc 99.33, Test_acc 62.89
2024-09-02 15:31:06,337 [podnet.py] => Task 2, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.27, Train_acc 99.89, Test_acc 61.15
2024-09-02 15:31:08,225 [podnet.py] => Task 2, Epoch 53/300 (LR 0.09249) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.26, Train_acc 99.91, Test_acc 60.31
2024-09-02 15:31:10,085 [podnet.py] => Task 2, Epoch 54/300 (LR 0.09222) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.29, Train_acc 99.78, Test_acc 60.43
2024-09-02 15:31:11,825 [podnet.py] => Task 2, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.26, Train_acc 99.98, Test_acc 62.00
2024-09-02 15:31:13,732 [podnet.py] => Task 2, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.98, Test_acc 61.04
2024-09-02 15:31:15,415 [podnet.py] => Task 2, Epoch 57/300 (LR 0.09135) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.25, Train_acc 99.98, Test_acc 62.07
2024-09-02 15:31:17,062 [podnet.py] => Task 2, Epoch 58/300 (LR 0.09106) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.25, Train_acc 100.00, Test_acc 62.30
2024-09-02 15:31:18,909 [podnet.py] => Task 2, Epoch 59/300 (LR 0.09076) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 99.98, Test_acc 63.87
2024-09-02 15:31:20,838 [podnet.py] => Task 2, Epoch 60/300 (LR 0.09045) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 100.00, Test_acc 63.02
2024-09-02 15:31:22,839 [podnet.py] => Task 2, Epoch 61/300 (LR 0.09014) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.24, Train_acc 100.00, Test_acc 65.06
2024-09-02 15:31:24,834 [podnet.py] => Task 2, Epoch 62/300 (LR 0.08983) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.00
2024-09-02 15:31:26,745 [podnet.py] => Task 2, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.89
2024-09-02 15:31:28,817 [podnet.py] => Task 2, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.93, Test_acc 57.74
2024-09-02 15:31:30,849 [podnet.py] => Task 2, Epoch 65/300 (LR 0.08886) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.28, Train_acc 99.36, Test_acc 47.89
2024-09-02 15:31:32,876 [podnet.py] => Task 2, Epoch 66/300 (LR 0.08853) => LSC_loss 0.53, Spatial_loss 0.63, Flat_loss 0.49, Train_acc 89.55, Test_acc 28.76
2024-09-02 15:31:35,070 [podnet.py] => Task 2, Epoch 67/300 (LR 0.08819) => LSC_loss 0.35, Spatial_loss 0.60, Flat_loss 0.45, Train_acc 92.48, Test_acc 33.69
2024-09-02 15:31:36,950 [podnet.py] => Task 2, Epoch 68/300 (LR 0.08785) => LSC_loss 0.18, Spatial_loss 0.50, Flat_loss 0.39, Train_acc 96.44, Test_acc 52.48
2024-09-02 15:31:38,536 [podnet.py] => Task 2, Epoch 69/300 (LR 0.08751) => LSC_loss 0.23, Spatial_loss 0.56, Flat_loss 0.41, Train_acc 94.89, Test_acc 49.48
2024-09-02 15:31:40,112 [podnet.py] => Task 2, Epoch 70/300 (LR 0.08716) => LSC_loss 0.15, Spatial_loss 0.49, Flat_loss 0.38, Train_acc 97.22, Test_acc 59.48
2024-09-02 15:31:41,770 [podnet.py] => Task 2, Epoch 71/300 (LR 0.08680) => LSC_loss 0.09, Spatial_loss 0.44, Flat_loss 0.34, Train_acc 98.91, Test_acc 56.63
2024-09-02 15:31:43,697 [podnet.py] => Task 2, Epoch 72/300 (LR 0.08645) => LSC_loss 0.06, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.76, Test_acc 57.94
2024-09-02 15:31:45,379 [podnet.py] => Task 2, Epoch 73/300 (LR 0.08609) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 99.58, Test_acc 58.94
2024-09-02 15:31:47,334 [podnet.py] => Task 2, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.28, Train_acc 99.89, Test_acc 61.46
2024-09-02 15:31:49,109 [podnet.py] => Task 2, Epoch 75/300 (LR 0.08536) => LSC_loss 0.06, Spatial_loss 0.33, Flat_loss 0.26, Train_acc 99.89, Test_acc 60.07
2024-09-02 15:31:51,029 [podnet.py] => Task 2, Epoch 76/300 (LR 0.08498) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.26, Train_acc 99.96, Test_acc 62.31
2024-09-02 15:31:52,974 [podnet.py] => Task 2, Epoch 77/300 (LR 0.08461) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 100.00, Test_acc 61.52
2024-09-02 15:31:55,096 [podnet.py] => Task 2, Epoch 78/300 (LR 0.08423) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.98, Test_acc 63.13
2024-09-02 15:31:56,942 [podnet.py] => Task 2, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.93, Test_acc 63.81
2024-09-02 15:31:58,525 [podnet.py] => Task 2, Epoch 80/300 (LR 0.08346) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.89, Test_acc 61.46
2024-09-02 15:32:00,178 [podnet.py] => Task 2, Epoch 81/300 (LR 0.08307) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 100.00, Test_acc 62.02
2024-09-02 15:32:02,042 [podnet.py] => Task 2, Epoch 82/300 (LR 0.08267) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:32:04,139 [podnet.py] => Task 2, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.23, Train_acc 100.00, Test_acc 62.69
2024-09-02 15:32:06,034 [podnet.py] => Task 2, Epoch 84/300 (LR 0.08187) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.94
2024-09-02 15:32:07,755 [podnet.py] => Task 2, Epoch 85/300 (LR 0.08147) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.02
2024-09-02 15:32:09,614 [podnet.py] => Task 2, Epoch 86/300 (LR 0.08106) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 100.00, Test_acc 61.94
2024-09-02 15:32:11,528 [podnet.py] => Task 2, Epoch 87/300 (LR 0.08065) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.91, Test_acc 60.72
2024-09-02 15:32:13,599 [podnet.py] => Task 2, Epoch 88/300 (LR 0.08023) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.96, Test_acc 61.06
2024-09-02 15:32:15,539 [podnet.py] => Task 2, Epoch 89/300 (LR 0.07981) => LSC_loss 0.06, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.62, Test_acc 63.67
2024-09-02 15:32:17,396 [podnet.py] => Task 2, Epoch 90/300 (LR 0.07939) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.84, Test_acc 62.83
2024-09-02 15:32:19,377 [podnet.py] => Task 2, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.93, Test_acc 60.61
2024-09-02 15:32:21,496 [podnet.py] => Task 2, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 99.98, Test_acc 62.52
2024-09-02 15:32:23,450 [podnet.py] => Task 2, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.96, Test_acc 61.94
2024-09-02 15:32:25,275 [podnet.py] => Task 2, Epoch 94/300 (LR 0.07767) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 99.96, Test_acc 62.85
2024-09-02 15:32:26,961 [podnet.py] => Task 2, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.89, Test_acc 62.33
2024-09-02 15:32:28,747 [podnet.py] => Task 2, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.22, Train_acc 99.96, Test_acc 61.72
2024-09-02 15:32:31,007 [podnet.py] => Task 2, Epoch 97/300 (LR 0.07635) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.28
2024-09-02 15:32:32,781 [podnet.py] => Task 2, Epoch 98/300 (LR 0.07590) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:32:34,519 [podnet.py] => Task 2, Epoch 99/300 (LR 0.07545) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 62.54
2024-09-02 15:32:36,344 [podnet.py] => Task 2, Epoch 100/300 (LR 0.07500) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 100.00, Test_acc 60.37
2024-09-02 15:32:38,034 [podnet.py] => Task 2, Epoch 101/300 (LR 0.07455) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.94
2024-09-02 15:32:39,680 [podnet.py] => Task 2, Epoch 102/300 (LR 0.07409) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.39
2024-09-02 15:32:41,353 [podnet.py] => Task 2, Epoch 103/300 (LR 0.07363) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 61.15
2024-09-02 15:32:43,063 [podnet.py] => Task 2, Epoch 104/300 (LR 0.07316) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.26
2024-09-02 15:32:44,846 [podnet.py] => Task 2, Epoch 105/300 (LR 0.07270) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 60.19
2024-09-02 15:32:46,669 [podnet.py] => Task 2, Epoch 106/300 (LR 0.07223) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.83
2024-09-02 15:32:48,440 [podnet.py] => Task 2, Epoch 107/300 (LR 0.07176) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.50
2024-09-02 15:32:50,151 [podnet.py] => Task 2, Epoch 108/300 (LR 0.07129) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.85
2024-09-02 15:32:52,023 [podnet.py] => Task 2, Epoch 109/300 (LR 0.07081) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 60.76
2024-09-02 15:32:53,867 [podnet.py] => Task 2, Epoch 110/300 (LR 0.07034) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 61.11
2024-09-02 15:32:55,687 [podnet.py] => Task 2, Epoch 111/300 (LR 0.06986) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.49, Test_acc 54.81
2024-09-02 15:32:57,392 [podnet.py] => Task 2, Epoch 112/300 (LR 0.06938) => LSC_loss 0.16, Spatial_loss 0.39, Flat_loss 0.31, Train_acc 96.53, Test_acc 36.30
2024-09-02 15:32:59,042 [podnet.py] => Task 2, Epoch 113/300 (LR 0.06889) => LSC_loss 0.24, Spatial_loss 0.51, Flat_loss 0.39, Train_acc 94.71, Test_acc 43.69
2024-09-02 15:33:00,888 [podnet.py] => Task 2, Epoch 114/300 (LR 0.06841) => LSC_loss 0.27, Spatial_loss 0.55, Flat_loss 0.40, Train_acc 94.24, Test_acc 48.67
2024-09-02 15:33:02,571 [podnet.py] => Task 2, Epoch 115/300 (LR 0.06792) => LSC_loss 0.18, Spatial_loss 0.49, Flat_loss 0.36, Train_acc 96.66, Test_acc 55.85
2024-09-02 15:33:04,446 [podnet.py] => Task 2, Epoch 116/300 (LR 0.06743) => LSC_loss 0.16, Spatial_loss 0.49, Flat_loss 0.37, Train_acc 96.71, Test_acc 56.83
2024-09-02 15:33:06,155 [podnet.py] => Task 2, Epoch 117/300 (LR 0.06694) => LSC_loss 0.09, Spatial_loss 0.42, Flat_loss 0.32, Train_acc 98.71, Test_acc 63.02
2024-09-02 15:33:07,809 [podnet.py] => Task 2, Epoch 118/300 (LR 0.06644) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.44, Test_acc 62.83
2024-09-02 15:33:09,515 [podnet.py] => Task 2, Epoch 119/300 (LR 0.06595) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.27, Train_acc 99.78, Test_acc 64.41
2024-09-02 15:33:11,412 [podnet.py] => Task 2, Epoch 120/300 (LR 0.06545) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.25, Train_acc 99.98, Test_acc 64.46
2024-09-02 15:33:13,123 [podnet.py] => Task 2, Epoch 121/300 (LR 0.06495) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.24, Train_acc 99.96, Test_acc 62.96
2024-09-02 15:33:14,885 [podnet.py] => Task 2, Epoch 122/300 (LR 0.06445) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:33:16,619 [podnet.py] => Task 2, Epoch 123/300 (LR 0.06395) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.26
2024-09-02 15:33:18,449 [podnet.py] => Task 2, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 100.00, Test_acc 63.33
2024-09-02 15:33:20,215 [podnet.py] => Task 2, Epoch 125/300 (LR 0.06294) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.96, Test_acc 62.50
2024-09-02 15:33:22,085 [podnet.py] => Task 2, Epoch 126/300 (LR 0.06243) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 100.00, Test_acc 62.74
2024-09-02 15:33:23,950 [podnet.py] => Task 2, Epoch 127/300 (LR 0.06193) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.04
2024-09-02 15:33:25,882 [podnet.py] => Task 2, Epoch 128/300 (LR 0.06142) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.48
2024-09-02 15:33:27,722 [podnet.py] => Task 2, Epoch 129/300 (LR 0.06091) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.93
2024-09-02 15:33:29,420 [podnet.py] => Task 2, Epoch 130/300 (LR 0.06040) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.43
2024-09-02 15:33:31,019 [podnet.py] => Task 2, Epoch 131/300 (LR 0.05988) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.04
2024-09-02 15:33:32,752 [podnet.py] => Task 2, Epoch 132/300 (LR 0.05937) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.69
2024-09-02 15:33:34,446 [podnet.py] => Task 2, Epoch 133/300 (LR 0.05885) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.74
2024-09-02 15:33:36,164 [podnet.py] => Task 2, Epoch 134/300 (LR 0.05834) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.98, Test_acc 59.56
2024-09-02 15:33:38,018 [podnet.py] => Task 2, Epoch 135/300 (LR 0.05782) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.52
2024-09-02 15:33:39,757 [podnet.py] => Task 2, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.98, Test_acc 63.02
2024-09-02 15:33:41,663 [podnet.py] => Task 2, Epoch 137/300 (LR 0.05679) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 63.59
2024-09-02 15:33:43,644 [podnet.py] => Task 2, Epoch 138/300 (LR 0.05627) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:33:45,403 [podnet.py] => Task 2, Epoch 139/300 (LR 0.05575) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 64.39
2024-09-02 15:33:46,997 [podnet.py] => Task 2, Epoch 140/300 (LR 0.05523) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 62.76
2024-09-02 15:33:48,842 [podnet.py] => Task 2, Epoch 141/300 (LR 0.05471) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.69
2024-09-02 15:33:50,607 [podnet.py] => Task 2, Epoch 142/300 (LR 0.05418) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 64.93
2024-09-02 15:33:52,306 [podnet.py] => Task 2, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 62.11
2024-09-02 15:33:53,962 [podnet.py] => Task 2, Epoch 144/300 (LR 0.05314) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.91, Test_acc 64.65
2024-09-02 15:33:55,611 [podnet.py] => Task 2, Epoch 145/300 (LR 0.05262) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 61.28
2024-09-02 15:33:57,240 [podnet.py] => Task 2, Epoch 146/300 (LR 0.05209) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.96, Test_acc 63.15
2024-09-02 15:33:58,805 [podnet.py] => Task 2, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 61.94
2024-09-02 15:34:00,215 [podnet.py] => Task 2, Epoch 148/300 (LR 0.05105) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.91, Test_acc 62.24
2024-09-02 15:34:01,727 [podnet.py] => Task 2, Epoch 149/300 (LR 0.05052) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.39
2024-09-02 15:34:03,426 [podnet.py] => Task 2, Epoch 150/300 (LR 0.05000) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.26
2024-09-02 15:34:05,157 [podnet.py] => Task 2, Epoch 151/300 (LR 0.04948) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 63.81
2024-09-02 15:34:07,002 [podnet.py] => Task 2, Epoch 152/300 (LR 0.04895) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.19
2024-09-02 15:34:08,631 [podnet.py] => Task 2, Epoch 153/300 (LR 0.04843) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 62.30
2024-09-02 15:34:10,382 [podnet.py] => Task 2, Epoch 154/300 (LR 0.04791) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.96, Test_acc 63.94
2024-09-02 15:34:12,037 [podnet.py] => Task 2, Epoch 155/300 (LR 0.04738) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 62.63
2024-09-02 15:34:13,730 [podnet.py] => Task 2, Epoch 156/300 (LR 0.04686) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.07
2024-09-02 15:34:15,364 [podnet.py] => Task 2, Epoch 157/300 (LR 0.04634) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:34:17,057 [podnet.py] => Task 2, Epoch 158/300 (LR 0.04582) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 62.31
2024-09-02 15:34:18,839 [podnet.py] => Task 2, Epoch 159/300 (LR 0.04529) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.78
2024-09-02 15:34:20,450 [podnet.py] => Task 2, Epoch 160/300 (LR 0.04477) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 99.98, Test_acc 60.89
2024-09-02 15:34:22,191 [podnet.py] => Task 2, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.67
2024-09-02 15:34:24,019 [podnet.py] => Task 2, Epoch 162/300 (LR 0.04373) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.65
2024-09-02 15:34:25,748 [podnet.py] => Task 2, Epoch 163/300 (LR 0.04321) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.46
2024-09-02 15:34:27,541 [podnet.py] => Task 2, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.93
2024-09-02 15:34:29,341 [podnet.py] => Task 2, Epoch 165/300 (LR 0.04218) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 62.37
2024-09-02 15:34:31,117 [podnet.py] => Task 2, Epoch 166/300 (LR 0.04166) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:34:32,911 [podnet.py] => Task 2, Epoch 167/300 (LR 0.04115) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.54
2024-09-02 15:34:34,669 [podnet.py] => Task 2, Epoch 168/300 (LR 0.04063) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.22
2024-09-02 15:34:36,381 [podnet.py] => Task 2, Epoch 169/300 (LR 0.04012) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.91
2024-09-02 15:34:38,147 [podnet.py] => Task 2, Epoch 170/300 (LR 0.03960) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.57
2024-09-02 15:34:40,239 [podnet.py] => Task 2, Epoch 171/300 (LR 0.03909) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.17
2024-09-02 15:34:42,149 [podnet.py] => Task 2, Epoch 172/300 (LR 0.03858) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.72
2024-09-02 15:34:43,851 [podnet.py] => Task 2, Epoch 173/300 (LR 0.03807) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.70
2024-09-02 15:34:45,494 [podnet.py] => Task 2, Epoch 174/300 (LR 0.03757) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.63
2024-09-02 15:34:47,176 [podnet.py] => Task 2, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.76
2024-09-02 15:34:48,741 [podnet.py] => Task 2, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:34:50,339 [podnet.py] => Task 2, Epoch 177/300 (LR 0.03605) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.96, Test_acc 63.31
2024-09-02 15:34:52,026 [podnet.py] => Task 2, Epoch 178/300 (LR 0.03555) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.49, Test_acc 58.59
2024-09-02 15:34:54,018 [podnet.py] => Task 2, Epoch 179/300 (LR 0.03505) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.69, Test_acc 58.78
2024-09-02 15:34:55,786 [podnet.py] => Task 2, Epoch 180/300 (LR 0.03455) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.07
2024-09-02 15:34:57,510 [podnet.py] => Task 2, Epoch 181/300 (LR 0.03405) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.39
2024-09-02 15:34:59,086 [podnet.py] => Task 2, Epoch 182/300 (LR 0.03356) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.96
2024-09-02 15:35:00,708 [podnet.py] => Task 2, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.89
2024-09-02 15:35:02,353 [podnet.py] => Task 2, Epoch 184/300 (LR 0.03257) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.17
2024-09-02 15:35:04,219 [podnet.py] => Task 2, Epoch 185/300 (LR 0.03208) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.96
2024-09-02 15:35:05,847 [podnet.py] => Task 2, Epoch 186/300 (LR 0.03159) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:35:07,517 [podnet.py] => Task 2, Epoch 187/300 (LR 0.03111) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:35:09,410 [podnet.py] => Task 2, Epoch 188/300 (LR 0.03062) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 99.98, Test_acc 63.00
2024-09-02 15:35:11,212 [podnet.py] => Task 2, Epoch 189/300 (LR 0.03014) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.26
2024-09-02 15:35:12,996 [podnet.py] => Task 2, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.85
2024-09-02 15:35:14,852 [podnet.py] => Task 2, Epoch 191/300 (LR 0.02919) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.06
2024-09-02 15:35:16,725 [podnet.py] => Task 2, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.74
2024-09-02 15:35:18,437 [podnet.py] => Task 2, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.85
2024-09-02 15:35:20,008 [podnet.py] => Task 2, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.43
2024-09-02 15:35:21,700 [podnet.py] => Task 2, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.46
2024-09-02 15:35:23,375 [podnet.py] => Task 2, Epoch 196/300 (LR 0.02684) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:35:24,991 [podnet.py] => Task 2, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 62.33
2024-09-02 15:35:26,601 [podnet.py] => Task 2, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.22
2024-09-02 15:35:28,339 [podnet.py] => Task 2, Epoch 199/300 (LR 0.02545) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 63.44
2024-09-02 15:35:29,932 [podnet.py] => Task 2, Epoch 200/300 (LR 0.02500) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.78
2024-09-02 15:35:31,570 [podnet.py] => Task 2, Epoch 201/300 (LR 0.02455) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:35:33,263 [podnet.py] => Task 2, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.98
2024-09-02 15:35:34,951 [podnet.py] => Task 2, Epoch 203/300 (LR 0.02365) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 64.61
2024-09-02 15:35:36,902 [podnet.py] => Task 2, Epoch 204/300 (LR 0.02321) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.84, Test_acc 63.89
2024-09-02 15:35:38,685 [podnet.py] => Task 2, Epoch 205/300 (LR 0.02277) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.98, Test_acc 62.56
2024-09-02 15:35:40,296 [podnet.py] => Task 2, Epoch 206/300 (LR 0.02233) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.69
2024-09-02 15:35:41,994 [podnet.py] => Task 2, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.09
2024-09-02 15:35:43,654 [podnet.py] => Task 2, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:35:45,367 [podnet.py] => Task 2, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.91
2024-09-02 15:35:46,941 [podnet.py] => Task 2, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.52
2024-09-02 15:35:48,510 [podnet.py] => Task 2, Epoch 211/300 (LR 0.02019) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.37
2024-09-02 15:35:50,224 [podnet.py] => Task 2, Epoch 212/300 (LR 0.01977) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.20
2024-09-02 15:35:51,859 [podnet.py] => Task 2, Epoch 213/300 (LR 0.01935) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.98, Test_acc 62.81
2024-09-02 15:35:53,573 [podnet.py] => Task 2, Epoch 214/300 (LR 0.01894) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.57
2024-09-02 15:35:55,360 [podnet.py] => Task 2, Epoch 215/300 (LR 0.01853) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.48
2024-09-02 15:35:57,292 [podnet.py] => Task 2, Epoch 216/300 (LR 0.01813) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 99.98, Test_acc 64.30
2024-09-02 15:35:59,192 [podnet.py] => Task 2, Epoch 217/300 (LR 0.01773) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.96, Test_acc 63.78
2024-09-02 15:36:00,905 [podnet.py] => Task 2, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.39
2024-09-02 15:36:02,805 [podnet.py] => Task 2, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.54
2024-09-02 15:36:04,567 [podnet.py] => Task 2, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.91
2024-09-02 15:36:06,194 [podnet.py] => Task 2, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.11
2024-09-02 15:36:07,905 [podnet.py] => Task 2, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.31
2024-09-02 15:36:09,681 [podnet.py] => Task 2, Epoch 223/300 (LR 0.01539) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.57
2024-09-02 15:36:11,251 [podnet.py] => Task 2, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:36:12,857 [podnet.py] => Task 2, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:36:14,425 [podnet.py] => Task 2, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.33
2024-09-02 15:36:16,124 [podnet.py] => Task 2, Epoch 227/300 (LR 0.01391) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:36:17,803 [podnet.py] => Task 2, Epoch 228/300 (LR 0.01355) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 64.93
2024-09-02 15:36:19,633 [podnet.py] => Task 2, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.98, Test_acc 63.46
2024-09-02 15:36:21,355 [podnet.py] => Task 2, Epoch 230/300 (LR 0.01284) => LSC_loss 0.06, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.91, Test_acc 55.98
2024-09-02 15:36:23,033 [podnet.py] => Task 2, Epoch 231/300 (LR 0.01249) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.26, Train_acc 99.15, Test_acc 60.87
2024-09-02 15:36:24,540 [podnet.py] => Task 2, Epoch 232/300 (LR 0.01215) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.48
2024-09-02 15:36:26,094 [podnet.py] => Task 2, Epoch 233/300 (LR 0.01181) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.67
2024-09-02 15:36:27,684 [podnet.py] => Task 2, Epoch 234/300 (LR 0.01147) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.81
2024-09-02 15:36:29,415 [podnet.py] => Task 2, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.93
2024-09-02 15:36:31,249 [podnet.py] => Task 2, Epoch 236/300 (LR 0.01082) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.20
2024-09-02 15:36:33,378 [podnet.py] => Task 2, Epoch 237/300 (LR 0.01049) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:36:35,268 [podnet.py] => Task 2, Epoch 238/300 (LR 0.01017) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.93
2024-09-02 15:36:36,879 [podnet.py] => Task 2, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.19
2024-09-02 15:36:38,410 [podnet.py] => Task 2, Epoch 240/300 (LR 0.00955) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.17
2024-09-02 15:36:39,989 [podnet.py] => Task 2, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:36:41,540 [podnet.py] => Task 2, Epoch 242/300 (LR 0.00894) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.52
2024-09-02 15:36:43,222 [podnet.py] => Task 2, Epoch 243/300 (LR 0.00865) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:36:45,070 [podnet.py] => Task 2, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.50
2024-09-02 15:36:46,954 [podnet.py] => Task 2, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:36:48,884 [podnet.py] => Task 2, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.72
2024-09-02 15:36:50,691 [podnet.py] => Task 2, Epoch 247/300 (LR 0.00751) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:36:52,656 [podnet.py] => Task 2, Epoch 248/300 (LR 0.00723) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.46
2024-09-02 15:36:54,473 [podnet.py] => Task 2, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:36:56,127 [podnet.py] => Task 2, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.50
2024-09-02 15:36:57,649 [podnet.py] => Task 2, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.24
2024-09-02 15:36:59,336 [podnet.py] => Task 2, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:37:00,947 [podnet.py] => Task 2, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.91
2024-09-02 15:37:02,664 [podnet.py] => Task 2, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:37:04,527 [podnet.py] => Task 2, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:37:06,231 [podnet.py] => Task 2, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.91
2024-09-02 15:37:07,904 [podnet.py] => Task 2, Epoch 257/300 (LR 0.00498) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:37:09,583 [podnet.py] => Task 2, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:37:11,409 [podnet.py] => Task 2, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:37:13,224 [podnet.py] => Task 2, Epoch 260/300 (LR 0.00432) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:37:15,077 [podnet.py] => Task 2, Epoch 261/300 (LR 0.00411) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.80
2024-09-02 15:37:16,765 [podnet.py] => Task 2, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.26
2024-09-02 15:37:18,478 [podnet.py] => Task 2, Epoch 263/300 (LR 0.00371) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.50
2024-09-02 15:37:20,306 [podnet.py] => Task 2, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.44
2024-09-02 15:37:21,919 [podnet.py] => Task 2, Epoch 265/300 (LR 0.00332) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.78
2024-09-02 15:37:23,639 [podnet.py] => Task 2, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:37:25,264 [podnet.py] => Task 2, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.65
2024-09-02 15:37:26,935 [podnet.py] => Task 2, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.37
2024-09-02 15:37:28,680 [podnet.py] => Task 2, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:37:30,766 [podnet.py] => Task 2, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:37:32,834 [podnet.py] => Task 2, Epoch 271/300 (LR 0.00229) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:37:34,735 [podnet.py] => Task 2, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:37:36,441 [podnet.py] => Task 2, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:37:38,164 [podnet.py] => Task 2, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.89
2024-09-02 15:37:39,805 [podnet.py] => Task 2, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.26
2024-09-02 15:37:41,400 [podnet.py] => Task 2, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:37:42,964 [podnet.py] => Task 2, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:37:44,600 [podnet.py] => Task 2, Epoch 278/300 (LR 0.00132) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:37:46,321 [podnet.py] => Task 2, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:37:47,861 [podnet.py] => Task 2, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.24
2024-09-02 15:37:49,617 [podnet.py] => Task 2, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:37:51,363 [podnet.py] => Task 2, Epoch 282/300 (LR 0.00089) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.04
2024-09-02 15:37:53,179 [podnet.py] => Task 2, Epoch 283/300 (LR 0.00079) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.87
2024-09-02 15:37:54,970 [podnet.py] => Task 2, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.09
2024-09-02 15:37:56,745 [podnet.py] => Task 2, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:37:58,465 [podnet.py] => Task 2, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.35
2024-09-02 15:38:00,391 [podnet.py] => Task 2, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.11
2024-09-02 15:38:02,278 [podnet.py] => Task 2, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.96
2024-09-02 15:38:04,103 [podnet.py] => Task 2, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.94
2024-09-02 15:38:05,834 [podnet.py] => Task 2, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:38:07,623 [podnet.py] => Task 2, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.00
2024-09-02 15:38:09,328 [podnet.py] => Task 2, Epoch 292/300 (LR 0.00018) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.15
2024-09-02 15:38:11,048 [podnet.py] => Task 2, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.17
2024-09-02 15:38:12,878 [podnet.py] => Task 2, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.11
2024-09-02 15:38:14,729 [podnet.py] => Task 2, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:38:16,345 [podnet.py] => Task 2, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:38:18,021 [podnet.py] => Task 2, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.28
2024-09-02 15:38:19,797 [podnet.py] => Task 2, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:38:21,382 [podnet.py] => Task 2, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.43
2024-09-02 15:38:23,183 [podnet.py] => Task 2, Epoch 300/300 (LR 0.00000) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.09
2024-09-02 15:38:23,184 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 15:38:23,184 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 15:38:24,782 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 15:38:26,603 [base.py] => Reducing exemplars...(55 per classes)
2024-09-02 15:38:28,104 [base.py] => Constructing exemplars...(55 per classes)
2024-09-02 15:38:30,938 [podnet.py] => Exemplar size: 495
2024-09-02 15:38:30,938 [trainer.py] => CNN: {'total': 65.09, '00-04': 57.57, '05-06': 51.42, '07-08': 97.58, 'old': 55.81, 'new': 97.58}
2024-09-02 15:38:30,938 [trainer.py] => NME: {'total': 66.31, '00-04': 70.83, '05-06': 43.08, '07-08': 78.25, 'old': 62.9, 'new': 78.25}
2024-09-02 15:38:30,938 [trainer.py] => CNN top1 curve: [88.9, 72.17, 65.09]
2024-09-02 15:38:30,939 [trainer.py] => CNN top5 curve: [100.0, 98.02, 91.8]
2024-09-02 15:38:30,939 [trainer.py] => NME top1 curve: [88.9, 76.4, 66.31]
2024-09-02 15:38:30,939 [trainer.py] => NME top5 curve: [100.0, 98.05, 93.43]

2024-09-02 15:38:30,939 [trainer.py] => Average Accuracy (CNN): 75.38666666666667
2024-09-02 15:38:30,939 [trainer.py] => Average Accuracy (NME): 77.20333333333333
2024-09-02 15:38:30,940 [trainer.py] => Forgetting (CNN): 37.955
