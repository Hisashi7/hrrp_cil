2025-03-28 17:18:11,778 [trainer.py] => config: ./exps/gem.json
2025-03-28 17:18:11,778 [trainer.py] => prefix: cil
2025-03-28 17:18:11,778 [trainer.py] => dataset: hrrp9
2025-03-28 17:18:11,779 [trainer.py] => memory_size: 500
2025-03-28 17:18:11,779 [trainer.py] => memory_per_class: 20
2025-03-28 17:18:11,779 [trainer.py] => fixed_memory: False
2025-03-28 17:18:11,779 [trainer.py] => shuffle: True
2025-03-28 17:18:11,779 [trainer.py] => init_cls: 5
2025-03-28 17:18:11,779 [trainer.py] => increment: 2
2025-03-28 17:18:11,779 [trainer.py] => model_name: gem
2025-03-28 17:18:11,779 [trainer.py] => convnet_type: resnet18
2025-03-28 17:18:11,779 [trainer.py] => init_train: False
2025-03-28 17:18:11,779 [trainer.py] => seed: 1993
2025-03-28 17:18:11,779 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2025-03-28 17:18:11,779 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2025-03-28 17:18:11,779 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_35172.pth
2025-03-28 17:18:11,779 [trainer.py] => fc_path2: checkpoints/init_train/fc_35172.pth
2025-03-28 17:18:11,779 [trainer.py] => seed1: [110]
2025-03-28 17:18:11,779 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2025-03-28 17:18:11,779 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2025-03-28 17:18:11,779 [trainer.py] => device: [device(type='cuda', index=0)]
2025-03-28 17:18:11,779 [trainer.py] => seed2: [2001]
2025-03-28 17:18:11,779 [trainer.py] => epochs: 150
2025-03-28 17:18:11,779 [trainer.py] => lrate: 0.1
2025-03-28 17:18:11,779 [trainer.py] => milestones: [50, 80, 120]
2025-03-28 17:18:11,779 [trainer.py] => lrate_decay: 0.1
2025-03-28 17:18:11,779 [trainer.py] => momentum: 0
2025-03-28 17:18:11,779 [trainer.py] => batch_size: 128
2025-03-28 17:18:11,780 [trainer.py] => weight_decay: 0.0002
2025-03-28 17:18:11,780 [trainer.py] => num_workers: 4
2025-03-28 17:18:12,309 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2025-03-28 17:18:12,687 [trainer.py] => All params: 3843904
2025-03-28 17:18:12,687 [trainer.py] => Trainable params: 3843904
2025-03-28 17:18:12,690 [gem.py] => Learning on 0-5
2025-03-28 17:18:12,765 [gem.py] => init_train?---False
2025-03-28 17:18:13,413 [base.py] => Reducing exemplars...(100 per classes)
2025-03-28 17:18:13,413 [base.py] => Constructing exemplars...(100 per classes)
2025-03-28 17:18:18,350 [trainer.py] => task:0 training time:5.66s
2025-03-28 17:18:18,351 [trainer.py] => All params: 3846469
2025-03-28 17:18:19,153 [gem.py] => Exemplar size: 500
2025-03-28 17:18:19,153 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2025-03-28 17:18:19,153 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2025-03-28 17:18:19,154 [trainer.py] => CNN top1 curve: [89.93]
2025-03-28 17:18:19,154 [trainer.py] => CNN top5 curve: [100.0]
2025-03-28 17:18:19,154 [trainer.py] => NME top1 curve: [90.0]
2025-03-28 17:18:19,154 [trainer.py] => NME top5 curve: [100.0]

2025-03-28 17:18:19,154 [trainer.py] => Average Accuracy (CNN): 89.93
2025-03-28 17:18:19,154 [trainer.py] => Average Accuracy (NME): 90.0
2025-03-28 17:18:19,154 [trainer.py] => All params: 3846469
2025-03-28 17:18:19,155 [trainer.py] => Trainable params: 3846469
2025-03-28 17:18:19,155 [gem.py] => Learning on 5-7
2025-03-28 17:18:23,419 [gem.py] => Task 1, Epoch 1/150 => Loss 0.338, Train_accy 88.52, Test_accy 61.55
2025-03-28 17:18:41,393 [gem.py] => Task 1, Epoch 6/150 => Loss 0.012, Train_accy 99.95, Test_accy 61.07
2025-03-28 17:18:58,322 [gem.py] => Task 1, Epoch 11/150 => Loss 0.004, Train_accy 100.00, Test_accy 61.05
2025-03-28 17:19:16,945 [gem.py] => Task 1, Epoch 16/150 => Loss 0.002, Train_accy 100.00, Test_accy 62.64
2025-03-28 17:19:36,078 [gem.py] => Task 1, Epoch 21/150 => Loss 0.002, Train_accy 100.00, Test_accy 63.10
2025-03-28 17:19:56,433 [gem.py] => Task 1, Epoch 26/150 => Loss 0.001, Train_accy 100.00, Test_accy 63.19
2025-03-28 17:20:17,911 [gem.py] => Task 1, Epoch 31/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.52
2025-03-28 17:20:39,377 [gem.py] => Task 1, Epoch 36/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.00
2025-03-28 17:20:59,528 [gem.py] => Task 1, Epoch 41/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.05
2025-03-28 17:21:20,978 [gem.py] => Task 1, Epoch 46/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.33
2025-03-28 17:21:42,122 [gem.py] => Task 1, Epoch 51/150 => Loss 0.001, Train_accy 100.00, Test_accy 65.69
2025-03-28 17:22:03,233 [gem.py] => Task 1, Epoch 56/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.45
2025-03-28 17:22:22,344 [gem.py] => Task 1, Epoch 61/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.79
2025-03-28 17:22:42,253 [gem.py] => Task 1, Epoch 66/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.76
2025-03-28 17:23:02,014 [gem.py] => Task 1, Epoch 71/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.88
2025-03-28 17:23:21,769 [gem.py] => Task 1, Epoch 76/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.83
2025-03-28 17:23:41,126 [gem.py] => Task 1, Epoch 81/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.69
2025-03-28 17:24:00,129 [gem.py] => Task 1, Epoch 86/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.69
2025-03-28 17:24:19,959 [gem.py] => Task 1, Epoch 91/150 => Loss 0.001, Train_accy 100.00, Test_accy 65.60
2025-03-28 17:24:40,990 [gem.py] => Task 1, Epoch 96/150 => Loss 0.000, Train_accy 100.00, Test_accy 65.29
2025-03-28 17:24:59,809 [gem.py] => Task 1, Epoch 101/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.69
2025-03-28 17:25:17,640 [gem.py] => Task 1, Epoch 106/150 => Loss 0.000, Train_accy 100.00, Test_accy 65.00
2025-03-28 17:25:37,592 [gem.py] => Task 1, Epoch 111/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.31
2025-03-28 17:25:56,573 [gem.py] => Task 1, Epoch 116/150 => Loss 0.000, Train_accy 100.00, Test_accy 64.95
2025-03-28 17:26:16,300 [gem.py] => Task 1, Epoch 121/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.24
2025-03-28 17:26:35,500 [gem.py] => Task 1, Epoch 126/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.95
2025-03-28 17:26:54,675 [gem.py] => Task 1, Epoch 131/150 => Loss 0.001, Train_accy 100.00, Test_accy 64.81
2025-03-28 17:27:14,404 [gem.py] => Task 1, Epoch 136/150 => Loss 0.001, Train_accy 100.00, Test_accy 65.10
2025-03-28 17:27:32,584 [gem.py] => Task 1, Epoch 141/150 => Loss 0.001, Train_accy 100.00, Test_accy 65.31
2025-03-28 17:27:51,635 [gem.py] => Task 1, Epoch 146/150 => Loss 0.000, Train_accy 100.00, Test_accy 65.38
2025-03-28 17:28:07,316 [gem.py] => Task 1, Epoch 150/150 => Loss 0.001, Train_accy 100.00
2025-03-28 17:28:07,317 [gem.py] => 100 epoches training time:396.30s
2025-03-28 17:28:07,318 [gem.py] => Average training time of single epoch:3.84s
2025-03-28 17:28:07,324 [base.py] => Reducing exemplars...(71 per classes)
2025-03-28 17:28:08,727 [base.py] => Constructing exemplars...(71 per classes)
2025-03-28 17:28:10,540 [trainer.py] => task:1 training time:591.39s
2025-03-28 17:28:10,541 [trainer.py] => All params: 3847495
2025-03-28 17:28:11,475 [gem.py] => Exemplar size: 497
2025-03-28 17:28:11,476 [trainer.py] => CNN: {'total': 64.17, '00-04': 77.37, '05-06': 31.17, 'old': 77.37, 'new': 31.17}
2025-03-28 17:28:11,476 [trainer.py] => NME: {'total': 76.67, '00-04': 75.37, '05-06': 79.92, 'old': 75.37, 'new': 79.92}
2025-03-28 17:28:11,476 [trainer.py] => CNN top1 curve: [89.93, 64.17]
2025-03-28 17:28:11,476 [trainer.py] => CNN top5 curve: [100.0, 98.6]
2025-03-28 17:28:11,476 [trainer.py] => NME top1 curve: [90.0, 76.67]
2025-03-28 17:28:11,476 [trainer.py] => NME top5 curve: [100.0, 98.64]

2025-03-28 17:28:11,476 [trainer.py] => Average Accuracy (CNN): 77.05000000000001
2025-03-28 17:28:11,476 [trainer.py] => Average Accuracy (NME): 83.33500000000001
2025-03-28 17:28:11,476 [trainer.py] => All params: 3847495
2025-03-28 17:28:11,477 [trainer.py] => Trainable params: 3847495
2025-03-28 17:28:11,477 [gem.py] => Learning on 7-9
2025-03-28 17:28:17,186 [gem.py] => Task 2, Epoch 1/150 => Loss 0.195, Train_accy 94.25, Test_accy 50.94
2025-03-28 17:28:41,872 [gem.py] => Task 2, Epoch 6/150 => Loss 0.006, Train_accy 100.00, Test_accy 55.76
2025-03-28 17:29:06,551 [gem.py] => Task 2, Epoch 11/150 => Loss 0.003, Train_accy 100.00, Test_accy 55.72
2025-03-28 17:29:33,169 [gem.py] => Task 2, Epoch 16/150 => Loss 0.002, Train_accy 100.00, Test_accy 56.81
2025-03-28 17:29:57,552 [gem.py] => Task 2, Epoch 21/150 => Loss 0.018, Train_accy 99.52, Test_accy 55.52
2025-03-28 17:30:21,759 [gem.py] => Task 2, Epoch 26/150 => Loss 0.001, Train_accy 100.00, Test_accy 57.91
2025-03-28 17:30:46,131 [gem.py] => Task 2, Epoch 31/150 => Loss 0.001, Train_accy 100.00, Test_accy 58.15
2025-03-28 17:31:14,634 [gem.py] => Task 2, Epoch 36/150 => Loss 0.001, Train_accy 100.00, Test_accy 59.02
2025-03-28 17:31:39,298 [gem.py] => Task 2, Epoch 41/150 => Loss 0.001, Train_accy 100.00, Test_accy 57.91
2025-03-28 17:32:05,780 [gem.py] => Task 2, Epoch 46/150 => Loss 0.001, Train_accy 100.00, Test_accy 57.93
2025-03-28 17:32:31,221 [gem.py] => Task 2, Epoch 51/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.17
2025-03-28 17:32:57,636 [gem.py] => Task 2, Epoch 56/150 => Loss 0.001, Train_accy 100.00, Test_accy 57.04
2025-03-28 17:33:25,105 [gem.py] => Task 2, Epoch 61/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.48
2025-03-28 17:33:51,911 [gem.py] => Task 2, Epoch 66/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.72
2025-03-28 17:34:18,505 [gem.py] => Task 2, Epoch 71/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.33
2025-03-28 17:34:44,542 [gem.py] => Task 2, Epoch 76/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.28
2025-03-28 17:35:09,927 [gem.py] => Task 2, Epoch 81/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.24
2025-03-28 17:35:35,178 [gem.py] => Task 2, Epoch 86/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.24
2025-03-28 17:36:00,561 [gem.py] => Task 2, Epoch 91/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.54
2025-03-28 17:36:25,706 [gem.py] => Task 2, Epoch 96/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.15
2025-03-28 17:36:52,149 [gem.py] => Task 2, Epoch 101/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.07
2025-03-28 17:37:18,477 [gem.py] => Task 2, Epoch 106/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.72
2025-03-28 17:37:43,580 [gem.py] => Task 2, Epoch 111/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.72
2025-03-28 17:38:09,253 [gem.py] => Task 2, Epoch 116/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.37
2025-03-28 17:38:34,847 [gem.py] => Task 2, Epoch 121/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.74
2025-03-28 17:39:02,659 [gem.py] => Task 2, Epoch 126/150 => Loss 0.001, Train_accy 100.00, Test_accy 57.39
2025-03-28 17:39:27,969 [gem.py] => Task 2, Epoch 131/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.78
2025-03-28 17:39:54,301 [gem.py] => Task 2, Epoch 136/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.83
2025-03-28 17:40:20,126 [gem.py] => Task 2, Epoch 141/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.22
2025-03-28 17:40:47,015 [gem.py] => Task 2, Epoch 146/150 => Loss 0.000, Train_accy 100.00, Test_accy 57.89
2025-03-28 17:41:07,019 [gem.py] => Task 2, Epoch 150/150 => Loss 0.000, Train_accy 100.00
2025-03-28 17:41:07,019 [gem.py] => 100 epoches training time:514.90s
2025-03-28 17:41:07,019 [gem.py] => Average training time of single epoch:5.08s
2025-03-28 17:41:07,024 [base.py] => Reducing exemplars...(55 per classes)
2025-03-28 17:41:08,655 [base.py] => Constructing exemplars...(55 per classes)
2025-03-28 17:41:10,249 [trainer.py] => task:2 training time:778.77s
2025-03-28 17:41:10,249 [trainer.py] => All params: 3848521
2025-03-28 17:41:11,268 [gem.py] => Exemplar size: 495
2025-03-28 17:41:11,269 [trainer.py] => CNN: {'total': 57.69, '00-04': 65.0, '05-06': 15.67, '07-08': 81.42, 'old': 50.9, 'new': 81.42}
2025-03-28 17:41:11,269 [trainer.py] => NME: {'total': 62.8, '00-04': 60.13, '05-06': 46.75, '07-08': 85.5, 'old': 56.31, 'new': 85.5}
2025-03-28 17:41:11,269 [trainer.py] => CNN top1 curve: [89.93, 64.17, 57.69]
2025-03-28 17:41:11,269 [trainer.py] => CNN top5 curve: [100.0, 98.6, 95.0]
2025-03-28 17:41:11,269 [trainer.py] => NME top1 curve: [90.0, 76.67, 62.8]
2025-03-28 17:41:11,269 [trainer.py] => NME top5 curve: [100.0, 98.64, 95.59]

2025-03-28 17:41:11,269 [trainer.py] => Average Accuracy (CNN): 70.59666666666668
2025-03-28 17:41:11,269 [trainer.py] => Average Accuracy (NME): 76.49000000000001
2025-03-28 17:41:11,269 [trainer.py] => Time consumed in all training process:1378.58s
2025-03-28 17:41:11,269 [trainer.py] => Average Time consumed in single task:458.61s
2025-03-28 17:41:11,308 [trainer.py] => Model state dict saved successfully at: saved_pth/hrrp9/gem/time_2025_03_28_17_18_11_cil_1993_M=500.pth
2025-03-28 17:41:11,309 [trainer.py] => Forgetting (CNN): 20.215000000000003
