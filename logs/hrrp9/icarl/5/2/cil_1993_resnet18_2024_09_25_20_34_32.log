2024-09-25 20:34:32,165 [trainer.py] => config: ./exps/icarl.json
2024-09-25 20:34:32,165 [trainer.py] => prefix: cil
2024-09-25 20:34:32,165 [trainer.py] => dataset: hrrp9
2024-09-25 20:34:32,165 [trainer.py] => memory_size: 500
2024-09-25 20:34:32,165 [trainer.py] => memory_per_class: 20
2024-09-25 20:34:32,165 [trainer.py] => fixed_memory: False
2024-09-25 20:34:32,165 [trainer.py] => shuffle: True
2024-09-25 20:34:32,165 [trainer.py] => init_cls: 5
2024-09-25 20:34:32,165 [trainer.py] => increment: 2
2024-09-25 20:34:32,165 [trainer.py] => model_name: icarl
2024-09-25 20:34:32,166 [trainer.py] => convnet_type: resnet18
2024-09-25 20:34:32,166 [trainer.py] => device: [device(type='cuda', index=3)]
2024-09-25 20:34:32,166 [trainer.py] => init_train: False
2024-09-25 20:34:32,166 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-25 20:34:32,166 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-25 20:34:32,166 [trainer.py] => seed: 1993
2024-09-25 20:34:32,166 [trainer.py] => epochs: 150
2024-09-25 20:34:32,166 [trainer.py] => lrate: 0.1
2024-09-25 20:34:32,166 [trainer.py] => milestones: [50, 80, 120]
2024-09-25 20:34:32,166 [trainer.py] => lrate_decay: 0.1
2024-09-25 20:34:32,166 [trainer.py] => momentum: 0.9
2024-09-25 20:34:32,166 [trainer.py] => batch_size: 128
2024-09-25 20:34:32,166 [trainer.py] => weight_decay: 0.0002
2024-09-25 20:34:32,166 [trainer.py] => num_workers: 8
2024-09-25 20:34:32,166 [trainer.py] => T: 2
2024-09-25 20:34:32,818 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-25 20:34:33,268 [trainer.py] => All params: 3843904
2024-09-25 20:34:33,268 [trainer.py] => Trainable params: 3843904
2024-09-25 20:34:33,290 [icarl.py] => Learning on 0-5
2024-09-25 20:34:33,502 [icarl.py] => init_train?---False
2024-09-25 20:34:34,290 [base.py] => Reducing exemplars...(100 per classes)
2024-09-25 20:34:34,290 [base.py] => Constructing exemplars...(100 per classes)
2024-09-25 20:34:40,466 [icarl.py] => Exemplar size: 500
2024-09-25 20:34:40,466 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-09-25 20:34:40,466 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-09-25 20:34:40,466 [trainer.py] => CNN top1 curve: [89.93]
2024-09-25 20:34:40,466 [trainer.py] => CNN top5 curve: [100.0]
2024-09-25 20:34:40,466 [trainer.py] => NME top1 curve: [90.0]
2024-09-25 20:34:40,466 [trainer.py] => NME top5 curve: [100.0]

2024-09-25 20:34:40,466 [trainer.py] => Average Accuracy (CNN): 89.93
2024-09-25 20:34:40,467 [trainer.py] => Average Accuracy (NME): 90.0
2024-09-25 20:34:40,467 [trainer.py] => All params: 3846469
2024-09-25 20:34:40,467 [trainer.py] => Trainable params: 3846469
2024-09-25 20:34:40,468 [icarl.py] => Learning on 5-7
2024-09-25 20:34:42,353 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.015, Train_accy 75.98, Test_accy 47.52
2024-09-25 20:34:48,270 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.015, Train_accy 98.84, Test_accy 62.31
2024-09-25 20:34:54,373 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.931, Train_accy 100.00, Test_accy 66.31
2024-09-25 20:35:00,451 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.925, Train_accy 100.00, Test_accy 67.57
2024-09-25 20:35:06,689 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.959, Train_accy 99.84, Test_accy 71.95
2024-09-25 20:35:12,802 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.937, Train_accy 99.96, Test_accy 68.83
2024-09-25 20:35:18,832 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.941, Train_accy 99.96, Test_accy 65.21
2024-09-25 20:35:24,885 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.925, Train_accy 100.00, Test_accy 67.07
2024-09-25 20:35:31,775 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.919, Train_accy 100.00, Test_accy 68.69
2024-09-25 20:35:37,703 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.17
2024-09-25 20:35:43,235 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.909, Train_accy 100.00, Test_accy 67.88
2024-09-25 20:35:48,640 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.910, Train_accy 100.00, Test_accy 68.74
2024-09-25 20:35:54,432 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.905, Train_accy 100.00, Test_accy 68.90
2024-09-25 20:35:59,808 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.904, Train_accy 100.00, Test_accy 69.76
2024-09-25 20:36:05,462 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.911, Train_accy 100.00, Test_accy 69.69
2024-09-25 20:36:11,327 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.903, Train_accy 100.00, Test_accy 69.26
2024-09-25 20:36:16,880 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.909, Train_accy 100.00, Test_accy 69.76
2024-09-25 20:36:22,268 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.909, Train_accy 100.00, Test_accy 69.00
2024-09-25 20:36:27,741 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.907, Train_accy 100.00, Test_accy 69.81
2024-09-25 20:36:33,273 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.907, Train_accy 100.00, Test_accy 69.83
2024-09-25 20:36:38,730 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.906, Train_accy 100.00, Test_accy 69.79
2024-09-25 20:36:44,256 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.908, Train_accy 100.00, Test_accy 69.69
2024-09-25 20:36:49,983 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.908, Train_accy 100.00, Test_accy 70.12
2024-09-25 20:36:55,276 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.903, Train_accy 100.00, Test_accy 69.33
2024-09-25 20:37:00,708 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.904, Train_accy 100.00, Test_accy 70.12
2024-09-25 20:37:06,167 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.906, Train_accy 100.00, Test_accy 69.40
2024-09-25 20:37:11,600 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.908, Train_accy 100.00, Test_accy 70.38
2024-09-25 20:37:16,795 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.909, Train_accy 100.00, Test_accy 69.69
2024-09-25 20:37:21,701 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.913, Train_accy 100.00, Test_accy 69.69
2024-09-25 20:37:26,992 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.909, Train_accy 100.00, Test_accy 70.12
2024-09-25 20:37:30,785 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.906, Train_accy 100.00
2024-09-25 20:37:30,786 [base.py] => Reducing exemplars...(71 per classes)
2024-09-25 20:37:31,604 [base.py] => Constructing exemplars...(71 per classes)
2024-09-25 20:37:33,860 [icarl.py] => Exemplar size: 497
2024-09-25 20:37:33,861 [trainer.py] => CNN: {'total': 69.83, '00-04': 59.07, '05-06': 96.75, 'old': 59.07, 'new': 96.75}
2024-09-25 20:37:33,861 [trainer.py] => NME: {'total': 77.14, '00-04': 71.4, '05-06': 91.5, 'old': 71.4, 'new': 91.5}
2024-09-25 20:37:33,861 [trainer.py] => CNN top1 curve: [89.93, 69.83]
2024-09-25 20:37:33,861 [trainer.py] => CNN top5 curve: [100.0, 98.81]
2024-09-25 20:37:33,861 [trainer.py] => NME top1 curve: [90.0, 77.14]
2024-09-25 20:37:33,861 [trainer.py] => NME top5 curve: [100.0, 98.98]

2024-09-25 20:37:33,861 [trainer.py] => Average Accuracy (CNN): 79.88
2024-09-25 20:37:33,861 [trainer.py] => Average Accuracy (NME): 83.57
2024-09-25 20:37:33,861 [trainer.py] => All params: 3847495
2024-09-25 20:37:33,862 [trainer.py] => Trainable params: 3847495
2024-09-25 20:37:33,862 [icarl.py] => Learning on 7-9
2024-09-25 20:37:35,363 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.509, Train_accy 76.85, Test_accy 29.91
2024-09-25 20:37:40,666 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.162, Train_accy 97.95, Test_accy 53.87
2024-09-25 20:37:45,974 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.017, Train_accy 100.00, Test_accy 64.65
2024-09-25 20:37:51,266 [icarl.py] => Task 2, Epoch 16/150 => Loss 0.998, Train_accy 100.00, Test_accy 64.89
2024-09-25 20:37:56,694 [icarl.py] => Task 2, Epoch 21/150 => Loss 0.994, Train_accy 100.00, Test_accy 67.30
2024-09-25 20:38:02,121 [icarl.py] => Task 2, Epoch 26/150 => Loss 0.994, Train_accy 100.00, Test_accy 67.28
2024-09-25 20:38:07,773 [icarl.py] => Task 2, Epoch 31/150 => Loss 0.992, Train_accy 100.00, Test_accy 64.06
2024-09-25 20:38:14,040 [icarl.py] => Task 2, Epoch 36/150 => Loss 0.994, Train_accy 100.00, Test_accy 64.57
2024-09-25 20:38:20,372 [icarl.py] => Task 2, Epoch 41/150 => Loss 0.986, Train_accy 100.00, Test_accy 67.33
2024-09-25 20:38:26,818 [icarl.py] => Task 2, Epoch 46/150 => Loss 0.989, Train_accy 100.00, Test_accy 66.26
2024-09-25 20:38:33,169 [icarl.py] => Task 2, Epoch 51/150 => Loss 0.987, Train_accy 100.00, Test_accy 67.63
2024-09-25 20:38:39,486 [icarl.py] => Task 2, Epoch 56/150 => Loss 0.985, Train_accy 100.00, Test_accy 67.54
2024-09-25 20:38:45,596 [icarl.py] => Task 2, Epoch 61/150 => Loss 0.984, Train_accy 100.00, Test_accy 66.41
2024-09-25 20:38:52,147 [icarl.py] => Task 2, Epoch 66/150 => Loss 0.983, Train_accy 100.00, Test_accy 66.69
2024-09-25 20:38:58,468 [icarl.py] => Task 2, Epoch 71/150 => Loss 0.981, Train_accy 100.00, Test_accy 65.31
2024-09-25 20:39:04,611 [icarl.py] => Task 2, Epoch 76/150 => Loss 0.985, Train_accy 100.00, Test_accy 65.81
2024-09-25 20:39:10,994 [icarl.py] => Task 2, Epoch 81/150 => Loss 0.984, Train_accy 100.00, Test_accy 66.04
2024-09-25 20:39:17,380 [icarl.py] => Task 2, Epoch 86/150 => Loss 0.981, Train_accy 100.00, Test_accy 66.15
2024-09-25 20:39:23,761 [icarl.py] => Task 2, Epoch 91/150 => Loss 0.981, Train_accy 100.00, Test_accy 67.48
2024-09-25 20:39:30,004 [icarl.py] => Task 2, Epoch 96/150 => Loss 0.983, Train_accy 100.00, Test_accy 67.20
2024-09-25 20:39:36,204 [icarl.py] => Task 2, Epoch 101/150 => Loss 0.981, Train_accy 100.00, Test_accy 66.09
2024-09-25 20:39:42,510 [icarl.py] => Task 2, Epoch 106/150 => Loss 0.989, Train_accy 100.00, Test_accy 67.24
2024-09-25 20:39:48,705 [icarl.py] => Task 2, Epoch 111/150 => Loss 0.980, Train_accy 100.00, Test_accy 66.72
2024-09-25 20:39:55,007 [icarl.py] => Task 2, Epoch 116/150 => Loss 0.978, Train_accy 100.00, Test_accy 68.22
2024-09-25 20:40:01,211 [icarl.py] => Task 2, Epoch 121/150 => Loss 0.980, Train_accy 100.00, Test_accy 66.00
2024-09-25 20:40:07,342 [icarl.py] => Task 2, Epoch 126/150 => Loss 0.985, Train_accy 100.00, Test_accy 66.89
2024-09-25 20:40:13,709 [icarl.py] => Task 2, Epoch 131/150 => Loss 0.984, Train_accy 100.00, Test_accy 65.96
2024-09-25 20:40:19,869 [icarl.py] => Task 2, Epoch 136/150 => Loss 0.984, Train_accy 100.00, Test_accy 67.59
2024-09-25 20:40:26,056 [icarl.py] => Task 2, Epoch 141/150 => Loss 0.981, Train_accy 100.00, Test_accy 66.07
2024-09-25 20:40:32,524 [icarl.py] => Task 2, Epoch 146/150 => Loss 0.981, Train_accy 100.00, Test_accy 66.09
2024-09-25 20:40:36,882 [icarl.py] => Task 2, Epoch 150/150 => Loss 0.977, Train_accy 100.00
2024-09-25 20:40:36,884 [base.py] => Reducing exemplars...(55 per classes)
2024-09-25 20:40:38,398 [base.py] => Constructing exemplars...(55 per classes)
2024-09-25 20:40:41,525 [icarl.py] => Exemplar size: 495
2024-09-25 20:40:41,526 [trainer.py] => CNN: {'total': 67.39, '00-04': 51.2, '05-06': 78.92, '07-08': 96.33, 'old': 59.12, 'new': 96.33}
2024-09-25 20:40:41,526 [trainer.py] => NME: {'total': 76.17, '00-04': 65.63, '05-06': 88.17, '07-08': 90.5, 'old': 72.07, 'new': 90.5}
2024-09-25 20:40:41,526 [trainer.py] => CNN top1 curve: [89.93, 69.83, 67.39]
2024-09-25 20:40:41,526 [trainer.py] => CNN top5 curve: [100.0, 98.81, 96.57]
2024-09-25 20:40:41,526 [trainer.py] => NME top1 curve: [90.0, 77.14, 76.17]
2024-09-25 20:40:41,526 [trainer.py] => NME top5 curve: [100.0, 98.98, 97.67]

2024-09-25 20:40:41,526 [trainer.py] => Average Accuracy (CNN): 75.71666666666665
2024-09-25 20:40:41,526 [trainer.py] => Average Accuracy (NME): 81.10333333333334
2024-09-25 20:40:41,527 [trainer.py] => Forgetting (CNN): 28.28
