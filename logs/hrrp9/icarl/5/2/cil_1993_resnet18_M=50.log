2024-10-23 15:24:20,210 [trainer.py] => config: ./exps/icarl.json
2024-10-23 15:24:20,218 [trainer.py] => prefix: cil
2024-10-23 15:24:20,218 [trainer.py] => dataset: hrrp9
2024-10-23 15:24:20,219 [trainer.py] => memory_size: 50
2024-10-23 15:24:20,219 [trainer.py] => memory_per_class: 20
2024-10-23 15:24:20,219 [trainer.py] => fixed_memory: False
2024-10-23 15:24:20,219 [trainer.py] => shuffle: True
2024-10-23 15:24:20,219 [trainer.py] => init_cls: 5
2024-10-23 15:24:20,219 [trainer.py] => increment: 2
2024-10-23 15:24:20,219 [trainer.py] => model_name: icarl
2024-10-23 15:24:20,220 [trainer.py] => convnet_type: resnet18
2024-10-23 15:24:20,220 [trainer.py] => device: [device(type='cuda', index=5)]
2024-10-23 15:24:20,220 [trainer.py] => init_train: False
2024-10-23 15:24:20,220 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 15:24:20,220 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 15:24:20,220 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 15:24:20,221 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 15:24:20,221 [trainer.py] => seed: 1993
2024-10-23 15:24:20,221 [trainer.py] => init_epoch: 0
2024-10-23 15:24:20,221 [trainer.py] => init_lr: 0.1
2024-10-23 15:24:20,221 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-23 15:24:20,221 [trainer.py] => init_lr_decay: 0.1
2024-10-23 15:24:20,221 [trainer.py] => init_weight_decay: 0.0005
2024-10-23 15:24:20,222 [trainer.py] => epochs: 150
2024-10-23 15:24:20,222 [trainer.py] => lrate: 0.1
2024-10-23 15:24:20,222 [trainer.py] => milestones: [80, 120]
2024-10-23 15:24:20,222 [trainer.py] => lrate_decay: 0.1
2024-10-23 15:24:20,222 [trainer.py] => momentum: 0.9
2024-10-23 15:24:20,222 [trainer.py] => batch_size: 128
2024-10-23 15:24:20,223 [trainer.py] => weight_decay: 0.0002
2024-10-23 15:24:20,223 [trainer.py] => num_workers: 8
2024-10-23 15:24:20,223 [trainer.py] => T: 2
2024-10-23 15:24:21,200 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 15:24:21,915 [trainer.py] => All params: 3843904
2024-10-23 15:24:21,915 [trainer.py] => Trainable params: 3843904
2024-10-23 15:24:21,918 [icarl.py] => Learning on 0-5
2024-10-23 15:24:22,423 [icarl.py] => init_train?---False
2024-10-23 15:24:23,853 [base.py] => Reducing exemplars...(10 per classes)
2024-10-23 15:24:23,854 [base.py] => Constructing exemplars...(10 per classes)
2024-10-23 15:24:29,625 [trainer.py] => All params: 3846469
2024-10-23 15:24:31,403 [icarl.py] => Exemplar size: 50
2024-10-23 15:24:31,414 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 15:24:31,415 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 15:24:31,415 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 15:24:31,415 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 15:24:31,415 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 15:24:31,415 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 15:24:31,416 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 15:24:31,416 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 15:24:31,417 [trainer.py] => All params: 3846469
2024-10-23 15:24:31,417 [trainer.py] => Trainable params: 3846469
2024-10-23 15:24:31,419 [icarl.py] => Learning on 5-7
2024-10-23 15:24:34,200 [icarl.py] => Task 1, Epoch 1/150 => Loss 1.935, Train_accy 79.06, Test_accy 23.48
2024-10-23 15:24:42,561 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.072, Train_accy 99.11, Test_accy 29.36
2024-10-23 15:24:51,323 [icarl.py] => Task 1, Epoch 11/150 => Loss 1.006, Train_accy 100.00, Test_accy 35.36
2024-10-23 15:24:59,566 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.992, Train_accy 100.00, Test_accy 35.45
2024-10-23 15:25:08,356 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.990, Train_accy 100.00, Test_accy 37.83
2024-10-23 15:25:16,380 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.988, Train_accy 100.00, Test_accy 38.00
2024-10-23 15:25:25,172 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.990, Train_accy 100.00, Test_accy 36.21
2024-10-23 15:25:33,429 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.985, Train_accy 100.00, Test_accy 36.52
2024-10-23 15:25:41,837 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.987, Train_accy 100.00, Test_accy 35.86
2024-10-23 15:25:50,413 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.987, Train_accy 100.00, Test_accy 37.60
2024-10-23 15:25:59,462 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.986, Train_accy 100.00, Test_accy 35.74
2024-10-23 15:26:07,549 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.986, Train_accy 100.00, Test_accy 35.17
2024-10-23 15:26:15,208 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.982, Train_accy 100.00, Test_accy 36.33
2024-10-23 15:26:23,447 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.986, Train_accy 100.00, Test_accy 34.14
2024-10-23 15:26:32,057 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.983, Train_accy 100.00, Test_accy 33.21
2024-10-23 15:26:40,468 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.984, Train_accy 100.00, Test_accy 33.90
2024-10-23 15:26:49,555 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.983, Train_accy 100.00, Test_accy 34.60
2024-10-23 15:26:57,439 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.980, Train_accy 100.00, Test_accy 34.43
2024-10-23 15:27:05,887 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.978, Train_accy 100.00, Test_accy 34.69
2024-10-23 15:27:14,747 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.33
2024-10-23 15:27:23,749 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.62
2024-10-23 15:27:32,378 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.38
2024-10-23 15:27:40,807 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.33
2024-10-23 15:27:49,620 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.50
2024-10-23 15:27:58,252 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.978, Train_accy 100.00, Test_accy 34.29
2024-10-23 15:28:07,234 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.43
2024-10-23 15:28:15,920 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.52
2024-10-23 15:28:24,816 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.980, Train_accy 100.00, Test_accy 34.45
2024-10-23 15:28:34,083 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.979, Train_accy 100.00, Test_accy 34.43
2024-10-23 15:28:42,434 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.977, Train_accy 100.00, Test_accy 34.48
2024-10-23 15:28:48,933 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.978, Train_accy 100.00
2024-10-23 15:28:48,935 [base.py] => Reducing exemplars...(7 per classes)
2024-10-23 15:28:51,278 [base.py] => Constructing exemplars...(7 per classes)
2024-10-23 15:28:54,054 [trainer.py] => All params: 3847495
2024-10-23 15:28:56,221 [icarl.py] => Exemplar size: 49
2024-10-23 15:28:56,221 [trainer.py] => CNN: {'total': 34.4, '00-04': 9.2, '05-06': 97.42, 'old': 9.2, 'new': 97.42}
2024-10-23 15:28:56,222 [trainer.py] => NME: {'total': 61.5, '00-04': 47.67, '05-06': 96.08, 'old': 47.67, 'new': 96.08}
2024-10-23 15:28:56,222 [trainer.py] => CNN top1 curve: [89.93, 34.4]
2024-10-23 15:28:56,222 [trainer.py] => CNN top5 curve: [100.0, 98.19]
2024-10-23 15:28:56,222 [trainer.py] => NME top1 curve: [90.0, 61.5]
2024-10-23 15:28:56,222 [trainer.py] => NME top5 curve: [100.0, 97.38]

2024-10-23 15:28:56,222 [trainer.py] => Average Accuracy (CNN): 62.165000000000006
2024-10-23 15:28:56,222 [trainer.py] => Average Accuracy (NME): 75.75
2024-10-23 15:28:56,222 [trainer.py] => All params: 3847495
2024-10-23 15:28:56,223 [trainer.py] => Trainable params: 3847495
2024-10-23 15:28:56,224 [icarl.py] => Learning on 7-9
2024-10-23 15:28:59,317 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.569, Train_accy 71.52, Test_accy 15.98
2024-10-23 15:29:08,561 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.349, Train_accy 96.86, Test_accy 21.69
2024-10-23 15:29:19,405 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.205, Train_accy 97.90, Test_accy 21.52
2024-10-23 15:29:31,330 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.142, Train_accy 98.32, Test_accy 21.56
2024-10-23 15:29:42,945 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.068, Train_accy 98.94, Test_accy 22.57
2024-10-23 15:29:55,113 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.058, Train_accy 98.94, Test_accy 22.52
2024-10-23 15:30:08,479 [icarl.py] => Task 2, Epoch 31/150 => Loss 0.994, Train_accy 99.98, Test_accy 27.52
2024-10-23 15:30:21,646 [icarl.py] => Task 2, Epoch 36/150 => Loss 0.974, Train_accy 100.00, Test_accy 27.89
2024-10-23 15:30:35,623 [icarl.py] => Task 2, Epoch 41/150 => Loss 0.968, Train_accy 100.00, Test_accy 25.78
2024-10-23 15:30:48,937 [icarl.py] => Task 2, Epoch 46/150 => Loss 0.961, Train_accy 100.00, Test_accy 26.52
2024-10-23 15:31:02,608 [icarl.py] => Task 2, Epoch 51/150 => Loss 0.958, Train_accy 100.00, Test_accy 25.72
2024-10-23 15:31:15,438 [icarl.py] => Task 2, Epoch 56/150 => Loss 0.959, Train_accy 100.00, Test_accy 26.09
2024-10-23 15:31:28,601 [icarl.py] => Task 2, Epoch 61/150 => Loss 0.956, Train_accy 100.00, Test_accy 26.70
2024-10-23 15:31:41,321 [icarl.py] => Task 2, Epoch 66/150 => Loss 0.955, Train_accy 100.00, Test_accy 25.61
2024-10-23 15:31:55,545 [icarl.py] => Task 2, Epoch 71/150 => Loss 0.955, Train_accy 100.00, Test_accy 24.39
2024-10-23 15:32:10,124 [icarl.py] => Task 2, Epoch 76/150 => Loss 0.953, Train_accy 100.00, Test_accy 24.28
2024-10-23 15:32:24,960 [icarl.py] => Task 2, Epoch 81/150 => Loss 0.951, Train_accy 100.00, Test_accy 24.87
2024-10-23 15:32:40,675 [icarl.py] => Task 2, Epoch 86/150 => Loss 0.948, Train_accy 100.00, Test_accy 25.13
2024-10-23 15:32:56,267 [icarl.py] => Task 2, Epoch 91/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.61
2024-10-23 15:33:13,502 [icarl.py] => Task 2, Epoch 96/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.52
2024-10-23 15:33:31,894 [icarl.py] => Task 2, Epoch 101/150 => Loss 0.948, Train_accy 100.00, Test_accy 24.59
2024-10-23 15:33:49,372 [icarl.py] => Task 2, Epoch 106/150 => Loss 0.948, Train_accy 100.00, Test_accy 24.70
2024-10-23 15:34:06,121 [icarl.py] => Task 2, Epoch 111/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.50
2024-10-23 15:34:23,872 [icarl.py] => Task 2, Epoch 116/150 => Loss 0.949, Train_accy 100.00, Test_accy 24.48
2024-10-23 15:34:38,502 [icarl.py] => Task 2, Epoch 121/150 => Loss 0.949, Train_accy 100.00, Test_accy 24.52
2024-10-23 15:34:54,362 [icarl.py] => Task 2, Epoch 126/150 => Loss 0.946, Train_accy 100.00, Test_accy 24.89
2024-10-23 15:35:10,335 [icarl.py] => Task 2, Epoch 131/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.61
2024-10-23 15:35:25,951 [icarl.py] => Task 2, Epoch 136/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.43
2024-10-23 15:35:41,640 [icarl.py] => Task 2, Epoch 141/150 => Loss 0.947, Train_accy 100.00, Test_accy 24.48
2024-10-23 15:35:57,344 [icarl.py] => Task 2, Epoch 146/150 => Loss 0.946, Train_accy 100.00, Test_accy 24.61
2024-10-23 15:36:07,482 [icarl.py] => Task 2, Epoch 150/150 => Loss 0.947, Train_accy 100.00
2024-10-23 15:36:07,483 [base.py] => Reducing exemplars...(5 per classes)
2024-10-23 15:36:11,893 [base.py] => Constructing exemplars...(5 per classes)
2024-10-23 15:36:17,044 [trainer.py] => All params: 3848521
2024-10-23 15:36:21,470 [icarl.py] => Exemplar size: 45
2024-10-23 15:36:21,494 [trainer.py] => CNN: {'total': 24.52, '00-04': 2.13, '05-06': 7.17, '07-08': 97.83, 'old': 3.57, 'new': 97.83}
2024-10-23 15:36:21,494 [trainer.py] => NME: {'total': 41.43, '00-04': 22.47, '05-06': 35.67, '07-08': 94.58, 'old': 26.24, 'new': 94.58}
2024-10-23 15:36:21,495 [trainer.py] => CNN top1 curve: [89.93, 34.4, 24.52]
2024-10-23 15:36:21,495 [trainer.py] => CNN top5 curve: [100.0, 98.19, 81.81]
2024-10-23 15:36:21,495 [trainer.py] => NME top1 curve: [90.0, 61.5, 41.43]
2024-10-23 15:36:21,495 [trainer.py] => NME top5 curve: [100.0, 97.38, 87.15]

2024-10-23 15:36:21,495 [trainer.py] => Average Accuracy (CNN): 49.616666666666674
2024-10-23 15:36:21,496 [trainer.py] => Average Accuracy (NME): 64.31
2024-10-23 15:36:21,496 [trainer.py] => Forgetting (CNN): 89.025
