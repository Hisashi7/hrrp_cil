2024-10-31 10:06:01,230 [trainer.py] => config: ./exps/icarl.json
2024-10-31 10:06:01,230 [trainer.py] => prefix: cil
2024-10-31 10:06:01,230 [trainer.py] => dataset: hrrp9
2024-10-31 10:06:01,230 [trainer.py] => memory_size: 500
2024-10-31 10:06:01,230 [trainer.py] => memory_per_class: 20
2024-10-31 10:06:01,230 [trainer.py] => fixed_memory: False
2024-10-31 10:06:01,230 [trainer.py] => shuffle: True
2024-10-31 10:06:01,230 [trainer.py] => init_cls: 5
2024-10-31 10:06:01,230 [trainer.py] => increment: 2
2024-10-31 10:06:01,230 [trainer.py] => model_name: icarl
2024-10-31 10:06:01,230 [trainer.py] => convnet_type: resnet18
2024-10-31 10:06:01,230 [trainer.py] => device: [device(type='cuda', index=1)]
2024-10-31 10:06:01,231 [trainer.py] => init_train: False
2024-10-31 10:06:01,231 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_42503.pth
2024-10-31 10:06:01,231 [trainer.py] => fc_path2: checkpoints/init_train/fc_42503.pth
2024-10-31 10:06:01,231 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_35172.pth
2024-10-31 10:06:01,231 [trainer.py] => fc_path: checkpoints/init_train/fc_35172.pth
2024-10-31 10:06:01,231 [trainer.py] => seed2: [1993]
2024-10-31 10:06:01,231 [trainer.py] => seed: 2001
2024-10-31 10:06:01,231 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2024-10-31 10:06:01,231 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2024-10-31 10:06:01,231 [trainer.py] => init_epoch: 0
2024-10-31 10:06:01,231 [trainer.py] => init_lr: 0.1
2024-10-31 10:06:01,231 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-31 10:06:01,231 [trainer.py] => init_lr_decay: 0.1
2024-10-31 10:06:01,231 [trainer.py] => init_weight_decay: 0.0005
2024-10-31 10:06:01,231 [trainer.py] => epochs: 150
2024-10-31 10:06:01,231 [trainer.py] => lrate: 0.1
2024-10-31 10:06:01,231 [trainer.py] => milestones: [80, 120]
2024-10-31 10:06:01,231 [trainer.py] => lrate_decay: 0.1
2024-10-31 10:06:01,231 [trainer.py] => momentum: 0.9
2024-10-31 10:06:01,231 [trainer.py] => batch_size: 128
2024-10-31 10:06:01,232 [trainer.py] => weight_decay: 0.0002
2024-10-31 10:06:01,232 [trainer.py] => num_workers: 8
2024-10-31 10:06:01,232 [trainer.py] => T: 2
2024-10-31 10:06:02,230 [data_manager.py] => [3, 5, 1, 7, 2, 8, 6, 4, 0]
2024-10-31 10:06:03,059 [trainer.py] => All params: 3843904
2024-10-31 10:06:03,059 [trainer.py] => Trainable params: 3843904
2024-10-31 10:06:03,063 [icarl.py] => Learning on 0-5
2024-10-31 10:06:03,637 [icarl.py] => init_train?---False
2024-10-31 10:06:05,187 [base.py] => Reducing exemplars...(100 per classes)
2024-10-31 10:06:05,188 [base.py] => Constructing exemplars...(100 per classes)
2024-10-31 10:06:15,626 [trainer.py] => All params: 3846469
2024-10-31 10:06:17,964 [icarl.py] => Exemplar size: 500
2024-10-31 10:06:17,965 [trainer.py] => CNN: {'total': 90.13, '00-04': 90.13, 'old': 0, 'new': 90.13}
2024-10-31 10:06:17,965 [trainer.py] => NME: {'total': 89.53, '00-04': 89.53, 'old': 0, 'new': 89.53}
2024-10-31 10:06:17,965 [trainer.py] => CNN top1 curve: [90.13]
2024-10-31 10:06:17,965 [trainer.py] => CNN top5 curve: [100.0]
2024-10-31 10:06:17,965 [trainer.py] => NME top1 curve: [89.53]
2024-10-31 10:06:17,966 [trainer.py] => NME top5 curve: [100.0]

2024-10-31 10:06:17,966 [trainer.py] => Average Accuracy (CNN): 90.13
2024-10-31 10:06:17,966 [trainer.py] => Average Accuracy (NME): 89.53
2024-10-31 10:06:17,967 [trainer.py] => All params: 3846469
2024-10-31 10:06:17,967 [trainer.py] => Trainable params: 3846469
2024-10-31 10:06:17,969 [icarl.py] => Learning on 5-7
2024-10-31 10:06:21,559 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.507, Train_accy 62.27, Test_accy 17.45
2024-10-31 10:06:32,571 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.348, Train_accy 94.91, Test_accy 60.43
2024-10-31 10:06:44,268 [icarl.py] => Task 1, Epoch 11/150 => Loss 1.085, Train_accy 99.76, Test_accy 72.90
2024-10-31 10:06:57,977 [icarl.py] => Task 1, Epoch 16/150 => Loss 1.103, Train_accy 99.42, Test_accy 72.69
2024-10-31 10:07:12,558 [icarl.py] => Task 1, Epoch 21/150 => Loss 1.034, Train_accy 99.93, Test_accy 74.43
2024-10-31 10:07:26,930 [icarl.py] => Task 1, Epoch 26/150 => Loss 1.075, Train_accy 99.89, Test_accy 74.95
2024-10-31 10:07:41,688 [icarl.py] => Task 1, Epoch 31/150 => Loss 1.036, Train_accy 99.98, Test_accy 77.00
2024-10-31 10:07:55,987 [icarl.py] => Task 1, Epoch 36/150 => Loss 1.019, Train_accy 100.00, Test_accy 77.12
2024-10-31 10:08:09,170 [icarl.py] => Task 1, Epoch 41/150 => Loss 1.018, Train_accy 99.98, Test_accy 76.29
2024-10-31 10:08:23,310 [icarl.py] => Task 1, Epoch 46/150 => Loss 1.013, Train_accy 100.00, Test_accy 77.74
2024-10-31 10:08:37,236 [icarl.py] => Task 1, Epoch 51/150 => Loss 1.010, Train_accy 100.00, Test_accy 76.14
2024-10-31 10:08:50,314 [icarl.py] => Task 1, Epoch 56/150 => Loss 1.011, Train_accy 100.00, Test_accy 77.19
2024-10-31 10:08:59,623 [icarl.py] => Task 1, Epoch 61/150 => Loss 1.009, Train_accy 100.00, Test_accy 76.95
2024-10-31 10:09:08,793 [icarl.py] => Task 1, Epoch 66/150 => Loss 1.008, Train_accy 100.00, Test_accy 78.79
2024-10-31 10:09:17,944 [icarl.py] => Task 1, Epoch 71/150 => Loss 1.011, Train_accy 100.00, Test_accy 75.71
2024-10-31 10:09:26,802 [icarl.py] => Task 1, Epoch 76/150 => Loss 1.008, Train_accy 100.00, Test_accy 75.86
2024-10-31 10:09:35,546 [icarl.py] => Task 1, Epoch 81/150 => Loss 1.003, Train_accy 100.00, Test_accy 77.36
2024-10-31 10:09:44,506 [icarl.py] => Task 1, Epoch 86/150 => Loss 1.003, Train_accy 100.00, Test_accy 76.38
2024-10-31 10:09:53,163 [icarl.py] => Task 1, Epoch 91/150 => Loss 1.007, Train_accy 100.00, Test_accy 77.10
2024-10-31 10:10:01,949 [icarl.py] => Task 1, Epoch 96/150 => Loss 1.001, Train_accy 100.00, Test_accy 76.88
2024-10-31 10:10:10,797 [icarl.py] => Task 1, Epoch 101/150 => Loss 1.003, Train_accy 100.00, Test_accy 76.60
2024-10-31 10:10:20,945 [icarl.py] => Task 1, Epoch 106/150 => Loss 1.003, Train_accy 100.00, Test_accy 77.38
2024-10-31 10:10:29,571 [icarl.py] => Task 1, Epoch 111/150 => Loss 1.002, Train_accy 100.00, Test_accy 77.24
2024-10-31 10:10:38,375 [icarl.py] => Task 1, Epoch 116/150 => Loss 1.002, Train_accy 100.00, Test_accy 76.71
2024-10-31 10:10:47,323 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.998, Train_accy 100.00, Test_accy 76.60
2024-10-31 10:10:56,385 [icarl.py] => Task 1, Epoch 126/150 => Loss 1.003, Train_accy 100.00, Test_accy 77.02
2024-10-31 10:11:05,042 [icarl.py] => Task 1, Epoch 131/150 => Loss 1.001, Train_accy 100.00, Test_accy 77.40
2024-10-31 10:11:13,543 [icarl.py] => Task 1, Epoch 136/150 => Loss 1.000, Train_accy 100.00, Test_accy 76.93
2024-10-31 10:11:22,140 [icarl.py] => Task 1, Epoch 141/150 => Loss 1.003, Train_accy 100.00, Test_accy 77.14
2024-10-31 10:11:30,603 [icarl.py] => Task 1, Epoch 146/150 => Loss 1.001, Train_accy 100.00, Test_accy 77.19
2024-10-31 10:11:37,079 [icarl.py] => Task 1, Epoch 150/150 => Loss 1.000, Train_accy 100.00
2024-10-31 10:11:37,080 [base.py] => Reducing exemplars...(71 per classes)
2024-10-31 10:11:39,089 [base.py] => Constructing exemplars...(71 per classes)
2024-10-31 10:11:42,790 [trainer.py] => All params: 3847495
2024-10-31 10:11:44,883 [icarl.py] => Exemplar size: 497
2024-10-31 10:11:44,884 [trainer.py] => CNN: {'total': 77.36, '00-04': 70.77, '05-06': 93.83, 'old': 70.77, 'new': 93.83}
2024-10-31 10:11:44,884 [trainer.py] => NME: {'total': 81.76, '00-04': 78.63, '05-06': 89.58, 'old': 78.63, 'new': 89.58}
2024-10-31 10:11:44,884 [trainer.py] => CNN top1 curve: [90.13, 77.36]
2024-10-31 10:11:44,884 [trainer.py] => CNN top5 curve: [100.0, 99.26]
2024-10-31 10:11:44,884 [trainer.py] => NME top1 curve: [89.53, 81.76]
2024-10-31 10:11:44,884 [trainer.py] => NME top5 curve: [100.0, 99.38]

2024-10-31 10:11:44,884 [trainer.py] => Average Accuracy (CNN): 83.745
2024-10-31 10:11:44,884 [trainer.py] => Average Accuracy (NME): 85.64500000000001
2024-10-31 10:11:44,885 [trainer.py] => All params: 3847495
2024-10-31 10:11:44,885 [trainer.py] => Trainable params: 3847495
2024-10-31 10:11:44,886 [icarl.py] => Learning on 7-9
2024-10-31 10:11:47,521 [icarl.py] => Task 2, Epoch 1/150 => Loss 3.085, Train_accy 68.91, Test_accy 13.24
2024-10-31 10:11:56,284 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.617, Train_accy 91.33, Test_accy 49.19
2024-10-31 10:12:04,659 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.212, Train_accy 99.02, Test_accy 54.54
2024-10-31 10:12:13,084 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.123, Train_accy 99.96, Test_accy 63.50
2024-10-31 10:12:21,314 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.217, Train_accy 98.73, Test_accy 56.78
2024-10-31 10:12:29,655 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.125, Train_accy 99.96, Test_accy 64.37
2024-10-31 10:12:39,287 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.102, Train_accy 100.00, Test_accy 63.28
2024-10-31 10:12:48,821 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.100, Train_accy 100.00, Test_accy 62.78
2024-10-31 10:12:58,813 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.101, Train_accy 100.00, Test_accy 61.54
2024-10-31 10:13:07,610 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.096, Train_accy 100.00, Test_accy 62.24
2024-10-31 10:13:16,685 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.093, Train_accy 100.00, Test_accy 61.78
2024-10-31 10:13:26,228 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.097, Train_accy 100.00, Test_accy 59.98
2024-10-31 10:13:36,021 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.089, Train_accy 100.00, Test_accy 62.04
2024-10-31 10:13:45,283 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.092, Train_accy 100.00, Test_accy 57.46
2024-10-31 10:13:55,616 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.089, Train_accy 100.00, Test_accy 59.24
2024-10-31 10:14:05,859 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.099, Train_accy 100.00, Test_accy 60.19
2024-10-31 10:14:15,989 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.092, Train_accy 100.00, Test_accy 62.15
2024-10-31 10:14:26,545 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.078, Train_accy 100.00, Test_accy 60.87
2024-10-31 10:14:36,239 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.083, Train_accy 100.00, Test_accy 62.02
2024-10-31 10:14:45,804 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.084, Train_accy 100.00, Test_accy 62.41
2024-10-31 10:14:56,254 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.081, Train_accy 100.00, Test_accy 60.59
2024-10-31 10:15:05,664 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.083, Train_accy 100.00, Test_accy 61.89
2024-10-31 10:15:15,315 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.079, Train_accy 100.00, Test_accy 61.20
2024-10-31 10:15:25,098 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.076, Train_accy 100.00, Test_accy 62.48
2024-10-31 10:15:34,526 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.075, Train_accy 100.00, Test_accy 60.57
2024-10-31 10:15:44,812 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.082, Train_accy 100.00, Test_accy 61.19
2024-10-31 10:15:55,049 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.082, Train_accy 100.00, Test_accy 61.17
2024-10-31 10:16:05,076 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.082, Train_accy 100.00, Test_accy 62.17
2024-10-31 10:16:15,788 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.077, Train_accy 100.00, Test_accy 60.50
2024-10-31 10:16:24,980 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.076, Train_accy 100.00, Test_accy 60.41
2024-10-31 10:16:30,611 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.083, Train_accy 100.00
2024-10-31 10:16:30,611 [base.py] => Reducing exemplars...(55 per classes)
2024-10-31 10:16:32,706 [base.py] => Constructing exemplars...(55 per classes)
2024-10-31 10:16:34,980 [trainer.py] => All params: 3848521
2024-10-31 10:16:36,576 [icarl.py] => Exemplar size: 495
2024-10-31 10:16:36,577 [trainer.py] => CNN: {'total': 61.63, '00-04': 52.73, '05-06': 55.58, '07-08': 89.92, 'old': 53.55, 'new': 89.92}
2024-10-31 10:16:36,577 [trainer.py] => NME: {'total': 73.19, '00-04': 69.57, '05-06': 72.83, '07-08': 82.58, 'old': 70.5, 'new': 82.58}
2024-10-31 10:16:36,577 [trainer.py] => CNN top1 curve: [90.13, 77.36, 61.63]
2024-10-31 10:16:36,577 [trainer.py] => CNN top5 curve: [100.0, 99.26, 96.72]
2024-10-31 10:16:36,577 [trainer.py] => NME top1 curve: [89.53, 81.76, 73.19]
2024-10-31 10:16:36,577 [trainer.py] => NME top5 curve: [100.0, 99.38, 97.35]

2024-10-31 10:16:36,577 [trainer.py] => Average Accuracy (CNN): 76.37333333333333
2024-10-31 10:16:36,577 [trainer.py] => Average Accuracy (NME): 81.49333333333334
2024-10-31 10:16:36,578 [trainer.py] => Forgetting (CNN): 37.825
