2024-10-31 10:06:10,985 [trainer.py] => config: ./exps/icarl.json
2024-10-31 10:06:10,986 [trainer.py] => prefix: cil
2024-10-31 10:06:10,986 [trainer.py] => dataset: hrrp9
2024-10-31 10:06:10,986 [trainer.py] => memory_size: 400
2024-10-31 10:06:10,987 [trainer.py] => memory_per_class: 20
2024-10-31 10:06:10,987 [trainer.py] => fixed_memory: False
2024-10-31 10:06:10,987 [trainer.py] => shuffle: True
2024-10-31 10:06:10,987 [trainer.py] => init_cls: 5
2024-10-31 10:06:10,987 [trainer.py] => increment: 2
2024-10-31 10:06:10,988 [trainer.py] => model_name: icarl
2024-10-31 10:06:10,988 [trainer.py] => convnet_type: resnet18
2024-10-31 10:06:10,988 [trainer.py] => device: [device(type='cuda', index=1)]
2024-10-31 10:06:10,989 [trainer.py] => init_train: False
2024-10-31 10:06:10,989 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_42503.pth
2024-10-31 10:06:10,989 [trainer.py] => fc_path2: checkpoints/init_train/fc_42503.pth
2024-10-31 10:06:10,989 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_35172.pth
2024-10-31 10:06:10,990 [trainer.py] => fc_path: checkpoints/init_train/fc_35172.pth
2024-10-31 10:06:10,990 [trainer.py] => seed2: [1993]
2024-10-31 10:06:10,990 [trainer.py] => seed: 2001
2024-10-31 10:06:10,991 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2024-10-31 10:06:10,991 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2024-10-31 10:06:10,992 [trainer.py] => init_epoch: 0
2024-10-31 10:06:10,992 [trainer.py] => init_lr: 0.1
2024-10-31 10:06:10,992 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-31 10:06:10,992 [trainer.py] => init_lr_decay: 0.1
2024-10-31 10:06:10,993 [trainer.py] => init_weight_decay: 0.0005
2024-10-31 10:06:10,993 [trainer.py] => epochs: 150
2024-10-31 10:06:10,993 [trainer.py] => lrate: 0.1
2024-10-31 10:06:10,993 [trainer.py] => milestones: [80, 120]
2024-10-31 10:06:10,994 [trainer.py] => lrate_decay: 0.1
2024-10-31 10:06:10,994 [trainer.py] => momentum: 0.9
2024-10-31 10:06:10,994 [trainer.py] => batch_size: 128
2024-10-31 10:06:10,994 [trainer.py] => weight_decay: 0.0002
2024-10-31 10:06:10,995 [trainer.py] => num_workers: 8
2024-10-31 10:06:10,995 [trainer.py] => T: 2
2024-10-31 10:06:11,977 [data_manager.py] => [3, 5, 1, 7, 2, 8, 6, 4, 0]
2024-10-31 10:06:12,901 [trainer.py] => All params: 3843904
2024-10-31 10:06:12,916 [trainer.py] => Trainable params: 3843904
2024-10-31 10:06:12,925 [icarl.py] => Learning on 0-5
2024-10-31 10:06:13,602 [icarl.py] => init_train?---False
2024-10-31 10:06:15,145 [base.py] => Reducing exemplars...(80 per classes)
2024-10-31 10:06:15,146 [base.py] => Constructing exemplars...(80 per classes)
2024-10-31 10:06:25,694 [trainer.py] => All params: 3846469
2024-10-31 10:06:27,896 [icarl.py] => Exemplar size: 400
2024-10-31 10:06:27,896 [trainer.py] => CNN: {'total': 90.13, '00-04': 90.13, 'old': 0, 'new': 90.13}
2024-10-31 10:06:27,896 [trainer.py] => NME: {'total': 89.53, '00-04': 89.53, 'old': 0, 'new': 89.53}
2024-10-31 10:06:27,897 [trainer.py] => CNN top1 curve: [90.13]
2024-10-31 10:06:27,897 [trainer.py] => CNN top5 curve: [100.0]
2024-10-31 10:06:27,897 [trainer.py] => NME top1 curve: [89.53]
2024-10-31 10:06:27,897 [trainer.py] => NME top5 curve: [100.0]

2024-10-31 10:06:27,897 [trainer.py] => Average Accuracy (CNN): 90.13
2024-10-31 10:06:27,897 [trainer.py] => Average Accuracy (NME): 89.53
2024-10-31 10:06:27,897 [trainer.py] => All params: 3846469
2024-10-31 10:06:27,898 [trainer.py] => Trainable params: 3846469
2024-10-31 10:06:27,899 [icarl.py] => Learning on 5-7
2024-10-31 10:06:31,742 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.291, Train_accy 72.80, Test_accy 25.60
2024-10-31 10:06:43,328 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.152, Train_accy 99.11, Test_accy 61.48
2024-10-31 10:06:56,333 [icarl.py] => Task 1, Epoch 11/150 => Loss 1.048, Train_accy 99.95, Test_accy 75.52
2024-10-31 10:07:10,184 [icarl.py] => Task 1, Epoch 16/150 => Loss 1.034, Train_accy 100.00, Test_accy 76.24
2024-10-31 10:07:23,688 [icarl.py] => Task 1, Epoch 21/150 => Loss 1.027, Train_accy 100.00, Test_accy 75.55
2024-10-31 10:07:38,214 [icarl.py] => Task 1, Epoch 26/150 => Loss 1.025, Train_accy 100.00, Test_accy 77.31
2024-10-31 10:07:52,566 [icarl.py] => Task 1, Epoch 31/150 => Loss 1.026, Train_accy 100.00, Test_accy 76.40
2024-10-31 10:08:06,112 [icarl.py] => Task 1, Epoch 36/150 => Loss 1.024, Train_accy 100.00, Test_accy 77.67
2024-10-31 10:08:18,720 [icarl.py] => Task 1, Epoch 41/150 => Loss 1.027, Train_accy 100.00, Test_accy 77.40
2024-10-31 10:08:32,629 [icarl.py] => Task 1, Epoch 46/150 => Loss 1.024, Train_accy 100.00, Test_accy 76.38
2024-10-31 10:08:45,422 [icarl.py] => Task 1, Epoch 51/150 => Loss 1.022, Train_accy 100.00, Test_accy 75.31
2024-10-31 10:08:56,012 [icarl.py] => Task 1, Epoch 56/150 => Loss 1.021, Train_accy 100.00, Test_accy 74.90
2024-10-31 10:09:06,094 [icarl.py] => Task 1, Epoch 61/150 => Loss 1.021, Train_accy 100.00, Test_accy 73.10
2024-10-31 10:09:14,486 [icarl.py] => Task 1, Epoch 66/150 => Loss 1.021, Train_accy 100.00, Test_accy 75.60
2024-10-31 10:09:22,947 [icarl.py] => Task 1, Epoch 71/150 => Loss 1.024, Train_accy 100.00, Test_accy 76.60
2024-10-31 10:09:31,269 [icarl.py] => Task 1, Epoch 76/150 => Loss 1.022, Train_accy 100.00, Test_accy 75.67
2024-10-31 10:09:40,447 [icarl.py] => Task 1, Epoch 81/150 => Loss 1.020, Train_accy 100.00, Test_accy 74.69
2024-10-31 10:09:49,158 [icarl.py] => Task 1, Epoch 86/150 => Loss 1.016, Train_accy 100.00, Test_accy 75.19
2024-10-31 10:09:57,902 [icarl.py] => Task 1, Epoch 91/150 => Loss 1.016, Train_accy 100.00, Test_accy 75.26
2024-10-31 10:10:06,345 [icarl.py] => Task 1, Epoch 96/150 => Loss 1.016, Train_accy 100.00, Test_accy 74.83
2024-10-31 10:10:15,006 [icarl.py] => Task 1, Epoch 101/150 => Loss 1.017, Train_accy 100.00, Test_accy 75.36
2024-10-31 10:10:23,350 [icarl.py] => Task 1, Epoch 106/150 => Loss 1.014, Train_accy 100.00, Test_accy 74.00
2024-10-31 10:10:31,974 [icarl.py] => Task 1, Epoch 111/150 => Loss 1.016, Train_accy 100.00, Test_accy 75.02
2024-10-31 10:10:40,635 [icarl.py] => Task 1, Epoch 116/150 => Loss 1.015, Train_accy 100.00, Test_accy 74.21
2024-10-31 10:10:49,006 [icarl.py] => Task 1, Epoch 121/150 => Loss 1.015, Train_accy 100.00, Test_accy 75.10
2024-10-31 10:10:57,747 [icarl.py] => Task 1, Epoch 126/150 => Loss 1.014, Train_accy 100.00, Test_accy 74.36
2024-10-31 10:11:06,346 [icarl.py] => Task 1, Epoch 131/150 => Loss 1.014, Train_accy 100.00, Test_accy 73.71
2024-10-31 10:11:14,705 [icarl.py] => Task 1, Epoch 136/150 => Loss 1.015, Train_accy 100.00, Test_accy 73.86
2024-10-31 10:11:22,681 [icarl.py] => Task 1, Epoch 141/150 => Loss 1.017, Train_accy 100.00, Test_accy 75.14
2024-10-31 10:11:30,965 [icarl.py] => Task 1, Epoch 146/150 => Loss 1.014, Train_accy 100.00, Test_accy 74.17
2024-10-31 10:11:37,175 [icarl.py] => Task 1, Epoch 150/150 => Loss 1.016, Train_accy 100.00
2024-10-31 10:11:37,176 [base.py] => Reducing exemplars...(57 per classes)
2024-10-31 10:11:39,032 [base.py] => Constructing exemplars...(57 per classes)
2024-10-31 10:11:42,193 [trainer.py] => All params: 3847495
2024-10-31 10:11:44,349 [icarl.py] => Exemplar size: 399
2024-10-31 10:11:44,349 [trainer.py] => CNN: {'total': 75.48, '00-04': 68.33, '05-06': 93.33, 'old': 68.33, 'new': 93.33}
2024-10-31 10:11:44,355 [trainer.py] => NME: {'total': 83.12, '00-04': 80.27, '05-06': 90.25, 'old': 80.27, 'new': 90.25}
2024-10-31 10:11:44,363 [trainer.py] => CNN top1 curve: [90.13, 75.48]
2024-10-31 10:11:44,364 [trainer.py] => CNN top5 curve: [100.0, 99.48]
2024-10-31 10:11:44,367 [trainer.py] => NME top1 curve: [89.53, 83.12]
2024-10-31 10:11:44,368 [trainer.py] => NME top5 curve: [100.0, 99.24]

2024-10-31 10:11:44,368 [trainer.py] => Average Accuracy (CNN): 82.805
2024-10-31 10:11:44,368 [trainer.py] => Average Accuracy (NME): 86.325
2024-10-31 10:11:44,369 [trainer.py] => All params: 3847495
2024-10-31 10:11:44,370 [trainer.py] => Trainable params: 3847495
2024-10-31 10:11:44,371 [icarl.py] => Learning on 7-9
2024-10-31 10:11:46,947 [icarl.py] => Task 2, Epoch 1/150 => Loss 3.043, Train_accy 68.99, Test_accy 11.52
2024-10-31 10:11:55,132 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.838, Train_accy 88.61, Test_accy 20.93
2024-10-31 10:12:03,614 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.512, Train_accy 94.86, Test_accy 38.31
2024-10-31 10:12:11,857 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.318, Train_accy 98.39, Test_accy 47.83
2024-10-31 10:12:20,345 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.232, Train_accy 99.39, Test_accy 47.44
2024-10-31 10:12:28,506 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.174, Train_accy 99.95, Test_accy 59.26
2024-10-31 10:12:36,733 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.147, Train_accy 100.00, Test_accy 53.93
2024-10-31 10:12:45,337 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.145, Train_accy 100.00, Test_accy 54.57
2024-10-31 10:12:54,598 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.141, Train_accy 100.00, Test_accy 53.63
2024-10-31 10:13:03,168 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.135, Train_accy 100.00, Test_accy 50.61
2024-10-31 10:13:11,844 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.137, Train_accy 100.00, Test_accy 52.85
2024-10-31 10:13:20,689 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.136, Train_accy 100.00, Test_accy 50.80
2024-10-31 10:13:29,872 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.134, Train_accy 100.00, Test_accy 52.96
2024-10-31 10:13:39,186 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.135, Train_accy 100.00, Test_accy 52.76
2024-10-31 10:13:48,595 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.129, Train_accy 100.00, Test_accy 52.72
2024-10-31 10:13:59,002 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.132, Train_accy 100.00, Test_accy 51.59
2024-10-31 10:14:08,989 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.128, Train_accy 100.00, Test_accy 51.89
2024-10-31 10:14:18,081 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.125, Train_accy 100.00, Test_accy 52.28
2024-10-31 10:14:27,899 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.124, Train_accy 100.00, Test_accy 52.22
2024-10-31 10:14:37,072 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.123, Train_accy 100.00, Test_accy 51.69
2024-10-31 10:14:46,202 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.125, Train_accy 100.00, Test_accy 51.81
2024-10-31 10:14:55,170 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.123, Train_accy 100.00, Test_accy 52.13
2024-10-31 10:15:04,856 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.123, Train_accy 100.00, Test_accy 51.04
2024-10-31 10:15:14,459 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.122, Train_accy 100.00, Test_accy 51.61
2024-10-31 10:15:23,658 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.124, Train_accy 100.00, Test_accy 51.80
2024-10-31 10:15:33,226 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.123, Train_accy 100.00, Test_accy 51.39
2024-10-31 10:15:43,143 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.121, Train_accy 100.00, Test_accy 50.69
2024-10-31 10:15:53,474 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.123, Train_accy 100.00, Test_accy 51.91
2024-10-31 10:16:03,624 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.123, Train_accy 100.00, Test_accy 51.50
2024-10-31 10:16:12,342 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.124, Train_accy 100.00, Test_accy 51.44
2024-10-31 10:16:19,066 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.123, Train_accy 100.00
2024-10-31 10:16:19,067 [base.py] => Reducing exemplars...(44 per classes)
2024-10-31 10:16:21,753 [base.py] => Constructing exemplars...(44 per classes)
2024-10-31 10:16:25,013 [trainer.py] => All params: 3848521
2024-10-31 10:16:26,951 [icarl.py] => Exemplar size: 396
2024-10-31 10:16:26,951 [trainer.py] => CNN: {'total': 51.2, '00-04': 44.3, '05-06': 32.58, '07-08': 87.08, 'old': 40.95, 'new': 87.08}
2024-10-31 10:16:26,952 [trainer.py] => NME: {'total': 68.26, '00-04': 66.23, '05-06': 60.42, '07-08': 81.17, 'old': 64.57, 'new': 81.17}
2024-10-31 10:16:26,952 [trainer.py] => CNN top1 curve: [90.13, 75.48, 51.2]
2024-10-31 10:16:26,952 [trainer.py] => CNN top5 curve: [100.0, 99.48, 95.85]
2024-10-31 10:16:26,952 [trainer.py] => NME top1 curve: [89.53, 83.12, 68.26]
2024-10-31 10:16:26,952 [trainer.py] => NME top5 curve: [100.0, 99.24, 97.11]

2024-10-31 10:16:26,952 [trainer.py] => Average Accuracy (CNN): 72.27
2024-10-31 10:16:26,952 [trainer.py] => Average Accuracy (NME): 80.30333333333334
2024-10-31 10:16:26,953 [trainer.py] => Forgetting (CNN): 53.29
