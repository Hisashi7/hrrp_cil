2024-09-25 20:24:47,451 [trainer.py] => config: ./exps/icarl.json
2024-09-25 20:24:47,451 [trainer.py] => prefix: cil
2024-09-25 20:24:47,451 [trainer.py] => dataset: hrrp9
2024-09-25 20:24:47,451 [trainer.py] => memory_size: 500
2024-09-25 20:24:47,451 [trainer.py] => memory_per_class: 20
2024-09-25 20:24:47,451 [trainer.py] => fixed_memory: False
2024-09-25 20:24:47,451 [trainer.py] => shuffle: True
2024-09-25 20:24:47,451 [trainer.py] => init_cls: 5
2024-09-25 20:24:47,451 [trainer.py] => increment: 2
2024-09-25 20:24:47,452 [trainer.py] => model_name: icarl
2024-09-25 20:24:47,452 [trainer.py] => convnet_type: resnet18
2024-09-25 20:24:47,452 [trainer.py] => device: [device(type='cuda', index=3)]
2024-09-25 20:24:47,452 [trainer.py] => init_train: False
2024-09-25 20:24:47,452 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-25 20:24:47,452 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-25 20:24:47,452 [trainer.py] => seed: 1993
2024-09-25 20:24:47,452 [trainer.py] => epochs: 150
2024-09-25 20:24:47,452 [trainer.py] => lrate: 0.1
2024-09-25 20:24:47,452 [trainer.py] => milestones: [50, 80, 120]
2024-09-25 20:24:47,452 [trainer.py] => lrate_decay: 0.1
2024-09-25 20:24:47,452 [trainer.py] => momentum: 0.5
2024-09-25 20:24:47,452 [trainer.py] => batch_size: 128
2024-09-25 20:24:47,452 [trainer.py] => weight_decay: 0.0002
2024-09-25 20:24:47,452 [trainer.py] => num_workers: 8
2024-09-25 20:24:47,452 [trainer.py] => T: 2
2024-09-25 20:24:48,115 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-25 20:24:48,562 [trainer.py] => All params: 3843904
2024-09-25 20:24:48,562 [trainer.py] => Trainable params: 3843904
2024-09-25 20:24:48,586 [icarl.py] => Learning on 0-5
2024-09-25 20:24:48,804 [icarl.py] => init_train?---False
2024-09-25 20:24:49,581 [base.py] => Reducing exemplars...(100 per classes)
2024-09-25 20:24:49,582 [base.py] => Constructing exemplars...(100 per classes)
2024-09-25 20:24:56,122 [icarl.py] => Exemplar size: 500
2024-09-25 20:24:56,122 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-09-25 20:24:56,122 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-09-25 20:24:56,122 [trainer.py] => CNN top1 curve: [89.93]
2024-09-25 20:24:56,122 [trainer.py] => CNN top5 curve: [100.0]
2024-09-25 20:24:56,122 [trainer.py] => NME top1 curve: [90.0]
2024-09-25 20:24:56,122 [trainer.py] => NME top5 curve: [100.0]

2024-09-25 20:24:56,122 [trainer.py] => Average Accuracy (CNN): 89.93
2024-09-25 20:24:56,122 [trainer.py] => Average Accuracy (NME): 90.0
2024-09-25 20:24:56,123 [trainer.py] => All params: 3846469
2024-09-25 20:24:56,123 [trainer.py] => Trainable params: 3846469
2024-09-25 20:24:56,124 [icarl.py] => Learning on 5-7
2024-09-25 20:24:57,978 [icarl.py] => Task 1, Epoch 1/150 => Loss 1.594, Train_accy 82.13, Test_accy 58.76
2024-09-25 20:25:04,042 [icarl.py] => Task 1, Epoch 6/150 => Loss 0.951, Train_accy 99.98, Test_accy 62.79
2024-09-25 20:25:10,203 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.928, Train_accy 99.98, Test_accy 66.38
2024-09-25 20:25:16,357 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.922, Train_accy 100.00, Test_accy 65.17
2024-09-25 20:25:22,368 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.917, Train_accy 100.00, Test_accy 67.62
2024-09-25 20:25:28,405 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.921, Train_accy 100.00, Test_accy 66.31
2024-09-25 20:25:34,586 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.915, Train_accy 100.00, Test_accy 69.05
2024-09-25 20:25:40,502 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.921, Train_accy 100.00, Test_accy 68.62
2024-09-25 20:25:46,462 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.915, Train_accy 100.00, Test_accy 69.43
2024-09-25 20:25:52,448 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.910, Train_accy 100.00, Test_accy 69.74
2024-09-25 20:25:58,482 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.910, Train_accy 100.00, Test_accy 68.81
2024-09-25 20:26:04,812 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.64
2024-09-25 20:26:10,799 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.906, Train_accy 100.00, Test_accy 69.81
2024-09-25 20:26:16,903 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.905, Train_accy 100.00, Test_accy 70.40
2024-09-25 20:26:22,930 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.81
2024-09-25 20:26:28,853 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.905, Train_accy 100.00, Test_accy 70.36
2024-09-25 20:26:34,829 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.910, Train_accy 100.00, Test_accy 70.02
2024-09-25 20:26:40,771 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.910, Train_accy 100.00, Test_accy 69.45
2024-09-25 20:26:46,884 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.908, Train_accy 100.00, Test_accy 70.57
2024-09-25 20:26:52,854 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.908, Train_accy 100.00, Test_accy 70.62
2024-09-25 20:26:58,866 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.907, Train_accy 100.00, Test_accy 70.81
2024-09-25 20:27:04,780 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.910, Train_accy 100.00, Test_accy 70.45
2024-09-25 20:27:10,886 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.909, Train_accy 100.00, Test_accy 70.83
2024-09-25 20:27:16,851 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.904, Train_accy 100.00, Test_accy 70.29
2024-09-25 20:27:22,972 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.905, Train_accy 100.00, Test_accy 70.83
2024-09-25 20:27:29,034 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.907, Train_accy 100.00, Test_accy 70.33
2024-09-25 20:27:35,040 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.909, Train_accy 100.00, Test_accy 70.81
2024-09-25 20:27:40,981 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.910, Train_accy 100.00, Test_accy 70.55
2024-09-25 20:27:47,067 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.914, Train_accy 100.00, Test_accy 70.52
2024-09-25 20:27:53,053 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.910, Train_accy 100.00, Test_accy 70.55
2024-09-25 20:27:57,412 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.907, Train_accy 100.00
2024-09-25 20:27:57,413 [base.py] => Reducing exemplars...(71 per classes)
2024-09-25 20:27:58,524 [base.py] => Constructing exemplars...(71 per classes)
2024-09-25 20:28:01,457 [icarl.py] => Exemplar size: 497
2024-09-25 20:28:01,457 [trainer.py] => CNN: {'total': 70.64, '00-04': 60.07, '05-06': 97.08, 'old': 60.07, 'new': 97.08}
2024-09-25 20:28:01,457 [trainer.py] => NME: {'total': 78.88, '00-04': 73.47, '05-06': 92.42, 'old': 73.47, 'new': 92.42}
2024-09-25 20:28:01,457 [trainer.py] => CNN top1 curve: [89.93, 70.64]
2024-09-25 20:28:01,457 [trainer.py] => CNN top5 curve: [100.0, 98.86]
2024-09-25 20:28:01,457 [trainer.py] => NME top1 curve: [90.0, 78.88]
2024-09-25 20:28:01,457 [trainer.py] => NME top5 curve: [100.0, 99.02]

2024-09-25 20:28:01,457 [trainer.py] => Average Accuracy (CNN): 80.285
2024-09-25 20:28:01,458 [trainer.py] => Average Accuracy (NME): 84.44
2024-09-25 20:28:01,458 [trainer.py] => All params: 3847495
2024-09-25 20:28:01,458 [trainer.py] => Trainable params: 3847495
2024-09-25 20:28:01,459 [icarl.py] => Learning on 7-9
2024-09-25 20:28:03,344 [icarl.py] => Task 2, Epoch 1/150 => Loss 1.997, Train_accy 82.17, Test_accy 41.26
2024-09-25 20:28:09,689 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.083, Train_accy 99.98, Test_accy 57.61
2024-09-25 20:28:15,897 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.067, Train_accy 100.00, Test_accy 62.31
2024-09-25 20:28:22,047 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.050, Train_accy 100.00, Test_accy 61.13
2024-09-25 20:28:28,353 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.052, Train_accy 100.00, Test_accy 63.54
2024-09-25 20:28:34,678 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.051, Train_accy 100.00, Test_accy 64.72
2024-09-25 20:28:40,988 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.050, Train_accy 100.00, Test_accy 64.96
2024-09-25 20:28:47,207 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.052, Train_accy 100.00, Test_accy 64.39
2024-09-25 20:28:53,194 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.045, Train_accy 100.00, Test_accy 61.37
2024-09-25 20:28:59,414 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.045, Train_accy 100.00, Test_accy 50.54
2024-09-25 20:29:05,548 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.047, Train_accy 100.00, Test_accy 67.20
2024-09-25 20:29:11,665 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.046, Train_accy 100.00, Test_accy 67.54
2024-09-25 20:29:17,778 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.046, Train_accy 100.00, Test_accy 66.94
2024-09-25 20:29:23,833 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.042, Train_accy 100.00, Test_accy 67.09
2024-09-25 20:29:30,045 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.040, Train_accy 100.00, Test_accy 66.31
2024-09-25 20:29:36,178 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.042, Train_accy 100.00, Test_accy 66.81
2024-09-25 20:29:42,228 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.044, Train_accy 100.00, Test_accy 66.87
2024-09-25 20:29:48,319 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.043, Train_accy 100.00, Test_accy 67.02
2024-09-25 20:29:54,481 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.041, Train_accy 100.00, Test_accy 67.63
2024-09-25 20:30:00,785 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.043, Train_accy 100.00, Test_accy 67.54
2024-09-25 20:30:07,011 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.042, Train_accy 100.00, Test_accy 66.74
2024-09-25 20:30:13,332 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.046, Train_accy 100.00, Test_accy 67.39
2024-09-25 20:30:19,720 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.041, Train_accy 100.00, Test_accy 67.19
2024-09-25 20:30:25,868 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.038, Train_accy 100.00, Test_accy 68.19
2024-09-25 20:30:32,008 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.040, Train_accy 100.00, Test_accy 66.46
2024-09-25 20:30:38,214 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.046, Train_accy 100.00, Test_accy 67.46
2024-09-25 20:30:44,392 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.043, Train_accy 100.00, Test_accy 66.85
2024-09-25 20:30:50,402 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.044, Train_accy 100.00, Test_accy 67.83
2024-09-25 20:30:56,478 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.043, Train_accy 100.00, Test_accy 66.46
2024-09-25 20:31:02,720 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.042, Train_accy 100.00, Test_accy 66.50
2024-09-25 20:31:07,243 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.039, Train_accy 100.00
2024-09-25 20:31:07,244 [base.py] => Reducing exemplars...(55 per classes)
2024-09-25 20:31:08,692 [base.py] => Constructing exemplars...(55 per classes)
2024-09-25 20:31:11,688 [icarl.py] => Exemplar size: 495
2024-09-25 20:31:11,688 [trainer.py] => CNN: {'total': 67.83, '00-04': 52.53, '05-06': 77.25, '07-08': 96.67, 'old': 59.6, 'new': 96.67}
2024-09-25 20:31:11,688 [trainer.py] => NME: {'total': 78.0, '00-04': 69.27, '05-06': 84.92, '07-08': 92.92, 'old': 73.74, 'new': 92.92}
2024-09-25 20:31:11,688 [trainer.py] => CNN top1 curve: [89.93, 70.64, 67.83]
2024-09-25 20:31:11,688 [trainer.py] => CNN top5 curve: [100.0, 98.86, 95.94]
2024-09-25 20:31:11,688 [trainer.py] => NME top1 curve: [90.0, 78.88, 78.0]
2024-09-25 20:31:11,688 [trainer.py] => NME top5 curve: [100.0, 99.02, 97.8]

2024-09-25 20:31:11,689 [trainer.py] => Average Accuracy (CNN): 76.13333333333333
2024-09-25 20:31:11,689 [trainer.py] => Average Accuracy (NME): 82.29333333333334
2024-09-25 20:31:11,689 [trainer.py] => Forgetting (CNN): 28.615000000000002
