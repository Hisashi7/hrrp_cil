2024-10-23 15:23:53,816 [trainer.py] => config: ./exps/icarl.json
2024-10-23 15:23:53,816 [trainer.py] => prefix: cil
2024-10-23 15:23:53,816 [trainer.py] => dataset: hrrp9
2024-10-23 15:23:53,816 [trainer.py] => memory_size: 200
2024-10-23 15:23:53,816 [trainer.py] => memory_per_class: 20
2024-10-23 15:23:53,816 [trainer.py] => fixed_memory: False
2024-10-23 15:23:53,816 [trainer.py] => shuffle: True
2024-10-23 15:23:53,817 [trainer.py] => init_cls: 5
2024-10-23 15:23:53,817 [trainer.py] => increment: 2
2024-10-23 15:23:53,817 [trainer.py] => model_name: icarl
2024-10-23 15:23:53,817 [trainer.py] => convnet_type: resnet18
2024-10-23 15:23:53,817 [trainer.py] => device: [device(type='cuda', index=5)]
2024-10-23 15:23:53,817 [trainer.py] => init_train: False
2024-10-23 15:23:53,817 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 15:23:53,817 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 15:23:53,817 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 15:23:53,817 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 15:23:53,817 [trainer.py] => seed: 1993
2024-10-23 15:23:53,817 [trainer.py] => init_epoch: 0
2024-10-23 15:23:53,817 [trainer.py] => init_lr: 0.1
2024-10-23 15:23:53,818 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-23 15:23:53,818 [trainer.py] => init_lr_decay: 0.1
2024-10-23 15:23:53,818 [trainer.py] => init_weight_decay: 0.0005
2024-10-23 15:23:53,818 [trainer.py] => epochs: 150
2024-10-23 15:23:53,818 [trainer.py] => lrate: 0.1
2024-10-23 15:23:53,818 [trainer.py] => milestones: [80, 120]
2024-10-23 15:23:53,818 [trainer.py] => lrate_decay: 0.1
2024-10-23 15:23:53,818 [trainer.py] => momentum: 0.9
2024-10-23 15:23:53,818 [trainer.py] => batch_size: 128
2024-10-23 15:23:53,818 [trainer.py] => weight_decay: 0.0002
2024-10-23 15:23:53,818 [trainer.py] => num_workers: 8
2024-10-23 15:23:53,818 [trainer.py] => T: 2
2024-10-23 15:23:54,618 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 15:23:55,189 [trainer.py] => All params: 3843904
2024-10-23 15:23:55,216 [trainer.py] => Trainable params: 3843904
2024-10-23 15:23:55,220 [icarl.py] => Learning on 0-5
2024-10-23 15:23:55,655 [icarl.py] => init_train?---False
2024-10-23 15:23:56,829 [base.py] => Reducing exemplars...(40 per classes)
2024-10-23 15:23:56,829 [base.py] => Constructing exemplars...(40 per classes)
2024-10-23 15:24:02,796 [trainer.py] => All params: 3846469
2024-10-23 15:24:04,519 [icarl.py] => Exemplar size: 200
2024-10-23 15:24:04,519 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 15:24:04,519 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 15:24:04,519 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 15:24:04,519 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 15:24:04,519 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 15:24:04,519 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 15:24:04,520 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 15:24:04,520 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 15:24:04,520 [trainer.py] => All params: 3846469
2024-10-23 15:24:04,520 [trainer.py] => Trainable params: 3846469
2024-10-23 15:24:04,522 [icarl.py] => Learning on 5-7
2024-10-23 15:24:06,719 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.107, Train_accy 77.50, Test_accy 26.67
2024-10-23 15:24:14,587 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.041, Train_accy 99.36, Test_accy 55.71
2024-10-23 15:24:23,307 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.978, Train_accy 100.00, Test_accy 54.86
2024-10-23 15:24:31,836 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.967, Train_accy 100.00, Test_accy 55.45
2024-10-23 15:24:40,477 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.965, Train_accy 100.00, Test_accy 56.43
2024-10-23 15:24:50,076 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.963, Train_accy 100.00, Test_accy 56.83
2024-10-23 15:24:58,540 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.962, Train_accy 100.00, Test_accy 60.45
2024-10-23 15:25:07,748 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.960, Train_accy 100.00, Test_accy 58.93
2024-10-23 15:25:16,379 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.960, Train_accy 100.00, Test_accy 59.31
2024-10-23 15:25:25,467 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.960, Train_accy 100.00, Test_accy 59.50
2024-10-23 15:25:34,104 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.961, Train_accy 100.00, Test_accy 57.24
2024-10-23 15:25:43,340 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.958, Train_accy 100.00, Test_accy 56.14
2024-10-23 15:25:52,030 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.960, Train_accy 100.00, Test_accy 57.38
2024-10-23 15:26:00,368 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.958, Train_accy 100.00, Test_accy 54.57
2024-10-23 15:26:09,357 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.958, Train_accy 100.00, Test_accy 60.52
2024-10-23 15:26:18,041 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.959, Train_accy 100.00, Test_accy 57.48
2024-10-23 15:26:26,680 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.955, Train_accy 100.00, Test_accy 56.26
2024-10-23 15:26:35,953 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.954, Train_accy 100.00, Test_accy 56.33
2024-10-23 15:26:44,547 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.50
2024-10-23 15:26:52,933 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.953, Train_accy 100.00, Test_accy 56.48
2024-10-23 15:27:02,120 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.83
2024-10-23 15:27:10,957 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.952, Train_accy 100.00, Test_accy 57.07
2024-10-23 15:27:19,848 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.29
2024-10-23 15:27:27,747 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.952, Train_accy 100.00, Test_accy 55.83
2024-10-23 15:27:36,952 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.31
2024-10-23 15:27:45,769 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.951, Train_accy 100.00, Test_accy 56.79
2024-10-23 15:27:54,909 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.17
2024-10-23 15:28:03,730 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.69
2024-10-23 15:28:12,909 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.952, Train_accy 100.00, Test_accy 56.74
2024-10-23 15:28:21,749 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.951, Train_accy 100.00, Test_accy 56.60
2024-10-23 15:28:27,684 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.953, Train_accy 100.00
2024-10-23 15:28:27,685 [base.py] => Reducing exemplars...(28 per classes)
2024-10-23 15:28:29,372 [base.py] => Constructing exemplars...(28 per classes)
2024-10-23 15:28:32,116 [trainer.py] => All params: 3847495
2024-10-23 15:28:34,113 [icarl.py] => Exemplar size: 196
2024-10-23 15:28:34,113 [trainer.py] => CNN: {'total': 56.71, '00-04': 40.4, '05-06': 97.5, 'old': 40.4, 'new': 97.5}
2024-10-23 15:28:34,114 [trainer.py] => NME: {'total': 70.48, '00-04': 60.87, '05-06': 94.5, 'old': 60.87, 'new': 94.5}
2024-10-23 15:28:34,114 [trainer.py] => CNN top1 curve: [89.93, 56.71]
2024-10-23 15:28:34,114 [trainer.py] => CNN top5 curve: [100.0, 99.02]
2024-10-23 15:28:34,114 [trainer.py] => NME top1 curve: [90.0, 70.48]
2024-10-23 15:28:34,114 [trainer.py] => NME top5 curve: [100.0, 99.02]

2024-10-23 15:28:34,114 [trainer.py] => Average Accuracy (CNN): 73.32000000000001
2024-10-23 15:28:34,114 [trainer.py] => Average Accuracy (NME): 80.24000000000001
2024-10-23 15:28:34,114 [trainer.py] => All params: 3847495
2024-10-23 15:28:34,115 [trainer.py] => Trainable params: 3847495
2024-10-23 15:28:34,119 [icarl.py] => Learning on 7-9
2024-10-23 15:28:36,801 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.862, Train_accy 72.59, Test_accy 15.33
2024-10-23 15:28:45,914 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.593, Train_accy 93.97, Test_accy 21.91
2024-10-23 15:28:54,552 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.420, Train_accy 95.33, Test_accy 26.26
2024-10-23 15:29:04,969 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.256, Train_accy 97.88, Test_accy 40.00
2024-10-23 15:29:15,791 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.147, Train_accy 99.67, Test_accy 35.57
2024-10-23 15:29:27,391 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.090, Train_accy 100.00, Test_accy 47.22
2024-10-23 15:29:38,498 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.070, Train_accy 100.00, Test_accy 40.35
2024-10-23 15:29:50,554 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.062, Train_accy 100.00, Test_accy 44.15
2024-10-23 15:30:03,556 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.061, Train_accy 100.00, Test_accy 47.48
2024-10-23 15:30:15,797 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.053, Train_accy 100.00, Test_accy 47.11
2024-10-23 15:30:29,966 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.052, Train_accy 100.00, Test_accy 41.54
2024-10-23 15:30:43,868 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.050, Train_accy 100.00, Test_accy 45.04
2024-10-23 15:30:58,027 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.048, Train_accy 100.00, Test_accy 42.56
2024-10-23 15:31:12,463 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.049, Train_accy 100.00, Test_accy 42.59
2024-10-23 15:31:26,204 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.047, Train_accy 100.00, Test_accy 40.81
2024-10-23 15:31:40,277 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.047, Train_accy 100.00, Test_accy 42.93
2024-10-23 15:31:54,768 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.045, Train_accy 100.00, Test_accy 41.76
2024-10-23 15:32:07,864 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.040, Train_accy 100.00, Test_accy 42.17
2024-10-23 15:32:22,185 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.040, Train_accy 100.00, Test_accy 42.04
2024-10-23 15:32:36,602 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.11
2024-10-23 15:32:51,483 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.57
2024-10-23 15:33:07,829 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.039, Train_accy 100.00, Test_accy 42.44
2024-10-23 15:33:24,799 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.041, Train_accy 100.00, Test_accy 41.50
2024-10-23 15:33:42,231 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.041, Train_accy 100.00, Test_accy 41.78
2024-10-23 15:33:59,908 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.89
2024-10-23 15:34:17,288 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.07
2024-10-23 15:34:36,190 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.87
2024-10-23 15:34:55,200 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.040, Train_accy 100.00, Test_accy 41.28
2024-10-23 15:35:12,615 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.039, Train_accy 100.00, Test_accy 42.80
2024-10-23 15:35:31,536 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.039, Train_accy 100.00, Test_accy 42.26
2024-10-23 15:35:44,367 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.040, Train_accy 100.00
2024-10-23 15:35:44,368 [base.py] => Reducing exemplars...(22 per classes)
2024-10-23 15:35:49,868 [base.py] => Constructing exemplars...(22 per classes)
2024-10-23 15:35:56,032 [trainer.py] => All params: 3848521
2024-10-23 15:36:00,660 [icarl.py] => Exemplar size: 198
2024-10-23 15:36:00,661 [trainer.py] => CNN: {'total': 41.17, '00-04': 22.03, '05-06': 32.25, '07-08': 97.92, 'old': 24.95, 'new': 97.92}
2024-10-23 15:36:00,661 [trainer.py] => NME: {'total': 59.33, '00-04': 43.97, '05-06': 63.67, '07-08': 93.42, 'old': 49.6, 'new': 93.42}
2024-10-23 15:36:00,661 [trainer.py] => CNN top1 curve: [89.93, 56.71, 41.17]
2024-10-23 15:36:00,661 [trainer.py] => CNN top5 curve: [100.0, 99.02, 91.67]
2024-10-23 15:36:00,661 [trainer.py] => NME top1 curve: [90.0, 70.48, 59.33]
2024-10-23 15:36:00,662 [trainer.py] => NME top5 curve: [100.0, 99.02, 95.09]

2024-10-23 15:36:00,662 [trainer.py] => Average Accuracy (CNN): 62.60333333333333
2024-10-23 15:36:00,662 [trainer.py] => Average Accuracy (NME): 73.27
2024-10-23 15:36:00,663 [trainer.py] => Forgetting (CNN): 66.575
