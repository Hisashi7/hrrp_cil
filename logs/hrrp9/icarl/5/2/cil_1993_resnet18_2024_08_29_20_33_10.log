2024-08-29 20:33:10,394 [trainer.py] => config: ./exps/icarl.json
2024-08-29 20:33:10,394 [trainer.py] => prefix: cil
2024-08-29 20:33:10,394 [trainer.py] => dataset: hrrp9
2024-08-29 20:33:10,394 [trainer.py] => memory_size: 500
2024-08-29 20:33:10,394 [trainer.py] => memory_per_class: 20
2024-08-29 20:33:10,394 [trainer.py] => fixed_memory: False
2024-08-29 20:33:10,394 [trainer.py] => shuffle: True
2024-08-29 20:33:10,394 [trainer.py] => init_cls: 5
2024-08-29 20:33:10,394 [trainer.py] => increment: 2
2024-08-29 20:33:10,395 [trainer.py] => model_name: icarl
2024-08-29 20:33:10,395 [trainer.py] => convnet_type: resnet18
2024-08-29 20:33:10,395 [trainer.py] => device: [device(type='cuda', index=5)]
2024-08-29 20:33:10,395 [trainer.py] => init_train: False
2024-08-29 20:33:10,395 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-08-29 20:33:10,395 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-08-29 20:33:10,395 [trainer.py] => seed: 1993
2024-08-29 20:33:10,846 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-08-29 20:33:12,760 [trainer.py] => All params: 3843904
2024-08-29 20:33:12,761 [trainer.py] => Trainable params: 3843904
2024-08-29 20:33:12,763 [icarl.py] => Learning on 0-5
2024-08-29 20:33:14,284 [icarl.py] => init_train?---False
2024-08-29 20:33:17,341 [base.py] => Reducing exemplars...(100 per classes)
2024-08-29 20:33:17,341 [base.py] => Constructing exemplars...(100 per classes)
2024-08-29 20:33:29,300 [icarl.py] => Exemplar size: 500
2024-08-29 20:33:29,300 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-08-29 20:33:29,301 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-08-29 20:33:29,301 [trainer.py] => CNN top1 curve: [89.93]
2024-08-29 20:33:29,301 [trainer.py] => CNN top5 curve: [100.0]
2024-08-29 20:33:29,301 [trainer.py] => NME top1 curve: [90.0]
2024-08-29 20:33:29,301 [trainer.py] => NME top5 curve: [100.0]

2024-08-29 20:33:29,301 [trainer.py] => Average Accuracy (CNN): 89.93
2024-08-29 20:33:29,301 [trainer.py] => Average Accuracy (NME): 90.0
2024-08-29 20:33:29,302 [trainer.py] => All params: 3846469
2024-08-29 20:33:29,302 [trainer.py] => Trainable params: 3846469
2024-08-29 20:33:29,303 [icarl.py] => Learning on 5-7
2024-08-29 20:33:33,083 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.026, Train_accy 75.47, Test_accy 26.93
2024-08-29 20:33:45,086 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.057, Train_accy 98.11, Test_accy 56.60
2024-08-29 20:33:58,124 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.933, Train_accy 99.98, Test_accy 67.10
2024-08-29 20:34:10,493 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.924, Train_accy 99.98, Test_accy 66.33
2024-08-29 20:34:22,900 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.925, Train_accy 100.00, Test_accy 71.60
2024-08-29 20:34:35,062 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.980, Train_accy 99.62, Test_accy 65.21
2024-08-29 20:34:47,938 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.937, Train_accy 99.91, Test_accy 65.88
2024-08-29 20:35:00,024 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.927, Train_accy 99.98, Test_accy 68.67
2024-08-29 20:35:12,920 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.919, Train_accy 100.00, Test_accy 67.93
2024-08-29 20:35:25,127 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.67
2024-08-29 20:35:37,260 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.912, Train_accy 100.00, Test_accy 66.57
2024-08-29 20:35:49,782 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.914, Train_accy 100.00, Test_accy 67.93
2024-08-29 20:36:02,782 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.918, Train_accy 100.00, Test_accy 63.48
2024-08-29 20:36:14,875 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.908, Train_accy 100.00, Test_accy 69.36
2024-08-29 20:36:26,388 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.914, Train_accy 100.00, Test_accy 69.43
2024-08-29 20:36:38,483 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.976, Train_accy 99.58, Test_accy 61.55
2024-08-29 20:36:49,754 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.930, Train_accy 99.96, Test_accy 66.79
2024-08-29 20:37:01,749 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.917, Train_accy 100.00, Test_accy 67.43
2024-08-29 20:37:13,049 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.914, Train_accy 100.00, Test_accy 68.60
2024-08-29 20:37:24,229 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.21
2024-08-29 20:37:35,726 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.910, Train_accy 100.00, Test_accy 68.81
2024-08-29 20:37:47,702 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.912, Train_accy 100.00, Test_accy 68.43
2024-08-29 20:37:59,362 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.60
2024-08-29 20:38:11,399 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.906, Train_accy 100.00, Test_accy 67.98
2024-08-29 20:38:23,593 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.906, Train_accy 100.00, Test_accy 68.71
2024-08-29 20:38:35,697 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.909, Train_accy 100.00, Test_accy 68.43
2024-08-29 20:38:47,307 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.910, Train_accy 100.00, Test_accy 69.45
2024-08-29 20:38:59,412 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.43
2024-08-29 20:39:11,345 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.915, Train_accy 100.00, Test_accy 68.83
2024-08-29 20:39:23,501 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.57
2024-08-29 20:39:32,101 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.908, Train_accy 100.00
2024-08-29 20:39:32,101 [base.py] => Reducing exemplars...(71 per classes)
2024-08-29 20:39:36,741 [base.py] => Constructing exemplars...(71 per classes)
2024-08-29 20:39:45,037 [icarl.py] => Exemplar size: 497
2024-08-29 20:39:45,038 [trainer.py] => CNN: {'total': 68.67, '00-04': 57.07, '05-06': 97.67, 'old': 57.07, 'new': 97.67}
2024-08-29 20:39:45,038 [trainer.py] => NME: {'total': 77.07, '00-04': 70.57, '05-06': 93.33, 'old': 70.57, 'new': 93.33}
2024-08-29 20:39:45,038 [trainer.py] => CNN top1 curve: [89.93, 68.67]
2024-08-29 20:39:45,038 [trainer.py] => CNN top5 curve: [100.0, 98.67]
2024-08-29 20:39:45,038 [trainer.py] => NME top1 curve: [90.0, 77.07]
2024-08-29 20:39:45,038 [trainer.py] => NME top5 curve: [100.0, 98.83]

2024-08-29 20:39:45,038 [trainer.py] => Average Accuracy (CNN): 79.30000000000001
2024-08-29 20:39:45,038 [trainer.py] => Average Accuracy (NME): 83.535
2024-08-29 20:39:45,039 [trainer.py] => All params: 3847495
2024-08-29 20:39:45,039 [trainer.py] => Trainable params: 3847495
2024-08-29 20:39:45,040 [icarl.py] => Learning on 7-9
2024-08-29 20:39:49,338 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.529, Train_accy 76.34, Test_accy 27.22
2024-08-29 20:40:01,838 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.123, Train_accy 98.55, Test_accy 63.98
2024-08-29 20:40:14,174 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.017, Train_accy 99.98, Test_accy 67.22
2024-08-29 20:40:27,084 [icarl.py] => Task 2, Epoch 16/150 => Loss 0.991, Train_accy 100.00, Test_accy 66.17
2024-08-29 20:40:39,231 [icarl.py] => Task 2, Epoch 21/150 => Loss 0.994, Train_accy 100.00, Test_accy 64.80
2024-08-29 20:40:51,717 [icarl.py] => Task 2, Epoch 26/150 => Loss 0.990, Train_accy 100.00, Test_accy 67.26
2024-08-29 20:41:04,092 [icarl.py] => Task 2, Epoch 31/150 => Loss 0.988, Train_accy 100.00, Test_accy 66.07
2024-08-29 20:41:17,152 [icarl.py] => Task 2, Epoch 36/150 => Loss 0.990, Train_accy 100.00, Test_accy 66.63
2024-08-29 20:41:29,364 [icarl.py] => Task 2, Epoch 41/150 => Loss 0.985, Train_accy 100.00, Test_accy 62.02
2024-08-29 20:41:41,772 [icarl.py] => Task 2, Epoch 46/150 => Loss 0.985, Train_accy 100.00, Test_accy 64.91
2024-08-29 20:41:54,715 [icarl.py] => Task 2, Epoch 51/150 => Loss 0.989, Train_accy 100.00, Test_accy 66.63
2024-08-29 20:42:07,541 [icarl.py] => Task 2, Epoch 56/150 => Loss 0.988, Train_accy 100.00, Test_accy 67.69
2024-08-29 20:42:20,212 [icarl.py] => Task 2, Epoch 61/150 => Loss 0.983, Train_accy 100.00, Test_accy 66.02
2024-08-29 20:42:32,806 [icarl.py] => Task 2, Epoch 66/150 => Loss 0.983, Train_accy 100.00, Test_accy 67.65
2024-08-29 20:42:45,419 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.000, Train_accy 99.84, Test_accy 59.09
2024-08-29 20:42:57,446 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.318, Train_accy 94.66, Test_accy 52.83
2024-08-29 20:43:09,310 [icarl.py] => Task 2, Epoch 81/150 => Loss 0.998, Train_accy 100.00, Test_accy 68.33
2024-08-29 20:43:21,020 [icarl.py] => Task 2, Epoch 86/150 => Loss 0.990, Train_accy 100.00, Test_accy 68.30
2024-08-29 20:43:33,013 [icarl.py] => Task 2, Epoch 91/150 => Loss 0.990, Train_accy 100.00, Test_accy 68.78
2024-08-29 20:43:45,004 [icarl.py] => Task 2, Epoch 96/150 => Loss 0.987, Train_accy 100.00, Test_accy 69.39
2024-08-29 20:43:56,947 [icarl.py] => Task 2, Epoch 101/150 => Loss 0.988, Train_accy 100.00, Test_accy 67.59
2024-08-29 20:44:09,102 [icarl.py] => Task 2, Epoch 106/150 => Loss 0.992, Train_accy 100.00, Test_accy 69.09
2024-08-29 20:44:20,388 [icarl.py] => Task 2, Epoch 111/150 => Loss 0.983, Train_accy 100.00, Test_accy 68.87
2024-08-29 20:44:32,422 [icarl.py] => Task 2, Epoch 116/150 => Loss 0.979, Train_accy 100.00, Test_accy 69.94
2024-08-29 20:44:44,625 [icarl.py] => Task 2, Epoch 121/150 => Loss 0.982, Train_accy 100.00, Test_accy 67.24
2024-08-29 20:44:56,334 [icarl.py] => Task 2, Epoch 126/150 => Loss 0.987, Train_accy 100.00, Test_accy 68.43
2024-08-29 20:45:08,156 [icarl.py] => Task 2, Epoch 131/150 => Loss 0.985, Train_accy 100.00, Test_accy 67.80
2024-08-29 20:45:19,965 [icarl.py] => Task 2, Epoch 136/150 => Loss 0.986, Train_accy 100.00, Test_accy 69.30
2024-08-29 20:45:31,404 [icarl.py] => Task 2, Epoch 141/150 => Loss 0.985, Train_accy 100.00, Test_accy 67.56
2024-08-29 20:45:43,051 [icarl.py] => Task 2, Epoch 146/150 => Loss 0.981, Train_accy 100.00, Test_accy 67.59
2024-08-29 20:45:50,701 [icarl.py] => Task 2, Epoch 150/150 => Loss 0.981, Train_accy 100.00
2024-08-29 20:45:50,702 [base.py] => Reducing exemplars...(55 per classes)
2024-08-29 20:45:55,992 [base.py] => Constructing exemplars...(55 per classes)
2024-08-29 20:46:03,163 [icarl.py] => Exemplar size: 495
2024-08-29 20:46:03,163 [trainer.py] => CNN: {'total': 69.31, '00-04': 53.5, '05-06': 80.0, '07-08': 98.17, 'old': 61.07, 'new': 98.17}
2024-08-29 20:46:03,164 [trainer.py] => NME: {'total': 75.24, '00-04': 63.97, '05-06': 85.08, '07-08': 93.58, 'old': 70.0, 'new': 93.58}
2024-08-29 20:46:03,164 [trainer.py] => CNN top1 curve: [89.93, 68.67, 69.31]
2024-08-29 20:46:03,164 [trainer.py] => CNN top5 curve: [100.0, 98.67, 96.04]
2024-08-29 20:46:03,165 [trainer.py] => NME top1 curve: [90.0, 77.07, 75.24]
2024-08-29 20:46:03,165 [trainer.py] => NME top5 curve: [100.0, 98.83, 97.2]

2024-08-29 20:46:03,165 [trainer.py] => Average Accuracy (CNN): 75.97000000000001
2024-08-29 20:46:03,165 [trainer.py] => Average Accuracy (NME): 80.77
2024-08-29 20:46:03,167 [trainer.py] => Forgetting (CNN): 27.050000000000004
