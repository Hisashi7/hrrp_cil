2024-09-25 20:13:33,917 [trainer.py] => config: ./exps/icarl.json
2024-09-25 20:13:33,918 [trainer.py] => prefix: cil
2024-09-25 20:13:33,918 [trainer.py] => dataset: hrrp9
2024-09-25 20:13:33,918 [trainer.py] => memory_size: 500
2024-09-25 20:13:33,918 [trainer.py] => memory_per_class: 20
2024-09-25 20:13:33,918 [trainer.py] => fixed_memory: False
2024-09-25 20:13:33,918 [trainer.py] => shuffle: True
2024-09-25 20:13:33,918 [trainer.py] => init_cls: 5
2024-09-25 20:13:33,918 [trainer.py] => increment: 2
2024-09-25 20:13:33,918 [trainer.py] => model_name: icarl
2024-09-25 20:13:33,918 [trainer.py] => convnet_type: resnet18
2024-09-25 20:13:33,918 [trainer.py] => device: [device(type='cuda', index=3)]
2024-09-25 20:13:33,918 [trainer.py] => init_train: False
2024-09-25 20:13:33,918 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-25 20:13:33,918 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-25 20:13:33,918 [trainer.py] => seed: 1993
2024-09-25 20:13:33,918 [trainer.py] => epochs: 150
2024-09-25 20:13:33,918 [trainer.py] => lrate: 0.1
2024-09-25 20:13:33,918 [trainer.py] => milestones: [50, 80, 120]
2024-09-25 20:13:33,918 [trainer.py] => lrate_decay: 0.1
2024-09-25 20:13:33,918 [trainer.py] => momentum: 0.1
2024-09-25 20:13:33,918 [trainer.py] => batch_size: 128
2024-09-25 20:13:33,918 [trainer.py] => weight_decay: 0.0002
2024-09-25 20:13:33,919 [trainer.py] => num_workers: 8
2024-09-25 20:13:33,919 [trainer.py] => T: 2
2024-09-25 20:13:34,633 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-25 20:13:35,151 [trainer.py] => All params: 3843904
2024-09-25 20:13:35,152 [trainer.py] => Trainable params: 3843904
2024-09-25 20:13:35,155 [icarl.py] => Learning on 0-5
2024-09-25 20:13:35,461 [icarl.py] => init_train?---False
2024-09-25 20:13:36,366 [base.py] => Reducing exemplars...(100 per classes)
2024-09-25 20:13:36,366 [base.py] => Constructing exemplars...(100 per classes)
2024-09-25 20:13:42,944 [icarl.py] => Exemplar size: 500
2024-09-25 20:13:42,944 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-09-25 20:13:42,944 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-09-25 20:13:42,944 [trainer.py] => CNN top1 curve: [89.93]
2024-09-25 20:13:42,944 [trainer.py] => CNN top5 curve: [100.0]
2024-09-25 20:13:42,944 [trainer.py] => NME top1 curve: [90.0]
2024-09-25 20:13:42,944 [trainer.py] => NME top5 curve: [100.0]

2024-09-25 20:13:42,944 [trainer.py] => Average Accuracy (CNN): 89.93
2024-09-25 20:13:42,944 [trainer.py] => Average Accuracy (NME): 90.0
2024-09-25 20:13:42,945 [trainer.py] => All params: 3846469
2024-09-25 20:13:42,945 [trainer.py] => Trainable params: 3846469
2024-09-25 20:13:42,946 [icarl.py] => Learning on 5-7
2024-09-25 20:13:44,999 [icarl.py] => Task 1, Epoch 1/150 => Loss 1.697, Train_accy 78.76, Test_accy 61.14
2024-09-25 20:13:51,786 [icarl.py] => Task 1, Epoch 6/150 => Loss 0.967, Train_accy 99.76, Test_accy 62.55
2024-09-25 20:13:58,676 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.933, Train_accy 100.00, Test_accy 63.67
2024-09-25 20:14:05,461 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.924, Train_accy 100.00, Test_accy 63.14
2024-09-25 20:14:12,125 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.920, Train_accy 100.00, Test_accy 65.90
2024-09-25 20:14:19,181 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.919, Train_accy 100.00, Test_accy 65.67
2024-09-25 20:14:25,826 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.916, Train_accy 100.00, Test_accy 68.31
2024-09-25 20:14:32,600 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.926, Train_accy 99.98, Test_accy 67.86
2024-09-25 20:14:39,012 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.918, Train_accy 100.00, Test_accy 69.00
2024-09-25 20:14:45,585 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.912, Train_accy 100.00, Test_accy 68.83
2024-09-25 20:14:52,286 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.913, Train_accy 100.00, Test_accy 68.14
2024-09-25 20:14:59,032 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.914, Train_accy 100.00, Test_accy 68.55
2024-09-25 20:15:05,990 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.909, Train_accy 100.00, Test_accy 69.19
2024-09-25 20:15:12,806 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.907, Train_accy 100.00, Test_accy 69.64
2024-09-25 20:15:19,585 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.914, Train_accy 100.00, Test_accy 69.12
2024-09-25 20:15:26,362 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.907, Train_accy 100.00, Test_accy 69.57
2024-09-25 20:15:33,045 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.913, Train_accy 100.00, Test_accy 69.14
2024-09-25 20:15:39,861 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.913, Train_accy 100.00, Test_accy 68.67
2024-09-25 20:15:46,667 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.911, Train_accy 100.00, Test_accy 69.60
2024-09-25 20:15:53,475 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.911, Train_accy 100.00, Test_accy 69.71
2024-09-25 20:16:00,025 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.909, Train_accy 100.00, Test_accy 69.64
2024-09-25 20:16:06,842 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.79
2024-09-25 20:16:13,854 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.93
2024-09-25 20:16:20,737 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.907, Train_accy 100.00, Test_accy 69.31
2024-09-25 20:16:27,495 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.908, Train_accy 100.00, Test_accy 69.76
2024-09-25 20:16:34,038 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.910, Train_accy 100.00, Test_accy 69.36
2024-09-25 20:16:40,794 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.90
2024-09-25 20:16:47,225 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.67
2024-09-25 20:16:54,058 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.917, Train_accy 100.00, Test_accy 69.62
2024-09-25 20:17:00,687 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.912, Train_accy 100.00, Test_accy 69.74
2024-09-25 20:17:05,579 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.910, Train_accy 100.00
2024-09-25 20:17:05,580 [base.py] => Reducing exemplars...(71 per classes)
2024-09-25 20:17:06,957 [base.py] => Constructing exemplars...(71 per classes)
2024-09-25 20:17:10,377 [icarl.py] => Exemplar size: 497
2024-09-25 20:17:10,377 [trainer.py] => CNN: {'total': 69.38, '00-04': 58.23, '05-06': 97.25, 'old': 58.23, 'new': 97.25}
2024-09-25 20:17:10,377 [trainer.py] => NME: {'total': 79.6, '00-04': 74.97, '05-06': 91.17, 'old': 74.97, 'new': 91.17}
2024-09-25 20:17:10,378 [trainer.py] => CNN top1 curve: [89.93, 69.38]
2024-09-25 20:17:10,378 [trainer.py] => CNN top5 curve: [100.0, 98.98]
2024-09-25 20:17:10,378 [trainer.py] => NME top1 curve: [90.0, 79.6]
2024-09-25 20:17:10,378 [trainer.py] => NME top5 curve: [100.0, 99.0]

2024-09-25 20:17:10,378 [trainer.py] => Average Accuracy (CNN): 79.655
2024-09-25 20:17:10,378 [trainer.py] => Average Accuracy (NME): 84.8
2024-09-25 20:17:10,378 [trainer.py] => All params: 3847495
2024-09-25 20:17:10,379 [trainer.py] => Trainable params: 3847495
2024-09-25 20:17:10,380 [icarl.py] => Learning on 7-9
2024-09-25 20:17:12,319 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.019, Train_accy 81.12, Test_accy 44.39
2024-09-25 20:17:19,281 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.084, Train_accy 99.91, Test_accy 57.74
2024-09-25 20:17:26,156 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.064, Train_accy 100.00, Test_accy 61.00
2024-09-25 20:17:32,905 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.048, Train_accy 100.00, Test_accy 55.61
2024-09-25 20:17:40,003 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.052, Train_accy 100.00, Test_accy 62.22
2024-09-25 20:17:46,910 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.048, Train_accy 100.00, Test_accy 62.20
2024-09-25 20:17:53,878 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.046, Train_accy 100.00, Test_accy 64.22
2024-09-25 20:18:00,772 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.048, Train_accy 100.00, Test_accy 63.48
2024-09-25 20:18:07,828 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.040, Train_accy 100.00, Test_accy 55.91
2024-09-25 20:18:14,649 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.042, Train_accy 100.00, Test_accy 49.56
2024-09-25 20:18:22,103 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.044, Train_accy 100.00, Test_accy 65.13
2024-09-25 20:18:28,841 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.041, Train_accy 100.00, Test_accy 66.30
2024-09-25 20:18:36,176 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.042, Train_accy 100.00, Test_accy 65.85
2024-09-25 20:18:43,367 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.038, Train_accy 100.00, Test_accy 66.09
2024-09-25 20:18:50,072 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.037, Train_accy 100.00, Test_accy 65.28
2024-09-25 20:18:57,418 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.037, Train_accy 100.00, Test_accy 65.72
2024-09-25 20:19:04,424 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.038, Train_accy 100.00, Test_accy 65.96
2024-09-25 20:19:11,410 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.038, Train_accy 100.00, Test_accy 65.74
2024-09-25 20:19:18,586 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.037, Train_accy 100.00, Test_accy 66.46
2024-09-25 20:19:25,384 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.038, Train_accy 100.00, Test_accy 66.37
2024-09-25 20:19:32,382 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.038, Train_accy 100.00, Test_accy 65.85
2024-09-25 20:19:39,269 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.041, Train_accy 100.00, Test_accy 66.35
2024-09-25 20:19:46,255 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.037, Train_accy 100.00, Test_accy 65.96
2024-09-25 20:19:53,233 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.034, Train_accy 100.00, Test_accy 66.78
2024-09-25 20:20:00,257 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.034, Train_accy 100.00, Test_accy 65.50
2024-09-25 20:20:07,049 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.042, Train_accy 100.00, Test_accy 66.31
2024-09-25 20:20:14,136 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.039, Train_accy 100.00, Test_accy 65.63
2024-09-25 20:20:21,063 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.040, Train_accy 100.00, Test_accy 66.46
2024-09-25 20:20:27,786 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.037, Train_accy 100.00, Test_accy 65.44
2024-09-25 20:20:34,614 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.038, Train_accy 100.00, Test_accy 65.67
2024-09-25 20:20:39,567 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.033, Train_accy 100.00
2024-09-25 20:20:39,567 [base.py] => Reducing exemplars...(55 per classes)
2024-09-25 20:20:41,421 [base.py] => Constructing exemplars...(55 per classes)
2024-09-25 20:20:44,837 [icarl.py] => Exemplar size: 495
2024-09-25 20:20:44,838 [trainer.py] => CNN: {'total': 66.56, '00-04': 50.27, '05-06': 77.25, '07-08': 96.58, 'old': 57.98, 'new': 96.58}
2024-09-25 20:20:44,838 [trainer.py] => NME: {'total': 78.48, '00-04': 70.5, '05-06': 84.67, '07-08': 92.25, 'old': 74.55, 'new': 92.25}
2024-09-25 20:20:44,838 [trainer.py] => CNN top1 curve: [89.93, 69.38, 66.56]
2024-09-25 20:20:44,838 [trainer.py] => CNN top5 curve: [100.0, 98.98, 95.69]
2024-09-25 20:20:44,838 [trainer.py] => NME top1 curve: [90.0, 79.6, 78.48]
2024-09-25 20:20:44,838 [trainer.py] => NME top5 curve: [100.0, 99.0, 97.67]

2024-09-25 20:20:44,838 [trainer.py] => Average Accuracy (CNN): 75.29
2024-09-25 20:20:44,838 [trainer.py] => Average Accuracy (NME): 82.69333333333333
2024-09-25 20:20:44,839 [trainer.py] => Forgetting (CNN): 29.830000000000002
