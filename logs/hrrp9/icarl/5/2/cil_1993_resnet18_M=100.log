2024-10-23 15:24:06,398 [trainer.py] => config: ./exps/icarl.json
2024-10-23 15:24:06,401 [trainer.py] => prefix: cil
2024-10-23 15:24:06,401 [trainer.py] => dataset: hrrp9
2024-10-23 15:24:06,401 [trainer.py] => memory_size: 100
2024-10-23 15:24:06,401 [trainer.py] => memory_per_class: 20
2024-10-23 15:24:06,401 [trainer.py] => fixed_memory: False
2024-10-23 15:24:06,402 [trainer.py] => shuffle: True
2024-10-23 15:24:06,402 [trainer.py] => init_cls: 5
2024-10-23 15:24:06,402 [trainer.py] => increment: 2
2024-10-23 15:24:06,402 [trainer.py] => model_name: icarl
2024-10-23 15:24:06,402 [trainer.py] => convnet_type: resnet18
2024-10-23 15:24:06,403 [trainer.py] => device: [device(type='cuda', index=5)]
2024-10-23 15:24:06,403 [trainer.py] => init_train: False
2024-10-23 15:24:06,403 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 15:24:06,403 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 15:24:06,403 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 15:24:06,404 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 15:24:06,404 [trainer.py] => seed: 1993
2024-10-23 15:24:06,404 [trainer.py] => init_epoch: 0
2024-10-23 15:24:06,404 [trainer.py] => init_lr: 0.1
2024-10-23 15:24:06,404 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-23 15:24:06,405 [trainer.py] => init_lr_decay: 0.1
2024-10-23 15:24:06,405 [trainer.py] => init_weight_decay: 0.0005
2024-10-23 15:24:06,405 [trainer.py] => epochs: 150
2024-10-23 15:24:06,405 [trainer.py] => lrate: 0.1
2024-10-23 15:24:06,405 [trainer.py] => milestones: [80, 120]
2024-10-23 15:24:06,406 [trainer.py] => lrate_decay: 0.1
2024-10-23 15:24:06,406 [trainer.py] => momentum: 0.9
2024-10-23 15:24:06,406 [trainer.py] => batch_size: 128
2024-10-23 15:24:06,407 [trainer.py] => weight_decay: 0.0002
2024-10-23 15:24:06,407 [trainer.py] => num_workers: 8
2024-10-23 15:24:06,407 [trainer.py] => T: 2
2024-10-23 15:24:07,377 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 15:24:08,045 [trainer.py] => All params: 3843904
2024-10-23 15:24:08,046 [trainer.py] => Trainable params: 3843904
2024-10-23 15:24:08,049 [icarl.py] => Learning on 0-5
2024-10-23 15:24:08,441 [icarl.py] => init_train?---False
2024-10-23 15:24:09,776 [base.py] => Reducing exemplars...(20 per classes)
2024-10-23 15:24:09,777 [base.py] => Constructing exemplars...(20 per classes)
2024-10-23 15:24:15,306 [trainer.py] => All params: 3846469
2024-10-23 15:24:16,981 [icarl.py] => Exemplar size: 100
2024-10-23 15:24:16,994 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 15:24:16,994 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 15:24:16,995 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 15:24:16,995 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 15:24:16,995 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 15:24:16,995 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 15:24:16,997 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 15:24:16,997 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 15:24:16,998 [trainer.py] => All params: 3846469
2024-10-23 15:24:16,998 [trainer.py] => Trainable params: 3846469
2024-10-23 15:24:16,999 [icarl.py] => Learning on 5-7
2024-10-23 15:24:19,896 [icarl.py] => Task 1, Epoch 1/150 => Loss 1.995, Train_accy 77.71, Test_accy 21.29
2024-10-23 15:24:28,526 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.149, Train_accy 97.66, Test_accy 30.74
2024-10-23 15:24:37,315 [icarl.py] => Task 1, Epoch 11/150 => Loss 1.415, Train_accy 94.10, Test_accy 24.36
2024-10-23 15:24:46,959 [icarl.py] => Task 1, Epoch 16/150 => Loss 1.117, Train_accy 98.88, Test_accy 41.48
2024-10-23 15:24:55,291 [icarl.py] => Task 1, Epoch 21/150 => Loss 1.054, Train_accy 99.80, Test_accy 43.98
2024-10-23 15:25:03,975 [icarl.py] => Task 1, Epoch 26/150 => Loss 1.351, Train_accy 94.61, Test_accy 28.98
2024-10-23 15:25:13,439 [icarl.py] => Task 1, Epoch 31/150 => Loss 1.248, Train_accy 95.49, Test_accy 31.21
2024-10-23 15:25:22,263 [icarl.py] => Task 1, Epoch 36/150 => Loss 1.072, Train_accy 99.76, Test_accy 41.90
2024-10-23 15:25:30,731 [icarl.py] => Task 1, Epoch 41/150 => Loss 1.114, Train_accy 98.95, Test_accy 36.38
2024-10-23 15:25:40,192 [icarl.py] => Task 1, Epoch 46/150 => Loss 1.022, Train_accy 100.00, Test_accy 44.69
2024-10-23 15:25:48,566 [icarl.py] => Task 1, Epoch 51/150 => Loss 1.381, Train_accy 95.56, Test_accy 32.26
2024-10-23 15:25:58,159 [icarl.py] => Task 1, Epoch 56/150 => Loss 1.124, Train_accy 99.05, Test_accy 43.86
2024-10-23 15:26:07,004 [icarl.py] => Task 1, Epoch 61/150 => Loss 1.660, Train_accy 88.95, Test_accy 34.21
2024-10-23 15:26:15,034 [icarl.py] => Task 1, Epoch 66/150 => Loss 1.147, Train_accy 98.80, Test_accy 41.69
2024-10-23 15:26:23,773 [icarl.py] => Task 1, Epoch 71/150 => Loss 1.083, Train_accy 99.66, Test_accy 25.12
2024-10-23 15:26:32,623 [icarl.py] => Task 1, Epoch 76/150 => Loss 1.108, Train_accy 99.56, Test_accy 46.62
2024-10-23 15:26:40,721 [icarl.py] => Task 1, Epoch 81/150 => Loss 1.092, Train_accy 99.56, Test_accy 43.52
2024-10-23 15:26:49,849 [icarl.py] => Task 1, Epoch 86/150 => Loss 1.066, Train_accy 99.76, Test_accy 44.10
2024-10-23 15:26:58,258 [icarl.py] => Task 1, Epoch 91/150 => Loss 1.052, Train_accy 99.85, Test_accy 44.64
2024-10-23 15:27:07,058 [icarl.py] => Task 1, Epoch 96/150 => Loss 1.074, Train_accy 99.07, Test_accy 43.71
2024-10-23 15:27:16,236 [icarl.py] => Task 1, Epoch 101/150 => Loss 1.079, Train_accy 99.29, Test_accy 44.43
2024-10-23 15:27:24,611 [icarl.py] => Task 1, Epoch 106/150 => Loss 1.056, Train_accy 99.90, Test_accy 42.29
2024-10-23 15:27:33,956 [icarl.py] => Task 1, Epoch 111/150 => Loss 1.034, Train_accy 100.00, Test_accy 44.74
2024-10-23 15:27:42,317 [icarl.py] => Task 1, Epoch 116/150 => Loss 1.033, Train_accy 100.00, Test_accy 44.69
2024-10-23 15:27:51,613 [icarl.py] => Task 1, Epoch 121/150 => Loss 1.033, Train_accy 100.00, Test_accy 45.88
2024-10-23 15:27:59,781 [icarl.py] => Task 1, Epoch 126/150 => Loss 1.039, Train_accy 100.00, Test_accy 46.55
2024-10-23 15:28:09,174 [icarl.py] => Task 1, Epoch 131/150 => Loss 1.020, Train_accy 100.00, Test_accy 46.14
2024-10-23 15:28:18,298 [icarl.py] => Task 1, Epoch 136/150 => Loss 1.023, Train_accy 100.00, Test_accy 44.69
2024-10-23 15:28:26,362 [icarl.py] => Task 1, Epoch 141/150 => Loss 1.011, Train_accy 100.00, Test_accy 46.33
2024-10-23 15:28:35,769 [icarl.py] => Task 1, Epoch 146/150 => Loss 1.018, Train_accy 99.98, Test_accy 46.24
2024-10-23 15:28:42,144 [icarl.py] => Task 1, Epoch 150/150 => Loss 1.058, Train_accy 99.95
2024-10-23 15:28:42,144 [base.py] => Reducing exemplars...(14 per classes)
2024-10-23 15:28:44,080 [base.py] => Constructing exemplars...(14 per classes)
2024-10-23 15:28:46,900 [trainer.py] => All params: 3847495
2024-10-23 15:28:49,282 [icarl.py] => Exemplar size: 98
2024-10-23 15:28:49,283 [trainer.py] => CNN: {'total': 44.76, '00-04': 23.97, '05-06': 96.75, 'old': 23.97, 'new': 96.75}
2024-10-23 15:28:49,283 [trainer.py] => NME: {'total': 60.62, '00-04': 48.17, '05-06': 91.75, 'old': 48.17, 'new': 91.75}
2024-10-23 15:28:49,283 [trainer.py] => CNN top1 curve: [89.93, 44.76]
2024-10-23 15:28:49,283 [trainer.py] => CNN top5 curve: [100.0, 96.79]
2024-10-23 15:28:49,283 [trainer.py] => NME top1 curve: [90.0, 60.62]
2024-10-23 15:28:49,283 [trainer.py] => NME top5 curve: [100.0, 96.79]

2024-10-23 15:28:49,283 [trainer.py] => Average Accuracy (CNN): 67.345
2024-10-23 15:28:49,284 [trainer.py] => Average Accuracy (NME): 75.31
2024-10-23 15:28:49,284 [trainer.py] => All params: 3847495
2024-10-23 15:28:49,284 [trainer.py] => Trainable params: 3847495
2024-10-23 15:28:49,285 [icarl.py] => Learning on 7-9
2024-10-23 15:28:52,617 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.272, Train_accy 78.77, Test_accy 21.37
2024-10-23 15:29:03,267 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.166, Train_accy 97.00, Test_accy 23.91
2024-10-23 15:29:13,658 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.035, Train_accy 97.66, Test_accy 27.41
2024-10-23 15:29:25,712 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.421, Train_accy 93.14, Test_accy 26.98
2024-10-23 15:29:37,380 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.245, Train_accy 94.27, Test_accy 29.44
2024-10-23 15:29:49,597 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.092, Train_accy 98.44, Test_accy 34.04
2024-10-23 15:30:02,553 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.133, Train_accy 98.58, Test_accy 40.54
2024-10-23 15:30:16,948 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.200, Train_accy 95.17, Test_accy 34.35
2024-10-23 15:30:30,952 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.149, Train_accy 95.63, Test_accy 33.30
2024-10-23 15:30:44,489 [icarl.py] => Task 2, Epoch 46/150 => Loss 0.973, Train_accy 99.12, Test_accy 36.15
2024-10-23 15:30:58,493 [icarl.py] => Task 2, Epoch 51/150 => Loss 0.982, Train_accy 99.07, Test_accy 34.65
2024-10-23 15:31:12,527 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.318, Train_accy 94.39, Test_accy 38.94
2024-10-23 15:31:26,188 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.025, Train_accy 99.44, Test_accy 46.15
2024-10-23 15:31:39,851 [icarl.py] => Task 2, Epoch 66/150 => Loss 0.957, Train_accy 99.32, Test_accy 38.15
2024-10-23 15:31:53,362 [icarl.py] => Task 2, Epoch 71/150 => Loss 0.934, Train_accy 99.88, Test_accy 34.69
2024-10-23 15:32:07,770 [icarl.py] => Task 2, Epoch 76/150 => Loss 0.952, Train_accy 99.41, Test_accy 41.33
2024-10-23 15:32:22,971 [icarl.py] => Task 2, Epoch 81/150 => Loss 0.933, Train_accy 99.71, Test_accy 39.43
2024-10-23 15:32:40,597 [icarl.py] => Task 2, Epoch 86/150 => Loss 0.932, Train_accy 99.73, Test_accy 37.74
2024-10-23 15:32:57,152 [icarl.py] => Task 2, Epoch 91/150 => Loss 0.951, Train_accy 99.76, Test_accy 35.72
2024-10-23 15:33:13,465 [icarl.py] => Task 2, Epoch 96/150 => Loss 0.981, Train_accy 99.83, Test_accy 39.06
2024-10-23 15:33:32,260 [icarl.py] => Task 2, Epoch 101/150 => Loss 0.942, Train_accy 99.80, Test_accy 36.22
2024-10-23 15:33:50,404 [icarl.py] => Task 2, Epoch 106/150 => Loss 0.914, Train_accy 99.88, Test_accy 39.67
2024-10-23 15:34:06,112 [icarl.py] => Task 2, Epoch 111/150 => Loss 0.984, Train_accy 99.44, Test_accy 35.20
2024-10-23 15:34:23,425 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.036, Train_accy 99.49, Test_accy 36.52
2024-10-23 15:34:41,070 [icarl.py] => Task 2, Epoch 121/150 => Loss 0.929, Train_accy 99.78, Test_accy 39.15
2024-10-23 15:34:58,117 [icarl.py] => Task 2, Epoch 126/150 => Loss 0.915, Train_accy 99.95, Test_accy 39.02
2024-10-23 15:35:15,284 [icarl.py] => Task 2, Epoch 131/150 => Loss 0.904, Train_accy 99.95, Test_accy 38.57
2024-10-23 15:35:31,777 [icarl.py] => Task 2, Epoch 136/150 => Loss 0.906, Train_accy 99.95, Test_accy 40.43
2024-10-23 15:35:48,596 [icarl.py] => Task 2, Epoch 141/150 => Loss 0.966, Train_accy 99.88, Test_accy 37.93
2024-10-23 15:36:04,039 [icarl.py] => Task 2, Epoch 146/150 => Loss 0.908, Train_accy 99.93, Test_accy 41.69
2024-10-23 15:36:14,942 [icarl.py] => Task 2, Epoch 150/150 => Loss 0.935, Train_accy 99.93
2024-10-23 15:36:14,943 [base.py] => Reducing exemplars...(11 per classes)
2024-10-23 15:36:20,221 [base.py] => Constructing exemplars...(11 per classes)
2024-10-23 15:36:25,105 [trainer.py] => All params: 3848521
2024-10-23 15:36:29,281 [icarl.py] => Exemplar size: 99
2024-10-23 15:36:29,282 [trainer.py] => CNN: {'total': 38.89, '00-04': 21.43, '05-06': 25.5, '07-08': 95.92, 'old': 22.6, 'new': 95.92}
2024-10-23 15:36:29,282 [trainer.py] => NME: {'total': 51.98, '00-04': 34.8, '05-06': 56.17, '07-08': 90.75, 'old': 40.9, 'new': 90.75}
2024-10-23 15:36:29,282 [trainer.py] => CNN top1 curve: [89.93, 44.76, 38.89]
2024-10-23 15:36:29,283 [trainer.py] => CNN top5 curve: [100.0, 96.79, 87.43]
2024-10-23 15:36:29,283 [trainer.py] => NME top1 curve: [90.0, 60.62, 51.98]
2024-10-23 15:36:29,283 [trainer.py] => NME top5 curve: [100.0, 96.79, 89.96]

2024-10-23 15:36:29,283 [trainer.py] => Average Accuracy (CNN): 57.85999999999999
2024-10-23 15:36:29,283 [trainer.py] => Average Accuracy (NME): 67.53333333333333
2024-10-23 15:36:29,284 [trainer.py] => Forgetting (CNN): 69.875
