2024-10-28 11:43:36,314 [trainer.py] => config: ./exps/icarl.json
2024-10-28 11:43:36,315 [trainer.py] => prefix: cil
2024-10-28 11:43:36,315 [trainer.py] => dataset: hrrp9
2024-10-28 11:43:36,315 [trainer.py] => memory_size: 500
2024-10-28 11:43:36,315 [trainer.py] => memory_per_class: 20
2024-10-28 11:43:36,316 [trainer.py] => fixed_memory: False
2024-10-28 11:43:36,316 [trainer.py] => shuffle: True
2024-10-28 11:43:36,316 [trainer.py] => init_cls: 5
2024-10-28 11:43:36,316 [trainer.py] => increment: 2
2024-10-28 11:43:36,317 [trainer.py] => model_name: icarl
2024-10-28 11:43:36,317 [trainer.py] => convnet_type: resnet18
2024-10-28 11:43:36,317 [trainer.py] => device: [device(type='cuda', index=2)]
2024-10-28 11:43:36,317 [trainer.py] => init_train: False
2024-10-28 11:43:36,318 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_42503.pth
2024-10-28 11:43:36,318 [trainer.py] => fc_path2: checkpoints/init_train/fc_42503.pth
2024-10-28 11:43:36,318 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-28 11:43:36,319 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-28 11:43:36,319 [trainer.py] => seed2: [1993]
2024-10-28 11:43:36,320 [trainer.py] => seed: 110
2024-10-28 11:43:36,320 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42871.pth
2024-10-28 11:43:36,320 [trainer.py] => fc_path: checkpoints/init_train/fc_42871.pth
2024-10-28 11:43:36,321 [trainer.py] => init_epoch: 0
2024-10-28 11:43:36,321 [trainer.py] => init_lr: 0.1
2024-10-28 11:43:36,322 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-28 11:43:36,322 [trainer.py] => init_lr_decay: 0.1
2024-10-28 11:43:36,322 [trainer.py] => init_weight_decay: 0.0005
2024-10-28 11:43:36,322 [trainer.py] => epochs: 150
2024-10-28 11:43:36,323 [trainer.py] => lrate: 0.1
2024-10-28 11:43:36,323 [trainer.py] => milestones: [80, 120]
2024-10-28 11:43:36,323 [trainer.py] => lrate_decay: 0.1
2024-10-28 11:43:36,323 [trainer.py] => momentum: 0.9
2024-10-28 11:43:36,324 [trainer.py] => batch_size: 128
2024-10-28 11:43:36,324 [trainer.py] => weight_decay: 0.0002
2024-10-28 11:43:36,324 [trainer.py] => num_workers: 8
2024-10-28 11:43:36,325 [trainer.py] => T: 2
2024-10-28 11:43:37,084 [data_manager.py] => [4, 2, 8, 7, 1, 6, 5, 3, 0]
2024-10-28 11:43:38,444 [trainer.py] => All params: 3843904
2024-10-28 11:43:38,445 [trainer.py] => Trainable params: 3843904
2024-10-28 11:43:38,448 [icarl.py] => Learning on 0-5
2024-10-28 11:43:38,813 [icarl.py] => init_train?---False
2024-10-28 11:43:39,796 [base.py] => Reducing exemplars...(100 per classes)
2024-10-28 11:43:39,797 [base.py] => Constructing exemplars...(100 per classes)
2024-10-28 11:43:47,206 [trainer.py] => All params: 3846469
2024-10-28 11:43:48,472 [icarl.py] => Exemplar size: 500
2024-10-28 11:43:48,472 [trainer.py] => CNN: {'total': 96.3, '00-04': 96.3, 'old': 0, 'new': 96.3}
2024-10-28 11:43:48,472 [trainer.py] => NME: {'total': 96.27, '00-04': 96.27, 'old': 0, 'new': 96.27}
2024-10-28 11:43:48,473 [trainer.py] => CNN top1 curve: [96.3]
2024-10-28 11:43:48,473 [trainer.py] => CNN top5 curve: [100.0]
2024-10-28 11:43:48,473 [trainer.py] => NME top1 curve: [96.27]
2024-10-28 11:43:48,473 [trainer.py] => NME top5 curve: [100.0]

2024-10-28 11:43:48,473 [trainer.py] => Average Accuracy (CNN): 96.3
2024-10-28 11:43:48,474 [trainer.py] => Average Accuracy (NME): 96.27
2024-10-28 11:43:48,474 [trainer.py] => All params: 3846469
2024-10-28 11:43:48,475 [trainer.py] => Trainable params: 3846469
2024-10-28 11:43:48,476 [icarl.py] => Learning on 5-7
2024-10-28 11:43:50,717 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.196, Train_accy 69.42, Test_accy 36.76
2024-10-28 11:43:58,159 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.095, Train_accy 96.73, Test_accy 66.14
2024-10-28 11:44:06,167 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.927, Train_accy 99.87, Test_accy 72.86
2024-10-28 11:44:13,936 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.896, Train_accy 100.00, Test_accy 74.76
2024-10-28 11:44:21,923 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.883, Train_accy 100.00, Test_accy 73.24
2024-10-28 11:44:29,893 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.899, Train_accy 99.96, Test_accy 77.40
2024-10-28 11:44:37,691 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.883, Train_accy 99.98, Test_accy 76.21
2024-10-28 11:44:45,816 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.894, Train_accy 99.96, Test_accy 77.64
2024-10-28 11:44:53,447 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.880, Train_accy 100.00, Test_accy 77.64
2024-10-28 11:45:01,569 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.871, Train_accy 100.00, Test_accy 77.62
2024-10-28 11:45:09,547 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.872, Train_accy 100.00, Test_accy 75.07
2024-10-28 11:45:18,693 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.875, Train_accy 100.00, Test_accy 76.86
2024-10-28 11:45:27,566 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.875, Train_accy 100.00, Test_accy 75.74
2024-10-28 11:45:35,693 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.877, Train_accy 100.00, Test_accy 75.48
2024-10-28 11:45:43,599 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.875, Train_accy 100.00, Test_accy 78.17
2024-10-28 11:45:51,785 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.874, Train_accy 100.00, Test_accy 75.79
2024-10-28 11:45:59,383 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.904, Train_accy 99.44, Test_accy 76.38
2024-10-28 11:46:07,329 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.870, Train_accy 100.00, Test_accy 76.93
2024-10-28 11:46:15,567 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.870, Train_accy 100.00, Test_accy 78.10
2024-10-28 11:46:23,864 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.867, Train_accy 100.00, Test_accy 77.33
2024-10-28 11:46:32,024 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.865, Train_accy 100.00, Test_accy 77.36
2024-10-28 11:46:39,765 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.868, Train_accy 100.00, Test_accy 76.24
2024-10-28 11:46:47,776 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.866, Train_accy 100.00, Test_accy 77.55
2024-10-28 11:46:56,297 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.865, Train_accy 100.00, Test_accy 76.36
2024-10-28 11:47:04,205 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.871, Train_accy 100.00, Test_accy 76.55
2024-10-28 11:47:12,285 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.869, Train_accy 100.00, Test_accy 76.26
2024-10-28 11:47:20,339 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.866, Train_accy 100.00, Test_accy 77.60
2024-10-28 11:47:28,269 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.868, Train_accy 100.00, Test_accy 76.83
2024-10-28 11:47:35,805 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.871, Train_accy 100.00, Test_accy 76.95
2024-10-28 11:47:43,455 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.869, Train_accy 100.00, Test_accy 76.79
2024-10-28 11:47:49,257 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.868, Train_accy 100.00
2024-10-28 11:47:49,259 [base.py] => Reducing exemplars...(71 per classes)
2024-10-28 11:47:51,137 [base.py] => Constructing exemplars...(71 per classes)
2024-10-28 11:47:54,285 [trainer.py] => All params: 3847495
2024-10-28 11:47:56,084 [icarl.py] => Exemplar size: 497
2024-10-28 11:47:56,085 [trainer.py] => CNN: {'total': 76.79, '00-04': 68.7, '05-06': 97.0, 'old': 68.7, 'new': 97.0}
2024-10-28 11:47:56,085 [trainer.py] => NME: {'total': 85.62, '00-04': 81.93, '05-06': 94.83, 'old': 81.93, 'new': 94.83}
2024-10-28 11:47:56,085 [trainer.py] => CNN top1 curve: [96.3, 76.79]
2024-10-28 11:47:56,085 [trainer.py] => CNN top5 curve: [100.0, 99.69]
2024-10-28 11:47:56,085 [trainer.py] => NME top1 curve: [96.27, 85.62]
2024-10-28 11:47:56,085 [trainer.py] => NME top5 curve: [100.0, 99.69]

2024-10-28 11:47:56,085 [trainer.py] => Average Accuracy (CNN): 86.545
2024-10-28 11:47:56,085 [trainer.py] => Average Accuracy (NME): 90.945
2024-10-28 11:47:56,086 [trainer.py] => All params: 3847495
2024-10-28 11:47:56,088 [trainer.py] => Trainable params: 3847495
2024-10-28 11:47:56,089 [icarl.py] => Learning on 7-9
2024-10-28 11:47:58,393 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.849, Train_accy 76.21, Test_accy 14.69
2024-10-28 11:48:06,597 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.565, Train_accy 92.06, Test_accy 34.02
2024-10-28 11:48:14,813 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.234, Train_accy 98.87, Test_accy 54.93
2024-10-28 11:48:22,936 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.143, Train_accy 100.00, Test_accy 60.28
2024-10-28 11:48:30,965 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.204, Train_accy 99.07, Test_accy 58.65
2024-10-28 11:48:38,795 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.120, Train_accy 100.00, Test_accy 60.09
2024-10-28 11:48:46,606 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.117, Train_accy 100.00, Test_accy 59.59
2024-10-28 11:48:54,677 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.114, Train_accy 100.00, Test_accy 61.44
2024-10-28 11:49:02,759 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.115, Train_accy 100.00, Test_accy 57.80
2024-10-28 11:49:10,682 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.106, Train_accy 100.00, Test_accy 62.06
2024-10-28 11:49:18,655 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.104, Train_accy 100.00, Test_accy 61.44
2024-10-28 11:49:26,681 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.104, Train_accy 100.00, Test_accy 57.52
2024-10-28 11:49:34,546 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.108, Train_accy 99.98, Test_accy 58.94
2024-10-28 11:49:42,554 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.101, Train_accy 100.00, Test_accy 60.57
2024-10-28 11:49:50,622 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.101, Train_accy 100.00, Test_accy 58.31
2024-10-28 11:49:58,869 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.120, Train_accy 99.89, Test_accy 59.19
2024-10-28 11:50:06,877 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.099, Train_accy 100.00, Test_accy 60.11
2024-10-28 11:50:14,919 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.092, Train_accy 100.00, Test_accy 60.74
2024-10-28 11:50:22,709 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.098, Train_accy 99.98, Test_accy 61.20
2024-10-28 11:50:30,952 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.100, Train_accy 100.00, Test_accy 60.61
2024-10-28 11:50:39,108 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.094, Train_accy 100.00, Test_accy 60.00
2024-10-28 11:50:46,996 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.093, Train_accy 100.00, Test_accy 60.33
2024-10-28 11:50:55,099 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.093, Train_accy 100.00, Test_accy 59.56
2024-10-28 11:51:02,970 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.097, Train_accy 100.00, Test_accy 61.06
2024-10-28 11:51:10,404 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.094, Train_accy 100.00, Test_accy 59.07
2024-10-28 11:51:18,544 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.093, Train_accy 100.00, Test_accy 60.31
2024-10-28 11:51:26,517 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.093, Train_accy 100.00, Test_accy 60.30
2024-10-28 11:51:34,557 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.094, Train_accy 100.00, Test_accy 61.61
2024-10-28 11:51:42,287 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.095, Train_accy 100.00, Test_accy 59.78
2024-10-28 11:51:50,374 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.094, Train_accy 100.00, Test_accy 59.41
2024-10-28 11:51:55,560 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.100, Train_accy 100.00
2024-10-28 11:51:55,561 [base.py] => Reducing exemplars...(55 per classes)
2024-10-28 11:51:57,802 [base.py] => Constructing exemplars...(55 per classes)
2024-10-28 11:52:00,750 [trainer.py] => All params: 3848521
2024-10-28 11:52:02,755 [icarl.py] => Exemplar size: 495
2024-10-28 11:52:02,755 [trainer.py] => CNN: {'total': 61.22, '00-04': 49.63, '05-06': 65.58, '07-08': 85.83, 'old': 54.19, 'new': 85.83}
2024-10-28 11:52:02,756 [trainer.py] => NME: {'total': 71.48, '00-04': 68.4, '05-06': 79.33, '07-08': 71.33, 'old': 71.52, 'new': 71.33}
2024-10-28 11:52:02,756 [trainer.py] => CNN top1 curve: [96.3, 76.79, 61.22]
2024-10-28 11:52:02,756 [trainer.py] => CNN top5 curve: [100.0, 99.69, 97.65]
2024-10-28 11:52:02,756 [trainer.py] => NME top1 curve: [96.27, 85.62, 71.48]
2024-10-28 11:52:02,756 [trainer.py] => NME top5 curve: [100.0, 99.69, 97.61]

2024-10-28 11:52:02,757 [trainer.py] => Average Accuracy (CNN): 78.10333333333334
2024-10-28 11:52:02,757 [trainer.py] => Average Accuracy (NME): 84.45666666666666
2024-10-28 11:52:02,758 [trainer.py] => Forgetting (CNN): 39.045
