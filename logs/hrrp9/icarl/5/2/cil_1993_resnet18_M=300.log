2024-10-23 15:23:40,730 [trainer.py] => config: ./exps/icarl.json
2024-10-23 15:23:40,730 [trainer.py] => prefix: cil
2024-10-23 15:23:40,730 [trainer.py] => dataset: hrrp9
2024-10-23 15:23:40,730 [trainer.py] => memory_size: 300
2024-10-23 15:23:40,730 [trainer.py] => memory_per_class: 20
2024-10-23 15:23:40,730 [trainer.py] => fixed_memory: False
2024-10-23 15:23:40,731 [trainer.py] => shuffle: True
2024-10-23 15:23:40,731 [trainer.py] => init_cls: 5
2024-10-23 15:23:40,731 [trainer.py] => increment: 2
2024-10-23 15:23:40,731 [trainer.py] => model_name: icarl
2024-10-23 15:23:40,731 [trainer.py] => convnet_type: resnet18
2024-10-23 15:23:40,731 [trainer.py] => device: [device(type='cuda', index=5)]
2024-10-23 15:23:40,731 [trainer.py] => init_train: False
2024-10-23 15:23:40,731 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 15:23:40,731 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 15:23:40,731 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 15:23:40,731 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 15:23:40,731 [trainer.py] => seed: 1993
2024-10-23 15:23:40,731 [trainer.py] => init_epoch: 0
2024-10-23 15:23:40,731 [trainer.py] => init_lr: 0.1
2024-10-23 15:23:40,731 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-23 15:23:40,731 [trainer.py] => init_lr_decay: 0.1
2024-10-23 15:23:40,731 [trainer.py] => init_weight_decay: 0.0005
2024-10-23 15:23:40,731 [trainer.py] => epochs: 150
2024-10-23 15:23:40,731 [trainer.py] => lrate: 0.1
2024-10-23 15:23:40,731 [trainer.py] => milestones: [80, 120]
2024-10-23 15:23:40,731 [trainer.py] => lrate_decay: 0.1
2024-10-23 15:23:40,731 [trainer.py] => momentum: 0.9
2024-10-23 15:23:40,731 [trainer.py] => batch_size: 128
2024-10-23 15:23:40,731 [trainer.py] => weight_decay: 0.0002
2024-10-23 15:23:40,732 [trainer.py] => num_workers: 8
2024-10-23 15:23:40,732 [trainer.py] => T: 2
2024-10-23 15:23:41,411 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 15:23:42,000 [trainer.py] => All params: 3843904
2024-10-23 15:23:42,001 [trainer.py] => Trainable params: 3843904
2024-10-23 15:23:42,004 [icarl.py] => Learning on 0-5
2024-10-23 15:23:42,347 [icarl.py] => init_train?---False
2024-10-23 15:23:43,392 [base.py] => Reducing exemplars...(60 per classes)
2024-10-23 15:23:43,392 [base.py] => Constructing exemplars...(60 per classes)
2024-10-23 15:23:49,414 [trainer.py] => All params: 3846469
2024-10-23 15:23:50,673 [icarl.py] => Exemplar size: 300
2024-10-23 15:23:50,682 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 15:23:50,682 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 15:23:50,683 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 15:23:50,683 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 15:23:50,683 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 15:23:50,683 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 15:23:50,684 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 15:23:50,684 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 15:23:50,685 [trainer.py] => All params: 3846469
2024-10-23 15:23:50,685 [trainer.py] => Trainable params: 3846469
2024-10-23 15:23:50,686 [icarl.py] => Learning on 5-7
2024-10-23 15:23:52,930 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.051, Train_accy 77.98, Test_accy 27.07
2024-10-23 15:24:00,001 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.024, Train_accy 99.40, Test_accy 58.24
2024-10-23 15:24:07,450 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.956, Train_accy 100.00, Test_accy 58.90
2024-10-23 15:24:15,711 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.949, Train_accy 100.00, Test_accy 60.43
2024-10-23 15:24:24,054 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.946, Train_accy 100.00, Test_accy 60.95
2024-10-23 15:24:32,780 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.944, Train_accy 100.00, Test_accy 61.26
2024-10-23 15:24:41,483 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.948, Train_accy 100.00, Test_accy 63.71
2024-10-23 15:24:50,624 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.946, Train_accy 100.00, Test_accy 61.81
2024-10-23 15:24:59,418 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.943, Train_accy 100.00, Test_accy 63.57
2024-10-23 15:25:08,433 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.944, Train_accy 100.00, Test_accy 62.43
2024-10-23 15:25:17,575 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.942, Train_accy 100.00, Test_accy 61.45
2024-10-23 15:25:26,331 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.943, Train_accy 100.00, Test_accy 61.64
2024-10-23 15:25:35,225 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.943, Train_accy 100.00, Test_accy 63.90
2024-10-23 15:25:44,585 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.943, Train_accy 100.00, Test_accy 63.90
2024-10-23 15:25:53,172 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.943, Train_accy 100.00, Test_accy 63.98
2024-10-23 15:26:01,390 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.941, Train_accy 100.00, Test_accy 61.55
2024-10-23 15:26:10,266 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.941, Train_accy 100.00, Test_accy 61.21
2024-10-23 15:26:19,375 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.937, Train_accy 100.00, Test_accy 63.05
2024-10-23 15:26:28,300 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.936, Train_accy 100.00, Test_accy 62.57
2024-10-23 15:26:37,781 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.935, Train_accy 100.00, Test_accy 62.10
2024-10-23 15:26:46,889 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.935, Train_accy 100.00, Test_accy 62.62
2024-10-23 15:26:55,919 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.935, Train_accy 100.00, Test_accy 62.02
2024-10-23 15:27:05,651 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.934, Train_accy 100.00, Test_accy 62.55
2024-10-23 15:27:15,395 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.935, Train_accy 100.00, Test_accy 63.00
2024-10-23 15:27:24,382 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.935, Train_accy 100.00, Test_accy 63.29
2024-10-23 15:27:33,499 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.934, Train_accy 100.00, Test_accy 62.71
2024-10-23 15:27:42,254 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.935, Train_accy 100.00, Test_accy 63.67
2024-10-23 15:27:51,923 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.935, Train_accy 100.00, Test_accy 62.93
2024-10-23 15:28:00,585 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.934, Train_accy 100.00, Test_accy 62.50
2024-10-23 15:28:10,099 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.934, Train_accy 100.00, Test_accy 63.24
2024-10-23 15:28:16,199 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.934, Train_accy 100.00
2024-10-23 15:28:16,200 [base.py] => Reducing exemplars...(42 per classes)
2024-10-23 15:28:18,195 [base.py] => Constructing exemplars...(42 per classes)
2024-10-23 15:28:21,051 [trainer.py] => All params: 3847495
2024-10-23 15:28:23,217 [icarl.py] => Exemplar size: 294
2024-10-23 15:28:23,217 [trainer.py] => CNN: {'total': 62.86, '00-04': 49.3, '05-06': 96.75, 'old': 49.3, 'new': 96.75}
2024-10-23 15:28:23,217 [trainer.py] => NME: {'total': 74.67, '00-04': 67.37, '05-06': 92.92, 'old': 67.37, 'new': 92.92}
2024-10-23 15:28:23,217 [trainer.py] => CNN top1 curve: [89.93, 62.86]
2024-10-23 15:28:23,217 [trainer.py] => CNN top5 curve: [100.0, 98.83]
2024-10-23 15:28:23,217 [trainer.py] => NME top1 curve: [90.0, 74.67]
2024-10-23 15:28:23,217 [trainer.py] => NME top5 curve: [100.0, 99.07]

2024-10-23 15:28:23,217 [trainer.py] => Average Accuracy (CNN): 76.39500000000001
2024-10-23 15:28:23,217 [trainer.py] => Average Accuracy (NME): 82.33500000000001
2024-10-23 15:28:23,218 [trainer.py] => All params: 3847495
2024-10-23 15:28:23,218 [trainer.py] => Trainable params: 3847495
2024-10-23 15:28:23,242 [icarl.py] => Learning on 7-9
2024-10-23 15:28:26,381 [icarl.py] => Task 2, Epoch 1/150 => Loss 3.018, Train_accy 72.66, Test_accy 13.65
2024-10-23 15:28:36,245 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.637, Train_accy 92.22, Test_accy 21.74
2024-10-23 15:28:45,422 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.413, Train_accy 95.32, Test_accy 38.93
2024-10-23 15:28:54,573 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.237, Train_accy 98.30, Test_accy 44.57
2024-10-23 15:29:04,960 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.124, Train_accy 99.93, Test_accy 54.98
2024-10-23 15:29:15,774 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.094, Train_accy 100.00, Test_accy 54.85
2024-10-23 15:29:27,307 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.088, Train_accy 100.00, Test_accy 55.91
2024-10-23 15:29:39,249 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.076, Train_accy 100.00, Test_accy 54.13
2024-10-23 15:29:51,479 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.078, Train_accy 100.00, Test_accy 50.67
2024-10-23 15:30:04,078 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.073, Train_accy 100.00, Test_accy 51.63
2024-10-23 15:30:17,222 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.072, Train_accy 100.00, Test_accy 53.83
2024-10-23 15:30:30,506 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.071, Train_accy 100.00, Test_accy 54.30
2024-10-23 15:30:43,549 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.069, Train_accy 100.00, Test_accy 51.89
2024-10-23 15:30:57,856 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.068, Train_accy 100.00, Test_accy 53.02
2024-10-23 15:31:12,148 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.068, Train_accy 100.00, Test_accy 52.81
2024-10-23 15:31:26,303 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.068, Train_accy 100.00, Test_accy 51.89
2024-10-23 15:31:40,979 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.063, Train_accy 100.00, Test_accy 51.44
2024-10-23 15:31:55,059 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.059, Train_accy 100.00, Test_accy 51.76
2024-10-23 15:32:09,633 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.060, Train_accy 100.00, Test_accy 52.30
2024-10-23 15:32:23,578 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.061, Train_accy 100.00, Test_accy 52.69
2024-10-23 15:32:39,764 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.060, Train_accy 100.00, Test_accy 51.85
2024-10-23 15:32:55,121 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.059, Train_accy 100.00, Test_accy 51.59
2024-10-23 15:33:10,823 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.060, Train_accy 100.00, Test_accy 51.63
2024-10-23 15:33:28,853 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.059, Train_accy 100.00, Test_accy 52.61
2024-10-23 15:33:46,781 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.059, Train_accy 100.00, Test_accy 52.17
2024-10-23 15:34:05,278 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.061, Train_accy 100.00, Test_accy 51.09
2024-10-23 15:34:23,466 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.059, Train_accy 100.00, Test_accy 51.43
2024-10-23 15:34:43,079 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.059, Train_accy 100.00, Test_accy 52.09
2024-10-23 15:35:00,061 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.059, Train_accy 100.00, Test_accy 52.22
2024-10-23 15:35:18,332 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.059, Train_accy 100.00, Test_accy 51.59
2024-10-23 15:35:29,442 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.061, Train_accy 100.00
2024-10-23 15:35:29,443 [base.py] => Reducing exemplars...(33 per classes)
2024-10-23 15:35:35,490 [base.py] => Constructing exemplars...(33 per classes)
2024-10-23 15:35:41,758 [trainer.py] => All params: 3848521
2024-10-23 15:35:46,504 [icarl.py] => Exemplar size: 297
2024-10-23 15:35:46,542 [trainer.py] => CNN: {'total': 51.06, '00-04': 32.23, '05-06': 53.17, '07-08': 96.0, 'old': 38.21, 'new': 96.0}
2024-10-23 15:35:46,546 [trainer.py] => NME: {'total': 64.87, '00-04': 53.3, '05-06': 68.17, '07-08': 90.5, 'old': 57.55, 'new': 90.5}
2024-10-23 15:35:46,546 [trainer.py] => CNN top1 curve: [89.93, 62.86, 51.06]
2024-10-23 15:35:46,546 [trainer.py] => CNN top5 curve: [100.0, 98.83, 93.57]
2024-10-23 15:35:46,546 [trainer.py] => NME top1 curve: [90.0, 74.67, 64.87]
2024-10-23 15:35:46,547 [trainer.py] => NME top5 curve: [100.0, 99.07, 96.24]

2024-10-23 15:35:46,547 [trainer.py] => Average Accuracy (CNN): 67.95
2024-10-23 15:35:46,547 [trainer.py] => Average Accuracy (NME): 76.51333333333334
2024-10-23 15:35:46,557 [trainer.py] => Forgetting (CNN): 50.64
