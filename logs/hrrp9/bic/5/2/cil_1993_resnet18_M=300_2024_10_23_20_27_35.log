2024-10-23 20:27:35,025 [trainer.py] => config: ./exps/bic.json
2024-10-23 20:27:35,025 [trainer.py] => prefix: cil
2024-10-23 20:27:35,026 [trainer.py] => dataset: hrrp9
2024-10-23 20:27:35,026 [trainer.py] => memory_size: 300
2024-10-23 20:27:35,026 [trainer.py] => memory_per_class: 20
2024-10-23 20:27:35,026 [trainer.py] => fixed_memory: False
2024-10-23 20:27:35,026 [trainer.py] => shuffle: True
2024-10-23 20:27:35,026 [trainer.py] => init_cls: 5
2024-10-23 20:27:35,026 [trainer.py] => increment: 2
2024-10-23 20:27:35,026 [trainer.py] => model_name: bic
2024-10-23 20:27:35,026 [trainer.py] => convnet_type: resnet18
2024-10-23 20:27:35,026 [trainer.py] => device: [device(type='cuda', index=3)]
2024-10-23 20:27:35,026 [trainer.py] => init_train: False
2024-10-23 20:27:35,026 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 20:27:35,026 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 20:27:35,026 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 20:27:35,026 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 20:27:35,026 [trainer.py] => seed: 1993
2024-10-23 20:27:35,026 [trainer.py] => init_epochs: 0
2024-10-23 20:27:35,026 [trainer.py] => epochs: 150
2024-10-23 20:27:35,026 [trainer.py] => lrate: 0.1
2024-10-23 20:27:35,026 [trainer.py] => milestones: [50, 80, 120]
2024-10-23 20:27:35,026 [trainer.py] => lrate_decay: 0.1
2024-10-23 20:27:35,026 [trainer.py] => momentum: 0.9
2024-10-23 20:27:35,026 [trainer.py] => batch_size: 128
2024-10-23 20:27:35,027 [trainer.py] => split_ratio: 0.1
2024-10-23 20:27:35,027 [trainer.py] => weight_decay: 0.0002
2024-10-23 20:27:35,027 [trainer.py] => num_workers: 0
2024-10-23 20:27:35,027 [trainer.py] => T: 2
2024-10-23 20:27:35,027 [trainer.py] => bc_lrate: 0.001
2024-10-23 20:27:35,027 [trainer.py] => bc_epochs: [100, 100, 5]
2024-10-23 20:27:35,776 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 20:27:36,321 [trainer.py] => All params: 3843904
2024-10-23 20:27:36,322 [trainer.py] => Trainable params: 3843904
2024-10-23 20:27:36,325 [bic.py] => Learning on 0-5
2024-10-23 20:27:36,365 [bic.py] => Parameters of bias layer:
2024-10-23 20:27:36,365 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:27:36,604 [base.py] => Reducing exemplars...(60 per classes)
2024-10-23 20:27:36,604 [base.py] => Constructing exemplars...(60 per classes)
2024-10-23 20:27:41,658 [bic.py] => Parameters of bias layer:
2024-10-23 20:27:41,660 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:27:41,660 [trainer.py] => All params: 3846471
2024-10-23 20:27:42,084 [bic.py] => Exemplar size: 300
2024-10-23 20:27:42,084 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 20:27:42,085 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 20:27:42,085 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 20:27:42,085 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 20:27:42,085 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 20:27:42,085 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 20:27:42,085 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 20:27:42,085 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 20:27:42,085 [trainer.py] => All params: 3846471
2024-10-23 20:27:42,086 [trainer.py] => Trainable params: 3846471
2024-10-23 20:27:42,087 [bic.py] => Learning on 5-7
2024-10-23 20:27:42,107 [bic.py] => Stage1 dset: 4258, Stage2 dset: 42
2024-10-23 20:27:42,108 [bic.py] => Lambda: 0.714
2024-10-23 20:27:42,122 [bic.py] => Parameters of bias layer:
2024-10-23 20:27:42,122 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:27:42,122 [bic.py] => 1 => 1.000, 0.000
2024-10-23 20:27:43,460 [bic.py] => training => Task 1, Epoch 1/150 => Loss 1.049, Train_accy 88.000, Test_accy 26.620
2024-10-23 20:27:44,594 [bic.py] => training => Task 1, Epoch 2/150 => Loss 0.788, Train_accy 94.880, Test_accy 45.260
2024-10-23 20:27:45,785 [bic.py] => training => Task 1, Epoch 3/150 => Loss 0.731, Train_accy 98.710, Test_accy 54.330
2024-10-23 20:27:46,931 [bic.py] => training => Task 1, Epoch 4/150 => Loss 0.709, Train_accy 99.180, Test_accy 56.900
2024-10-23 20:27:48,092 [bic.py] => training => Task 1, Epoch 5/150 => Loss 0.704, Train_accy 99.770, Test_accy 56.790
2024-10-23 20:27:49,104 [bic.py] => training => Task 1, Epoch 6/150 => Loss 0.697, Train_accy 99.840, Test_accy 58.020
2024-10-23 20:27:50,184 [bic.py] => training => Task 1, Epoch 7/150 => Loss 0.691, Train_accy 99.950, Test_accy 55.690
2024-10-23 20:27:51,272 [bic.py] => training => Task 1, Epoch 8/150 => Loss 0.689, Train_accy 100.000, Test_accy 57.790
2024-10-23 20:27:52,368 [bic.py] => training => Task 1, Epoch 9/150 => Loss 0.688, Train_accy 100.000, Test_accy 56.900
2024-10-23 20:27:53,469 [bic.py] => training => Task 1, Epoch 10/150 => Loss 0.685, Train_accy 100.000, Test_accy 57.550
2024-10-23 20:27:54,468 [bic.py] => training => Task 1, Epoch 11/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.980
2024-10-23 20:27:55,507 [bic.py] => training => Task 1, Epoch 12/150 => Loss 0.685, Train_accy 100.000, Test_accy 56.670
2024-10-23 20:27:56,522 [bic.py] => training => Task 1, Epoch 13/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.430
2024-10-23 20:27:57,502 [bic.py] => training => Task 1, Epoch 14/150 => Loss 0.680, Train_accy 100.000, Test_accy 58.450
2024-10-23 20:27:58,519 [bic.py] => training => Task 1, Epoch 15/150 => Loss 0.679, Train_accy 100.000, Test_accy 55.380
2024-10-23 20:27:59,616 [bic.py] => training => Task 1, Epoch 16/150 => Loss 0.682, Train_accy 100.000, Test_accy 58.760
2024-10-23 20:28:00,795 [bic.py] => training => Task 1, Epoch 17/150 => Loss 0.680, Train_accy 100.000, Test_accy 58.950
2024-10-23 20:28:01,886 [bic.py] => training => Task 1, Epoch 18/150 => Loss 0.679, Train_accy 100.000, Test_accy 58.620
2024-10-23 20:28:03,012 [bic.py] => training => Task 1, Epoch 19/150 => Loss 0.680, Train_accy 100.000, Test_accy 60.400
2024-10-23 20:28:04,095 [bic.py] => training => Task 1, Epoch 20/150 => Loss 0.681, Train_accy 100.000, Test_accy 59.120
2024-10-23 20:28:05,258 [bic.py] => training => Task 1, Epoch 21/150 => Loss 0.676, Train_accy 100.000, Test_accy 59.450
2024-10-23 20:28:06,384 [bic.py] => training => Task 1, Epoch 22/150 => Loss 0.679, Train_accy 100.000, Test_accy 59.570
2024-10-23 20:28:07,565 [bic.py] => training => Task 1, Epoch 23/150 => Loss 0.679, Train_accy 100.000, Test_accy 60.140
2024-10-23 20:28:08,577 [bic.py] => training => Task 1, Epoch 24/150 => Loss 0.679, Train_accy 100.000, Test_accy 58.810
2024-10-23 20:28:09,533 [bic.py] => training => Task 1, Epoch 25/150 => Loss 0.680, Train_accy 100.000, Test_accy 61.290
2024-10-23 20:28:10,487 [bic.py] => training => Task 1, Epoch 26/150 => Loss 0.678, Train_accy 100.000, Test_accy 59.070
2024-10-23 20:28:11,528 [bic.py] => training => Task 1, Epoch 27/150 => Loss 0.678, Train_accy 100.000, Test_accy 60.950
2024-10-23 20:28:12,520 [bic.py] => training => Task 1, Epoch 28/150 => Loss 0.679, Train_accy 100.000, Test_accy 60.260
2024-10-23 20:28:13,527 [bic.py] => training => Task 1, Epoch 29/150 => Loss 0.681, Train_accy 100.000, Test_accy 59.100
2024-10-23 20:28:14,512 [bic.py] => training => Task 1, Epoch 30/150 => Loss 0.677, Train_accy 100.000, Test_accy 60.120
2024-10-23 20:28:15,506 [bic.py] => training => Task 1, Epoch 31/150 => Loss 0.677, Train_accy 100.000, Test_accy 59.670
2024-10-23 20:28:16,847 [bic.py] => training => Task 1, Epoch 32/150 => Loss 0.679, Train_accy 100.000, Test_accy 58.600
2024-10-23 20:28:18,019 [bic.py] => training => Task 1, Epoch 33/150 => Loss 0.677, Train_accy 100.000, Test_accy 58.330
2024-10-23 20:28:19,157 [bic.py] => training => Task 1, Epoch 34/150 => Loss 0.680, Train_accy 100.000, Test_accy 58.620
2024-10-23 20:28:20,266 [bic.py] => training => Task 1, Epoch 35/150 => Loss 0.680, Train_accy 100.000, Test_accy 61.360
2024-10-23 20:28:21,365 [bic.py] => training => Task 1, Epoch 36/150 => Loss 0.678, Train_accy 100.000, Test_accy 60.100
2024-10-23 20:28:22,442 [bic.py] => training => Task 1, Epoch 37/150 => Loss 0.679, Train_accy 100.000, Test_accy 61.070
2024-10-23 20:28:23,711 [bic.py] => training => Task 1, Epoch 38/150 => Loss 0.677, Train_accy 100.000, Test_accy 60.450
2024-10-23 20:28:24,776 [bic.py] => training => Task 1, Epoch 39/150 => Loss 0.676, Train_accy 100.000, Test_accy 58.860
2024-10-23 20:28:25,979 [bic.py] => training => Task 1, Epoch 40/150 => Loss 0.677, Train_accy 100.000, Test_accy 60.600
2024-10-23 20:28:27,215 [bic.py] => training => Task 1, Epoch 41/150 => Loss 0.678, Train_accy 100.000, Test_accy 60.170
2024-10-23 20:28:28,421 [bic.py] => training => Task 1, Epoch 42/150 => Loss 0.677, Train_accy 100.000, Test_accy 60.790
2024-10-23 20:28:29,562 [bic.py] => training => Task 1, Epoch 43/150 => Loss 0.678, Train_accy 100.000, Test_accy 62.170
2024-10-23 20:28:30,825 [bic.py] => training => Task 1, Epoch 44/150 => Loss 0.677, Train_accy 100.000, Test_accy 61.120
2024-10-23 20:28:31,901 [bic.py] => training => Task 1, Epoch 45/150 => Loss 0.676, Train_accy 100.000, Test_accy 57.050
2024-10-23 20:28:33,189 [bic.py] => training => Task 1, Epoch 46/150 => Loss 0.677, Train_accy 100.000, Test_accy 61.520
2024-10-23 20:28:34,374 [bic.py] => training => Task 1, Epoch 47/150 => Loss 0.678, Train_accy 100.000, Test_accy 61.740
2024-10-23 20:28:35,533 [bic.py] => training => Task 1, Epoch 48/150 => Loss 0.676, Train_accy 100.000, Test_accy 61.450
2024-10-23 20:28:36,712 [bic.py] => training => Task 1, Epoch 49/150 => Loss 0.675, Train_accy 100.000, Test_accy 57.430
2024-10-23 20:28:38,038 [bic.py] => training => Task 1, Epoch 50/150 => Loss 0.677, Train_accy 100.000, Test_accy 63.000
2024-10-23 20:28:39,196 [bic.py] => training => Task 1, Epoch 51/150 => Loss 0.676, Train_accy 100.000, Test_accy 60.830
2024-10-23 20:28:40,339 [bic.py] => training => Task 1, Epoch 52/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.210
2024-10-23 20:28:41,523 [bic.py] => training => Task 1, Epoch 53/150 => Loss 0.675, Train_accy 100.000, Test_accy 60.620
2024-10-23 20:28:42,660 [bic.py] => training => Task 1, Epoch 54/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.760
2024-10-23 20:28:43,826 [bic.py] => training => Task 1, Epoch 55/150 => Loss 0.675, Train_accy 100.000, Test_accy 61.900
2024-10-23 20:28:45,032 [bic.py] => training => Task 1, Epoch 56/150 => Loss 0.675, Train_accy 100.000, Test_accy 61.520
2024-10-23 20:28:46,227 [bic.py] => training => Task 1, Epoch 57/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.810
2024-10-23 20:28:47,416 [bic.py] => training => Task 1, Epoch 58/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.790
2024-10-23 20:28:48,505 [bic.py] => training => Task 1, Epoch 59/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.690
2024-10-23 20:28:49,608 [bic.py] => training => Task 1, Epoch 60/150 => Loss 0.675, Train_accy 100.000, Test_accy 61.810
2024-10-23 20:28:50,760 [bic.py] => training => Task 1, Epoch 61/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.830
2024-10-23 20:28:51,871 [bic.py] => training => Task 1, Epoch 62/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.170
2024-10-23 20:28:53,088 [bic.py] => training => Task 1, Epoch 63/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.980
2024-10-23 20:28:54,297 [bic.py] => training => Task 1, Epoch 64/150 => Loss 0.675, Train_accy 100.000, Test_accy 62.170
2024-10-23 20:28:55,583 [bic.py] => training => Task 1, Epoch 65/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.050
2024-10-23 20:28:56,754 [bic.py] => training => Task 1, Epoch 66/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.360
2024-10-23 20:28:57,950 [bic.py] => training => Task 1, Epoch 67/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.640
2024-10-23 20:28:59,157 [bic.py] => training => Task 1, Epoch 68/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.120
2024-10-23 20:29:00,326 [bic.py] => training => Task 1, Epoch 69/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.100
2024-10-23 20:29:01,598 [bic.py] => training => Task 1, Epoch 70/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:29:02,808 [bic.py] => training => Task 1, Epoch 71/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.710
2024-10-23 20:29:04,045 [bic.py] => training => Task 1, Epoch 72/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.260
2024-10-23 20:29:05,365 [bic.py] => training => Task 1, Epoch 73/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.000
2024-10-23 20:29:06,637 [bic.py] => training => Task 1, Epoch 74/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.520
2024-10-23 20:29:07,985 [bic.py] => training => Task 1, Epoch 75/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.670
2024-10-23 20:29:09,248 [bic.py] => training => Task 1, Epoch 76/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.050
2024-10-23 20:29:10,519 [bic.py] => training => Task 1, Epoch 77/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:29:11,893 [bic.py] => training => Task 1, Epoch 78/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.260
2024-10-23 20:29:13,115 [bic.py] => training => Task 1, Epoch 79/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.290
2024-10-23 20:29:14,352 [bic.py] => training => Task 1, Epoch 80/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.240
2024-10-23 20:29:15,542 [bic.py] => training => Task 1, Epoch 81/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:29:16,803 [bic.py] => training => Task 1, Epoch 82/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:29:18,039 [bic.py] => training => Task 1, Epoch 83/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.790
2024-10-23 20:29:19,392 [bic.py] => training => Task 1, Epoch 84/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.710
2024-10-23 20:29:20,579 [bic.py] => training => Task 1, Epoch 85/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:29:21,819 [bic.py] => training => Task 1, Epoch 86/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.640
2024-10-23 20:29:23,107 [bic.py] => training => Task 1, Epoch 87/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.810
2024-10-23 20:29:24,472 [bic.py] => training => Task 1, Epoch 88/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.400
2024-10-23 20:29:25,869 [bic.py] => training => Task 1, Epoch 89/150 => Loss 0.675, Train_accy 100.000, Test_accy 62.620
2024-10-23 20:29:27,171 [bic.py] => training => Task 1, Epoch 90/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.240
2024-10-23 20:29:28,443 [bic.py] => training => Task 1, Epoch 91/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.980
2024-10-23 20:29:29,747 [bic.py] => training => Task 1, Epoch 92/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.290
2024-10-23 20:29:30,972 [bic.py] => training => Task 1, Epoch 93/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.170
2024-10-23 20:29:32,182 [bic.py] => training => Task 1, Epoch 94/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.240
2024-10-23 20:29:33,346 [bic.py] => training => Task 1, Epoch 95/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.600
2024-10-23 20:29:34,621 [bic.py] => training => Task 1, Epoch 96/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.140
2024-10-23 20:29:35,874 [bic.py] => training => Task 1, Epoch 97/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.550
2024-10-23 20:29:37,307 [bic.py] => training => Task 1, Epoch 98/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.380
2024-10-23 20:29:38,665 [bic.py] => training => Task 1, Epoch 99/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.380
2024-10-23 20:29:40,042 [bic.py] => training => Task 1, Epoch 100/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.880
2024-10-23 20:29:41,288 [bic.py] => training => Task 1, Epoch 101/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.830
2024-10-23 20:29:42,574 [bic.py] => training => Task 1, Epoch 102/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.140
2024-10-23 20:29:43,984 [bic.py] => training => Task 1, Epoch 103/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.400
2024-10-23 20:29:45,307 [bic.py] => training => Task 1, Epoch 104/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.210
2024-10-23 20:29:46,564 [bic.py] => training => Task 1, Epoch 105/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.360
2024-10-23 20:29:47,795 [bic.py] => training => Task 1, Epoch 106/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.740
2024-10-23 20:29:49,223 [bic.py] => training => Task 1, Epoch 107/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:29:50,501 [bic.py] => training => Task 1, Epoch 108/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.710
2024-10-23 20:29:51,822 [bic.py] => training => Task 1, Epoch 109/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.050
2024-10-23 20:29:53,199 [bic.py] => training => Task 1, Epoch 110/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:29:54,531 [bic.py] => training => Task 1, Epoch 111/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:29:55,846 [bic.py] => training => Task 1, Epoch 112/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.550
2024-10-23 20:29:57,186 [bic.py] => training => Task 1, Epoch 113/150 => Loss 0.675, Train_accy 100.000, Test_accy 61.950
2024-10-23 20:29:58,437 [bic.py] => training => Task 1, Epoch 114/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.810
2024-10-23 20:29:59,808 [bic.py] => training => Task 1, Epoch 115/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.480
2024-10-23 20:30:01,076 [bic.py] => training => Task 1, Epoch 116/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.880
2024-10-23 20:30:02,574 [bic.py] => training => Task 1, Epoch 117/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.740
2024-10-23 20:30:03,999 [bic.py] => training => Task 1, Epoch 118/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.810
2024-10-23 20:30:05,376 [bic.py] => training => Task 1, Epoch 119/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.760
2024-10-23 20:30:06,846 [bic.py] => training => Task 1, Epoch 120/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.360
2024-10-23 20:30:08,263 [bic.py] => training => Task 1, Epoch 121/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.430
2024-10-23 20:30:09,785 [bic.py] => training => Task 1, Epoch 122/150 => Loss 0.675, Train_accy 100.000, Test_accy 62.310
2024-10-23 20:30:11,175 [bic.py] => training => Task 1, Epoch 123/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.790
2024-10-23 20:30:12,474 [bic.py] => training => Task 1, Epoch 124/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.520
2024-10-23 20:30:13,779 [bic.py] => training => Task 1, Epoch 125/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.880
2024-10-23 20:30:14,944 [bic.py] => training => Task 1, Epoch 126/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:30:16,013 [bic.py] => training => Task 1, Epoch 127/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.000
2024-10-23 20:30:17,145 [bic.py] => training => Task 1, Epoch 128/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.550
2024-10-23 20:30:18,279 [bic.py] => training => Task 1, Epoch 129/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.880
2024-10-23 20:30:19,486 [bic.py] => training => Task 1, Epoch 130/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.620
2024-10-23 20:30:20,744 [bic.py] => training => Task 1, Epoch 131/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.930
2024-10-23 20:30:21,819 [bic.py] => training => Task 1, Epoch 132/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.520
2024-10-23 20:30:22,936 [bic.py] => training => Task 1, Epoch 133/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.550
2024-10-23 20:30:24,037 [bic.py] => training => Task 1, Epoch 134/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:30:25,145 [bic.py] => training => Task 1, Epoch 135/150 => Loss 0.672, Train_accy 100.000, Test_accy 61.880
2024-10-23 20:30:26,256 [bic.py] => training => Task 1, Epoch 136/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.690
2024-10-23 20:30:27,357 [bic.py] => training => Task 1, Epoch 137/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.740
2024-10-23 20:30:28,498 [bic.py] => training => Task 1, Epoch 138/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.760
2024-10-23 20:30:29,706 [bic.py] => training => Task 1, Epoch 139/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:30:30,976 [bic.py] => training => Task 1, Epoch 140/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.790
2024-10-23 20:30:32,126 [bic.py] => training => Task 1, Epoch 141/150 => Loss 0.673, Train_accy 100.000, Test_accy 61.500
2024-10-23 20:30:33,206 [bic.py] => training => Task 1, Epoch 142/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.240
2024-10-23 20:30:34,289 [bic.py] => training => Task 1, Epoch 143/150 => Loss 0.671, Train_accy 100.000, Test_accy 62.550
2024-10-23 20:30:35,518 [bic.py] => training => Task 1, Epoch 144/150 => Loss 0.674, Train_accy 100.000, Test_accy 61.380
2024-10-23 20:30:36,698 [bic.py] => training => Task 1, Epoch 145/150 => Loss 0.674, Train_accy 100.000, Test_accy 62.450
2024-10-23 20:30:37,873 [bic.py] => training => Task 1, Epoch 146/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.670
2024-10-23 20:30:39,018 [bic.py] => training => Task 1, Epoch 147/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.830
2024-10-23 20:30:40,192 [bic.py] => training => Task 1, Epoch 148/150 => Loss 0.672, Train_accy 100.000, Test_accy 62.310
2024-10-23 20:30:41,311 [bic.py] => training => Task 1, Epoch 149/150 => Loss 0.673, Train_accy 100.000, Test_accy 62.500
2024-10-23 20:30:42,595 [bic.py] => training => Task 1, Epoch 150/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.690
2024-10-23 20:30:42,826 [bic.py] => bias_correction => Task 1, Epoch 1/100 => Loss 1.512, Train_accy 85.710, Test_accy 63.930
2024-10-23 20:30:43,028 [bic.py] => bias_correction => Task 1, Epoch 2/100 => Loss 1.485, Train_accy 90.480, Test_accy 66.690
2024-10-23 20:30:43,222 [bic.py] => bias_correction => Task 1, Epoch 3/100 => Loss 1.435, Train_accy 90.480, Test_accy 71.310
2024-10-23 20:30:43,414 [bic.py] => bias_correction => Task 1, Epoch 4/100 => Loss 1.366, Train_accy 95.240, Test_accy 77.480
2024-10-23 20:30:43,612 [bic.py] => bias_correction => Task 1, Epoch 5/100 => Loss 1.299, Train_accy 95.240, Test_accy 77.570
2024-10-23 20:30:43,834 [bic.py] => bias_correction => Task 1, Epoch 6/100 => Loss 1.284, Train_accy 85.710, Test_accy 72.790
2024-10-23 20:30:44,060 [bic.py] => bias_correction => Task 1, Epoch 7/100 => Loss 1.338, Train_accy 78.570, Test_accy 68.810
2024-10-23 20:30:44,264 [bic.py] => bias_correction => Task 1, Epoch 8/100 => Loss 1.379, Train_accy 78.570, Test_accy 67.760
2024-10-23 20:30:44,451 [bic.py] => bias_correction => Task 1, Epoch 9/100 => Loss 1.389, Train_accy 78.570, Test_accy 69.190
2024-10-23 20:30:44,645 [bic.py] => bias_correction => Task 1, Epoch 10/100 => Loss 1.376, Train_accy 85.710, Test_accy 72.500
2024-10-23 20:30:44,854 [bic.py] => bias_correction => Task 1, Epoch 11/100 => Loss 1.337, Train_accy 95.240, Test_accy 76.640
2024-10-23 20:30:45,045 [bic.py] => bias_correction => Task 1, Epoch 12/100 => Loss 1.288, Train_accy 97.620, Test_accy 78.430
2024-10-23 20:30:45,249 [bic.py] => bias_correction => Task 1, Epoch 13/100 => Loss 1.277, Train_accy 95.240, Test_accy 75.310
2024-10-23 20:30:45,468 [bic.py] => bias_correction => Task 1, Epoch 14/100 => Loss 1.302, Train_accy 92.860, Test_accy 72.670
2024-10-23 20:30:45,681 [bic.py] => bias_correction => Task 1, Epoch 15/100 => Loss 1.325, Train_accy 92.860, Test_accy 71.790
2024-10-23 20:30:45,889 [bic.py] => bias_correction => Task 1, Epoch 16/100 => Loss 1.332, Train_accy 92.860, Test_accy 72.450
2024-10-23 20:30:46,092 [bic.py] => bias_correction => Task 1, Epoch 17/100 => Loss 1.323, Train_accy 95.240, Test_accy 74.670
2024-10-23 20:30:46,280 [bic.py] => bias_correction => Task 1, Epoch 18/100 => Loss 1.302, Train_accy 92.860, Test_accy 77.670
2024-10-23 20:30:46,508 [bic.py] => bias_correction => Task 1, Epoch 19/100 => Loss 1.279, Train_accy 97.620, Test_accy 78.170
2024-10-23 20:30:46,730 [bic.py] => bias_correction => Task 1, Epoch 20/100 => Loss 1.271, Train_accy 95.240, Test_accy 76.620
2024-10-23 20:30:46,928 [bic.py] => bias_correction => Task 1, Epoch 21/100 => Loss 1.286, Train_accy 95.240, Test_accy 75.210
2024-10-23 20:30:47,134 [bic.py] => bias_correction => Task 1, Epoch 22/100 => Loss 1.300, Train_accy 95.240, Test_accy 75.450
2024-10-23 20:30:47,329 [bic.py] => bias_correction => Task 1, Epoch 23/100 => Loss 1.298, Train_accy 95.240, Test_accy 76.860
2024-10-23 20:30:47,519 [bic.py] => bias_correction => Task 1, Epoch 24/100 => Loss 1.282, Train_accy 97.620, Test_accy 78.290
2024-10-23 20:30:47,717 [bic.py] => bias_correction => Task 1, Epoch 25/100 => Loss 1.269, Train_accy 95.240, Test_accy 78.400
2024-10-23 20:30:47,923 [bic.py] => bias_correction => Task 1, Epoch 26/100 => Loss 1.271, Train_accy 92.860, Test_accy 77.330
2024-10-23 20:30:48,120 [bic.py] => bias_correction => Task 1, Epoch 27/100 => Loss 1.279, Train_accy 95.240, Test_accy 76.430
2024-10-23 20:30:48,315 [bic.py] => bias_correction => Task 1, Epoch 28/100 => Loss 1.284, Train_accy 95.240, Test_accy 76.810
2024-10-23 20:30:48,507 [bic.py] => bias_correction => Task 1, Epoch 29/100 => Loss 1.282, Train_accy 92.860, Test_accy 77.810
2024-10-23 20:30:48,707 [bic.py] => bias_correction => Task 1, Epoch 30/100 => Loss 1.275, Train_accy 95.240, Test_accy 78.570
2024-10-23 20:30:48,910 [bic.py] => bias_correction => Task 1, Epoch 31/100 => Loss 1.268, Train_accy 97.620, Test_accy 78.430
2024-10-23 20:30:49,100 [bic.py] => bias_correction => Task 1, Epoch 32/100 => Loss 1.266, Train_accy 97.620, Test_accy 78.070
2024-10-23 20:30:49,296 [bic.py] => bias_correction => Task 1, Epoch 33/100 => Loss 1.271, Train_accy 95.240, Test_accy 77.500
2024-10-23 20:30:49,509 [bic.py] => bias_correction => Task 1, Epoch 34/100 => Loss 1.274, Train_accy 95.240, Test_accy 77.880
2024-10-23 20:30:49,742 [bic.py] => bias_correction => Task 1, Epoch 35/100 => Loss 1.272, Train_accy 97.620, Test_accy 78.480
2024-10-23 20:30:49,972 [bic.py] => bias_correction => Task 1, Epoch 36/100 => Loss 1.267, Train_accy 97.620, Test_accy 78.830
2024-10-23 20:30:50,211 [bic.py] => bias_correction => Task 1, Epoch 37/100 => Loss 1.264, Train_accy 95.240, Test_accy 78.790
2024-10-23 20:30:50,407 [bic.py] => bias_correction => Task 1, Epoch 38/100 => Loss 1.265, Train_accy 95.240, Test_accy 78.330
2024-10-23 20:30:50,654 [bic.py] => bias_correction => Task 1, Epoch 39/100 => Loss 1.268, Train_accy 92.860, Test_accy 78.310
2024-10-23 20:30:50,871 [bic.py] => bias_correction => Task 1, Epoch 40/100 => Loss 1.268, Train_accy 95.240, Test_accy 78.550
2024-10-23 20:30:51,096 [bic.py] => bias_correction => Task 1, Epoch 41/100 => Loss 1.267, Train_accy 95.240, Test_accy 78.830
2024-10-23 20:30:51,297 [bic.py] => bias_correction => Task 1, Epoch 42/100 => Loss 1.264, Train_accy 97.620, Test_accy 79.050
2024-10-23 20:30:51,504 [bic.py] => bias_correction => Task 1, Epoch 43/100 => Loss 1.262, Train_accy 97.620, Test_accy 78.810
2024-10-23 20:30:51,721 [bic.py] => bias_correction => Task 1, Epoch 44/100 => Loss 1.263, Train_accy 97.620, Test_accy 78.860
2024-10-23 20:30:51,950 [bic.py] => bias_correction => Task 1, Epoch 45/100 => Loss 1.264, Train_accy 97.620, Test_accy 78.790
2024-10-23 20:30:52,141 [bic.py] => bias_correction => Task 1, Epoch 46/100 => Loss 1.264, Train_accy 97.620, Test_accy 78.830
2024-10-23 20:30:52,344 [bic.py] => bias_correction => Task 1, Epoch 47/100 => Loss 1.263, Train_accy 97.620, Test_accy 79.120
2024-10-23 20:30:52,528 [bic.py] => bias_correction => Task 1, Epoch 48/100 => Loss 1.261, Train_accy 97.620, Test_accy 79.100
2024-10-23 20:30:52,710 [bic.py] => bias_correction => Task 1, Epoch 49/100 => Loss 1.261, Train_accy 95.240, Test_accy 78.950
2024-10-23 20:30:52,906 [bic.py] => bias_correction => Task 1, Epoch 50/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.100
2024-10-23 20:30:53,106 [bic.py] => bias_correction => Task 1, Epoch 51/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.120
2024-10-23 20:30:53,298 [bic.py] => bias_correction => Task 1, Epoch 52/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.070
2024-10-23 20:30:53,497 [bic.py] => bias_correction => Task 1, Epoch 53/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.000
2024-10-23 20:30:53,688 [bic.py] => bias_correction => Task 1, Epoch 54/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.020
2024-10-23 20:30:53,884 [bic.py] => bias_correction => Task 1, Epoch 55/100 => Loss 1.262, Train_accy 95.240, Test_accy 79.020
2024-10-23 20:30:54,087 [bic.py] => bias_correction => Task 1, Epoch 56/100 => Loss 1.261, Train_accy 95.240, Test_accy 78.980
2024-10-23 20:30:54,291 [bic.py] => bias_correction => Task 1, Epoch 57/100 => Loss 1.261, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:54,486 [bic.py] => bias_correction => Task 1, Epoch 58/100 => Loss 1.261, Train_accy 97.620, Test_accy 79.170
2024-10-23 20:30:54,687 [bic.py] => bias_correction => Task 1, Epoch 59/100 => Loss 1.261, Train_accy 97.620, Test_accy 79.240
2024-10-23 20:30:54,886 [bic.py] => bias_correction => Task 1, Epoch 60/100 => Loss 1.261, Train_accy 97.620, Test_accy 79.330
2024-10-23 20:30:55,088 [bic.py] => bias_correction => Task 1, Epoch 61/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.360
2024-10-23 20:30:55,317 [bic.py] => bias_correction => Task 1, Epoch 62/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.260
2024-10-23 20:30:55,508 [bic.py] => bias_correction => Task 1, Epoch 63/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.260
2024-10-23 20:30:55,713 [bic.py] => bias_correction => Task 1, Epoch 64/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.190
2024-10-23 20:30:55,949 [bic.py] => bias_correction => Task 1, Epoch 65/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.170
2024-10-23 20:30:56,149 [bic.py] => bias_correction => Task 1, Epoch 66/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:56,347 [bic.py] => bias_correction => Task 1, Epoch 67/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.240
2024-10-23 20:30:56,549 [bic.py] => bias_correction => Task 1, Epoch 68/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.190
2024-10-23 20:30:56,738 [bic.py] => bias_correction => Task 1, Epoch 69/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:56,941 [bic.py] => bias_correction => Task 1, Epoch 70/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:57,161 [bic.py] => bias_correction => Task 1, Epoch 71/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.190
2024-10-23 20:30:57,362 [bic.py] => bias_correction => Task 1, Epoch 72/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:57,609 [bic.py] => bias_correction => Task 1, Epoch 73/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.240
2024-10-23 20:30:57,885 [bic.py] => bias_correction => Task 1, Epoch 74/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:58,186 [bic.py] => bias_correction => Task 1, Epoch 75/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.210
2024-10-23 20:30:58,468 [bic.py] => bias_correction => Task 1, Epoch 76/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.190
2024-10-23 20:30:58,682 [bic.py] => bias_correction => Task 1, Epoch 77/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.190
2024-10-23 20:30:58,894 [bic.py] => bias_correction => Task 1, Epoch 78/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:30:59,094 [bic.py] => bias_correction => Task 1, Epoch 79/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:30:59,292 [bic.py] => bias_correction => Task 1, Epoch 80/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:30:59,510 [bic.py] => bias_correction => Task 1, Epoch 81/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:30:59,740 [bic.py] => bias_correction => Task 1, Epoch 82/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:30:59,976 [bic.py] => bias_correction => Task 1, Epoch 83/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:31:00,193 [bic.py] => bias_correction => Task 1, Epoch 84/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:31:00,416 [bic.py] => bias_correction => Task 1, Epoch 85/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:31:00,644 [bic.py] => bias_correction => Task 1, Epoch 86/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:31:00,855 [bic.py] => bias_correction => Task 1, Epoch 87/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.310
2024-10-23 20:31:01,084 [bic.py] => bias_correction => Task 1, Epoch 88/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:01,308 [bic.py] => bias_correction => Task 1, Epoch 89/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:01,604 [bic.py] => bias_correction => Task 1, Epoch 90/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:01,911 [bic.py] => bias_correction => Task 1, Epoch 91/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:02,170 [bic.py] => bias_correction => Task 1, Epoch 92/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:02,377 [bic.py] => bias_correction => Task 1, Epoch 93/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:02,647 [bic.py] => bias_correction => Task 1, Epoch 94/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:02,874 [bic.py] => bias_correction => Task 1, Epoch 95/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,080 [bic.py] => bias_correction => Task 1, Epoch 96/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,281 [bic.py] => bias_correction => Task 1, Epoch 97/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,485 [bic.py] => bias_correction => Task 1, Epoch 98/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,694 [bic.py] => bias_correction => Task 1, Epoch 99/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,883 [bic.py] => bias_correction => Task 1, Epoch 100/100 => Loss 1.260, Train_accy 97.620, Test_accy 79.290
2024-10-23 20:31:03,884 [base.py] => Reducing exemplars...(42 per classes)
2024-10-23 20:31:04,983 [base.py] => Constructing exemplars...(42 per classes)
2024-10-23 20:31:06,975 [bic.py] => Parameters of bias layer:
2024-10-23 20:31:06,975 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:31:06,976 [bic.py] => 1 => 0.527, -1.087
2024-10-23 20:31:06,976 [trainer.py] => All params: 3847499
2024-10-23 20:31:07,458 [bic.py] => Exemplar size: 294
2024-10-23 20:31:07,459 [trainer.py] => CNN: {'total': 79.29, '00-04': 79.37, '05-06': 79.08, 'old': 79.37, 'new': 79.08}
2024-10-23 20:31:07,459 [trainer.py] => NME: {'total': 76.14, '00-04': 69.33, '05-06': 93.17, 'old': 69.33, 'new': 93.17}
2024-10-23 20:31:07,459 [trainer.py] => CNN top1 curve: [89.93, 79.29]
2024-10-23 20:31:07,459 [trainer.py] => CNN top5 curve: [100.0, 99.02]
2024-10-23 20:31:07,459 [trainer.py] => NME top1 curve: [90.0, 76.14]
2024-10-23 20:31:07,459 [trainer.py] => NME top5 curve: [100.0, 99.1]

2024-10-23 20:31:07,459 [trainer.py] => Average Accuracy (CNN): 84.61000000000001
2024-10-23 20:31:07,459 [trainer.py] => Average Accuracy (NME): 83.07
2024-10-23 20:31:07,459 [trainer.py] => All params: 3847499
2024-10-23 20:31:07,460 [trainer.py] => Trainable params: 3847499
2024-10-23 20:31:07,461 [bic.py] => Learning on 7-9
2024-10-23 20:31:07,479 [bic.py] => Stage1 dset: 4258, Stage2 dset: 36
2024-10-23 20:31:07,479 [bic.py] => Lambda: 0.778
2024-10-23 20:31:07,490 [bic.py] => Parameters of bias layer:
2024-10-23 20:31:07,491 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:31:07,491 [bic.py] => 1 => 0.527, -1.087
2024-10-23 20:31:07,491 [bic.py] => 2 => 1.000, 0.000
2024-10-23 20:31:08,753 [bic.py] => training => Task 2, Epoch 1/150 => Loss 1.270, Train_accy 92.410, Test_accy 26.040
2024-10-23 20:31:09,987 [bic.py] => training => Task 2, Epoch 2/150 => Loss 1.119, Train_accy 96.710, Test_accy 36.780
2024-10-23 20:31:11,186 [bic.py] => training => Task 2, Epoch 3/150 => Loss 1.087, Train_accy 97.130, Test_accy 33.350
2024-10-23 20:31:12,545 [bic.py] => training => Task 2, Epoch 4/150 => Loss 1.078, Train_accy 99.060, Test_accy 40.260
2024-10-23 20:31:13,788 [bic.py] => training => Task 2, Epoch 5/150 => Loss 1.070, Train_accy 99.740, Test_accy 43.610
2024-10-23 20:31:14,996 [bic.py] => training => Task 2, Epoch 6/150 => Loss 1.064, Train_accy 99.770, Test_accy 46.570
2024-10-23 20:31:16,413 [bic.py] => training => Task 2, Epoch 7/150 => Loss 1.061, Train_accy 99.930, Test_accy 44.000
2024-10-23 20:31:17,677 [bic.py] => training => Task 2, Epoch 8/150 => Loss 1.059, Train_accy 99.980, Test_accy 50.130
2024-10-23 20:31:18,948 [bic.py] => training => Task 2, Epoch 9/150 => Loss 1.057, Train_accy 99.930, Test_accy 50.460
2024-10-23 20:31:20,173 [bic.py] => training => Task 2, Epoch 10/150 => Loss 1.054, Train_accy 100.000, Test_accy 51.650
2024-10-23 20:31:21,468 [bic.py] => training => Task 2, Epoch 11/150 => Loss 1.056, Train_accy 99.980, Test_accy 45.610
2024-10-23 20:31:22,661 [bic.py] => training => Task 2, Epoch 12/150 => Loss 1.055, Train_accy 99.980, Test_accy 49.020
2024-10-23 20:31:23,876 [bic.py] => training => Task 2, Epoch 13/150 => Loss 1.056, Train_accy 100.000, Test_accy 54.610
2024-10-23 20:31:24,998 [bic.py] => training => Task 2, Epoch 14/150 => Loss 1.055, Train_accy 99.980, Test_accy 46.590
2024-10-23 20:31:26,231 [bic.py] => training => Task 2, Epoch 15/150 => Loss 1.053, Train_accy 99.980, Test_accy 53.220
2024-10-23 20:31:27,523 [bic.py] => training => Task 2, Epoch 16/150 => Loss 1.051, Train_accy 100.000, Test_accy 49.520
2024-10-23 20:31:28,826 [bic.py] => training => Task 2, Epoch 17/150 => Loss 1.051, Train_accy 99.980, Test_accy 49.940
2024-10-23 20:31:30,090 [bic.py] => training => Task 2, Epoch 18/150 => Loss 1.054, Train_accy 100.000, Test_accy 57.110
2024-10-23 20:31:31,424 [bic.py] => training => Task 2, Epoch 19/150 => Loss 1.051, Train_accy 99.980, Test_accy 53.020
2024-10-23 20:31:32,642 [bic.py] => training => Task 2, Epoch 20/150 => Loss 1.050, Train_accy 100.000, Test_accy 51.110
2024-10-23 20:31:33,955 [bic.py] => training => Task 2, Epoch 21/150 => Loss 1.050, Train_accy 99.980, Test_accy 48.520
2024-10-23 20:31:35,249 [bic.py] => training => Task 2, Epoch 22/150 => Loss 1.050, Train_accy 100.000, Test_accy 55.280
2024-10-23 20:31:36,494 [bic.py] => training => Task 2, Epoch 23/150 => Loss 1.051, Train_accy 99.950, Test_accy 52.060
2024-10-23 20:31:37,754 [bic.py] => training => Task 2, Epoch 24/150 => Loss 1.050, Train_accy 100.000, Test_accy 49.370
2024-10-23 20:31:39,094 [bic.py] => training => Task 2, Epoch 25/150 => Loss 1.051, Train_accy 99.980, Test_accy 51.060
2024-10-23 20:31:40,348 [bic.py] => training => Task 2, Epoch 26/150 => Loss 1.050, Train_accy 100.000, Test_accy 51.780
2024-10-23 20:31:41,567 [bic.py] => training => Task 2, Epoch 27/150 => Loss 1.051, Train_accy 100.000, Test_accy 52.940
2024-10-23 20:31:42,787 [bic.py] => training => Task 2, Epoch 28/150 => Loss 1.051, Train_accy 99.980, Test_accy 53.430
2024-10-23 20:31:43,973 [bic.py] => training => Task 2, Epoch 29/150 => Loss 1.048, Train_accy 100.000, Test_accy 54.440
2024-10-23 20:31:45,119 [bic.py] => training => Task 2, Epoch 30/150 => Loss 1.052, Train_accy 99.980, Test_accy 55.070
2024-10-23 20:31:46,238 [bic.py] => training => Task 2, Epoch 31/150 => Loss 1.050, Train_accy 100.000, Test_accy 51.390
2024-10-23 20:31:47,397 [bic.py] => training => Task 2, Epoch 32/150 => Loss 1.051, Train_accy 100.000, Test_accy 51.370
2024-10-23 20:31:48,722 [bic.py] => training => Task 2, Epoch 33/150 => Loss 1.050, Train_accy 99.980, Test_accy 49.570
2024-10-23 20:31:49,991 [bic.py] => training => Task 2, Epoch 34/150 => Loss 1.049, Train_accy 100.000, Test_accy 52.960
2024-10-23 20:31:51,268 [bic.py] => training => Task 2, Epoch 35/150 => Loss 1.048, Train_accy 100.000, Test_accy 49.240
2024-10-23 20:31:52,550 [bic.py] => training => Task 2, Epoch 36/150 => Loss 1.050, Train_accy 100.000, Test_accy 56.570
2024-10-23 20:31:53,698 [bic.py] => training => Task 2, Epoch 37/150 => Loss 1.050, Train_accy 99.930, Test_accy 43.690
2024-10-23 20:31:54,900 [bic.py] => training => Task 2, Epoch 38/150 => Loss 1.049, Train_accy 100.000, Test_accy 51.940
2024-10-23 20:31:56,209 [bic.py] => training => Task 2, Epoch 39/150 => Loss 1.047, Train_accy 100.000, Test_accy 49.090
2024-10-23 20:31:57,406 [bic.py] => training => Task 2, Epoch 40/150 => Loss 1.051, Train_accy 99.980, Test_accy 51.910
2024-10-23 20:31:58,762 [bic.py] => training => Task 2, Epoch 41/150 => Loss 1.049, Train_accy 100.000, Test_accy 51.700
2024-10-23 20:32:00,150 [bic.py] => training => Task 2, Epoch 42/150 => Loss 1.050, Train_accy 100.000, Test_accy 58.310
2024-10-23 20:32:01,347 [bic.py] => training => Task 2, Epoch 43/150 => Loss 1.051, Train_accy 99.980, Test_accy 56.910
2024-10-23 20:32:02,584 [bic.py] => training => Task 2, Epoch 44/150 => Loss 1.051, Train_accy 100.000, Test_accy 50.500
2024-10-23 20:32:03,892 [bic.py] => training => Task 2, Epoch 45/150 => Loss 1.050, Train_accy 100.000, Test_accy 52.780
2024-10-23 20:32:05,116 [bic.py] => training => Task 2, Epoch 46/150 => Loss 1.051, Train_accy 100.000, Test_accy 59.670
2024-10-23 20:32:06,377 [bic.py] => training => Task 2, Epoch 47/150 => Loss 1.049, Train_accy 99.980, Test_accy 46.810
2024-10-23 20:32:07,667 [bic.py] => training => Task 2, Epoch 48/150 => Loss 1.050, Train_accy 100.000, Test_accy 47.590
2024-10-23 20:32:08,824 [bic.py] => training => Task 2, Epoch 49/150 => Loss 1.049, Train_accy 100.000, Test_accy 51.410
2024-10-23 20:32:09,983 [bic.py] => training => Task 2, Epoch 50/150 => Loss 1.046, Train_accy 100.000, Test_accy 45.850
2024-10-23 20:32:11,223 [bic.py] => training => Task 2, Epoch 51/150 => Loss 1.048, Train_accy 100.000, Test_accy 54.060
2024-10-23 20:32:12,409 [bic.py] => training => Task 2, Epoch 52/150 => Loss 1.049, Train_accy 100.000, Test_accy 52.740
2024-10-23 20:32:13,605 [bic.py] => training => Task 2, Epoch 53/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.940
2024-10-23 20:32:14,696 [bic.py] => training => Task 2, Epoch 54/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.460
2024-10-23 20:32:15,863 [bic.py] => training => Task 2, Epoch 55/150 => Loss 1.047, Train_accy 100.000, Test_accy 54.060
2024-10-23 20:32:17,090 [bic.py] => training => Task 2, Epoch 56/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.700
2024-10-23 20:32:18,317 [bic.py] => training => Task 2, Epoch 57/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.870
2024-10-23 20:32:19,570 [bic.py] => training => Task 2, Epoch 58/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.780
2024-10-23 20:32:20,790 [bic.py] => training => Task 2, Epoch 59/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.260
2024-10-23 20:32:22,164 [bic.py] => training => Task 2, Epoch 60/150 => Loss 1.048, Train_accy 100.000, Test_accy 52.690
2024-10-23 20:32:23,471 [bic.py] => training => Task 2, Epoch 61/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.110
2024-10-23 20:32:24,682 [bic.py] => training => Task 2, Epoch 62/150 => Loss 1.044, Train_accy 100.000, Test_accy 53.540
2024-10-23 20:32:25,859 [bic.py] => training => Task 2, Epoch 63/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.590
2024-10-23 20:32:27,086 [bic.py] => training => Task 2, Epoch 64/150 => Loss 1.045, Train_accy 100.000, Test_accy 50.930
2024-10-23 20:32:28,286 [bic.py] => training => Task 2, Epoch 65/150 => Loss 1.047, Train_accy 100.000, Test_accy 54.740
2024-10-23 20:32:29,565 [bic.py] => training => Task 2, Epoch 66/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.460
2024-10-23 20:32:30,899 [bic.py] => training => Task 2, Epoch 67/150 => Loss 1.047, Train_accy 100.000, Test_accy 51.870
2024-10-23 20:32:32,151 [bic.py] => training => Task 2, Epoch 68/150 => Loss 1.044, Train_accy 100.000, Test_accy 52.130
2024-10-23 20:32:33,419 [bic.py] => training => Task 2, Epoch 69/150 => Loss 1.046, Train_accy 100.000, Test_accy 54.040
2024-10-23 20:32:34,616 [bic.py] => training => Task 2, Epoch 70/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.700
2024-10-23 20:32:35,802 [bic.py] => training => Task 2, Epoch 71/150 => Loss 1.047, Train_accy 100.000, Test_accy 50.930
2024-10-23 20:32:36,910 [bic.py] => training => Task 2, Epoch 72/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.000
2024-10-23 20:32:38,032 [bic.py] => training => Task 2, Epoch 73/150 => Loss 1.047, Train_accy 100.000, Test_accy 51.890
2024-10-23 20:32:39,259 [bic.py] => training => Task 2, Epoch 74/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.040
2024-10-23 20:32:40,443 [bic.py] => training => Task 2, Epoch 75/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.980
2024-10-23 20:32:41,666 [bic.py] => training => Task 2, Epoch 76/150 => Loss 1.047, Train_accy 100.000, Test_accy 54.280
2024-10-23 20:32:42,865 [bic.py] => training => Task 2, Epoch 77/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.130
2024-10-23 20:32:44,049 [bic.py] => training => Task 2, Epoch 78/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.930
2024-10-23 20:32:45,197 [bic.py] => training => Task 2, Epoch 79/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.890
2024-10-23 20:32:46,436 [bic.py] => training => Task 2, Epoch 80/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.280
2024-10-23 20:32:47,566 [bic.py] => training => Task 2, Epoch 81/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.560
2024-10-23 20:32:48,617 [bic.py] => training => Task 2, Epoch 82/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.440
2024-10-23 20:32:49,667 [bic.py] => training => Task 2, Epoch 83/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.040
2024-10-23 20:32:50,770 [bic.py] => training => Task 2, Epoch 84/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.200
2024-10-23 20:32:51,820 [bic.py] => training => Task 2, Epoch 85/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.780
2024-10-23 20:32:52,916 [bic.py] => training => Task 2, Epoch 86/150 => Loss 1.045, Train_accy 100.000, Test_accy 53.350
2024-10-23 20:32:54,126 [bic.py] => training => Task 2, Epoch 87/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.350
2024-10-23 20:32:55,282 [bic.py] => training => Task 2, Epoch 88/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.110
2024-10-23 20:32:56,464 [bic.py] => training => Task 2, Epoch 89/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.560
2024-10-23 20:32:57,707 [bic.py] => training => Task 2, Epoch 90/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.070
2024-10-23 20:32:58,930 [bic.py] => training => Task 2, Epoch 91/150 => Loss 1.047, Train_accy 100.000, Test_accy 54.040
2024-10-23 20:33:00,171 [bic.py] => training => Task 2, Epoch 92/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.890
2024-10-23 20:33:01,278 [bic.py] => training => Task 2, Epoch 93/150 => Loss 1.049, Train_accy 100.000, Test_accy 53.370
2024-10-23 20:33:02,591 [bic.py] => training => Task 2, Epoch 94/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.740
2024-10-23 20:33:03,720 [bic.py] => training => Task 2, Epoch 95/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.890
2024-10-23 20:33:04,756 [bic.py] => training => Task 2, Epoch 96/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.690
2024-10-23 20:33:05,842 [bic.py] => training => Task 2, Epoch 97/150 => Loss 1.044, Train_accy 100.000, Test_accy 53.500
2024-10-23 20:33:06,969 [bic.py] => training => Task 2, Epoch 98/150 => Loss 1.046, Train_accy 100.000, Test_accy 54.690
2024-10-23 20:33:08,190 [bic.py] => training => Task 2, Epoch 99/150 => Loss 1.044, Train_accy 100.000, Test_accy 52.150
2024-10-23 20:33:09,457 [bic.py] => training => Task 2, Epoch 100/150 => Loss 1.044, Train_accy 100.000, Test_accy 51.300
2024-10-23 20:33:10,595 [bic.py] => training => Task 2, Epoch 101/150 => Loss 1.045, Train_accy 100.000, Test_accy 53.390
2024-10-23 20:33:11,755 [bic.py] => training => Task 2, Epoch 102/150 => Loss 1.045, Train_accy 100.000, Test_accy 53.810
2024-10-23 20:33:13,024 [bic.py] => training => Task 2, Epoch 103/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.800
2024-10-23 20:33:14,271 [bic.py] => training => Task 2, Epoch 104/150 => Loss 1.046, Train_accy 100.000, Test_accy 50.500
2024-10-23 20:33:15,522 [bic.py] => training => Task 2, Epoch 105/150 => Loss 1.047, Train_accy 100.000, Test_accy 51.220
2024-10-23 20:33:16,688 [bic.py] => training => Task 2, Epoch 106/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.110
2024-10-23 20:33:17,810 [bic.py] => training => Task 2, Epoch 107/150 => Loss 1.048, Train_accy 100.000, Test_accy 53.610
2024-10-23 20:33:19,008 [bic.py] => training => Task 2, Epoch 108/150 => Loss 1.047, Train_accy 100.000, Test_accy 54.020
2024-10-23 20:33:20,187 [bic.py] => training => Task 2, Epoch 109/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.430
2024-10-23 20:33:21,389 [bic.py] => training => Task 2, Epoch 110/150 => Loss 1.048, Train_accy 100.000, Test_accy 52.870
2024-10-23 20:33:22,498 [bic.py] => training => Task 2, Epoch 111/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.830
2024-10-23 20:33:23,631 [bic.py] => training => Task 2, Epoch 112/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.690
2024-10-23 20:33:24,681 [bic.py] => training => Task 2, Epoch 113/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.130
2024-10-23 20:33:25,748 [bic.py] => training => Task 2, Epoch 114/150 => Loss 1.045, Train_accy 100.000, Test_accy 53.830
2024-10-23 20:33:26,780 [bic.py] => training => Task 2, Epoch 115/150 => Loss 1.046, Train_accy 100.000, Test_accy 54.200
2024-10-23 20:33:27,962 [bic.py] => training => Task 2, Epoch 116/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.460
2024-10-23 20:33:29,057 [bic.py] => training => Task 2, Epoch 117/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.890
2024-10-23 20:33:30,163 [bic.py] => training => Task 2, Epoch 118/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.760
2024-10-23 20:33:31,216 [bic.py] => training => Task 2, Epoch 119/150 => Loss 1.044, Train_accy 100.000, Test_accy 52.780
2024-10-23 20:33:32,295 [bic.py] => training => Task 2, Epoch 120/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.590
2024-10-23 20:33:33,445 [bic.py] => training => Task 2, Epoch 121/150 => Loss 1.047, Train_accy 100.000, Test_accy 51.930
2024-10-23 20:33:34,552 [bic.py] => training => Task 2, Epoch 122/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.150
2024-10-23 20:33:35,687 [bic.py] => training => Task 2, Epoch 123/150 => Loss 1.046, Train_accy 100.000, Test_accy 51.330
2024-10-23 20:33:36,872 [bic.py] => training => Task 2, Epoch 124/150 => Loss 1.046, Train_accy 100.000, Test_accy 54.220
2024-10-23 20:33:38,113 [bic.py] => training => Task 2, Epoch 125/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.890
2024-10-23 20:33:39,246 [bic.py] => training => Task 2, Epoch 126/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.410
2024-10-23 20:33:40,467 [bic.py] => training => Task 2, Epoch 127/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.480
2024-10-23 20:33:41,632 [bic.py] => training => Task 2, Epoch 128/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.110
2024-10-23 20:33:42,898 [bic.py] => training => Task 2, Epoch 129/150 => Loss 1.044, Train_accy 100.000, Test_accy 53.590
2024-10-23 20:33:44,209 [bic.py] => training => Task 2, Epoch 130/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.500
2024-10-23 20:33:45,410 [bic.py] => training => Task 2, Epoch 131/150 => Loss 1.048, Train_accy 100.000, Test_accy 52.670
2024-10-23 20:33:46,693 [bic.py] => training => Task 2, Epoch 132/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.780
2024-10-23 20:33:47,879 [bic.py] => training => Task 2, Epoch 133/150 => Loss 1.047, Train_accy 100.000, Test_accy 51.910
2024-10-23 20:33:49,075 [bic.py] => training => Task 2, Epoch 134/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.440
2024-10-23 20:33:50,340 [bic.py] => training => Task 2, Epoch 135/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.390
2024-10-23 20:33:51,530 [bic.py] => training => Task 2, Epoch 136/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.960
2024-10-23 20:33:52,755 [bic.py] => training => Task 2, Epoch 137/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.570
2024-10-23 20:33:53,916 [bic.py] => training => Task 2, Epoch 138/150 => Loss 1.045, Train_accy 100.000, Test_accy 51.300
2024-10-23 20:33:55,040 [bic.py] => training => Task 2, Epoch 139/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.130
2024-10-23 20:33:56,197 [bic.py] => training => Task 2, Epoch 140/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.020
2024-10-23 20:33:57,312 [bic.py] => training => Task 2, Epoch 141/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.780
2024-10-23 20:33:58,571 [bic.py] => training => Task 2, Epoch 142/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.040
2024-10-23 20:33:59,894 [bic.py] => training => Task 2, Epoch 143/150 => Loss 1.046, Train_accy 100.000, Test_accy 52.940
2024-10-23 20:34:01,052 [bic.py] => training => Task 2, Epoch 144/150 => Loss 1.046, Train_accy 100.000, Test_accy 53.480
2024-10-23 20:34:02,175 [bic.py] => training => Task 2, Epoch 145/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.150
2024-10-23 20:34:03,339 [bic.py] => training => Task 2, Epoch 146/150 => Loss 1.048, Train_accy 100.000, Test_accy 54.850
2024-10-23 20:34:04,562 [bic.py] => training => Task 2, Epoch 147/150 => Loss 1.047, Train_accy 100.000, Test_accy 53.780
2024-10-23 20:34:05,840 [bic.py] => training => Task 2, Epoch 148/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.150
2024-10-23 20:34:07,087 [bic.py] => training => Task 2, Epoch 149/150 => Loss 1.047, Train_accy 100.000, Test_accy 52.650
2024-10-23 20:34:08,293 [bic.py] => training => Task 2, Epoch 150/150 => Loss 1.045, Train_accy 100.000, Test_accy 52.800
2024-10-23 20:34:08,586 [bic.py] => bias_correction => Task 2, Epoch 1/5 => Loss 1.974, Train_accy 63.890, Test_accy 51.060
2024-10-23 20:34:08,842 [bic.py] => bias_correction => Task 2, Epoch 2/5 => Loss 1.957, Train_accy 63.890, Test_accy 51.260
2024-10-23 20:34:09,098 [bic.py] => bias_correction => Task 2, Epoch 3/5 => Loss 1.919, Train_accy 69.440, Test_accy 54.150
2024-10-23 20:34:09,343 [bic.py] => bias_correction => Task 2, Epoch 4/5 => Loss 1.852, Train_accy 83.330, Test_accy 60.460
2024-10-23 20:34:09,579 [bic.py] => bias_correction => Task 2, Epoch 5/5 => Loss 1.745, Train_accy 91.670, Test_accy 70.240
2024-10-23 20:34:09,579 [base.py] => Reducing exemplars...(33 per classes)
2024-10-23 20:34:11,056 [base.py] => Constructing exemplars...(33 per classes)
2024-10-23 20:34:12,691 [bic.py] => Parameters of bias layer:
2024-10-23 20:34:12,691 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:34:12,692 [bic.py] => 1 => 0.527, -1.087
2024-10-23 20:34:12,692 [bic.py] => 2 => 0.384, -0.127
2024-10-23 20:34:12,693 [trainer.py] => All params: 3848527
2024-10-23 20:34:13,272 [bic.py] => Exemplar size: 297
2024-10-23 20:34:13,272 [trainer.py] => CNN: {'total': 70.24, '00-04': 67.13, '05-06': 60.25, '07-08': 88.0, 'old': 65.17, 'new': 88.0}
2024-10-23 20:34:13,272 [trainer.py] => NME: {'total': 70.72, '00-04': 61.9, '05-06': 67.67, '07-08': 95.83, 'old': 63.55, 'new': 95.83}
2024-10-23 20:34:13,272 [trainer.py] => CNN top1 curve: [89.93, 79.29, 70.24]
2024-10-23 20:34:13,272 [trainer.py] => CNN top5 curve: [100.0, 99.02, 96.31]
2024-10-23 20:34:13,272 [trainer.py] => NME top1 curve: [90.0, 76.14, 70.72]
2024-10-23 20:34:13,272 [trainer.py] => NME top5 curve: [100.0, 99.1, 97.85]

2024-10-23 20:34:13,272 [trainer.py] => Average Accuracy (CNN): 79.82000000000001
2024-10-23 20:34:13,272 [trainer.py] => Average Accuracy (NME): 78.95333333333333
2024-10-23 20:34:13,273 [trainer.py] => Forgetting (CNN): 20.815000000000005
