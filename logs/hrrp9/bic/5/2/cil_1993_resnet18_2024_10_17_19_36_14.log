2024-10-17 19:36:14,418 [trainer.py] => config: ./exps/bic.json
2024-10-17 19:36:14,418 [trainer.py] => prefix: cil
2024-10-17 19:36:14,418 [trainer.py] => dataset: hrrp9
2024-10-17 19:36:14,418 [trainer.py] => memory_size: 500
2024-10-17 19:36:14,418 [trainer.py] => memory_per_class: 20
2024-10-17 19:36:14,418 [trainer.py] => fixed_memory: False
2024-10-17 19:36:14,418 [trainer.py] => shuffle: True
2024-10-17 19:36:14,418 [trainer.py] => init_cls: 5
2024-10-17 19:36:14,418 [trainer.py] => increment: 2
2024-10-17 19:36:14,418 [trainer.py] => model_name: bic
2024-10-17 19:36:14,418 [trainer.py] => convnet_type: resnet18
2024-10-17 19:36:14,418 [trainer.py] => device: [device(type='cuda', index=0)]
2024-10-17 19:36:14,418 [trainer.py] => init_train: False
2024-10-17 19:36:14,419 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-17 19:36:14,419 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-17 19:36:14,419 [trainer.py] => seed: 1993
2024-10-17 19:36:14,419 [trainer.py] => init_epochs: 0
2024-10-17 19:36:14,419 [trainer.py] => epochs: 120
2024-10-17 19:36:14,419 [trainer.py] => lrate: 0.1
2024-10-17 19:36:14,419 [trainer.py] => milestones: [60, 100]
2024-10-17 19:36:14,419 [trainer.py] => lrate_decay: 0.1
2024-10-17 19:36:14,419 [trainer.py] => momentum: 0.9
2024-10-17 19:36:14,419 [trainer.py] => batch_size: 128
2024-10-17 19:36:14,419 [trainer.py] => split_ratio: 0.1
2024-10-17 19:36:14,419 [trainer.py] => weight_decay: 0.0002
2024-10-17 19:36:14,419 [trainer.py] => num_workers: 0
2024-10-17 19:36:14,419 [trainer.py] => T: 2
2024-10-17 19:36:14,419 [trainer.py] => bc_lrate: 0.01
2024-10-17 19:36:14,419 [trainer.py] => bc_epochs: [120, 120, 6]
2024-10-17 19:36:15,071 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-17 19:36:15,566 [trainer.py] => All params: 3843904
2024-10-17 19:36:15,566 [trainer.py] => Trainable params: 3843904
2024-10-17 19:36:15,569 [bic.py] => Learning on 0-5
2024-10-17 19:36:15,605 [bic.py] => Parameters of bias layer:
2024-10-17 19:36:15,605 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:36:15,608 [base.py] => Reducing exemplars...(100 per classes)
2024-10-17 19:36:15,608 [base.py] => Constructing exemplars...(100 per classes)
2024-10-17 19:36:21,437 [bic.py] => Parameters of bias layer:
2024-10-17 19:36:21,438 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:36:21,439 [trainer.py] => All params: 3846471
2024-10-17 19:36:21,830 [bic.py] => Exemplar size: 500
2024-10-17 19:36:21,830 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-17 19:36:21,830 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-17 19:36:21,831 [trainer.py] => CNN top1 curve: [89.93]
2024-10-17 19:36:21,831 [trainer.py] => CNN top5 curve: [100.0]
2024-10-17 19:36:21,831 [trainer.py] => NME top1 curve: [90.0]
2024-10-17 19:36:21,831 [trainer.py] => NME top5 curve: [100.0]

2024-10-17 19:36:21,831 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-17 19:36:21,831 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-17 19:36:21,831 [trainer.py] => All params: 3846471
2024-10-17 19:36:21,831 [trainer.py] => Trainable params: 3846471
2024-10-17 19:36:21,832 [bic.py] => Learning on 5-7
2024-10-17 19:36:21,857 [bic.py] => Stage1 dset: 4430, Stage2 dset: 70
2024-10-17 19:36:21,857 [bic.py] => Lambda: 0.714
2024-10-17 19:36:21,864 [bic.py] => Parameters of bias layer:
2024-10-17 19:36:21,864 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:36:21,865 [bic.py] => 1 => 1.000, 0.000
2024-10-17 19:36:23,180 [bic.py] => training => Task 1, Epoch 1/120 => Loss 1.028, Train_accy 87.340, Test_accy 37.290
2024-10-17 19:36:24,235 [bic.py] => training => Task 1, Epoch 2/120 => Loss 0.765, Train_accy 94.470, Test_accy 53.360
2024-10-17 19:36:25,287 [bic.py] => training => Task 1, Epoch 3/120 => Loss 0.711, Train_accy 98.470, Test_accy 58.380
2024-10-17 19:36:26,368 [bic.py] => training => Task 1, Epoch 4/120 => Loss 0.690, Train_accy 99.260, Test_accy 60.760
2024-10-17 19:36:27,426 [bic.py] => training => Task 1, Epoch 5/120 => Loss 0.680, Train_accy 99.800, Test_accy 60.290
2024-10-17 19:36:28,504 [bic.py] => training => Task 1, Epoch 6/120 => Loss 0.674, Train_accy 99.930, Test_accy 64.170
2024-10-17 19:36:29,594 [bic.py] => training => Task 1, Epoch 7/120 => Loss 0.670, Train_accy 100.000, Test_accy 60.500
2024-10-17 19:36:30,657 [bic.py] => training => Task 1, Epoch 8/120 => Loss 0.668, Train_accy 100.000, Test_accy 63.050
2024-10-17 19:36:31,729 [bic.py] => training => Task 1, Epoch 9/120 => Loss 0.664, Train_accy 100.000, Test_accy 61.860
2024-10-17 19:36:32,687 [bic.py] => training => Task 1, Epoch 10/120 => Loss 0.664, Train_accy 100.000, Test_accy 62.690
2024-10-17 19:36:33,625 [bic.py] => training => Task 1, Epoch 11/120 => Loss 0.663, Train_accy 100.000, Test_accy 62.170
2024-10-17 19:36:34,575 [bic.py] => training => Task 1, Epoch 12/120 => Loss 0.662, Train_accy 99.980, Test_accy 62.670
2024-10-17 19:36:35,547 [bic.py] => training => Task 1, Epoch 13/120 => Loss 0.664, Train_accy 100.000, Test_accy 64.740
2024-10-17 19:36:36,501 [bic.py] => training => Task 1, Epoch 14/120 => Loss 0.662, Train_accy 100.000, Test_accy 61.210
2024-10-17 19:36:37,558 [bic.py] => training => Task 1, Epoch 15/120 => Loss 0.661, Train_accy 100.000, Test_accy 65.310
2024-10-17 19:36:38,513 [bic.py] => training => Task 1, Epoch 16/120 => Loss 0.658, Train_accy 100.000, Test_accy 66.020
2024-10-17 19:36:39,556 [bic.py] => training => Task 1, Epoch 17/120 => Loss 0.659, Train_accy 100.000, Test_accy 63.600
2024-10-17 19:36:40,616 [bic.py] => training => Task 1, Epoch 18/120 => Loss 0.661, Train_accy 100.000, Test_accy 63.050
2024-10-17 19:36:41,692 [bic.py] => training => Task 1, Epoch 19/120 => Loss 0.661, Train_accy 100.000, Test_accy 66.570
2024-10-17 19:36:42,738 [bic.py] => training => Task 1, Epoch 20/120 => Loss 0.660, Train_accy 100.000, Test_accy 67.570
2024-10-17 19:36:43,795 [bic.py] => training => Task 1, Epoch 21/120 => Loss 0.659, Train_accy 100.000, Test_accy 65.050
2024-10-17 19:36:44,838 [bic.py] => training => Task 1, Epoch 22/120 => Loss 0.659, Train_accy 100.000, Test_accy 63.550
2024-10-17 19:36:45,913 [bic.py] => training => Task 1, Epoch 23/120 => Loss 0.659, Train_accy 100.000, Test_accy 63.290
2024-10-17 19:36:46,980 [bic.py] => training => Task 1, Epoch 24/120 => Loss 0.659, Train_accy 100.000, Test_accy 68.740
2024-10-17 19:36:48,060 [bic.py] => training => Task 1, Epoch 25/120 => Loss 0.659, Train_accy 100.000, Test_accy 65.950
2024-10-17 19:36:49,074 [bic.py] => training => Task 1, Epoch 26/120 => Loss 0.659, Train_accy 100.000, Test_accy 65.670
2024-10-17 19:36:50,153 [bic.py] => training => Task 1, Epoch 27/120 => Loss 0.658, Train_accy 100.000, Test_accy 64.170
2024-10-17 19:36:51,254 [bic.py] => training => Task 1, Epoch 28/120 => Loss 0.659, Train_accy 100.000, Test_accy 64.620
2024-10-17 19:36:52,352 [bic.py] => training => Task 1, Epoch 29/120 => Loss 0.658, Train_accy 100.000, Test_accy 68.520
2024-10-17 19:36:53,417 [bic.py] => training => Task 1, Epoch 30/120 => Loss 0.657, Train_accy 100.000, Test_accy 65.190
2024-10-17 19:36:54,488 [bic.py] => training => Task 1, Epoch 31/120 => Loss 0.658, Train_accy 100.000, Test_accy 67.860
2024-10-17 19:36:55,532 [bic.py] => training => Task 1, Epoch 32/120 => Loss 0.658, Train_accy 100.000, Test_accy 67.330
2024-10-17 19:36:56,536 [bic.py] => training => Task 1, Epoch 33/120 => Loss 0.657, Train_accy 100.000, Test_accy 66.430
2024-10-17 19:36:57,603 [bic.py] => training => Task 1, Epoch 34/120 => Loss 0.657, Train_accy 100.000, Test_accy 67.930
2024-10-17 19:36:58,676 [bic.py] => training => Task 1, Epoch 35/120 => Loss 0.656, Train_accy 100.000, Test_accy 67.430
2024-10-17 19:36:59,717 [bic.py] => training => Task 1, Epoch 36/120 => Loss 0.657, Train_accy 100.000, Test_accy 67.190
2024-10-17 19:37:00,784 [bic.py] => training => Task 1, Epoch 37/120 => Loss 0.658, Train_accy 100.000, Test_accy 63.570
2024-10-17 19:37:01,784 [bic.py] => training => Task 1, Epoch 38/120 => Loss 0.658, Train_accy 100.000, Test_accy 67.600
2024-10-17 19:37:02,902 [bic.py] => training => Task 1, Epoch 39/120 => Loss 0.659, Train_accy 100.000, Test_accy 69.900
2024-10-17 19:37:03,988 [bic.py] => training => Task 1, Epoch 40/120 => Loss 0.658, Train_accy 100.000, Test_accy 69.740
2024-10-17 19:37:05,054 [bic.py] => training => Task 1, Epoch 41/120 => Loss 0.656, Train_accy 100.000, Test_accy 66.380
2024-10-17 19:37:06,120 [bic.py] => training => Task 1, Epoch 42/120 => Loss 0.657, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:37:07,157 [bic.py] => training => Task 1, Epoch 43/120 => Loss 0.656, Train_accy 100.000, Test_accy 66.260
2024-10-17 19:37:08,162 [bic.py] => training => Task 1, Epoch 44/120 => Loss 0.657, Train_accy 100.000, Test_accy 66.120
2024-10-17 19:37:09,176 [bic.py] => training => Task 1, Epoch 45/120 => Loss 0.656, Train_accy 100.000, Test_accy 65.310
2024-10-17 19:37:10,316 [bic.py] => training => Task 1, Epoch 46/120 => Loss 0.658, Train_accy 100.000, Test_accy 64.640
2024-10-17 19:37:11,388 [bic.py] => training => Task 1, Epoch 47/120 => Loss 0.658, Train_accy 100.000, Test_accy 65.740
2024-10-17 19:37:12,542 [bic.py] => training => Task 1, Epoch 48/120 => Loss 0.656, Train_accy 100.000, Test_accy 66.290
2024-10-17 19:37:13,600 [bic.py] => training => Task 1, Epoch 49/120 => Loss 0.657, Train_accy 100.000, Test_accy 64.710
2024-10-17 19:37:14,695 [bic.py] => training => Task 1, Epoch 50/120 => Loss 0.655, Train_accy 100.000, Test_accy 65.950
2024-10-17 19:37:15,742 [bic.py] => training => Task 1, Epoch 51/120 => Loss 0.656, Train_accy 100.000, Test_accy 67.120
2024-10-17 19:37:16,807 [bic.py] => training => Task 1, Epoch 52/120 => Loss 0.657, Train_accy 100.000, Test_accy 66.210
2024-10-17 19:37:17,800 [bic.py] => training => Task 1, Epoch 53/120 => Loss 0.656, Train_accy 100.000, Test_accy 61.430
2024-10-17 19:37:18,814 [bic.py] => training => Task 1, Epoch 54/120 => Loss 0.656, Train_accy 100.000, Test_accy 64.830
2024-10-17 19:37:19,831 [bic.py] => training => Task 1, Epoch 55/120 => Loss 0.655, Train_accy 100.000, Test_accy 66.140
2024-10-17 19:37:20,871 [bic.py] => training => Task 1, Epoch 56/120 => Loss 0.655, Train_accy 100.000, Test_accy 69.020
2024-10-17 19:37:21,872 [bic.py] => training => Task 1, Epoch 57/120 => Loss 0.657, Train_accy 100.000, Test_accy 63.480
2024-10-17 19:37:22,929 [bic.py] => training => Task 1, Epoch 58/120 => Loss 0.658, Train_accy 100.000, Test_accy 64.740
2024-10-17 19:37:24,033 [bic.py] => training => Task 1, Epoch 59/120 => Loss 0.656, Train_accy 100.000, Test_accy 68.400
2024-10-17 19:37:25,080 [bic.py] => training => Task 1, Epoch 60/120 => Loss 0.656, Train_accy 100.000, Test_accy 66.760
2024-10-17 19:37:26,128 [bic.py] => training => Task 1, Epoch 61/120 => Loss 0.655, Train_accy 100.000, Test_accy 66.900
2024-10-17 19:37:27,135 [bic.py] => training => Task 1, Epoch 62/120 => Loss 0.653, Train_accy 100.000, Test_accy 66.360
2024-10-17 19:37:28,271 [bic.py] => training => Task 1, Epoch 63/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.690
2024-10-17 19:37:29,239 [bic.py] => training => Task 1, Epoch 64/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.000
2024-10-17 19:37:30,191 [bic.py] => training => Task 1, Epoch 65/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.210
2024-10-17 19:37:31,139 [bic.py] => training => Task 1, Epoch 66/120 => Loss 0.652, Train_accy 100.000, Test_accy 66.900
2024-10-17 19:37:32,183 [bic.py] => training => Task 1, Epoch 67/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.450
2024-10-17 19:37:33,257 [bic.py] => training => Task 1, Epoch 68/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.210
2024-10-17 19:37:34,300 [bic.py] => training => Task 1, Epoch 69/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.290
2024-10-17 19:37:35,365 [bic.py] => training => Task 1, Epoch 70/120 => Loss 0.652, Train_accy 100.000, Test_accy 66.860
2024-10-17 19:37:36,441 [bic.py] => training => Task 1, Epoch 71/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:37:37,450 [bic.py] => training => Task 1, Epoch 72/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.330
2024-10-17 19:37:38,440 [bic.py] => training => Task 1, Epoch 73/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.500
2024-10-17 19:37:39,534 [bic.py] => training => Task 1, Epoch 74/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.620
2024-10-17 19:37:40,627 [bic.py] => training => Task 1, Epoch 75/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.210
2024-10-17 19:37:41,743 [bic.py] => training => Task 1, Epoch 76/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.740
2024-10-17 19:37:42,830 [bic.py] => training => Task 1, Epoch 77/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.000
2024-10-17 19:37:43,894 [bic.py] => training => Task 1, Epoch 78/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.810
2024-10-17 19:37:44,903 [bic.py] => training => Task 1, Epoch 79/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.500
2024-10-17 19:37:45,982 [bic.py] => training => Task 1, Epoch 80/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:37:47,022 [bic.py] => training => Task 1, Epoch 81/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.480
2024-10-17 19:37:48,036 [bic.py] => training => Task 1, Epoch 82/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.810
2024-10-17 19:37:49,049 [bic.py] => training => Task 1, Epoch 83/120 => Loss 0.652, Train_accy 100.000, Test_accy 66.860
2024-10-17 19:37:50,043 [bic.py] => training => Task 1, Epoch 84/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.860
2024-10-17 19:37:50,990 [bic.py] => training => Task 1, Epoch 85/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.430
2024-10-17 19:37:51,938 [bic.py] => training => Task 1, Epoch 86/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.570
2024-10-17 19:37:52,952 [bic.py] => training => Task 1, Epoch 87/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.020
2024-10-17 19:37:53,906 [bic.py] => training => Task 1, Epoch 88/120 => Loss 0.653, Train_accy 100.000, Test_accy 68.240
2024-10-17 19:37:54,855 [bic.py] => training => Task 1, Epoch 89/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.120
2024-10-17 19:37:55,817 [bic.py] => training => Task 1, Epoch 90/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.290
2024-10-17 19:37:56,837 [bic.py] => training => Task 1, Epoch 91/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.050
2024-10-17 19:37:57,822 [bic.py] => training => Task 1, Epoch 92/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.600
2024-10-17 19:37:58,786 [bic.py] => training => Task 1, Epoch 93/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.860
2024-10-17 19:37:59,747 [bic.py] => training => Task 1, Epoch 94/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.380
2024-10-17 19:38:00,712 [bic.py] => training => Task 1, Epoch 95/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.790
2024-10-17 19:38:01,657 [bic.py] => training => Task 1, Epoch 96/120 => Loss 0.650, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:38:02,608 [bic.py] => training => Task 1, Epoch 97/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.050
2024-10-17 19:38:03,562 [bic.py] => training => Task 1, Epoch 98/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.260
2024-10-17 19:38:04,604 [bic.py] => training => Task 1, Epoch 99/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.520
2024-10-17 19:38:05,637 [bic.py] => training => Task 1, Epoch 100/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.360
2024-10-17 19:38:06,751 [bic.py] => training => Task 1, Epoch 101/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.900
2024-10-17 19:38:07,790 [bic.py] => training => Task 1, Epoch 102/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.620
2024-10-17 19:38:08,738 [bic.py] => training => Task 1, Epoch 103/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:38:09,704 [bic.py] => training => Task 1, Epoch 104/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.360
2024-10-17 19:38:10,703 [bic.py] => training => Task 1, Epoch 105/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.000
2024-10-17 19:38:11,794 [bic.py] => training => Task 1, Epoch 106/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.980
2024-10-17 19:38:12,806 [bic.py] => training => Task 1, Epoch 107/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.670
2024-10-17 19:38:13,854 [bic.py] => training => Task 1, Epoch 108/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.620
2024-10-17 19:38:14,888 [bic.py] => training => Task 1, Epoch 109/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.810
2024-10-17 19:38:15,983 [bic.py] => training => Task 1, Epoch 110/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.500
2024-10-17 19:38:17,066 [bic.py] => training => Task 1, Epoch 111/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.520
2024-10-17 19:38:18,215 [bic.py] => training => Task 1, Epoch 112/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.140
2024-10-17 19:38:19,350 [bic.py] => training => Task 1, Epoch 113/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.790
2024-10-17 19:38:20,315 [bic.py] => training => Task 1, Epoch 114/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.140
2024-10-17 19:38:21,377 [bic.py] => training => Task 1, Epoch 115/120 => Loss 0.653, Train_accy 100.000, Test_accy 67.830
2024-10-17 19:38:22,411 [bic.py] => training => Task 1, Epoch 116/120 => Loss 0.652, Train_accy 100.000, Test_accy 68.120
2024-10-17 19:38:23,456 [bic.py] => training => Task 1, Epoch 117/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.570
2024-10-17 19:38:24,530 [bic.py] => training => Task 1, Epoch 118/120 => Loss 0.651, Train_accy 100.000, Test_accy 68.000
2024-10-17 19:38:25,612 [bic.py] => training => Task 1, Epoch 119/120 => Loss 0.652, Train_accy 100.000, Test_accy 67.790
2024-10-17 19:38:26,650 [bic.py] => training => Task 1, Epoch 120/120 => Loss 0.651, Train_accy 100.000, Test_accy 67.310
2024-10-17 19:38:26,844 [bic.py] => bias_correction => Task 1, Epoch 1/120 => Loss 1.476, Train_accy 84.290, Test_accy 67.480
2024-10-17 19:38:27,012 [bic.py] => bias_correction => Task 1, Epoch 2/120 => Loss 1.458, Train_accy 84.290, Test_accy 68.980
2024-10-17 19:38:27,182 [bic.py] => bias_correction => Task 1, Epoch 3/120 => Loss 1.422, Train_accy 91.430, Test_accy 72.210
2024-10-17 19:38:27,343 [bic.py] => bias_correction => Task 1, Epoch 4/120 => Loss 1.369, Train_accy 94.290, Test_accy 77.050
2024-10-17 19:38:27,507 [bic.py] => bias_correction => Task 1, Epoch 5/120 => Loss 1.312, Train_accy 97.140, Test_accy 79.810
2024-10-17 19:38:27,667 [bic.py] => bias_correction => Task 1, Epoch 6/120 => Loss 1.282, Train_accy 91.430, Test_accy 77.190
2024-10-17 19:38:27,839 [bic.py] => bias_correction => Task 1, Epoch 7/120 => Loss 1.312, Train_accy 82.860, Test_accy 73.380
2024-10-17 19:38:27,997 [bic.py] => bias_correction => Task 1, Epoch 8/120 => Loss 1.356, Train_accy 78.570, Test_accy 71.740
2024-10-17 19:38:28,166 [bic.py] => bias_correction => Task 1, Epoch 9/120 => Loss 1.373, Train_accy 81.430, Test_accy 72.760
2024-10-17 19:38:28,328 [bic.py] => bias_correction => Task 1, Epoch 10/120 => Loss 1.362, Train_accy 87.140, Test_accy 75.600
2024-10-17 19:38:28,511 [bic.py] => bias_correction => Task 1, Epoch 11/120 => Loss 1.326, Train_accy 94.290, Test_accy 78.430
2024-10-17 19:38:28,674 [bic.py] => bias_correction => Task 1, Epoch 12/120 => Loss 1.287, Train_accy 97.140, Test_accy 78.710
2024-10-17 19:38:28,846 [bic.py] => bias_correction => Task 1, Epoch 13/120 => Loss 1.281, Train_accy 91.430, Test_accy 75.380
2024-10-17 19:38:29,016 [bic.py] => bias_correction => Task 1, Epoch 14/120 => Loss 1.300, Train_accy 90.000, Test_accy 73.020
2024-10-17 19:38:29,218 [bic.py] => bias_correction => Task 1, Epoch 15/120 => Loss 1.318, Train_accy 90.000, Test_accy 71.760
2024-10-17 19:38:29,381 [bic.py] => bias_correction => Task 1, Epoch 16/120 => Loss 1.324, Train_accy 90.000, Test_accy 72.830
2024-10-17 19:38:29,559 [bic.py] => bias_correction => Task 1, Epoch 17/120 => Loss 1.317, Train_accy 91.430, Test_accy 74.310
2024-10-17 19:38:29,723 [bic.py] => bias_correction => Task 1, Epoch 18/120 => Loss 1.300, Train_accy 94.290, Test_accy 77.260
2024-10-17 19:38:29,893 [bic.py] => bias_correction => Task 1, Epoch 19/120 => Loss 1.282, Train_accy 95.710, Test_accy 79.170
2024-10-17 19:38:30,057 [bic.py] => bias_correction => Task 1, Epoch 20/120 => Loss 1.275, Train_accy 94.290, Test_accy 78.170
2024-10-17 19:38:30,226 [bic.py] => bias_correction => Task 1, Epoch 21/120 => Loss 1.284, Train_accy 92.860, Test_accy 77.900
2024-10-17 19:38:30,380 [bic.py] => bias_correction => Task 1, Epoch 22/120 => Loss 1.296, Train_accy 92.860, Test_accy 77.640
2024-10-17 19:38:30,553 [bic.py] => bias_correction => Task 1, Epoch 23/120 => Loss 1.297, Train_accy 92.860, Test_accy 78.140
2024-10-17 19:38:30,719 [bic.py] => bias_correction => Task 1, Epoch 24/120 => Loss 1.287, Train_accy 97.140, Test_accy 78.860
2024-10-17 19:38:30,897 [bic.py] => bias_correction => Task 1, Epoch 25/120 => Loss 1.276, Train_accy 94.290, Test_accy 78.900
2024-10-17 19:38:31,098 [bic.py] => bias_correction => Task 1, Epoch 26/120 => Loss 1.273, Train_accy 94.290, Test_accy 77.400
2024-10-17 19:38:31,269 [bic.py] => bias_correction => Task 1, Epoch 27/120 => Loss 1.277, Train_accy 91.430, Test_accy 76.400
2024-10-17 19:38:31,437 [bic.py] => bias_correction => Task 1, Epoch 28/120 => Loss 1.282, Train_accy 91.430, Test_accy 76.070
2024-10-17 19:38:31,614 [bic.py] => bias_correction => Task 1, Epoch 29/120 => Loss 1.283, Train_accy 92.860, Test_accy 76.600
2024-10-17 19:38:31,779 [bic.py] => bias_correction => Task 1, Epoch 30/120 => Loss 1.280, Train_accy 95.710, Test_accy 77.790
2024-10-17 19:38:31,948 [bic.py] => bias_correction => Task 1, Epoch 31/120 => Loss 1.274, Train_accy 94.290, Test_accy 78.930
2024-10-17 19:38:32,113 [bic.py] => bias_correction => Task 1, Epoch 32/120 => Loss 1.270, Train_accy 95.710, Test_accy 79.430
2024-10-17 19:38:32,279 [bic.py] => bias_correction => Task 1, Epoch 33/120 => Loss 1.270, Train_accy 95.710, Test_accy 79.120
2024-10-17 19:38:32,445 [bic.py] => bias_correction => Task 1, Epoch 34/120 => Loss 1.273, Train_accy 95.710, Test_accy 78.710
2024-10-17 19:38:32,620 [bic.py] => bias_correction => Task 1, Epoch 35/120 => Loss 1.275, Train_accy 95.710, Test_accy 79.020
2024-10-17 19:38:32,784 [bic.py] => bias_correction => Task 1, Epoch 36/120 => Loss 1.273, Train_accy 97.140, Test_accy 79.450
2024-10-17 19:38:32,957 [bic.py] => bias_correction => Task 1, Epoch 37/120 => Loss 1.270, Train_accy 95.710, Test_accy 79.600
2024-10-17 19:38:33,120 [bic.py] => bias_correction => Task 1, Epoch 38/120 => Loss 1.267, Train_accy 94.290, Test_accy 79.100
2024-10-17 19:38:33,290 [bic.py] => bias_correction => Task 1, Epoch 39/120 => Loss 1.267, Train_accy 95.710, Test_accy 78.690
2024-10-17 19:38:33,451 [bic.py] => bias_correction => Task 1, Epoch 40/120 => Loss 1.269, Train_accy 95.710, Test_accy 78.310
2024-10-17 19:38:33,615 [bic.py] => bias_correction => Task 1, Epoch 41/120 => Loss 1.269, Train_accy 95.710, Test_accy 78.480
2024-10-17 19:38:33,782 [bic.py] => bias_correction => Task 1, Epoch 42/120 => Loss 1.269, Train_accy 95.710, Test_accy 78.810
2024-10-17 19:38:33,947 [bic.py] => bias_correction => Task 1, Epoch 43/120 => Loss 1.267, Train_accy 94.290, Test_accy 79.400
2024-10-17 19:38:34,108 [bic.py] => bias_correction => Task 1, Epoch 44/120 => Loss 1.265, Train_accy 95.710, Test_accy 79.830
2024-10-17 19:38:34,272 [bic.py] => bias_correction => Task 1, Epoch 45/120 => Loss 1.265, Train_accy 95.710, Test_accy 79.860
2024-10-17 19:38:34,436 [bic.py] => bias_correction => Task 1, Epoch 46/120 => Loss 1.265, Train_accy 97.140, Test_accy 80.070
2024-10-17 19:38:34,609 [bic.py] => bias_correction => Task 1, Epoch 47/120 => Loss 1.266, Train_accy 97.140, Test_accy 80.120
2024-10-17 19:38:34,773 [bic.py] => bias_correction => Task 1, Epoch 48/120 => Loss 1.265, Train_accy 95.710, Test_accy 80.070
2024-10-17 19:38:34,943 [bic.py] => bias_correction => Task 1, Epoch 49/120 => Loss 1.264, Train_accy 95.710, Test_accy 80.020
2024-10-17 19:38:35,114 [bic.py] => bias_correction => Task 1, Epoch 50/120 => Loss 1.263, Train_accy 94.290, Test_accy 80.120
2024-10-17 19:38:35,276 [bic.py] => bias_correction => Task 1, Epoch 51/120 => Loss 1.263, Train_accy 94.290, Test_accy 79.520
2024-10-17 19:38:35,456 [bic.py] => bias_correction => Task 1, Epoch 52/120 => Loss 1.263, Train_accy 95.710, Test_accy 79.480
2024-10-17 19:38:35,624 [bic.py] => bias_correction => Task 1, Epoch 53/120 => Loss 1.263, Train_accy 95.710, Test_accy 79.550
2024-10-17 19:38:35,797 [bic.py] => bias_correction => Task 1, Epoch 54/120 => Loss 1.263, Train_accy 94.290, Test_accy 79.620
2024-10-17 19:38:35,963 [bic.py] => bias_correction => Task 1, Epoch 55/120 => Loss 1.262, Train_accy 94.290, Test_accy 79.950
2024-10-17 19:38:36,140 [bic.py] => bias_correction => Task 1, Epoch 56/120 => Loss 1.262, Train_accy 94.290, Test_accy 80.360
2024-10-17 19:38:36,304 [bic.py] => bias_correction => Task 1, Epoch 57/120 => Loss 1.261, Train_accy 95.710, Test_accy 80.290
2024-10-17 19:38:36,533 [bic.py] => bias_correction => Task 1, Epoch 58/120 => Loss 1.261, Train_accy 95.710, Test_accy 80.430
2024-10-17 19:38:36,719 [bic.py] => bias_correction => Task 1, Epoch 59/120 => Loss 1.261, Train_accy 95.710, Test_accy 80.400
2024-10-17 19:38:36,887 [bic.py] => bias_correction => Task 1, Epoch 60/120 => Loss 1.261, Train_accy 95.710, Test_accy 80.480
2024-10-17 19:38:37,055 [bic.py] => bias_correction => Task 1, Epoch 61/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.450
2024-10-17 19:38:37,225 [bic.py] => bias_correction => Task 1, Epoch 62/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.380
2024-10-17 19:38:37,393 [bic.py] => bias_correction => Task 1, Epoch 63/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.450
2024-10-17 19:38:37,556 [bic.py] => bias_correction => Task 1, Epoch 64/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.400
2024-10-17 19:38:37,727 [bic.py] => bias_correction => Task 1, Epoch 65/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.330
2024-10-17 19:38:37,889 [bic.py] => bias_correction => Task 1, Epoch 66/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.360
2024-10-17 19:38:38,054 [bic.py] => bias_correction => Task 1, Epoch 67/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.430
2024-10-17 19:38:38,225 [bic.py] => bias_correction => Task 1, Epoch 68/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.430
2024-10-17 19:38:38,392 [bic.py] => bias_correction => Task 1, Epoch 69/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.500
2024-10-17 19:38:38,560 [bic.py] => bias_correction => Task 1, Epoch 70/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.480
2024-10-17 19:38:38,733 [bic.py] => bias_correction => Task 1, Epoch 71/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.500
2024-10-17 19:38:38,906 [bic.py] => bias_correction => Task 1, Epoch 72/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.450
2024-10-17 19:38:39,071 [bic.py] => bias_correction => Task 1, Epoch 73/120 => Loss 1.260, Train_accy 95.710, Test_accy 80.430
2024-10-17 19:38:39,243 [bic.py] => bias_correction => Task 1, Epoch 74/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.380
2024-10-17 19:38:39,405 [bic.py] => bias_correction => Task 1, Epoch 75/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.330
2024-10-17 19:38:39,585 [bic.py] => bias_correction => Task 1, Epoch 76/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:39,751 [bic.py] => bias_correction => Task 1, Epoch 77/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:39,916 [bic.py] => bias_correction => Task 1, Epoch 78/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,073 [bic.py] => bias_correction => Task 1, Epoch 79/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,246 [bic.py] => bias_correction => Task 1, Epoch 80/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,408 [bic.py] => bias_correction => Task 1, Epoch 81/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,574 [bic.py] => bias_correction => Task 1, Epoch 82/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,736 [bic.py] => bias_correction => Task 1, Epoch 83/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.290
2024-10-17 19:38:40,903 [bic.py] => bias_correction => Task 1, Epoch 84/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.310
2024-10-17 19:38:41,063 [bic.py] => bias_correction => Task 1, Epoch 85/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.310
2024-10-17 19:38:41,227 [bic.py] => bias_correction => Task 1, Epoch 86/120 => Loss 1.260, Train_accy 94.290, Test_accy 80.330
2024-10-17 19:38:41,389 [bic.py] => bias_correction => Task 1, Epoch 87/120 => Loss 1.259, Train_accy 94.290, Test_accy 80.430
2024-10-17 19:38:41,552 [bic.py] => bias_correction => Task 1, Epoch 88/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.500
2024-10-17 19:38:41,711 [bic.py] => bias_correction => Task 1, Epoch 89/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.450
2024-10-17 19:38:41,868 [bic.py] => bias_correction => Task 1, Epoch 90/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.480
2024-10-17 19:38:42,031 [bic.py] => bias_correction => Task 1, Epoch 91/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.500
2024-10-17 19:38:42,192 [bic.py] => bias_correction => Task 1, Epoch 92/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.480
2024-10-17 19:38:42,358 [bic.py] => bias_correction => Task 1, Epoch 93/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.500
2024-10-17 19:38:42,517 [bic.py] => bias_correction => Task 1, Epoch 94/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.520
2024-10-17 19:38:42,686 [bic.py] => bias_correction => Task 1, Epoch 95/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.570
2024-10-17 19:38:42,850 [bic.py] => bias_correction => Task 1, Epoch 96/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,018 [bic.py] => bias_correction => Task 1, Epoch 97/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,178 [bic.py] => bias_correction => Task 1, Epoch 98/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,347 [bic.py] => bias_correction => Task 1, Epoch 99/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,510 [bic.py] => bias_correction => Task 1, Epoch 100/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,678 [bic.py] => bias_correction => Task 1, Epoch 101/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:43,842 [bic.py] => bias_correction => Task 1, Epoch 102/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,008 [bic.py] => bias_correction => Task 1, Epoch 103/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,171 [bic.py] => bias_correction => Task 1, Epoch 104/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,334 [bic.py] => bias_correction => Task 1, Epoch 105/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,498 [bic.py] => bias_correction => Task 1, Epoch 106/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,659 [bic.py] => bias_correction => Task 1, Epoch 107/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,819 [bic.py] => bias_correction => Task 1, Epoch 108/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:44,978 [bic.py] => bias_correction => Task 1, Epoch 109/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:45,148 [bic.py] => bias_correction => Task 1, Epoch 110/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:45,315 [bic.py] => bias_correction => Task 1, Epoch 111/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:45,481 [bic.py] => bias_correction => Task 1, Epoch 112/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:45,647 [bic.py] => bias_correction => Task 1, Epoch 113/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:45,821 [bic.py] => bias_correction => Task 1, Epoch 114/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,004 [bic.py] => bias_correction => Task 1, Epoch 115/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,168 [bic.py] => bias_correction => Task 1, Epoch 116/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,337 [bic.py] => bias_correction => Task 1, Epoch 117/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,525 [bic.py] => bias_correction => Task 1, Epoch 118/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,684 [bic.py] => bias_correction => Task 1, Epoch 119/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,850 [bic.py] => bias_correction => Task 1, Epoch 120/120 => Loss 1.259, Train_accy 95.710, Test_accy 80.550
2024-10-17 19:38:46,850 [base.py] => Reducing exemplars...(71 per classes)
2024-10-17 19:38:47,873 [base.py] => Constructing exemplars...(71 per classes)
2024-10-17 19:38:49,944 [bic.py] => Parameters of bias layer:
2024-10-17 19:38:49,945 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:38:49,945 [bic.py] => 1 => 0.579, -1.282
2024-10-17 19:38:49,946 [trainer.py] => All params: 3847499
2024-10-17 19:38:50,343 [bic.py] => Exemplar size: 497
2024-10-17 19:38:50,343 [trainer.py] => CNN: {'total': 80.55, '00-04': 78.3, '05-06': 86.17, 'old': 78.3, 'new': 86.17}
2024-10-17 19:38:50,343 [trainer.py] => NME: {'total': 77.07, '00-04': 69.97, '05-06': 94.83, 'old': 69.97, 'new': 94.83}
2024-10-17 19:38:50,344 [trainer.py] => CNN top1 curve: [89.93, 80.55]
2024-10-17 19:38:50,344 [trainer.py] => CNN top5 curve: [100.0, 99.02]
2024-10-17 19:38:50,344 [trainer.py] => NME top1 curve: [90.0, 77.07]
2024-10-17 19:38:50,344 [trainer.py] => NME top5 curve: [100.0, 99.14]

2024-10-17 19:38:50,344 [trainer.py] => Average Accuracy (CNN): 85.24000000000001
2024-10-17 19:38:50,344 [trainer.py] => Average Accuracy (NME): 83.535
2024-10-17 19:38:50,345 [trainer.py] => All params: 3847499
2024-10-17 19:38:50,346 [trainer.py] => Trainable params: 3847499
2024-10-17 19:38:50,347 [bic.py] => Learning on 7-9
2024-10-17 19:38:50,362 [bic.py] => Stage1 dset: 4434, Stage2 dset: 63
2024-10-17 19:38:50,363 [bic.py] => Lambda: 0.778
2024-10-17 19:38:50,372 [bic.py] => Parameters of bias layer:
2024-10-17 19:38:50,372 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:38:50,372 [bic.py] => 1 => 0.579, -1.282
2024-10-17 19:38:50,372 [bic.py] => 2 => 1.000, 0.000
2024-10-17 19:38:51,579 [bic.py] => training => Task 2, Epoch 1/120 => Loss 1.300, Train_accy 91.570, Test_accy 30.240
2024-10-17 19:38:52,759 [bic.py] => training => Task 2, Epoch 2/120 => Loss 1.114, Train_accy 96.550, Test_accy 45.980
2024-10-17 19:38:53,848 [bic.py] => training => Task 2, Epoch 3/120 => Loss 1.079, Train_accy 98.240, Test_accy 43.670
2024-10-17 19:38:54,972 [bic.py] => training => Task 2, Epoch 4/120 => Loss 1.058, Train_accy 99.480, Test_accy 51.780
2024-10-17 19:38:56,088 [bic.py] => training => Task 2, Epoch 5/120 => Loss 1.048, Train_accy 99.840, Test_accy 54.220
2024-10-17 19:38:57,249 [bic.py] => training => Task 2, Epoch 6/120 => Loss 1.044, Train_accy 99.980, Test_accy 57.740
2024-10-17 19:38:58,371 [bic.py] => training => Task 2, Epoch 7/120 => Loss 1.040, Train_accy 100.000, Test_accy 58.810
2024-10-17 19:38:59,428 [bic.py] => training => Task 2, Epoch 8/120 => Loss 1.038, Train_accy 100.000, Test_accy 58.220
2024-10-17 19:39:00,451 [bic.py] => training => Task 2, Epoch 9/120 => Loss 1.036, Train_accy 100.000, Test_accy 62.980
2024-10-17 19:39:01,683 [bic.py] => training => Task 2, Epoch 10/120 => Loss 1.036, Train_accy 99.950, Test_accy 60.090
2024-10-17 19:39:02,706 [bic.py] => training => Task 2, Epoch 11/120 => Loss 1.035, Train_accy 100.000, Test_accy 59.330
2024-10-17 19:39:03,733 [bic.py] => training => Task 2, Epoch 12/120 => Loss 1.033, Train_accy 99.980, Test_accy 61.190
2024-10-17 19:39:04,830 [bic.py] => training => Task 2, Epoch 13/120 => Loss 1.033, Train_accy 99.980, Test_accy 60.830
2024-10-17 19:39:05,960 [bic.py] => training => Task 2, Epoch 14/120 => Loss 1.033, Train_accy 100.000, Test_accy 61.760
2024-10-17 19:39:07,053 [bic.py] => training => Task 2, Epoch 15/120 => Loss 1.034, Train_accy 100.000, Test_accy 64.130
2024-10-17 19:39:08,223 [bic.py] => training => Task 2, Epoch 16/120 => Loss 1.032, Train_accy 99.980, Test_accy 64.390
2024-10-17 19:39:09,453 [bic.py] => training => Task 2, Epoch 17/120 => Loss 1.032, Train_accy 100.000, Test_accy 62.960
2024-10-17 19:39:10,592 [bic.py] => training => Task 2, Epoch 18/120 => Loss 1.031, Train_accy 100.000, Test_accy 59.810
2024-10-17 19:39:11,755 [bic.py] => training => Task 2, Epoch 19/120 => Loss 1.030, Train_accy 99.980, Test_accy 63.850
2024-10-17 19:39:12,770 [bic.py] => training => Task 2, Epoch 20/120 => Loss 1.032, Train_accy 99.950, Test_accy 60.960
2024-10-17 19:39:13,795 [bic.py] => training => Task 2, Epoch 21/120 => Loss 1.031, Train_accy 99.980, Test_accy 64.200
2024-10-17 19:39:14,804 [bic.py] => training => Task 2, Epoch 22/120 => Loss 1.031, Train_accy 99.980, Test_accy 66.190
2024-10-17 19:39:15,824 [bic.py] => training => Task 2, Epoch 23/120 => Loss 1.031, Train_accy 99.980, Test_accy 57.570
2024-10-17 19:39:16,931 [bic.py] => training => Task 2, Epoch 24/120 => Loss 1.030, Train_accy 99.980, Test_accy 58.810
2024-10-17 19:39:17,938 [bic.py] => training => Task 2, Epoch 25/120 => Loss 1.030, Train_accy 99.980, Test_accy 64.390
2024-10-17 19:39:19,044 [bic.py] => training => Task 2, Epoch 26/120 => Loss 1.029, Train_accy 100.000, Test_accy 63.610
2024-10-17 19:39:20,152 [bic.py] => training => Task 2, Epoch 27/120 => Loss 1.029, Train_accy 100.000, Test_accy 64.350
2024-10-17 19:39:21,253 [bic.py] => training => Task 2, Epoch 28/120 => Loss 1.030, Train_accy 100.000, Test_accy 60.410
2024-10-17 19:39:22,372 [bic.py] => training => Task 2, Epoch 29/120 => Loss 1.030, Train_accy 99.980, Test_accy 61.810
2024-10-17 19:39:23,530 [bic.py] => training => Task 2, Epoch 30/120 => Loss 1.028, Train_accy 100.000, Test_accy 66.720
2024-10-17 19:39:24,638 [bic.py] => training => Task 2, Epoch 31/120 => Loss 1.029, Train_accy 99.980, Test_accy 60.300
2024-10-17 19:39:25,748 [bic.py] => training => Task 2, Epoch 32/120 => Loss 1.029, Train_accy 100.000, Test_accy 64.020
2024-10-17 19:39:26,913 [bic.py] => training => Task 2, Epoch 33/120 => Loss 1.029, Train_accy 99.980, Test_accy 66.780
2024-10-17 19:39:27,927 [bic.py] => training => Task 2, Epoch 34/120 => Loss 1.029, Train_accy 99.980, Test_accy 58.460
2024-10-17 19:39:28,950 [bic.py] => training => Task 2, Epoch 35/120 => Loss 1.029, Train_accy 100.000, Test_accy 58.020
2024-10-17 19:39:29,957 [bic.py] => training => Task 2, Epoch 36/120 => Loss 1.029, Train_accy 100.000, Test_accy 57.090
2024-10-17 19:39:30,969 [bic.py] => training => Task 2, Epoch 37/120 => Loss 1.028, Train_accy 100.000, Test_accy 54.000
2024-10-17 19:39:32,093 [bic.py] => training => Task 2, Epoch 38/120 => Loss 1.029, Train_accy 100.000, Test_accy 61.780
2024-10-17 19:39:33,334 [bic.py] => training => Task 2, Epoch 39/120 => Loss 1.029, Train_accy 100.000, Test_accy 61.440
2024-10-17 19:39:34,456 [bic.py] => training => Task 2, Epoch 40/120 => Loss 1.029, Train_accy 100.000, Test_accy 61.800
2024-10-17 19:39:35,570 [bic.py] => training => Task 2, Epoch 41/120 => Loss 1.028, Train_accy 100.000, Test_accy 62.540
2024-10-17 19:39:36,656 [bic.py] => training => Task 2, Epoch 42/120 => Loss 1.030, Train_accy 99.980, Test_accy 65.390
2024-10-17 19:39:37,710 [bic.py] => training => Task 2, Epoch 43/120 => Loss 1.028, Train_accy 100.000, Test_accy 65.500
2024-10-17 19:39:38,801 [bic.py] => training => Task 2, Epoch 44/120 => Loss 1.028, Train_accy 100.000, Test_accy 58.780
2024-10-17 19:39:39,893 [bic.py] => training => Task 2, Epoch 45/120 => Loss 1.027, Train_accy 100.000, Test_accy 61.330
2024-10-17 19:39:40,915 [bic.py] => training => Task 2, Epoch 46/120 => Loss 1.029, Train_accy 100.000, Test_accy 64.330
2024-10-17 19:39:42,031 [bic.py] => training => Task 2, Epoch 47/120 => Loss 1.028, Train_accy 100.000, Test_accy 61.590
2024-10-17 19:39:43,149 [bic.py] => training => Task 2, Epoch 48/120 => Loss 1.029, Train_accy 100.000, Test_accy 57.110
2024-10-17 19:39:44,284 [bic.py] => training => Task 2, Epoch 49/120 => Loss 1.031, Train_accy 100.000, Test_accy 56.590
2024-10-17 19:39:45,426 [bic.py] => training => Task 2, Epoch 50/120 => Loss 1.029, Train_accy 100.000, Test_accy 65.200
2024-10-17 19:39:46,461 [bic.py] => training => Task 2, Epoch 51/120 => Loss 1.029, Train_accy 100.000, Test_accy 62.830
2024-10-17 19:39:47,668 [bic.py] => training => Task 2, Epoch 52/120 => Loss 1.029, Train_accy 100.000, Test_accy 53.930
2024-10-17 19:39:48,817 [bic.py] => training => Task 2, Epoch 53/120 => Loss 1.028, Train_accy 100.000, Test_accy 56.630
2024-10-17 19:39:49,928 [bic.py] => training => Task 2, Epoch 54/120 => Loss 1.028, Train_accy 99.980, Test_accy 56.390
2024-10-17 19:39:51,016 [bic.py] => training => Task 2, Epoch 55/120 => Loss 1.028, Train_accy 100.000, Test_accy 63.720
2024-10-17 19:39:52,228 [bic.py] => training => Task 2, Epoch 56/120 => Loss 1.028, Train_accy 99.950, Test_accy 59.460
2024-10-17 19:39:53,281 [bic.py] => training => Task 2, Epoch 57/120 => Loss 1.028, Train_accy 100.000, Test_accy 60.070
2024-10-17 19:39:54,291 [bic.py] => training => Task 2, Epoch 58/120 => Loss 1.028, Train_accy 100.000, Test_accy 55.460
2024-10-17 19:39:55,332 [bic.py] => training => Task 2, Epoch 59/120 => Loss 1.028, Train_accy 100.000, Test_accy 60.720
2024-10-17 19:39:56,363 [bic.py] => training => Task 2, Epoch 60/120 => Loss 1.029, Train_accy 100.000, Test_accy 63.440
2024-10-17 19:39:57,390 [bic.py] => training => Task 2, Epoch 61/120 => Loss 1.027, Train_accy 100.000, Test_accy 60.060
2024-10-17 19:39:58,575 [bic.py] => training => Task 2, Epoch 62/120 => Loss 1.026, Train_accy 100.000, Test_accy 61.170
2024-10-17 19:39:59,703 [bic.py] => training => Task 2, Epoch 63/120 => Loss 1.026, Train_accy 100.000, Test_accy 61.020
2024-10-17 19:40:00,812 [bic.py] => training => Task 2, Epoch 64/120 => Loss 1.026, Train_accy 100.000, Test_accy 60.540
2024-10-17 19:40:01,926 [bic.py] => training => Task 2, Epoch 65/120 => Loss 1.026, Train_accy 100.000, Test_accy 59.940
2024-10-17 19:40:03,067 [bic.py] => training => Task 2, Epoch 66/120 => Loss 1.026, Train_accy 100.000, Test_accy 59.980
2024-10-17 19:40:04,225 [bic.py] => training => Task 2, Epoch 67/120 => Loss 1.026, Train_accy 100.000, Test_accy 60.830
2024-10-17 19:40:05,329 [bic.py] => training => Task 2, Epoch 68/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.430
2024-10-17 19:40:06,472 [bic.py] => training => Task 2, Epoch 69/120 => Loss 1.025, Train_accy 100.000, Test_accy 61.280
2024-10-17 19:40:07,602 [bic.py] => training => Task 2, Epoch 70/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.670
2024-10-17 19:40:08,600 [bic.py] => training => Task 2, Epoch 71/120 => Loss 1.024, Train_accy 100.000, Test_accy 60.720
2024-10-17 19:40:09,718 [bic.py] => training => Task 2, Epoch 72/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.780
2024-10-17 19:40:10,930 [bic.py] => training => Task 2, Epoch 73/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.610
2024-10-17 19:40:12,111 [bic.py] => training => Task 2, Epoch 74/120 => Loss 1.025, Train_accy 100.000, Test_accy 61.720
2024-10-17 19:40:13,281 [bic.py] => training => Task 2, Epoch 75/120 => Loss 1.026, Train_accy 100.000, Test_accy 59.810
2024-10-17 19:40:14,408 [bic.py] => training => Task 2, Epoch 76/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.780
2024-10-17 19:40:15,523 [bic.py] => training => Task 2, Epoch 77/120 => Loss 1.026, Train_accy 100.000, Test_accy 61.110
2024-10-17 19:40:16,613 [bic.py] => training => Task 2, Epoch 78/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.020
2024-10-17 19:40:17,739 [bic.py] => training => Task 2, Epoch 79/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.130
2024-10-17 19:40:18,890 [bic.py] => training => Task 2, Epoch 80/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.390
2024-10-17 19:40:20,005 [bic.py] => training => Task 2, Epoch 81/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.780
2024-10-17 19:40:21,194 [bic.py] => training => Task 2, Epoch 82/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.130
2024-10-17 19:40:22,380 [bic.py] => training => Task 2, Epoch 83/120 => Loss 1.024, Train_accy 100.000, Test_accy 58.460
2024-10-17 19:40:23,525 [bic.py] => training => Task 2, Epoch 84/120 => Loss 1.026, Train_accy 100.000, Test_accy 60.500
2024-10-17 19:40:24,684 [bic.py] => training => Task 2, Epoch 85/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.980
2024-10-17 19:40:25,789 [bic.py] => training => Task 2, Epoch 86/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.740
2024-10-17 19:40:26,868 [bic.py] => training => Task 2, Epoch 87/120 => Loss 1.026, Train_accy 100.000, Test_accy 60.630
2024-10-17 19:40:27,903 [bic.py] => training => Task 2, Epoch 88/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.300
2024-10-17 19:40:28,954 [bic.py] => training => Task 2, Epoch 89/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.700
2024-10-17 19:40:29,977 [bic.py] => training => Task 2, Epoch 90/120 => Loss 1.026, Train_accy 100.000, Test_accy 62.040
2024-10-17 19:40:31,065 [bic.py] => training => Task 2, Epoch 91/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.630
2024-10-17 19:40:32,222 [bic.py] => training => Task 2, Epoch 92/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.590
2024-10-17 19:40:33,454 [bic.py] => training => Task 2, Epoch 93/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.200
2024-10-17 19:40:34,537 [bic.py] => training => Task 2, Epoch 94/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.460
2024-10-17 19:40:35,609 [bic.py] => training => Task 2, Epoch 95/120 => Loss 1.025, Train_accy 100.000, Test_accy 61.460
2024-10-17 19:40:36,632 [bic.py] => training => Task 2, Epoch 96/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.830
2024-10-17 19:40:37,684 [bic.py] => training => Task 2, Epoch 97/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.910
2024-10-17 19:40:38,834 [bic.py] => training => Task 2, Epoch 98/120 => Loss 1.025, Train_accy 100.000, Test_accy 58.850
2024-10-17 19:40:39,926 [bic.py] => training => Task 2, Epoch 99/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.540
2024-10-17 19:40:41,065 [bic.py] => training => Task 2, Epoch 100/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.020
2024-10-17 19:40:42,196 [bic.py] => training => Task 2, Epoch 101/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.800
2024-10-17 19:40:43,303 [bic.py] => training => Task 2, Epoch 102/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.240
2024-10-17 19:40:44,384 [bic.py] => training => Task 2, Epoch 103/120 => Loss 1.024, Train_accy 100.000, Test_accy 60.000
2024-10-17 19:40:45,503 [bic.py] => training => Task 2, Epoch 104/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.800
2024-10-17 19:40:46,593 [bic.py] => training => Task 2, Epoch 105/120 => Loss 1.026, Train_accy 100.000, Test_accy 61.500
2024-10-17 19:40:47,656 [bic.py] => training => Task 2, Epoch 106/120 => Loss 1.024, Train_accy 100.000, Test_accy 60.740
2024-10-17 19:40:48,753 [bic.py] => training => Task 2, Epoch 107/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.350
2024-10-17 19:40:49,883 [bic.py] => training => Task 2, Epoch 108/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.650
2024-10-17 19:40:50,996 [bic.py] => training => Task 2, Epoch 109/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.850
2024-10-17 19:40:52,084 [bic.py] => training => Task 2, Epoch 110/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.020
2024-10-17 19:40:53,190 [bic.py] => training => Task 2, Epoch 111/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.190
2024-10-17 19:40:54,259 [bic.py] => training => Task 2, Epoch 112/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.570
2024-10-17 19:40:55,332 [bic.py] => training => Task 2, Epoch 113/120 => Loss 1.024, Train_accy 100.000, Test_accy 59.810
2024-10-17 19:40:56,399 [bic.py] => training => Task 2, Epoch 114/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.670
2024-10-17 19:40:57,541 [bic.py] => training => Task 2, Epoch 115/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.240
2024-10-17 19:40:58,633 [bic.py] => training => Task 2, Epoch 116/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.200
2024-10-17 19:40:59,723 [bic.py] => training => Task 2, Epoch 117/120 => Loss 1.025, Train_accy 100.000, Test_accy 59.980
2024-10-17 19:41:00,818 [bic.py] => training => Task 2, Epoch 118/120 => Loss 1.025, Train_accy 100.000, Test_accy 60.480
2024-10-17 19:41:01,934 [bic.py] => training => Task 2, Epoch 119/120 => Loss 1.024, Train_accy 100.000, Test_accy 59.740
2024-10-17 19:41:03,005 [bic.py] => training => Task 2, Epoch 120/120 => Loss 1.026, Train_accy 100.000, Test_accy 60.810
2024-10-17 19:41:03,248 [bic.py] => bias_correction => Task 2, Epoch 1/120 => Loss 1.914, Train_accy 74.600, Test_accy 59.260
2024-10-17 19:41:03,459 [bic.py] => bias_correction => Task 2, Epoch 2/120 => Loss 1.898, Train_accy 74.600, Test_accy 58.760
2024-10-17 19:41:03,664 [bic.py] => bias_correction => Task 2, Epoch 3/120 => Loss 1.867, Train_accy 74.600, Test_accy 59.930
2024-10-17 19:41:03,877 [bic.py] => bias_correction => Task 2, Epoch 4/120 => Loss 1.816, Train_accy 82.540, Test_accy 63.540
2024-10-17 19:41:04,084 [bic.py] => bias_correction => Task 2, Epoch 5/120 => Loss 1.738, Train_accy 98.410, Test_accy 70.670
2024-10-17 19:41:04,294 [bic.py] => bias_correction => Task 2, Epoch 6/120 => Loss 1.635, Train_accy 93.650, Test_accy 71.560
2024-10-17 19:41:04,294 [base.py] => Reducing exemplars...(55 per classes)
2024-10-17 19:41:05,662 [base.py] => Constructing exemplars...(55 per classes)
2024-10-17 19:41:07,352 [bic.py] => Parameters of bias layer:
2024-10-17 19:41:07,353 [bic.py] => 0 => 1.000, 0.000
2024-10-17 19:41:07,353 [bic.py] => 1 => 0.579, -1.282
2024-10-17 19:41:07,353 [bic.py] => 2 => 0.238, -0.173
2024-10-17 19:41:07,354 [trainer.py] => All params: 3848527
2024-10-17 19:41:07,841 [bic.py] => Exemplar size: 495
2024-10-17 19:41:07,841 [trainer.py] => CNN: {'total': 71.56, '00-04': 74.23, '05-06': 74.33, '07-08': 62.08, 'old': 74.26, 'new': 62.08}
2024-10-17 19:41:07,841 [trainer.py] => NME: {'total': 73.3, '00-04': 63.63, '05-06': 74.42, '07-08': 96.33, 'old': 66.71, 'new': 96.33}
2024-10-17 19:41:07,841 [trainer.py] => CNN top1 curve: [89.93, 80.55, 71.56]
2024-10-17 19:41:07,841 [trainer.py] => CNN top5 curve: [100.0, 99.02, 96.59]
2024-10-17 19:41:07,841 [trainer.py] => NME top1 curve: [90.0, 77.07, 73.3]
2024-10-17 19:41:07,841 [trainer.py] => NME top5 curve: [100.0, 99.14, 97.91]

2024-10-17 19:41:07,841 [trainer.py] => Average Accuracy (CNN): 80.68
2024-10-17 19:41:07,841 [trainer.py] => Average Accuracy (NME): 80.12333333333333
2024-10-17 19:41:07,842 [trainer.py] => Forgetting (CNN): 13.770000000000003
