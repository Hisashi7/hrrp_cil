2024-10-31 10:38:16,524 [trainer.py] => config: ./exps/bic.json
2024-10-31 10:38:16,524 [trainer.py] => prefix: cil
2024-10-31 10:38:16,524 [trainer.py] => dataset: hrrp9
2024-10-31 10:38:16,524 [trainer.py] => memory_size: 400
2024-10-31 10:38:16,525 [trainer.py] => memory_per_class: 20
2024-10-31 10:38:16,525 [trainer.py] => fixed_memory: False
2024-10-31 10:38:16,525 [trainer.py] => shuffle: True
2024-10-31 10:38:16,525 [trainer.py] => init_cls: 5
2024-10-31 10:38:16,525 [trainer.py] => increment: 2
2024-10-31 10:38:16,525 [trainer.py] => model_name: bic
2024-10-31 10:38:16,525 [trainer.py] => convnet_type: resnet18
2024-10-31 10:38:16,525 [trainer.py] => device: [device(type='cuda', index=3)]
2024-10-31 10:38:16,525 [trainer.py] => init_train: False
2024-10-31 10:38:16,525 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_42503.pth
2024-10-31 10:38:16,525 [trainer.py] => fc_path2: checkpoints/init_train/fc_42503.pth
2024-10-31 10:38:16,525 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_35172.pth
2024-10-31 10:38:16,525 [trainer.py] => fc_path: checkpoints/init_train/fc_35172.pth
2024-10-31 10:38:16,525 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2024-10-31 10:38:16,525 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2024-10-31 10:38:16,525 [trainer.py] => seed: 2001
2024-10-31 10:38:16,525 [trainer.py] => init_epochs: 0
2024-10-31 10:38:16,525 [trainer.py] => epochs: 150
2024-10-31 10:38:16,525 [trainer.py] => lrate: 0.1
2024-10-31 10:38:16,525 [trainer.py] => milestones: [50, 80, 120]
2024-10-31 10:38:16,525 [trainer.py] => lrate_decay: 0.1
2024-10-31 10:38:16,525 [trainer.py] => momentum: 0.9
2024-10-31 10:38:16,525 [trainer.py] => batch_size: 128
2024-10-31 10:38:16,525 [trainer.py] => split_ratio: 0.1
2024-10-31 10:38:16,525 [trainer.py] => weight_decay: 0.0002
2024-10-31 10:38:16,526 [trainer.py] => num_workers: 0
2024-10-31 10:38:16,526 [trainer.py] => T: 2
2024-10-31 10:38:16,526 [trainer.py] => bc_lrate: 0.001
2024-10-31 10:38:16,526 [trainer.py] => bc_epochs: [100, 100, 9]
2024-10-31 10:38:17,168 [data_manager.py] => [3, 5, 1, 7, 2, 8, 6, 4, 0]
2024-10-31 10:38:17,607 [trainer.py] => All params: 3843904
2024-10-31 10:38:17,607 [trainer.py] => Trainable params: 3843904
2024-10-31 10:38:17,632 [bic.py] => Learning on 0-5
2024-10-31 10:38:17,669 [bic.py] => Parameters of bias layer:
2024-10-31 10:38:17,670 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:38:17,672 [base.py] => Reducing exemplars...(80 per classes)
2024-10-31 10:38:17,673 [base.py] => Constructing exemplars...(80 per classes)
2024-10-31 10:38:22,713 [bic.py] => Parameters of bias layer:
2024-10-31 10:38:22,714 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:38:22,715 [trainer.py] => All params: 3846471
2024-10-31 10:38:23,072 [bic.py] => Exemplar size: 400
2024-10-31 10:38:23,073 [trainer.py] => CNN: {'total': 90.13, '00-04': 90.13, 'old': 0, 'new': 90.13}
2024-10-31 10:38:23,073 [trainer.py] => NME: {'total': 89.53, '00-04': 89.53, 'old': 0, 'new': 89.53}
2024-10-31 10:38:23,073 [trainer.py] => CNN top1 curve: [90.13]
2024-10-31 10:38:23,073 [trainer.py] => CNN top5 curve: [100.0]
2024-10-31 10:38:23,073 [trainer.py] => NME top1 curve: [89.53]
2024-10-31 10:38:23,073 [trainer.py] => NME top5 curve: [100.0]

2024-10-31 10:38:23,073 [trainer.py] => Average Accuracy (CNN): 90.13
2024-10-31 10:38:23,073 [trainer.py] => Average Accuracy (NME): 89.53
2024-10-31 10:38:23,073 [trainer.py] => All params: 3846471
2024-10-31 10:38:23,074 [trainer.py] => Trainable params: 3846471
2024-10-31 10:38:23,074 [bic.py] => Learning on 5-7
2024-10-31 10:38:23,087 [bic.py] => Stage1 dset: 4344, Stage2 dset: 56
2024-10-31 10:38:23,087 [bic.py] => Lambda: 0.714
2024-10-31 10:38:23,100 [bic.py] => Parameters of bias layer:
2024-10-31 10:38:23,100 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:38:23,101 [bic.py] => 1 => 1.000, 0.000
2024-10-31 10:38:24,328 [bic.py] => training => Task 1, Epoch 1/150 => Loss 1.118, Train_accy 89.690, Test_accy 29.020
2024-10-31 10:38:25,312 [bic.py] => training => Task 1, Epoch 2/150 => Loss 0.833, Train_accy 98.760, Test_accy 60.500
2024-10-31 10:38:26,318 [bic.py] => training => Task 1, Epoch 3/150 => Loss 0.781, Train_accy 99.680, Test_accy 61.380
2024-10-31 10:38:27,329 [bic.py] => training => Task 1, Epoch 4/150 => Loss 0.761, Train_accy 99.860, Test_accy 63.930
2024-10-31 10:38:28,354 [bic.py] => training => Task 1, Epoch 5/150 => Loss 0.752, Train_accy 99.980, Test_accy 62.550
2024-10-31 10:38:29,349 [bic.py] => training => Task 1, Epoch 6/150 => Loss 0.748, Train_accy 100.000, Test_accy 65.930
2024-10-31 10:38:30,341 [bic.py] => training => Task 1, Epoch 7/150 => Loss 0.744, Train_accy 100.000, Test_accy 64.140
2024-10-31 10:38:31,288 [bic.py] => training => Task 1, Epoch 8/150 => Loss 0.744, Train_accy 100.000, Test_accy 65.760
2024-10-31 10:38:32,285 [bic.py] => training => Task 1, Epoch 9/150 => Loss 0.741, Train_accy 100.000, Test_accy 66.360
2024-10-31 10:38:33,266 [bic.py] => training => Task 1, Epoch 10/150 => Loss 0.742, Train_accy 100.000, Test_accy 67.100
2024-10-31 10:38:34,225 [bic.py] => training => Task 1, Epoch 11/150 => Loss 0.740, Train_accy 100.000, Test_accy 67.500
2024-10-31 10:38:35,219 [bic.py] => training => Task 1, Epoch 12/150 => Loss 0.739, Train_accy 100.000, Test_accy 68.550
2024-10-31 10:38:36,184 [bic.py] => training => Task 1, Epoch 13/150 => Loss 0.739, Train_accy 100.000, Test_accy 68.620
2024-10-31 10:38:37,190 [bic.py] => training => Task 1, Epoch 14/150 => Loss 0.739, Train_accy 100.000, Test_accy 68.640
2024-10-31 10:38:38,198 [bic.py] => training => Task 1, Epoch 15/150 => Loss 0.739, Train_accy 100.000, Test_accy 66.240
2024-10-31 10:38:39,216 [bic.py] => training => Task 1, Epoch 16/150 => Loss 0.738, Train_accy 100.000, Test_accy 69.640
2024-10-31 10:38:40,183 [bic.py] => training => Task 1, Epoch 17/150 => Loss 0.737, Train_accy 100.000, Test_accy 69.000
2024-10-31 10:38:41,151 [bic.py] => training => Task 1, Epoch 18/150 => Loss 0.737, Train_accy 100.000, Test_accy 70.950
2024-10-31 10:38:42,185 [bic.py] => training => Task 1, Epoch 19/150 => Loss 0.737, Train_accy 100.000, Test_accy 70.260
2024-10-31 10:38:43,193 [bic.py] => training => Task 1, Epoch 20/150 => Loss 0.739, Train_accy 100.000, Test_accy 65.690
2024-10-31 10:38:44,133 [bic.py] => training => Task 1, Epoch 21/150 => Loss 0.738, Train_accy 100.000, Test_accy 66.740
2024-10-31 10:38:45,138 [bic.py] => training => Task 1, Epoch 22/150 => Loss 0.736, Train_accy 100.000, Test_accy 68.260
2024-10-31 10:38:46,117 [bic.py] => training => Task 1, Epoch 23/150 => Loss 0.737, Train_accy 100.000, Test_accy 69.810
2024-10-31 10:38:47,096 [bic.py] => training => Task 1, Epoch 24/150 => Loss 0.736, Train_accy 100.000, Test_accy 70.260
2024-10-31 10:38:48,024 [bic.py] => training => Task 1, Epoch 25/150 => Loss 0.736, Train_accy 100.000, Test_accy 71.710
2024-10-31 10:38:48,991 [bic.py] => training => Task 1, Epoch 26/150 => Loss 0.735, Train_accy 100.000, Test_accy 70.900
2024-10-31 10:38:49,966 [bic.py] => training => Task 1, Epoch 27/150 => Loss 0.737, Train_accy 100.000, Test_accy 71.880
2024-10-31 10:38:50,965 [bic.py] => training => Task 1, Epoch 28/150 => Loss 0.737, Train_accy 100.000, Test_accy 67.500
2024-10-31 10:38:51,924 [bic.py] => training => Task 1, Epoch 29/150 => Loss 0.737, Train_accy 100.000, Test_accy 68.710
2024-10-31 10:38:52,882 [bic.py] => training => Task 1, Epoch 30/150 => Loss 0.736, Train_accy 100.000, Test_accy 72.600
2024-10-31 10:38:53,882 [bic.py] => training => Task 1, Epoch 31/150 => Loss 0.735, Train_accy 100.000, Test_accy 70.950
2024-10-31 10:38:54,856 [bic.py] => training => Task 1, Epoch 32/150 => Loss 0.735, Train_accy 100.000, Test_accy 70.790
2024-10-31 10:38:55,847 [bic.py] => training => Task 1, Epoch 33/150 => Loss 0.735, Train_accy 100.000, Test_accy 71.550
2024-10-31 10:38:56,842 [bic.py] => training => Task 1, Epoch 34/150 => Loss 0.736, Train_accy 100.000, Test_accy 72.120
2024-10-31 10:38:57,799 [bic.py] => training => Task 1, Epoch 35/150 => Loss 0.736, Train_accy 100.000, Test_accy 71.120
2024-10-31 10:38:58,820 [bic.py] => training => Task 1, Epoch 36/150 => Loss 0.736, Train_accy 100.000, Test_accy 70.400
2024-10-31 10:38:59,808 [bic.py] => training => Task 1, Epoch 37/150 => Loss 0.735, Train_accy 100.000, Test_accy 68.550
2024-10-31 10:39:00,803 [bic.py] => training => Task 1, Epoch 38/150 => Loss 0.735, Train_accy 100.000, Test_accy 66.120
2024-10-31 10:39:01,771 [bic.py] => training => Task 1, Epoch 39/150 => Loss 0.735, Train_accy 100.000, Test_accy 70.670
2024-10-31 10:39:02,776 [bic.py] => training => Task 1, Epoch 40/150 => Loss 0.734, Train_accy 100.000, Test_accy 71.880
2024-10-31 10:39:03,781 [bic.py] => training => Task 1, Epoch 41/150 => Loss 0.735, Train_accy 100.000, Test_accy 73.100
2024-10-31 10:39:04,760 [bic.py] => training => Task 1, Epoch 42/150 => Loss 0.735, Train_accy 100.000, Test_accy 72.640
2024-10-31 10:39:05,722 [bic.py] => training => Task 1, Epoch 43/150 => Loss 0.734, Train_accy 100.000, Test_accy 72.070
2024-10-31 10:39:06,699 [bic.py] => training => Task 1, Epoch 44/150 => Loss 0.734, Train_accy 100.000, Test_accy 72.760
2024-10-31 10:39:07,657 [bic.py] => training => Task 1, Epoch 45/150 => Loss 0.735, Train_accy 100.000, Test_accy 69.360
2024-10-31 10:39:08,674 [bic.py] => training => Task 1, Epoch 46/150 => Loss 0.735, Train_accy 100.000, Test_accy 71.140
2024-10-31 10:39:09,674 [bic.py] => training => Task 1, Epoch 47/150 => Loss 0.734, Train_accy 100.000, Test_accy 72.120
2024-10-31 10:39:10,645 [bic.py] => training => Task 1, Epoch 48/150 => Loss 0.734, Train_accy 100.000, Test_accy 69.810
2024-10-31 10:39:11,587 [bic.py] => training => Task 1, Epoch 49/150 => Loss 0.733, Train_accy 100.000, Test_accy 72.050
2024-10-31 10:39:12,498 [bic.py] => training => Task 1, Epoch 50/150 => Loss 0.734, Train_accy 100.000, Test_accy 68.020
2024-10-31 10:39:13,510 [bic.py] => training => Task 1, Epoch 51/150 => Loss 0.733, Train_accy 100.000, Test_accy 72.000
2024-10-31 10:39:14,456 [bic.py] => training => Task 1, Epoch 52/150 => Loss 0.732, Train_accy 100.000, Test_accy 72.710
2024-10-31 10:39:15,444 [bic.py] => training => Task 1, Epoch 53/150 => Loss 0.732, Train_accy 100.000, Test_accy 72.690
2024-10-31 10:39:16,421 [bic.py] => training => Task 1, Epoch 54/150 => Loss 0.732, Train_accy 100.000, Test_accy 73.360
2024-10-31 10:39:17,413 [bic.py] => training => Task 1, Epoch 55/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.020
2024-10-31 10:39:18,403 [bic.py] => training => Task 1, Epoch 56/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.710
2024-10-31 10:39:19,402 [bic.py] => training => Task 1, Epoch 57/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.950
2024-10-31 10:39:20,402 [bic.py] => training => Task 1, Epoch 58/150 => Loss 0.730, Train_accy 100.000, Test_accy 72.980
2024-10-31 10:39:21,399 [bic.py] => training => Task 1, Epoch 59/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.500
2024-10-31 10:39:22,482 [bic.py] => training => Task 1, Epoch 60/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.050
2024-10-31 10:39:23,465 [bic.py] => training => Task 1, Epoch 61/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.760
2024-10-31 10:39:24,629 [bic.py] => training => Task 1, Epoch 62/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.000
2024-10-31 10:39:25,661 [bic.py] => training => Task 1, Epoch 63/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.170
2024-10-31 10:39:26,722 [bic.py] => training => Task 1, Epoch 64/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.810
2024-10-31 10:39:27,737 [bic.py] => training => Task 1, Epoch 65/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.880
2024-10-31 10:39:28,739 [bic.py] => training => Task 1, Epoch 66/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.400
2024-10-31 10:39:29,740 [bic.py] => training => Task 1, Epoch 67/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.620
2024-10-31 10:39:30,756 [bic.py] => training => Task 1, Epoch 68/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.000
2024-10-31 10:39:31,811 [bic.py] => training => Task 1, Epoch 69/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.830
2024-10-31 10:39:32,818 [bic.py] => training => Task 1, Epoch 70/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.810
2024-10-31 10:39:33,846 [bic.py] => training => Task 1, Epoch 71/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.400
2024-10-31 10:39:34,841 [bic.py] => training => Task 1, Epoch 72/150 => Loss 0.731, Train_accy 100.000, Test_accy 72.860
2024-10-31 10:39:35,837 [bic.py] => training => Task 1, Epoch 73/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.430
2024-10-31 10:39:36,808 [bic.py] => training => Task 1, Epoch 74/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.520
2024-10-31 10:39:37,833 [bic.py] => training => Task 1, Epoch 75/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.400
2024-10-31 10:39:38,846 [bic.py] => training => Task 1, Epoch 76/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.120
2024-10-31 10:39:39,883 [bic.py] => training => Task 1, Epoch 77/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.550
2024-10-31 10:39:40,945 [bic.py] => training => Task 1, Epoch 78/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.620
2024-10-31 10:39:41,941 [bic.py] => training => Task 1, Epoch 79/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.380
2024-10-31 10:39:42,938 [bic.py] => training => Task 1, Epoch 80/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.760
2024-10-31 10:39:43,984 [bic.py] => training => Task 1, Epoch 81/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.710
2024-10-31 10:39:45,052 [bic.py] => training => Task 1, Epoch 82/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.880
2024-10-31 10:39:46,065 [bic.py] => training => Task 1, Epoch 83/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.550
2024-10-31 10:39:47,097 [bic.py] => training => Task 1, Epoch 84/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.290
2024-10-31 10:39:48,139 [bic.py] => training => Task 1, Epoch 85/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.620
2024-10-31 10:39:49,167 [bic.py] => training => Task 1, Epoch 86/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.830
2024-10-31 10:39:50,149 [bic.py] => training => Task 1, Epoch 87/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.190
2024-10-31 10:39:51,176 [bic.py] => training => Task 1, Epoch 88/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.500
2024-10-31 10:39:52,234 [bic.py] => training => Task 1, Epoch 89/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.640
2024-10-31 10:39:53,230 [bic.py] => training => Task 1, Epoch 90/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.710
2024-10-31 10:39:54,331 [bic.py] => training => Task 1, Epoch 91/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.380
2024-10-31 10:39:55,420 [bic.py] => training => Task 1, Epoch 92/150 => Loss 0.731, Train_accy 100.000, Test_accy 74.050
2024-10-31 10:39:56,440 [bic.py] => training => Task 1, Epoch 93/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.400
2024-10-31 10:39:57,607 [bic.py] => training => Task 1, Epoch 94/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.640
2024-10-31 10:39:58,635 [bic.py] => training => Task 1, Epoch 95/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.670
2024-10-31 10:39:59,650 [bic.py] => training => Task 1, Epoch 96/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.690
2024-10-31 10:40:00,679 [bic.py] => training => Task 1, Epoch 97/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.140
2024-10-31 10:40:01,731 [bic.py] => training => Task 1, Epoch 98/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.480
2024-10-31 10:40:02,669 [bic.py] => training => Task 1, Epoch 99/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.760
2024-10-31 10:40:03,709 [bic.py] => training => Task 1, Epoch 100/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.950
2024-10-31 10:40:04,657 [bic.py] => training => Task 1, Epoch 101/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.480
2024-10-31 10:40:05,604 [bic.py] => training => Task 1, Epoch 102/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.710
2024-10-31 10:40:06,638 [bic.py] => training => Task 1, Epoch 103/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.670
2024-10-31 10:40:07,678 [bic.py] => training => Task 1, Epoch 104/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.210
2024-10-31 10:40:08,740 [bic.py] => training => Task 1, Epoch 105/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.000
2024-10-31 10:40:09,777 [bic.py] => training => Task 1, Epoch 106/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.310
2024-10-31 10:40:10,831 [bic.py] => training => Task 1, Epoch 107/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.790
2024-10-31 10:40:11,842 [bic.py] => training => Task 1, Epoch 108/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.600
2024-10-31 10:40:12,842 [bic.py] => training => Task 1, Epoch 109/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.620
2024-10-31 10:40:13,885 [bic.py] => training => Task 1, Epoch 110/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.240
2024-10-31 10:40:14,898 [bic.py] => training => Task 1, Epoch 111/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.140
2024-10-31 10:40:15,888 [bic.py] => training => Task 1, Epoch 112/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.880
2024-10-31 10:40:16,907 [bic.py] => training => Task 1, Epoch 113/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.950
2024-10-31 10:40:17,904 [bic.py] => training => Task 1, Epoch 114/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.710
2024-10-31 10:40:18,913 [bic.py] => training => Task 1, Epoch 115/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.310
2024-10-31 10:40:19,967 [bic.py] => training => Task 1, Epoch 116/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.620
2024-10-31 10:40:21,033 [bic.py] => training => Task 1, Epoch 117/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.000
2024-10-31 10:40:22,111 [bic.py] => training => Task 1, Epoch 118/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.380
2024-10-31 10:40:23,133 [bic.py] => training => Task 1, Epoch 119/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.980
2024-10-31 10:40:24,173 [bic.py] => training => Task 1, Epoch 120/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.240
2024-10-31 10:40:25,238 [bic.py] => training => Task 1, Epoch 121/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.210
2024-10-31 10:40:26,214 [bic.py] => training => Task 1, Epoch 122/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.260
2024-10-31 10:40:27,384 [bic.py] => training => Task 1, Epoch 123/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.980
2024-10-31 10:40:28,420 [bic.py] => training => Task 1, Epoch 124/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.670
2024-10-31 10:40:29,469 [bic.py] => training => Task 1, Epoch 125/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.860
2024-10-31 10:40:30,456 [bic.py] => training => Task 1, Epoch 126/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.570
2024-10-31 10:40:31,471 [bic.py] => training => Task 1, Epoch 127/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.900
2024-10-31 10:40:32,467 [bic.py] => training => Task 1, Epoch 128/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.670
2024-10-31 10:40:33,448 [bic.py] => training => Task 1, Epoch 129/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.400
2024-10-31 10:40:34,482 [bic.py] => training => Task 1, Epoch 130/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.900
2024-10-31 10:40:35,567 [bic.py] => training => Task 1, Epoch 131/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.860
2024-10-31 10:40:36,616 [bic.py] => training => Task 1, Epoch 132/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.810
2024-10-31 10:40:37,732 [bic.py] => training => Task 1, Epoch 133/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.670
2024-10-31 10:40:38,764 [bic.py] => training => Task 1, Epoch 134/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.430
2024-10-31 10:40:39,782 [bic.py] => training => Task 1, Epoch 135/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.550
2024-10-31 10:40:40,836 [bic.py] => training => Task 1, Epoch 136/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.430
2024-10-31 10:40:41,921 [bic.py] => training => Task 1, Epoch 137/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.070
2024-10-31 10:40:42,951 [bic.py] => training => Task 1, Epoch 138/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.860
2024-10-31 10:40:43,973 [bic.py] => training => Task 1, Epoch 139/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.980
2024-10-31 10:40:44,938 [bic.py] => training => Task 1, Epoch 140/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.600
2024-10-31 10:40:45,980 [bic.py] => training => Task 1, Epoch 141/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.860
2024-10-31 10:40:46,995 [bic.py] => training => Task 1, Epoch 142/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.790
2024-10-31 10:40:48,038 [bic.py] => training => Task 1, Epoch 143/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.760
2024-10-31 10:40:49,003 [bic.py] => training => Task 1, Epoch 144/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.500
2024-10-31 10:40:50,020 [bic.py] => training => Task 1, Epoch 145/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.480
2024-10-31 10:40:51,040 [bic.py] => training => Task 1, Epoch 146/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.830
2024-10-31 10:40:52,092 [bic.py] => training => Task 1, Epoch 147/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.550
2024-10-31 10:40:53,017 [bic.py] => training => Task 1, Epoch 148/150 => Loss 0.730, Train_accy 100.000, Test_accy 73.600
2024-10-31 10:40:53,917 [bic.py] => training => Task 1, Epoch 149/150 => Loss 0.731, Train_accy 100.000, Test_accy 73.640
2024-10-31 10:40:54,838 [bic.py] => training => Task 1, Epoch 150/150 => Loss 0.730, Train_accy 100.000, Test_accy 74.310
2024-10-31 10:40:55,047 [bic.py] => bias_correction => Task 1, Epoch 1/100 => Loss 1.458, Train_accy 89.290, Test_accy 73.980
2024-10-31 10:40:55,216 [bic.py] => bias_correction => Task 1, Epoch 2/100 => Loss 1.444, Train_accy 89.290, Test_accy 74.430
2024-10-31 10:40:55,389 [bic.py] => bias_correction => Task 1, Epoch 3/100 => Loss 1.418, Train_accy 89.290, Test_accy 76.240
2024-10-31 10:40:55,550 [bic.py] => bias_correction => Task 1, Epoch 4/100 => Loss 1.380, Train_accy 91.070, Test_accy 79.020
2024-10-31 10:40:55,712 [bic.py] => bias_correction => Task 1, Epoch 5/100 => Loss 1.335, Train_accy 96.430, Test_accy 82.100
2024-10-31 10:40:55,870 [bic.py] => bias_correction => Task 1, Epoch 6/100 => Loss 1.291, Train_accy 98.210, Test_accy 82.760
2024-10-31 10:40:56,029 [bic.py] => bias_correction => Task 1, Epoch 7/100 => Loss 1.272, Train_accy 92.860, Test_accy 79.550
2024-10-31 10:40:56,187 [bic.py] => bias_correction => Task 1, Epoch 8/100 => Loss 1.303, Train_accy 87.500, Test_accy 74.950
2024-10-31 10:40:56,346 [bic.py] => bias_correction => Task 1, Epoch 9/100 => Loss 1.343, Train_accy 83.930, Test_accy 74.120
2024-10-31 10:40:56,504 [bic.py] => bias_correction => Task 1, Epoch 10/100 => Loss 1.351, Train_accy 89.290, Test_accy 77.000
2024-10-31 10:40:56,668 [bic.py] => bias_correction => Task 1, Epoch 11/100 => Loss 1.325, Train_accy 96.430, Test_accy 81.070
2024-10-31 10:40:56,827 [bic.py] => bias_correction => Task 1, Epoch 12/100 => Loss 1.285, Train_accy 98.210, Test_accy 82.310
2024-10-31 10:40:56,987 [bic.py] => bias_correction => Task 1, Epoch 13/100 => Loss 1.268, Train_accy 96.430, Test_accy 80.710
2024-10-31 10:40:57,150 [bic.py] => bias_correction => Task 1, Epoch 14/100 => Loss 1.277, Train_accy 94.640, Test_accy 78.790
2024-10-31 10:40:57,310 [bic.py] => bias_correction => Task 1, Epoch 15/100 => Loss 1.293, Train_accy 92.860, Test_accy 77.450
2024-10-31 10:40:57,468 [bic.py] => bias_correction => Task 1, Epoch 16/100 => Loss 1.303, Train_accy 92.860, Test_accy 76.740
2024-10-31 10:40:57,627 [bic.py] => bias_correction => Task 1, Epoch 17/100 => Loss 1.304, Train_accy 92.860, Test_accy 77.550
2024-10-31 10:40:57,789 [bic.py] => bias_correction => Task 1, Epoch 18/100 => Loss 1.297, Train_accy 96.430, Test_accy 78.860
2024-10-31 10:40:57,944 [bic.py] => bias_correction => Task 1, Epoch 19/100 => Loss 1.284, Train_accy 96.430, Test_accy 80.430
2024-10-31 10:40:58,112 [bic.py] => bias_correction => Task 1, Epoch 20/100 => Loss 1.271, Train_accy 98.210, Test_accy 81.740
2024-10-31 10:40:58,269 [bic.py] => bias_correction => Task 1, Epoch 21/100 => Loss 1.262, Train_accy 98.210, Test_accy 81.620
2024-10-31 10:40:58,427 [bic.py] => bias_correction => Task 1, Epoch 22/100 => Loss 1.264, Train_accy 96.430, Test_accy 81.170
2024-10-31 10:40:58,590 [bic.py] => bias_correction => Task 1, Epoch 23/100 => Loss 1.274, Train_accy 96.430, Test_accy 80.690
2024-10-31 10:40:58,752 [bic.py] => bias_correction => Task 1, Epoch 24/100 => Loss 1.279, Train_accy 96.430, Test_accy 81.140
2024-10-31 10:40:58,910 [bic.py] => bias_correction => Task 1, Epoch 25/100 => Loss 1.273, Train_accy 98.210, Test_accy 81.520
2024-10-31 10:40:59,073 [bic.py] => bias_correction => Task 1, Epoch 26/100 => Loss 1.263, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:40:59,232 [bic.py] => bias_correction => Task 1, Epoch 27/100 => Loss 1.258, Train_accy 98.210, Test_accy 81.140
2024-10-31 10:40:59,397 [bic.py] => bias_correction => Task 1, Epoch 28/100 => Loss 1.259, Train_accy 96.430, Test_accy 80.480
2024-10-31 10:40:59,558 [bic.py] => bias_correction => Task 1, Epoch 29/100 => Loss 1.262, Train_accy 96.430, Test_accy 80.050
2024-10-31 10:40:59,722 [bic.py] => bias_correction => Task 1, Epoch 30/100 => Loss 1.264, Train_accy 96.430, Test_accy 79.860
2024-10-31 10:40:59,885 [bic.py] => bias_correction => Task 1, Epoch 31/100 => Loss 1.264, Train_accy 96.430, Test_accy 80.170
2024-10-31 10:41:00,091 [bic.py] => bias_correction => Task 1, Epoch 32/100 => Loss 1.262, Train_accy 98.210, Test_accy 80.710
2024-10-31 10:41:00,247 [bic.py] => bias_correction => Task 1, Epoch 33/100 => Loss 1.258, Train_accy 98.210, Test_accy 81.360
2024-10-31 10:41:00,403 [bic.py] => bias_correction => Task 1, Epoch 34/100 => Loss 1.255, Train_accy 98.210, Test_accy 81.900
2024-10-31 10:41:00,565 [bic.py] => bias_correction => Task 1, Epoch 35/100 => Loss 1.253, Train_accy 98.210, Test_accy 81.790
2024-10-31 10:41:00,725 [bic.py] => bias_correction => Task 1, Epoch 36/100 => Loss 1.254, Train_accy 98.210, Test_accy 81.790
2024-10-31 10:41:00,882 [bic.py] => bias_correction => Task 1, Epoch 37/100 => Loss 1.256, Train_accy 98.210, Test_accy 81.690
2024-10-31 10:41:01,043 [bic.py] => bias_correction => Task 1, Epoch 38/100 => Loss 1.256, Train_accy 98.210, Test_accy 81.880
2024-10-31 10:41:01,200 [bic.py] => bias_correction => Task 1, Epoch 39/100 => Loss 1.254, Train_accy 98.210, Test_accy 81.930
2024-10-31 10:41:01,359 [bic.py] => bias_correction => Task 1, Epoch 40/100 => Loss 1.252, Train_accy 98.210, Test_accy 81.900
2024-10-31 10:41:01,523 [bic.py] => bias_correction => Task 1, Epoch 41/100 => Loss 1.251, Train_accy 98.210, Test_accy 81.760
2024-10-31 10:41:01,687 [bic.py] => bias_correction => Task 1, Epoch 42/100 => Loss 1.250, Train_accy 98.210, Test_accy 81.430
2024-10-31 10:41:01,851 [bic.py] => bias_correction => Task 1, Epoch 43/100 => Loss 1.251, Train_accy 98.210, Test_accy 81.260
2024-10-31 10:41:02,008 [bic.py] => bias_correction => Task 1, Epoch 44/100 => Loss 1.251, Train_accy 98.210, Test_accy 81.240
2024-10-31 10:41:02,165 [bic.py] => bias_correction => Task 1, Epoch 45/100 => Loss 1.251, Train_accy 98.210, Test_accy 81.290
2024-10-31 10:41:02,325 [bic.py] => bias_correction => Task 1, Epoch 46/100 => Loss 1.250, Train_accy 98.210, Test_accy 81.640
2024-10-31 10:41:02,487 [bic.py] => bias_correction => Task 1, Epoch 47/100 => Loss 1.249, Train_accy 98.210, Test_accy 81.950
2024-10-31 10:41:02,646 [bic.py] => bias_correction => Task 1, Epoch 48/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.100
2024-10-31 10:41:02,816 [bic.py] => bias_correction => Task 1, Epoch 49/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:03,002 [bic.py] => bias_correction => Task 1, Epoch 50/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:03,178 [bic.py] => bias_correction => Task 1, Epoch 51/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:03,335 [bic.py] => bias_correction => Task 1, Epoch 52/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:03,499 [bic.py] => bias_correction => Task 1, Epoch 53/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.190
2024-10-31 10:41:03,663 [bic.py] => bias_correction => Task 1, Epoch 54/100 => Loss 1.248, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:03,851 [bic.py] => bias_correction => Task 1, Epoch 55/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:04,057 [bic.py] => bias_correction => Task 1, Epoch 56/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.190
2024-10-31 10:41:04,229 [bic.py] => bias_correction => Task 1, Epoch 57/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:04,436 [bic.py] => bias_correction => Task 1, Epoch 58/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.140
2024-10-31 10:41:04,600 [bic.py] => bias_correction => Task 1, Epoch 59/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.210
2024-10-31 10:41:04,764 [bic.py] => bias_correction => Task 1, Epoch 60/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:04,931 [bic.py] => bias_correction => Task 1, Epoch 61/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.140
2024-10-31 10:41:05,095 [bic.py] => bias_correction => Task 1, Epoch 62/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.170
2024-10-31 10:41:05,250 [bic.py] => bias_correction => Task 1, Epoch 63/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.100
2024-10-31 10:41:05,407 [bic.py] => bias_correction => Task 1, Epoch 64/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.120
2024-10-31 10:41:05,576 [bic.py] => bias_correction => Task 1, Epoch 65/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.100
2024-10-31 10:41:05,728 [bic.py] => bias_correction => Task 1, Epoch 66/100 => Loss 1.247, Train_accy 98.210, Test_accy 82.070
2024-10-31 10:41:05,882 [bic.py] => bias_correction => Task 1, Epoch 67/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:06,040 [bic.py] => bias_correction => Task 1, Epoch 68/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.950
2024-10-31 10:41:06,196 [bic.py] => bias_correction => Task 1, Epoch 69/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:06,351 [bic.py] => bias_correction => Task 1, Epoch 70/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:06,521 [bic.py] => bias_correction => Task 1, Epoch 71/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:06,692 [bic.py] => bias_correction => Task 1, Epoch 72/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:06,855 [bic.py] => bias_correction => Task 1, Epoch 73/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,026 [bic.py] => bias_correction => Task 1, Epoch 74/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,185 [bic.py] => bias_correction => Task 1, Epoch 75/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,373 [bic.py] => bias_correction => Task 1, Epoch 76/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,532 [bic.py] => bias_correction => Task 1, Epoch 77/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,691 [bic.py] => bias_correction => Task 1, Epoch 78/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.020
2024-10-31 10:41:07,857 [bic.py] => bias_correction => Task 1, Epoch 79/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,011 [bic.py] => bias_correction => Task 1, Epoch 80/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,172 [bic.py] => bias_correction => Task 1, Epoch 81/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,329 [bic.py] => bias_correction => Task 1, Epoch 82/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,488 [bic.py] => bias_correction => Task 1, Epoch 83/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,651 [bic.py] => bias_correction => Task 1, Epoch 84/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:08,826 [bic.py] => bias_correction => Task 1, Epoch 85/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:09,020 [bic.py] => bias_correction => Task 1, Epoch 86/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:09,188 [bic.py] => bias_correction => Task 1, Epoch 87/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:09,357 [bic.py] => bias_correction => Task 1, Epoch 88/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:09,522 [bic.py] => bias_correction => Task 1, Epoch 89/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:09,698 [bic.py] => bias_correction => Task 1, Epoch 90/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:09,866 [bic.py] => bias_correction => Task 1, Epoch 91/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:10,029 [bic.py] => bias_correction => Task 1, Epoch 92/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:10,193 [bic.py] => bias_correction => Task 1, Epoch 93/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:10,354 [bic.py] => bias_correction => Task 1, Epoch 94/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:10,513 [bic.py] => bias_correction => Task 1, Epoch 95/100 => Loss 1.246, Train_accy 98.210, Test_accy 82.000
2024-10-31 10:41:10,676 [bic.py] => bias_correction => Task 1, Epoch 96/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:10,845 [bic.py] => bias_correction => Task 1, Epoch 97/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.980
2024-10-31 10:41:11,003 [bic.py] => bias_correction => Task 1, Epoch 98/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.950
2024-10-31 10:41:11,168 [bic.py] => bias_correction => Task 1, Epoch 99/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.950
2024-10-31 10:41:11,385 [bic.py] => bias_correction => Task 1, Epoch 100/100 => Loss 1.246, Train_accy 98.210, Test_accy 81.950
2024-10-31 10:41:11,385 [base.py] => Reducing exemplars...(57 per classes)
2024-10-31 10:41:12,349 [base.py] => Constructing exemplars...(57 per classes)
2024-10-31 10:41:14,335 [bic.py] => Parameters of bias layer:
2024-10-31 10:41:14,336 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:41:14,336 [bic.py] => 1 => 0.528, -1.309
2024-10-31 10:41:14,337 [trainer.py] => All params: 3847499
2024-10-31 10:41:14,804 [bic.py] => Exemplar size: 399
2024-10-31 10:41:14,804 [trainer.py] => CNN: {'total': 81.95, '00-04': 81.17, '05-06': 83.92, 'old': 81.17, 'new': 83.92}
2024-10-31 10:41:14,804 [trainer.py] => NME: {'total': 80.55, '00-04': 77.47, '05-06': 88.25, 'old': 77.47, 'new': 88.25}
2024-10-31 10:41:14,804 [trainer.py] => CNN top1 curve: [90.13, 81.95]
2024-10-31 10:41:14,804 [trainer.py] => CNN top5 curve: [100.0, 99.29]
2024-10-31 10:41:14,804 [trainer.py] => NME top1 curve: [89.53, 80.55]
2024-10-31 10:41:14,804 [trainer.py] => NME top5 curve: [100.0, 99.4]

2024-10-31 10:41:14,805 [trainer.py] => Average Accuracy (CNN): 86.03999999999999
2024-10-31 10:41:14,805 [trainer.py] => Average Accuracy (NME): 85.03999999999999
2024-10-31 10:41:14,805 [trainer.py] => All params: 3847499
2024-10-31 10:41:14,805 [trainer.py] => Trainable params: 3847499
2024-10-31 10:41:14,807 [bic.py] => Learning on 7-9
2024-10-31 10:41:14,820 [bic.py] => Stage1 dset: 4354, Stage2 dset: 45
2024-10-31 10:41:14,820 [bic.py] => Lambda: 0.778
2024-10-31 10:41:14,829 [bic.py] => Parameters of bias layer:
2024-10-31 10:41:14,830 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:41:14,830 [bic.py] => 1 => 0.528, -1.309
2024-10-31 10:41:14,830 [bic.py] => 2 => 1.000, 0.000
2024-10-31 10:41:16,011 [bic.py] => training => Task 2, Epoch 1/150 => Loss 1.280, Train_accy 52.040, Test_accy 19.390
2024-10-31 10:41:17,122 [bic.py] => training => Task 2, Epoch 2/150 => Loss 1.342, Train_accy 79.510, Test_accy 22.670
2024-10-31 10:41:18,289 [bic.py] => training => Task 2, Epoch 3/150 => Loss 1.273, Train_accy 27.840, Test_accy 10.940
2024-10-31 10:41:19,446 [bic.py] => training => Task 2, Epoch 4/150 => Loss 1.435, Train_accy 71.270, Test_accy 15.070
2024-10-31 10:41:20,568 [bic.py] => training => Task 2, Epoch 5/150 => Loss 1.357, Train_accy 87.920, Test_accy 19.110
2024-10-31 10:41:21,655 [bic.py] => training => Task 2, Epoch 6/150 => Loss 1.286, Train_accy 68.740, Test_accy 17.330
2024-10-31 10:41:22,782 [bic.py] => training => Task 2, Epoch 7/150 => Loss 1.309, Train_accy 87.510, Test_accy 25.090
2024-10-31 10:41:23,962 [bic.py] => training => Task 2, Epoch 8/150 => Loss 1.389, Train_accy 83.580, Test_accy 20.190
2024-10-31 10:41:25,086 [bic.py] => training => Task 2, Epoch 9/150 => Loss 1.293, Train_accy 89.480, Test_accy 21.800
2024-10-31 10:41:26,235 [bic.py] => training => Task 2, Epoch 10/150 => Loss 1.243, Train_accy 88.310, Test_accy 24.480
2024-10-31 10:41:27,257 [bic.py] => training => Task 2, Epoch 11/150 => Loss 1.268, Train_accy 70.950, Test_accy 29.150
2024-10-31 10:41:28,401 [bic.py] => training => Task 2, Epoch 12/150 => Loss 1.276, Train_accy 90.490, Test_accy 28.300
2024-10-31 10:41:29,580 [bic.py] => training => Task 2, Epoch 13/150 => Loss 1.209, Train_accy 92.990, Test_accy 33.520
2024-10-31 10:41:30,680 [bic.py] => training => Task 2, Epoch 14/150 => Loss 1.194, Train_accy 94.350, Test_accy 39.240
2024-10-31 10:41:31,843 [bic.py] => training => Task 2, Epoch 15/150 => Loss 1.178, Train_accy 73.700, Test_accy 24.460
2024-10-31 10:41:32,972 [bic.py] => training => Task 2, Epoch 16/150 => Loss 1.288, Train_accy 74.000, Test_accy 31.700
2024-10-31 10:41:34,100 [bic.py] => training => Task 2, Epoch 17/150 => Loss 1.241, Train_accy 91.200, Test_accy 30.330
2024-10-31 10:41:35,106 [bic.py] => training => Task 2, Epoch 18/150 => Loss 1.227, Train_accy 88.240, Test_accy 24.330
2024-10-31 10:41:36,118 [bic.py] => training => Task 2, Epoch 19/150 => Loss 1.189, Train_accy 94.300, Test_accy 38.800
2024-10-31 10:41:37,228 [bic.py] => training => Task 2, Epoch 20/150 => Loss 1.184, Train_accy 59.600, Test_accy 19.430
2024-10-31 10:41:38,357 [bic.py] => training => Task 2, Epoch 21/150 => Loss 1.276, Train_accy 91.590, Test_accy 29.070
2024-10-31 10:41:39,497 [bic.py] => training => Task 2, Epoch 22/150 => Loss 1.180, Train_accy 94.650, Test_accy 35.570
2024-10-31 10:41:40,648 [bic.py] => training => Task 2, Epoch 23/150 => Loss 1.146, Train_accy 97.180, Test_accy 42.220
2024-10-31 10:41:41,737 [bic.py] => training => Task 2, Epoch 24/150 => Loss 1.131, Train_accy 93.750, Test_accy 35.020
2024-10-31 10:41:42,883 [bic.py] => training => Task 2, Epoch 25/150 => Loss 1.206, Train_accy 78.850, Test_accy 34.810
2024-10-31 10:41:43,986 [bic.py] => training => Task 2, Epoch 26/150 => Loss 1.199, Train_accy 94.560, Test_accy 39.520
2024-10-31 10:41:45,151 [bic.py] => training => Task 2, Epoch 27/150 => Loss 1.145, Train_accy 98.190, Test_accy 47.780
2024-10-31 10:41:46,244 [bic.py] => training => Task 2, Epoch 28/150 => Loss 1.149, Train_accy 97.080, Test_accy 43.720
2024-10-31 10:41:47,327 [bic.py] => training => Task 2, Epoch 29/150 => Loss 1.150, Train_accy 96.550, Test_accy 40.890
2024-10-31 10:41:48,417 [bic.py] => training => Task 2, Epoch 30/150 => Loss 1.136, Train_accy 98.990, Test_accy 48.720
2024-10-31 10:41:49,514 [bic.py] => training => Task 2, Epoch 31/150 => Loss 1.140, Train_accy 99.310, Test_accy 51.960
2024-10-31 10:41:50,558 [bic.py] => training => Task 2, Epoch 32/150 => Loss 1.125, Train_accy 96.370, Test_accy 48.390
2024-10-31 10:41:51,600 [bic.py] => training => Task 2, Epoch 33/150 => Loss 1.159, Train_accy 98.420, Test_accy 45.890
2024-10-31 10:41:52,719 [bic.py] => training => Task 2, Epoch 34/150 => Loss 1.124, Train_accy 99.220, Test_accy 45.060
2024-10-31 10:41:53,824 [bic.py] => training => Task 2, Epoch 35/150 => Loss 1.096, Train_accy 99.860, Test_accy 50.690
2024-10-31 10:41:55,065 [bic.py] => training => Task 2, Epoch 36/150 => Loss 1.088, Train_accy 99.430, Test_accy 44.700
2024-10-31 10:41:56,176 [bic.py] => training => Task 2, Epoch 37/150 => Loss 1.092, Train_accy 99.890, Test_accy 53.930
2024-10-31 10:41:57,299 [bic.py] => training => Task 2, Epoch 38/150 => Loss 1.113, Train_accy 98.460, Test_accy 38.190
2024-10-31 10:41:58,417 [bic.py] => training => Task 2, Epoch 39/150 => Loss 1.157, Train_accy 91.410, Test_accy 50.060
2024-10-31 10:41:59,495 [bic.py] => training => Task 2, Epoch 40/150 => Loss 1.206, Train_accy 95.220, Test_accy 45.720
2024-10-31 10:42:00,576 [bic.py] => training => Task 2, Epoch 41/150 => Loss 1.144, Train_accy 94.670, Test_accy 38.630
2024-10-31 10:42:01,660 [bic.py] => training => Task 2, Epoch 42/150 => Loss 1.170, Train_accy 96.070, Test_accy 39.700
2024-10-31 10:42:02,770 [bic.py] => training => Task 2, Epoch 43/150 => Loss 1.113, Train_accy 98.160, Test_accy 45.540
2024-10-31 10:42:03,885 [bic.py] => training => Task 2, Epoch 44/150 => Loss 1.105, Train_accy 98.510, Test_accy 47.700
2024-10-31 10:42:04,947 [bic.py] => training => Task 2, Epoch 45/150 => Loss 1.137, Train_accy 98.300, Test_accy 54.630
2024-10-31 10:42:06,080 [bic.py] => training => Task 2, Epoch 46/150 => Loss 1.152, Train_accy 97.910, Test_accy 41.760
2024-10-31 10:42:07,245 [bic.py] => training => Task 2, Epoch 47/150 => Loss 1.179, Train_accy 98.600, Test_accy 50.200
2024-10-31 10:42:08,374 [bic.py] => training => Task 2, Epoch 48/150 => Loss 1.138, Train_accy 98.280, Test_accy 53.560
2024-10-31 10:42:09,501 [bic.py] => training => Task 2, Epoch 49/150 => Loss 1.098, Train_accy 99.770, Test_accy 49.740
2024-10-31 10:42:10,700 [bic.py] => training => Task 2, Epoch 50/150 => Loss 1.090, Train_accy 99.860, Test_accy 50.480
2024-10-31 10:42:11,840 [bic.py] => training => Task 2, Epoch 51/150 => Loss 1.088, Train_accy 99.910, Test_accy 52.570
2024-10-31 10:42:12,978 [bic.py] => training => Task 2, Epoch 52/150 => Loss 1.084, Train_accy 99.950, Test_accy 52.700
2024-10-31 10:42:14,158 [bic.py] => training => Task 2, Epoch 53/150 => Loss 1.077, Train_accy 99.950, Test_accy 55.070
2024-10-31 10:42:15,358 [bic.py] => training => Task 2, Epoch 54/150 => Loss 1.096, Train_accy 99.910, Test_accy 54.980
2024-10-31 10:42:16,433 [bic.py] => training => Task 2, Epoch 55/150 => Loss 1.108, Train_accy 99.770, Test_accy 48.700
2024-10-31 10:42:17,653 [bic.py] => training => Task 2, Epoch 56/150 => Loss 1.085, Train_accy 99.890, Test_accy 51.150
2024-10-31 10:42:18,720 [bic.py] => training => Task 2, Epoch 57/150 => Loss 1.079, Train_accy 99.950, Test_accy 51.940
2024-10-31 10:42:19,755 [bic.py] => training => Task 2, Epoch 58/150 => Loss 1.080, Train_accy 99.950, Test_accy 51.220
2024-10-31 10:42:20,808 [bic.py] => training => Task 2, Epoch 59/150 => Loss 1.079, Train_accy 99.930, Test_accy 49.930
2024-10-31 10:42:21,843 [bic.py] => training => Task 2, Epoch 60/150 => Loss 1.093, Train_accy 99.910, Test_accy 52.960
2024-10-31 10:42:22,953 [bic.py] => training => Task 2, Epoch 61/150 => Loss 1.080, Train_accy 99.860, Test_accy 51.540
2024-10-31 10:42:24,123 [bic.py] => training => Task 2, Epoch 62/150 => Loss 1.091, Train_accy 99.930, Test_accy 52.630
2024-10-31 10:42:25,325 [bic.py] => training => Task 2, Epoch 63/150 => Loss 1.098, Train_accy 99.930, Test_accy 55.130
2024-10-31 10:42:26,449 [bic.py] => training => Task 2, Epoch 64/150 => Loss 1.088, Train_accy 99.720, Test_accy 51.090
2024-10-31 10:42:27,610 [bic.py] => training => Task 2, Epoch 65/150 => Loss 1.077, Train_accy 99.910, Test_accy 51.410
2024-10-31 10:42:28,738 [bic.py] => training => Task 2, Epoch 66/150 => Loss 1.082, Train_accy 99.950, Test_accy 53.800
2024-10-31 10:42:29,853 [bic.py] => training => Task 2, Epoch 67/150 => Loss 1.088, Train_accy 99.930, Test_accy 54.560
2024-10-31 10:42:30,996 [bic.py] => training => Task 2, Epoch 68/150 => Loss 1.105, Train_accy 99.910, Test_accy 49.300
2024-10-31 10:42:32,156 [bic.py] => training => Task 2, Epoch 69/150 => Loss 1.093, Train_accy 99.540, Test_accy 51.910
2024-10-31 10:42:33,311 [bic.py] => training => Task 2, Epoch 70/150 => Loss 1.090, Train_accy 99.950, Test_accy 55.570
2024-10-31 10:42:34,609 [bic.py] => training => Task 2, Epoch 71/150 => Loss 1.078, Train_accy 99.950, Test_accy 52.650
2024-10-31 10:42:35,738 [bic.py] => training => Task 2, Epoch 72/150 => Loss 1.081, Train_accy 99.950, Test_accy 52.440
2024-10-31 10:42:36,907 [bic.py] => training => Task 2, Epoch 73/150 => Loss 1.084, Train_accy 99.950, Test_accy 53.430
2024-10-31 10:42:38,104 [bic.py] => training => Task 2, Epoch 74/150 => Loss 1.082, Train_accy 99.860, Test_accy 52.720
2024-10-31 10:42:39,283 [bic.py] => training => Task 2, Epoch 75/150 => Loss 1.075, Train_accy 99.930, Test_accy 51.940
2024-10-31 10:42:40,398 [bic.py] => training => Task 2, Epoch 76/150 => Loss 1.083, Train_accy 99.930, Test_accy 52.810
2024-10-31 10:42:41,523 [bic.py] => training => Task 2, Epoch 77/150 => Loss 1.077, Train_accy 99.950, Test_accy 53.370
2024-10-31 10:42:42,580 [bic.py] => training => Task 2, Epoch 78/150 => Loss 1.071, Train_accy 99.950, Test_accy 53.000
2024-10-31 10:42:43,679 [bic.py] => training => Task 2, Epoch 79/150 => Loss 1.077, Train_accy 99.950, Test_accy 52.870
2024-10-31 10:42:44,729 [bic.py] => training => Task 2, Epoch 80/150 => Loss 1.073, Train_accy 99.950, Test_accy 52.520
2024-10-31 10:42:45,908 [bic.py] => training => Task 2, Epoch 81/150 => Loss 1.082, Train_accy 99.980, Test_accy 53.850
2024-10-31 10:42:47,084 [bic.py] => training => Task 2, Epoch 82/150 => Loss 1.082, Train_accy 99.980, Test_accy 54.850
2024-10-31 10:42:48,210 [bic.py] => training => Task 2, Epoch 83/150 => Loss 1.078, Train_accy 99.950, Test_accy 52.940
2024-10-31 10:42:49,350 [bic.py] => training => Task 2, Epoch 84/150 => Loss 1.099, Train_accy 99.980, Test_accy 49.060
2024-10-31 10:42:50,513 [bic.py] => training => Task 2, Epoch 85/150 => Loss 1.064, Train_accy 99.980, Test_accy 54.940
2024-10-31 10:42:51,690 [bic.py] => training => Task 2, Epoch 86/150 => Loss 1.076, Train_accy 99.950, Test_accy 54.390
2024-10-31 10:42:52,835 [bic.py] => training => Task 2, Epoch 87/150 => Loss 1.073, Train_accy 99.950, Test_accy 52.720
2024-10-31 10:42:53,998 [bic.py] => training => Task 2, Epoch 88/150 => Loss 1.065, Train_accy 99.980, Test_accy 54.690
2024-10-31 10:42:55,176 [bic.py] => training => Task 2, Epoch 89/150 => Loss 1.071, Train_accy 99.980, Test_accy 55.200
2024-10-31 10:42:56,399 [bic.py] => training => Task 2, Epoch 90/150 => Loss 1.084, Train_accy 99.950, Test_accy 52.780
2024-10-31 10:42:57,553 [bic.py] => training => Task 2, Epoch 91/150 => Loss 1.071, Train_accy 99.980, Test_accy 53.520
2024-10-31 10:42:58,767 [bic.py] => training => Task 2, Epoch 92/150 => Loss 1.070, Train_accy 99.980, Test_accy 53.650
2024-10-31 10:42:59,944 [bic.py] => training => Task 2, Epoch 93/150 => Loss 1.071, Train_accy 99.980, Test_accy 53.460
2024-10-31 10:43:01,105 [bic.py] => training => Task 2, Epoch 94/150 => Loss 1.071, Train_accy 99.950, Test_accy 52.430
2024-10-31 10:43:02,202 [bic.py] => training => Task 2, Epoch 95/150 => Loss 1.073, Train_accy 99.980, Test_accy 54.090
2024-10-31 10:43:03,445 [bic.py] => training => Task 2, Epoch 96/150 => Loss 1.073, Train_accy 99.980, Test_accy 53.630
2024-10-31 10:43:04,654 [bic.py] => training => Task 2, Epoch 97/150 => Loss 1.066, Train_accy 99.980, Test_accy 48.260
2024-10-31 10:43:05,869 [bic.py] => training => Task 2, Epoch 98/150 => Loss 1.069, Train_accy 99.980, Test_accy 53.070
2024-10-31 10:43:07,130 [bic.py] => training => Task 2, Epoch 99/150 => Loss 1.072, Train_accy 99.980, Test_accy 52.610
2024-10-31 10:43:08,461 [bic.py] => training => Task 2, Epoch 100/150 => Loss 1.060, Train_accy 99.980, Test_accy 53.700
2024-10-31 10:43:09,755 [bic.py] => training => Task 2, Epoch 101/150 => Loss 1.071, Train_accy 99.980, Test_accy 52.830
2024-10-31 10:43:11,014 [bic.py] => training => Task 2, Epoch 102/150 => Loss 1.081, Train_accy 99.980, Test_accy 53.260
2024-10-31 10:43:12,339 [bic.py] => training => Task 2, Epoch 103/150 => Loss 1.067, Train_accy 99.950, Test_accy 53.930
2024-10-31 10:43:13,497 [bic.py] => training => Task 2, Epoch 104/150 => Loss 1.071, Train_accy 99.980, Test_accy 51.690
2024-10-31 10:43:14,809 [bic.py] => training => Task 2, Epoch 105/150 => Loss 1.100, Train_accy 99.980, Test_accy 51.150
2024-10-31 10:43:16,032 [bic.py] => training => Task 2, Epoch 106/150 => Loss 1.068, Train_accy 99.980, Test_accy 55.060
2024-10-31 10:43:17,332 [bic.py] => training => Task 2, Epoch 107/150 => Loss 1.072, Train_accy 99.950, Test_accy 56.500
2024-10-31 10:43:18,631 [bic.py] => training => Task 2, Epoch 108/150 => Loss 1.105, Train_accy 99.980, Test_accy 51.310
2024-10-31 10:43:19,787 [bic.py] => training => Task 2, Epoch 109/150 => Loss 1.077, Train_accy 99.950, Test_accy 55.070
2024-10-31 10:43:21,013 [bic.py] => training => Task 2, Epoch 110/150 => Loss 1.064, Train_accy 99.980, Test_accy 55.630
2024-10-31 10:43:22,328 [bic.py] => training => Task 2, Epoch 111/150 => Loss 1.072, Train_accy 99.980, Test_accy 54.220
2024-10-31 10:43:23,574 [bic.py] => training => Task 2, Epoch 112/150 => Loss 1.129, Train_accy 99.950, Test_accy 52.930
2024-10-31 10:43:24,870 [bic.py] => training => Task 2, Epoch 113/150 => Loss 1.071, Train_accy 99.980, Test_accy 54.440
2024-10-31 10:43:26,062 [bic.py] => training => Task 2, Epoch 114/150 => Loss 1.076, Train_accy 99.980, Test_accy 54.650
2024-10-31 10:43:27,285 [bic.py] => training => Task 2, Epoch 115/150 => Loss 1.081, Train_accy 99.980, Test_accy 54.650
2024-10-31 10:43:28,596 [bic.py] => training => Task 2, Epoch 116/150 => Loss 1.068, Train_accy 99.980, Test_accy 55.630
2024-10-31 10:43:29,839 [bic.py] => training => Task 2, Epoch 117/150 => Loss 1.070, Train_accy 99.950, Test_accy 57.890
2024-10-31 10:43:31,049 [bic.py] => training => Task 2, Epoch 118/150 => Loss 1.065, Train_accy 99.980, Test_accy 55.810
2024-10-31 10:43:32,292 [bic.py] => training => Task 2, Epoch 119/150 => Loss 1.074, Train_accy 99.980, Test_accy 54.630
2024-10-31 10:43:33,500 [bic.py] => training => Task 2, Epoch 120/150 => Loss 1.080, Train_accy 99.980, Test_accy 52.980
2024-10-31 10:43:34,674 [bic.py] => training => Task 2, Epoch 121/150 => Loss 1.072, Train_accy 99.950, Test_accy 55.150
2024-10-31 10:43:35,943 [bic.py] => training => Task 2, Epoch 122/150 => Loss 1.070, Train_accy 99.980, Test_accy 54.720
2024-10-31 10:43:37,260 [bic.py] => training => Task 2, Epoch 123/150 => Loss 1.071, Train_accy 99.950, Test_accy 55.020
2024-10-31 10:43:38,467 [bic.py] => training => Task 2, Epoch 124/150 => Loss 1.081, Train_accy 99.980, Test_accy 55.940
2024-10-31 10:43:39,623 [bic.py] => training => Task 2, Epoch 125/150 => Loss 1.063, Train_accy 99.980, Test_accy 55.740
2024-10-31 10:43:40,814 [bic.py] => training => Task 2, Epoch 126/150 => Loss 1.078, Train_accy 99.980, Test_accy 51.430
2024-10-31 10:43:42,056 [bic.py] => training => Task 2, Epoch 127/150 => Loss 1.119, Train_accy 99.980, Test_accy 54.390
2024-10-31 10:43:43,190 [bic.py] => training => Task 2, Epoch 128/150 => Loss 1.070, Train_accy 99.950, Test_accy 55.760
2024-10-31 10:43:44,302 [bic.py] => training => Task 2, Epoch 129/150 => Loss 1.080, Train_accy 99.930, Test_accy 54.720
2024-10-31 10:43:45,531 [bic.py] => training => Task 2, Epoch 130/150 => Loss 1.076, Train_accy 99.950, Test_accy 53.810
2024-10-31 10:43:46,765 [bic.py] => training => Task 2, Epoch 131/150 => Loss 1.077, Train_accy 99.930, Test_accy 55.110
2024-10-31 10:43:48,166 [bic.py] => training => Task 2, Epoch 132/150 => Loss 1.082, Train_accy 99.980, Test_accy 54.350
2024-10-31 10:43:49,426 [bic.py] => training => Task 2, Epoch 133/150 => Loss 1.071, Train_accy 99.980, Test_accy 55.110
2024-10-31 10:43:50,645 [bic.py] => training => Task 2, Epoch 134/150 => Loss 1.081, Train_accy 99.950, Test_accy 54.440
2024-10-31 10:43:51,797 [bic.py] => training => Task 2, Epoch 135/150 => Loss 1.079, Train_accy 99.950, Test_accy 55.310
2024-10-31 10:43:53,146 [bic.py] => training => Task 2, Epoch 136/150 => Loss 1.079, Train_accy 99.950, Test_accy 55.330
2024-10-31 10:43:54,443 [bic.py] => training => Task 2, Epoch 137/150 => Loss 1.077, Train_accy 99.980, Test_accy 56.690
2024-10-31 10:43:55,642 [bic.py] => training => Task 2, Epoch 138/150 => Loss 1.079, Train_accy 99.950, Test_accy 55.460
2024-10-31 10:43:56,774 [bic.py] => training => Task 2, Epoch 139/150 => Loss 1.074, Train_accy 99.950, Test_accy 55.760
2024-10-31 10:43:58,015 [bic.py] => training => Task 2, Epoch 140/150 => Loss 1.077, Train_accy 99.950, Test_accy 55.440
2024-10-31 10:43:59,276 [bic.py] => training => Task 2, Epoch 141/150 => Loss 1.071, Train_accy 99.980, Test_accy 55.810
2024-10-31 10:44:00,591 [bic.py] => training => Task 2, Epoch 142/150 => Loss 1.079, Train_accy 99.980, Test_accy 55.370
2024-10-31 10:44:01,812 [bic.py] => training => Task 2, Epoch 143/150 => Loss 1.079, Train_accy 99.980, Test_accy 55.240
2024-10-31 10:44:03,090 [bic.py] => training => Task 2, Epoch 144/150 => Loss 1.077, Train_accy 99.980, Test_accy 54.390
2024-10-31 10:44:04,491 [bic.py] => training => Task 2, Epoch 145/150 => Loss 1.142, Train_accy 99.930, Test_accy 52.190
2024-10-31 10:44:05,695 [bic.py] => training => Task 2, Epoch 146/150 => Loss 1.089, Train_accy 99.980, Test_accy 54.500
2024-10-31 10:44:06,915 [bic.py] => training => Task 2, Epoch 147/150 => Loss 1.114, Train_accy 99.950, Test_accy 53.070
2024-10-31 10:44:08,151 [bic.py] => training => Task 2, Epoch 148/150 => Loss 1.097, Train_accy 99.980, Test_accy 53.690
2024-10-31 10:44:09,328 [bic.py] => training => Task 2, Epoch 149/150 => Loss 1.086, Train_accy 99.980, Test_accy 52.190
2024-10-31 10:44:10,673 [bic.py] => training => Task 2, Epoch 150/150 => Loss 1.115, Train_accy 99.950, Test_accy 51.280
2024-10-31 10:44:10,956 [bic.py] => bias_correction => Task 2, Epoch 1/9 => Loss 1.962, Train_accy 68.890, Test_accy 48.870
2024-10-31 10:44:11,193 [bic.py] => bias_correction => Task 2, Epoch 2/9 => Loss 1.960, Train_accy 68.890, Test_accy 46.700
2024-10-31 10:44:11,488 [bic.py] => bias_correction => Task 2, Epoch 3/9 => Loss 1.956, Train_accy 64.440, Test_accy 45.480
2024-10-31 10:44:11,761 [bic.py] => bias_correction => Task 2, Epoch 4/9 => Loss 1.949, Train_accy 64.440, Test_accy 44.960
2024-10-31 10:44:12,013 [bic.py] => bias_correction => Task 2, Epoch 5/9 => Loss 1.939, Train_accy 68.890, Test_accy 45.060
2024-10-31 10:44:12,294 [bic.py] => bias_correction => Task 2, Epoch 6/9 => Loss 1.922, Train_accy 71.110, Test_accy 45.980
2024-10-31 10:44:12,548 [bic.py] => bias_correction => Task 2, Epoch 7/9 => Loss 1.896, Train_accy 71.110, Test_accy 48.240
2024-10-31 10:44:12,830 [bic.py] => bias_correction => Task 2, Epoch 8/9 => Loss 1.853, Train_accy 80.000, Test_accy 52.310
2024-10-31 10:44:13,093 [bic.py] => bias_correction => Task 2, Epoch 9/9 => Loss 1.786, Train_accy 86.670, Test_accy 56.410
2024-10-31 10:44:13,093 [base.py] => Reducing exemplars...(44 per classes)
2024-10-31 10:44:14,602 [base.py] => Constructing exemplars...(44 per classes)
2024-10-31 10:44:16,456 [bic.py] => Parameters of bias layer:
2024-10-31 10:44:16,456 [bic.py] => 0 => 1.000, 0.000
2024-10-31 10:44:16,456 [bic.py] => 1 => 0.528, -1.309
2024-10-31 10:44:16,456 [bic.py] => 2 => 0.294, -0.176
2024-10-31 10:44:16,457 [trainer.py] => All params: 3848527
2024-10-31 10:44:17,163 [bic.py] => Exemplar size: 396
2024-10-31 10:44:17,163 [trainer.py] => CNN: {'total': 56.41, '00-04': 52.13, '05-06': 51.0, '07-08': 72.5, 'old': 51.81, 'new': 72.5}
2024-10-31 10:44:17,163 [trainer.py] => NME: {'total': 63.46, '00-04': 58.43, '05-06': 54.83, '07-08': 84.67, 'old': 57.4, 'new': 84.67}
2024-10-31 10:44:17,163 [trainer.py] => CNN top1 curve: [90.13, 81.95, 56.41]
2024-10-31 10:44:17,164 [trainer.py] => CNN top5 curve: [100.0, 99.29, 89.54]
2024-10-31 10:44:17,164 [trainer.py] => NME top1 curve: [89.53, 80.55, 63.46]
2024-10-31 10:44:17,164 [trainer.py] => NME top5 curve: [100.0, 99.4, 95.35]

2024-10-31 10:44:17,164 [trainer.py] => Average Accuracy (CNN): 76.16333333333333
2024-10-31 10:44:17,164 [trainer.py] => Average Accuracy (NME): 77.84666666666666
2024-10-31 10:44:17,165 [trainer.py] => Forgetting (CNN): 35.459999999999994
