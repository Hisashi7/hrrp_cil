2024-10-23 19:56:40,021 [trainer.py] => config: ./exps/bic.json
2024-10-23 19:56:40,021 [trainer.py] => prefix: cil
2024-10-23 19:56:40,021 [trainer.py] => dataset: hrrp9
2024-10-23 19:56:40,022 [trainer.py] => memory_size: 200
2024-10-23 19:56:40,022 [trainer.py] => memory_per_class: 20
2024-10-23 19:56:40,022 [trainer.py] => fixed_memory: False
2024-10-23 19:56:40,022 [trainer.py] => shuffle: True
2024-10-23 19:56:40,022 [trainer.py] => init_cls: 5
2024-10-23 19:56:40,023 [trainer.py] => increment: 2
2024-10-23 19:56:40,023 [trainer.py] => model_name: bic
2024-10-23 19:56:40,023 [trainer.py] => convnet_type: resnet18
2024-10-23 19:56:40,023 [trainer.py] => device: [device(type='cuda', index=3)]
2024-10-23 19:56:40,023 [trainer.py] => init_train: False
2024-10-23 19:56:40,023 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 19:56:40,024 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 19:56:40,024 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 19:56:40,024 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 19:56:40,024 [trainer.py] => seed: 1993
2024-10-23 19:56:40,024 [trainer.py] => init_epochs: 0
2024-10-23 19:56:40,025 [trainer.py] => epochs: 150
2024-10-23 19:56:40,025 [trainer.py] => lrate: 0.1
2024-10-23 19:56:40,025 [trainer.py] => milestones: [50, 80, 120]
2024-10-23 19:56:40,025 [trainer.py] => lrate_decay: 0.1
2024-10-23 19:56:40,025 [trainer.py] => momentum: 0.9
2024-10-23 19:56:40,025 [trainer.py] => batch_size: 128
2024-10-23 19:56:40,026 [trainer.py] => split_ratio: 0.1
2024-10-23 19:56:40,026 [trainer.py] => weight_decay: 0.0002
2024-10-23 19:56:40,026 [trainer.py] => num_workers: 0
2024-10-23 19:56:40,026 [trainer.py] => T: 2
2024-10-23 19:56:40,026 [trainer.py] => bc_lrate: 0.001
2024-10-23 19:56:40,027 [trainer.py] => bc_epochs: [100, 100, 100]
2024-10-23 19:56:40,741 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 19:56:41,706 [trainer.py] => All params: 3843904
2024-10-23 19:56:41,707 [trainer.py] => Trainable params: 3843904
2024-10-23 19:56:41,710 [bic.py] => Learning on 0-5
2024-10-23 19:56:41,762 [bic.py] => Parameters of bias layer:
2024-10-23 19:56:41,763 [bic.py] => 0 => 1.000, 0.000
2024-10-23 19:56:41,964 [base.py] => Reducing exemplars...(40 per classes)
2024-10-23 19:56:41,964 [base.py] => Constructing exemplars...(40 per classes)
2024-10-23 19:56:46,571 [bic.py] => Parameters of bias layer:
2024-10-23 19:56:46,573 [bic.py] => 0 => 1.000, 0.000
2024-10-23 19:56:46,573 [trainer.py] => All params: 3846471
2024-10-23 19:56:46,966 [bic.py] => Exemplar size: 200
2024-10-23 19:56:46,966 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 19:56:46,966 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 19:56:46,966 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 19:56:46,966 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 19:56:46,967 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 19:56:46,967 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 19:56:46,967 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 19:56:46,967 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 19:56:46,967 [trainer.py] => All params: 3846471
2024-10-23 19:56:46,967 [trainer.py] => Trainable params: 3846471
2024-10-23 19:56:46,968 [bic.py] => Learning on 5-7
2024-10-23 19:56:46,977 [bic.py] => Stage1 dset: 4172, Stage2 dset: 28
2024-10-23 19:56:46,978 [bic.py] => Lambda: 0.714
2024-10-23 19:56:46,984 [bic.py] => Parameters of bias layer:
2024-10-23 19:56:46,984 [bic.py] => 0 => 1.000, 0.000
2024-10-23 19:56:46,984 [bic.py] => 1 => 1.000, 0.000
2024-10-23 19:56:48,290 [bic.py] => training => Task 1, Epoch 1/150 => Loss 1.059, Train_accy 89.600, Test_accy 26.980
2024-10-23 19:56:49,407 [bic.py] => training => Task 1, Epoch 2/150 => Loss 0.791, Train_accy 96.960, Test_accy 42.210
2024-10-23 19:56:50,446 [bic.py] => training => Task 1, Epoch 3/150 => Loss 0.736, Train_accy 98.490, Test_accy 45.860
2024-10-23 19:56:51,484 [bic.py] => training => Task 1, Epoch 4/150 => Loss 0.717, Train_accy 99.280, Test_accy 50.520
2024-10-23 19:56:52,471 [bic.py] => training => Task 1, Epoch 5/150 => Loss 0.706, Train_accy 99.710, Test_accy 52.500
2024-10-23 19:56:53,431 [bic.py] => training => Task 1, Epoch 6/150 => Loss 0.702, Train_accy 99.930, Test_accy 53.000
2024-10-23 19:56:54,475 [bic.py] => training => Task 1, Epoch 7/150 => Loss 0.698, Train_accy 99.980, Test_accy 51.190
2024-10-23 19:56:55,558 [bic.py] => training => Task 1, Epoch 8/150 => Loss 0.698, Train_accy 100.000, Test_accy 51.570
2024-10-23 19:56:56,760 [bic.py] => training => Task 1, Epoch 9/150 => Loss 0.694, Train_accy 100.000, Test_accy 52.450
2024-10-23 19:56:57,830 [bic.py] => training => Task 1, Epoch 10/150 => Loss 0.694, Train_accy 100.000, Test_accy 52.210
2024-10-23 19:56:58,931 [bic.py] => training => Task 1, Epoch 11/150 => Loss 0.694, Train_accy 100.000, Test_accy 53.210
2024-10-23 19:56:59,939 [bic.py] => training => Task 1, Epoch 12/150 => Loss 0.693, Train_accy 100.000, Test_accy 52.980
2024-10-23 19:57:00,900 [bic.py] => training => Task 1, Epoch 13/150 => Loss 0.692, Train_accy 100.000, Test_accy 52.900
2024-10-23 19:57:01,947 [bic.py] => training => Task 1, Epoch 14/150 => Loss 0.690, Train_accy 100.000, Test_accy 53.190
2024-10-23 19:57:03,017 [bic.py] => training => Task 1, Epoch 15/150 => Loss 0.691, Train_accy 100.000, Test_accy 52.790
2024-10-23 19:57:03,991 [bic.py] => training => Task 1, Epoch 16/150 => Loss 0.689, Train_accy 100.000, Test_accy 54.170
2024-10-23 19:57:05,023 [bic.py] => training => Task 1, Epoch 17/150 => Loss 0.691, Train_accy 100.000, Test_accy 54.100
2024-10-23 19:57:06,051 [bic.py] => training => Task 1, Epoch 18/150 => Loss 0.690, Train_accy 100.000, Test_accy 54.260
2024-10-23 19:57:07,176 [bic.py] => training => Task 1, Epoch 19/150 => Loss 0.691, Train_accy 100.000, Test_accy 53.950
2024-10-23 19:57:08,534 [bic.py] => training => Task 1, Epoch 20/150 => Loss 0.690, Train_accy 100.000, Test_accy 53.790
2024-10-23 19:57:09,743 [bic.py] => training => Task 1, Epoch 21/150 => Loss 0.689, Train_accy 100.000, Test_accy 55.740
2024-10-23 19:57:10,771 [bic.py] => training => Task 1, Epoch 22/150 => Loss 0.690, Train_accy 100.000, Test_accy 54.880
2024-10-23 19:57:11,730 [bic.py] => training => Task 1, Epoch 23/150 => Loss 0.689, Train_accy 100.000, Test_accy 54.980
2024-10-23 19:57:12,776 [bic.py] => training => Task 1, Epoch 24/150 => Loss 0.688, Train_accy 100.000, Test_accy 56.210
2024-10-23 19:57:13,733 [bic.py] => training => Task 1, Epoch 25/150 => Loss 0.688, Train_accy 100.000, Test_accy 54.310
2024-10-23 19:57:14,719 [bic.py] => training => Task 1, Epoch 26/150 => Loss 0.687, Train_accy 100.000, Test_accy 55.670
2024-10-23 19:57:15,769 [bic.py] => training => Task 1, Epoch 27/150 => Loss 0.687, Train_accy 100.000, Test_accy 56.790
2024-10-23 19:57:16,752 [bic.py] => training => Task 1, Epoch 28/150 => Loss 0.689, Train_accy 100.000, Test_accy 54.570
2024-10-23 19:57:17,813 [bic.py] => training => Task 1, Epoch 29/150 => Loss 0.690, Train_accy 100.000, Test_accy 54.210
2024-10-23 19:57:18,948 [bic.py] => training => Task 1, Epoch 30/150 => Loss 0.688, Train_accy 100.000, Test_accy 54.980
2024-10-23 19:57:20,034 [bic.py] => training => Task 1, Epoch 31/150 => Loss 0.690, Train_accy 100.000, Test_accy 54.360
2024-10-23 19:57:21,138 [bic.py] => training => Task 1, Epoch 32/150 => Loss 0.688, Train_accy 100.000, Test_accy 56.640
2024-10-23 19:57:22,271 [bic.py] => training => Task 1, Epoch 33/150 => Loss 0.687, Train_accy 100.000, Test_accy 55.380
2024-10-23 19:57:23,400 [bic.py] => training => Task 1, Epoch 34/150 => Loss 0.689, Train_accy 100.000, Test_accy 56.380
2024-10-23 19:57:24,499 [bic.py] => training => Task 1, Epoch 35/150 => Loss 0.688, Train_accy 100.000, Test_accy 56.120
2024-10-23 19:57:25,585 [bic.py] => training => Task 1, Epoch 36/150 => Loss 0.686, Train_accy 100.000, Test_accy 54.830
2024-10-23 19:57:26,637 [bic.py] => training => Task 1, Epoch 37/150 => Loss 0.690, Train_accy 100.000, Test_accy 57.070
2024-10-23 19:57:27,725 [bic.py] => training => Task 1, Epoch 38/150 => Loss 0.688, Train_accy 100.000, Test_accy 55.810
2024-10-23 19:57:28,770 [bic.py] => training => Task 1, Epoch 39/150 => Loss 0.689, Train_accy 100.000, Test_accy 54.380
2024-10-23 19:57:29,811 [bic.py] => training => Task 1, Epoch 40/150 => Loss 0.688, Train_accy 100.000, Test_accy 55.570
2024-10-23 19:57:30,947 [bic.py] => training => Task 1, Epoch 41/150 => Loss 0.686, Train_accy 100.000, Test_accy 56.260
2024-10-23 19:57:32,115 [bic.py] => training => Task 1, Epoch 42/150 => Loss 0.687, Train_accy 100.000, Test_accy 56.600
2024-10-23 19:57:33,229 [bic.py] => training => Task 1, Epoch 43/150 => Loss 0.687, Train_accy 100.000, Test_accy 55.430
2024-10-23 19:57:34,332 [bic.py] => training => Task 1, Epoch 44/150 => Loss 0.687, Train_accy 100.000, Test_accy 55.380
2024-10-23 19:57:35,446 [bic.py] => training => Task 1, Epoch 45/150 => Loss 0.687, Train_accy 100.000, Test_accy 55.140
2024-10-23 19:57:36,425 [bic.py] => training => Task 1, Epoch 46/150 => Loss 0.687, Train_accy 100.000, Test_accy 56.550
2024-10-23 19:57:37,396 [bic.py] => training => Task 1, Epoch 47/150 => Loss 0.689, Train_accy 100.000, Test_accy 56.290
2024-10-23 19:57:38,569 [bic.py] => training => Task 1, Epoch 48/150 => Loss 0.689, Train_accy 100.000, Test_accy 54.740
2024-10-23 19:57:39,689 [bic.py] => training => Task 1, Epoch 49/150 => Loss 0.688, Train_accy 100.000, Test_accy 55.290
2024-10-23 19:57:40,890 [bic.py] => training => Task 1, Epoch 50/150 => Loss 0.689, Train_accy 100.000, Test_accy 55.000
2024-10-23 19:57:41,952 [bic.py] => training => Task 1, Epoch 51/150 => Loss 0.687, Train_accy 100.000, Test_accy 56.600
2024-10-23 19:57:43,005 [bic.py] => training => Task 1, Epoch 52/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.500
2024-10-23 19:57:44,012 [bic.py] => training => Task 1, Epoch 53/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.690
2024-10-23 19:57:45,086 [bic.py] => training => Task 1, Epoch 54/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.480
2024-10-23 19:57:46,086 [bic.py] => training => Task 1, Epoch 55/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.520
2024-10-23 19:57:47,075 [bic.py] => training => Task 1, Epoch 56/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.790
2024-10-23 19:57:48,228 [bic.py] => training => Task 1, Epoch 57/150 => Loss 0.685, Train_accy 100.000, Test_accy 56.570
2024-10-23 19:57:49,353 [bic.py] => training => Task 1, Epoch 58/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.020
2024-10-23 19:57:50,458 [bic.py] => training => Task 1, Epoch 59/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.670
2024-10-23 19:57:51,553 [bic.py] => training => Task 1, Epoch 60/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:57:52,709 [bic.py] => training => Task 1, Epoch 61/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.830
2024-10-23 19:57:53,802 [bic.py] => training => Task 1, Epoch 62/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.430
2024-10-23 19:57:54,860 [bic.py] => training => Task 1, Epoch 63/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:57:55,912 [bic.py] => training => Task 1, Epoch 64/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.740
2024-10-23 19:57:56,962 [bic.py] => training => Task 1, Epoch 65/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.100
2024-10-23 19:57:58,017 [bic.py] => training => Task 1, Epoch 66/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.100
2024-10-23 19:57:59,074 [bic.py] => training => Task 1, Epoch 67/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.120
2024-10-23 19:58:00,198 [bic.py] => training => Task 1, Epoch 68/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.810
2024-10-23 19:58:01,332 [bic.py] => training => Task 1, Epoch 69/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.760
2024-10-23 19:58:02,716 [bic.py] => training => Task 1, Epoch 70/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.810
2024-10-23 19:58:03,815 [bic.py] => training => Task 1, Epoch 71/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.640
2024-10-23 19:58:05,104 [bic.py] => training => Task 1, Epoch 72/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.000
2024-10-23 19:58:06,382 [bic.py] => training => Task 1, Epoch 73/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.810
2024-10-23 19:58:07,530 [bic.py] => training => Task 1, Epoch 74/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.980
2024-10-23 19:58:08,538 [bic.py] => training => Task 1, Epoch 75/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.500
2024-10-23 19:58:09,692 [bic.py] => training => Task 1, Epoch 76/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.740
2024-10-23 19:58:10,799 [bic.py] => training => Task 1, Epoch 77/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.000
2024-10-23 19:58:11,880 [bic.py] => training => Task 1, Epoch 78/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.120
2024-10-23 19:58:12,909 [bic.py] => training => Task 1, Epoch 79/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.120
2024-10-23 19:58:14,074 [bic.py] => training => Task 1, Epoch 80/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.290
2024-10-23 19:58:15,155 [bic.py] => training => Task 1, Epoch 81/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.430
2024-10-23 19:58:16,353 [bic.py] => training => Task 1, Epoch 82/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.760
2024-10-23 19:58:17,483 [bic.py] => training => Task 1, Epoch 83/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.400
2024-10-23 19:58:18,539 [bic.py] => training => Task 1, Epoch 84/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.380
2024-10-23 19:58:19,608 [bic.py] => training => Task 1, Epoch 85/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.500
2024-10-23 19:58:20,688 [bic.py] => training => Task 1, Epoch 86/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.100
2024-10-23 19:58:21,738 [bic.py] => training => Task 1, Epoch 87/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.070
2024-10-23 19:58:22,803 [bic.py] => training => Task 1, Epoch 88/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.400
2024-10-23 19:58:23,844 [bic.py] => training => Task 1, Epoch 89/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.570
2024-10-23 19:58:24,894 [bic.py] => training => Task 1, Epoch 90/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.140
2024-10-23 19:58:25,953 [bic.py] => training => Task 1, Epoch 91/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:58:27,177 [bic.py] => training => Task 1, Epoch 92/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.500
2024-10-23 19:58:28,339 [bic.py] => training => Task 1, Epoch 93/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.050
2024-10-23 19:58:29,399 [bic.py] => training => Task 1, Epoch 94/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.050
2024-10-23 19:58:30,535 [bic.py] => training => Task 1, Epoch 95/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.400
2024-10-23 19:58:31,588 [bic.py] => training => Task 1, Epoch 96/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.520
2024-10-23 19:58:32,777 [bic.py] => training => Task 1, Epoch 97/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.900
2024-10-23 19:58:33,787 [bic.py] => training => Task 1, Epoch 98/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.290
2024-10-23 19:58:34,948 [bic.py] => training => Task 1, Epoch 99/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:58:36,071 [bic.py] => training => Task 1, Epoch 100/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:58:37,166 [bic.py] => training => Task 1, Epoch 101/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.310
2024-10-23 19:58:38,211 [bic.py] => training => Task 1, Epoch 102/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.450
2024-10-23 19:58:39,311 [bic.py] => training => Task 1, Epoch 103/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.570
2024-10-23 19:58:40,331 [bic.py] => training => Task 1, Epoch 104/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.190
2024-10-23 19:58:41,381 [bic.py] => training => Task 1, Epoch 105/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.450
2024-10-23 19:58:42,487 [bic.py] => training => Task 1, Epoch 106/150 => Loss 0.684, Train_accy 100.000, Test_accy 56.930
2024-10-23 19:58:43,492 [bic.py] => training => Task 1, Epoch 107/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.190
2024-10-23 19:58:44,458 [bic.py] => training => Task 1, Epoch 108/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.100
2024-10-23 19:58:45,452 [bic.py] => training => Task 1, Epoch 109/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:58:46,433 [bic.py] => training => Task 1, Epoch 110/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.380
2024-10-23 19:58:47,490 [bic.py] => training => Task 1, Epoch 111/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.430
2024-10-23 19:58:48,563 [bic.py] => training => Task 1, Epoch 112/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:58:49,627 [bic.py] => training => Task 1, Epoch 113/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.430
2024-10-23 19:58:50,674 [bic.py] => training => Task 1, Epoch 114/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.520
2024-10-23 19:58:51,750 [bic.py] => training => Task 1, Epoch 115/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.190
2024-10-23 19:58:52,858 [bic.py] => training => Task 1, Epoch 116/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.600
2024-10-23 19:58:54,043 [bic.py] => training => Task 1, Epoch 117/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.600
2024-10-23 19:58:55,182 [bic.py] => training => Task 1, Epoch 118/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.640
2024-10-23 19:58:56,285 [bic.py] => training => Task 1, Epoch 119/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.170
2024-10-23 19:58:57,359 [bic.py] => training => Task 1, Epoch 120/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.070
2024-10-23 19:58:58,415 [bic.py] => training => Task 1, Epoch 121/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.430
2024-10-23 19:58:59,445 [bic.py] => training => Task 1, Epoch 122/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.640
2024-10-23 19:59:00,539 [bic.py] => training => Task 1, Epoch 123/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.210
2024-10-23 19:59:01,619 [bic.py] => training => Task 1, Epoch 124/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.310
2024-10-23 19:59:02,743 [bic.py] => training => Task 1, Epoch 125/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.520
2024-10-23 19:59:03,834 [bic.py] => training => Task 1, Epoch 126/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.620
2024-10-23 19:59:04,961 [bic.py] => training => Task 1, Epoch 127/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.520
2024-10-23 19:59:06,077 [bic.py] => training => Task 1, Epoch 128/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.670
2024-10-23 19:59:07,247 [bic.py] => training => Task 1, Epoch 129/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.480
2024-10-23 19:59:08,310 [bic.py] => training => Task 1, Epoch 130/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.380
2024-10-23 19:59:09,361 [bic.py] => training => Task 1, Epoch 131/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.170
2024-10-23 19:59:10,363 [bic.py] => training => Task 1, Epoch 132/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.070
2024-10-23 19:59:11,561 [bic.py] => training => Task 1, Epoch 133/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.310
2024-10-23 19:59:12,628 [bic.py] => training => Task 1, Epoch 134/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.690
2024-10-23 19:59:13,848 [bic.py] => training => Task 1, Epoch 135/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.500
2024-10-23 19:59:14,958 [bic.py] => training => Task 1, Epoch 136/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.290
2024-10-23 19:59:16,199 [bic.py] => training => Task 1, Epoch 137/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.520
2024-10-23 19:59:17,255 [bic.py] => training => Task 1, Epoch 138/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.190
2024-10-23 19:59:18,268 [bic.py] => training => Task 1, Epoch 139/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.830
2024-10-23 19:59:19,377 [bic.py] => training => Task 1, Epoch 140/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.500
2024-10-23 19:59:20,615 [bic.py] => training => Task 1, Epoch 141/150 => Loss 0.683, Train_accy 100.000, Test_accy 56.980
2024-10-23 19:59:21,777 [bic.py] => training => Task 1, Epoch 142/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.100
2024-10-23 19:59:22,835 [bic.py] => training => Task 1, Epoch 143/150 => Loss 0.684, Train_accy 100.000, Test_accy 57.400
2024-10-23 19:59:23,956 [bic.py] => training => Task 1, Epoch 144/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.240
2024-10-23 19:59:25,045 [bic.py] => training => Task 1, Epoch 145/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.570
2024-10-23 19:59:26,287 [bic.py] => training => Task 1, Epoch 146/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.360
2024-10-23 19:59:27,409 [bic.py] => training => Task 1, Epoch 147/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.450
2024-10-23 19:59:28,456 [bic.py] => training => Task 1, Epoch 148/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.450
2024-10-23 19:59:29,514 [bic.py] => training => Task 1, Epoch 149/150 => Loss 0.683, Train_accy 100.000, Test_accy 57.170
2024-10-23 19:59:30,779 [bic.py] => training => Task 1, Epoch 150/150 => Loss 0.682, Train_accy 100.000, Test_accy 57.000
2024-10-23 19:59:31,045 [bic.py] => bias_correction => Task 1, Epoch 1/150 => Loss 1.637, Train_accy 60.710, Test_accy 58.190
2024-10-23 19:59:31,238 [bic.py] => bias_correction => Task 1, Epoch 2/150 => Loss 1.617, Train_accy 64.290, Test_accy 60.400
2024-10-23 19:59:31,419 [bic.py] => bias_correction => Task 1, Epoch 3/150 => Loss 1.575, Train_accy 78.570, Test_accy 65.450
2024-10-23 19:59:31,605 [bic.py] => bias_correction => Task 1, Epoch 4/150 => Loss 1.503, Train_accy 82.140, Test_accy 72.380
2024-10-23 19:59:31,799 [bic.py] => bias_correction => Task 1, Epoch 5/150 => Loss 1.403, Train_accy 92.860, Test_accy 75.980
2024-10-23 19:59:31,993 [bic.py] => bias_correction => Task 1, Epoch 6/150 => Loss 1.356, Train_accy 82.140, Test_accy 71.600
2024-10-23 19:59:32,181 [bic.py] => bias_correction => Task 1, Epoch 7/150 => Loss 1.407, Train_accy 71.430, Test_accy 65.860
2024-10-23 19:59:32,372 [bic.py] => bias_correction => Task 1, Epoch 8/150 => Loss 1.443, Train_accy 71.430, Test_accy 63.600
2024-10-23 19:59:32,563 [bic.py] => bias_correction => Task 1, Epoch 9/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.520
2024-10-23 19:59:32,750 [bic.py] => bias_correction => Task 1, Epoch 10/150 => Loss 1.460, Train_accy 71.430, Test_accy 63.500
2024-10-23 19:59:32,943 [bic.py] => bias_correction => Task 1, Epoch 11/150 => Loss 1.461, Train_accy 71.430, Test_accy 63.550
2024-10-23 19:59:33,132 [bic.py] => bias_correction => Task 1, Epoch 12/150 => Loss 1.462, Train_accy 71.430, Test_accy 63.570
2024-10-23 19:59:33,328 [bic.py] => bias_correction => Task 1, Epoch 13/150 => Loss 1.461, Train_accy 71.430, Test_accy 63.520
2024-10-23 19:59:33,514 [bic.py] => bias_correction => Task 1, Epoch 14/150 => Loss 1.461, Train_accy 71.430, Test_accy 63.520
2024-10-23 19:59:33,784 [bic.py] => bias_correction => Task 1, Epoch 15/150 => Loss 1.460, Train_accy 71.430, Test_accy 63.550
2024-10-23 19:59:34,110 [bic.py] => bias_correction => Task 1, Epoch 16/150 => Loss 1.460, Train_accy 71.430, Test_accy 63.550
2024-10-23 19:59:34,394 [bic.py] => bias_correction => Task 1, Epoch 17/150 => Loss 1.459, Train_accy 71.430, Test_accy 63.500
2024-10-23 19:59:34,588 [bic.py] => bias_correction => Task 1, Epoch 18/150 => Loss 1.459, Train_accy 71.430, Test_accy 63.480
2024-10-23 19:59:34,774 [bic.py] => bias_correction => Task 1, Epoch 19/150 => Loss 1.459, Train_accy 71.430, Test_accy 63.430
2024-10-23 19:59:34,964 [bic.py] => bias_correction => Task 1, Epoch 20/150 => Loss 1.458, Train_accy 71.430, Test_accy 63.430
2024-10-23 19:59:35,163 [bic.py] => bias_correction => Task 1, Epoch 21/150 => Loss 1.458, Train_accy 71.430, Test_accy 63.430
2024-10-23 19:59:35,357 [bic.py] => bias_correction => Task 1, Epoch 22/150 => Loss 1.458, Train_accy 71.430, Test_accy 63.380
2024-10-23 19:59:35,545 [bic.py] => bias_correction => Task 1, Epoch 23/150 => Loss 1.458, Train_accy 71.430, Test_accy 63.380
2024-10-23 19:59:35,746 [bic.py] => bias_correction => Task 1, Epoch 24/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.450
2024-10-23 19:59:35,946 [bic.py] => bias_correction => Task 1, Epoch 25/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.400
2024-10-23 19:59:36,131 [bic.py] => bias_correction => Task 1, Epoch 26/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.330
2024-10-23 19:59:36,314 [bic.py] => bias_correction => Task 1, Epoch 27/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.310
2024-10-23 19:59:36,501 [bic.py] => bias_correction => Task 1, Epoch 28/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.290
2024-10-23 19:59:36,690 [bic.py] => bias_correction => Task 1, Epoch 29/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.290
2024-10-23 19:59:36,890 [bic.py] => bias_correction => Task 1, Epoch 30/150 => Loss 1.457, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:37,092 [bic.py] => bias_correction => Task 1, Epoch 31/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:37,278 [bic.py] => bias_correction => Task 1, Epoch 32/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:37,470 [bic.py] => bias_correction => Task 1, Epoch 33/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:37,775 [bic.py] => bias_correction => Task 1, Epoch 34/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:38,050 [bic.py] => bias_correction => Task 1, Epoch 35/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.240
2024-10-23 19:59:38,281 [bic.py] => bias_correction => Task 1, Epoch 36/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.240
2024-10-23 19:59:38,506 [bic.py] => bias_correction => Task 1, Epoch 37/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.240
2024-10-23 19:59:38,717 [bic.py] => bias_correction => Task 1, Epoch 38/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:38,919 [bic.py] => bias_correction => Task 1, Epoch 39/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:39,140 [bic.py] => bias_correction => Task 1, Epoch 40/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.210
2024-10-23 19:59:39,319 [bic.py] => bias_correction => Task 1, Epoch 41/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:39,514 [bic.py] => bias_correction => Task 1, Epoch 42/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:39,709 [bic.py] => bias_correction => Task 1, Epoch 43/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:39,893 [bic.py] => bias_correction => Task 1, Epoch 44/150 => Loss 1.456, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:40,076 [bic.py] => bias_correction => Task 1, Epoch 45/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:40,295 [bic.py] => bias_correction => Task 1, Epoch 46/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:40,502 [bic.py] => bias_correction => Task 1, Epoch 47/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:40,694 [bic.py] => bias_correction => Task 1, Epoch 48/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:40,931 [bic.py] => bias_correction => Task 1, Epoch 49/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:41,207 [bic.py] => bias_correction => Task 1, Epoch 50/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:41,488 [bic.py] => bias_correction => Task 1, Epoch 51/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:41,684 [bic.py] => bias_correction => Task 1, Epoch 52/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:41,885 [bic.py] => bias_correction => Task 1, Epoch 53/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:42,071 [bic.py] => bias_correction => Task 1, Epoch 54/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:42,263 [bic.py] => bias_correction => Task 1, Epoch 55/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:42,462 [bic.py] => bias_correction => Task 1, Epoch 56/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:42,676 [bic.py] => bias_correction => Task 1, Epoch 57/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:43,024 [bic.py] => bias_correction => Task 1, Epoch 58/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:43,220 [bic.py] => bias_correction => Task 1, Epoch 59/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:43,412 [bic.py] => bias_correction => Task 1, Epoch 60/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:43,754 [bic.py] => bias_correction => Task 1, Epoch 61/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:43,981 [bic.py] => bias_correction => Task 1, Epoch 62/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:44,235 [bic.py] => bias_correction => Task 1, Epoch 63/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:44,430 [bic.py] => bias_correction => Task 1, Epoch 64/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:44,624 [bic.py] => bias_correction => Task 1, Epoch 65/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:44,816 [bic.py] => bias_correction => Task 1, Epoch 66/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,015 [bic.py] => bias_correction => Task 1, Epoch 67/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,203 [bic.py] => bias_correction => Task 1, Epoch 68/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,387 [bic.py] => bias_correction => Task 1, Epoch 69/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,581 [bic.py] => bias_correction => Task 1, Epoch 70/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,769 [bic.py] => bias_correction => Task 1, Epoch 71/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:45,958 [bic.py] => bias_correction => Task 1, Epoch 72/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:46,141 [bic.py] => bias_correction => Task 1, Epoch 73/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:46,336 [bic.py] => bias_correction => Task 1, Epoch 74/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:46,523 [bic.py] => bias_correction => Task 1, Epoch 75/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:46,723 [bic.py] => bias_correction => Task 1, Epoch 76/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:46,916 [bic.py] => bias_correction => Task 1, Epoch 77/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:47,109 [bic.py] => bias_correction => Task 1, Epoch 78/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:47,323 [bic.py] => bias_correction => Task 1, Epoch 79/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:47,583 [bic.py] => bias_correction => Task 1, Epoch 80/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:47,816 [bic.py] => bias_correction => Task 1, Epoch 81/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:47,997 [bic.py] => bias_correction => Task 1, Epoch 82/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:48,185 [bic.py] => bias_correction => Task 1, Epoch 83/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:48,385 [bic.py] => bias_correction => Task 1, Epoch 84/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:48,654 [bic.py] => bias_correction => Task 1, Epoch 85/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:48,845 [bic.py] => bias_correction => Task 1, Epoch 86/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:49,097 [bic.py] => bias_correction => Task 1, Epoch 87/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:49,378 [bic.py] => bias_correction => Task 1, Epoch 88/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:49,637 [bic.py] => bias_correction => Task 1, Epoch 89/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:49,870 [bic.py] => bias_correction => Task 1, Epoch 90/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:50,055 [bic.py] => bias_correction => Task 1, Epoch 91/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:50,258 [bic.py] => bias_correction => Task 1, Epoch 92/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:50,453 [bic.py] => bias_correction => Task 1, Epoch 93/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:50,645 [bic.py] => bias_correction => Task 1, Epoch 94/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:50,835 [bic.py] => bias_correction => Task 1, Epoch 95/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,027 [bic.py] => bias_correction => Task 1, Epoch 96/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,252 [bic.py] => bias_correction => Task 1, Epoch 97/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,442 [bic.py] => bias_correction => Task 1, Epoch 98/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,629 [bic.py] => bias_correction => Task 1, Epoch 99/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,817 [bic.py] => bias_correction => Task 1, Epoch 100/150 => Loss 1.455, Train_accy 71.430, Test_accy 63.190
2024-10-23 19:59:51,817 [base.py] => Reducing exemplars...(28 per classes)
2024-10-23 19:59:52,829 [base.py] => Constructing exemplars...(28 per classes)
2024-10-23 19:59:54,930 [bic.py] => Parameters of bias layer:
2024-10-23 19:59:54,931 [bic.py] => 0 => 1.000, 0.000
2024-10-23 19:59:54,931 [bic.py] => 1 => -0.859, -0.584
2024-10-23 19:59:54,932 [trainer.py] => All params: 3847499
2024-10-23 19:59:55,448 [bic.py] => Exemplar size: 196
2024-10-23 19:59:55,449 [trainer.py] => CNN: {'total': 63.19, '00-04': 88.47, '05-06': 0.0, 'old': 88.47, 'new': 0.0}
2024-10-23 19:59:55,449 [trainer.py] => NME: {'total': 74.71, '00-04': 67.03, '05-06': 93.92, 'old': 67.03, 'new': 93.92}
2024-10-23 19:59:55,449 [trainer.py] => CNN top1 curve: [89.93, 63.19]
2024-10-23 19:59:55,449 [trainer.py] => CNN top5 curve: [100.0, 71.52]
2024-10-23 19:59:55,449 [trainer.py] => NME top1 curve: [90.0, 74.71]
2024-10-23 19:59:55,449 [trainer.py] => NME top5 curve: [100.0, 98.88]

2024-10-23 19:59:55,450 [trainer.py] => Average Accuracy (CNN): 76.56
2024-10-23 19:59:55,450 [trainer.py] => Average Accuracy (NME): 82.35499999999999
2024-10-23 19:59:55,451 [trainer.py] => All params: 3847499
2024-10-23 19:59:55,451 [trainer.py] => Trainable params: 3847499
2024-10-23 19:59:55,453 [bic.py] => Learning on 7-9
2024-10-23 19:59:55,498 [bic.py] => Stage1 dset: 4178, Stage2 dset: 18
2024-10-23 19:59:55,498 [bic.py] => Lambda: 0.778
2024-10-23 19:59:55,527 [bic.py] => Parameters of bias layer:
2024-10-23 19:59:55,527 [bic.py] => 0 => 1.000, 0.000
2024-10-23 19:59:55,527 [bic.py] => 1 => -0.859, -0.584
2024-10-23 19:59:55,527 [bic.py] => 2 => 1.000, 0.000
2024-10-23 19:59:56,638 [bic.py] => training => Task 2, Epoch 1/150 => Loss 1.126, Train_accy 92.800, Test_accy 26.430
2024-10-23 19:59:57,702 [bic.py] => training => Task 2, Epoch 2/150 => Loss 1.003, Train_accy 97.100, Test_accy 33.910
2024-10-23 19:59:58,739 [bic.py] => training => Task 2, Epoch 3/150 => Loss 0.979, Train_accy 97.990, Test_accy 37.630
2024-10-23 19:59:59,968 [bic.py] => training => Task 2, Epoch 4/150 => Loss 0.965, Train_accy 98.520, Test_accy 39.980
2024-10-23 20:00:01,198 [bic.py] => training => Task 2, Epoch 5/150 => Loss 0.957, Train_accy 98.660, Test_accy 42.650
2024-10-23 20:00:02,297 [bic.py] => training => Task 2, Epoch 6/150 => Loss 0.951, Train_accy 98.730, Test_accy 38.940
2024-10-23 20:00:03,362 [bic.py] => training => Task 2, Epoch 7/150 => Loss 0.948, Train_accy 98.760, Test_accy 42.960
2024-10-23 20:00:04,509 [bic.py] => training => Task 2, Epoch 8/150 => Loss 0.943, Train_accy 98.990, Test_accy 44.040
2024-10-23 20:00:05,671 [bic.py] => training => Task 2, Epoch 9/150 => Loss 0.944, Train_accy 99.350, Test_accy 44.310
2024-10-23 20:00:07,057 [bic.py] => training => Task 2, Epoch 10/150 => Loss 0.941, Train_accy 99.620, Test_accy 41.810
2024-10-23 20:00:08,625 [bic.py] => training => Task 2, Epoch 11/150 => Loss 0.939, Train_accy 99.500, Test_accy 39.000
2024-10-23 20:00:09,886 [bic.py] => training => Task 2, Epoch 12/150 => Loss 0.936, Train_accy 99.500, Test_accy 41.370
2024-10-23 20:00:11,021 [bic.py] => training => Task 2, Epoch 13/150 => Loss 0.936, Train_accy 99.830, Test_accy 44.670
2024-10-23 20:00:12,061 [bic.py] => training => Task 2, Epoch 14/150 => Loss 0.939, Train_accy 99.740, Test_accy 47.090
2024-10-23 20:00:13,165 [bic.py] => training => Task 2, Epoch 15/150 => Loss 0.938, Train_accy 99.690, Test_accy 44.460
2024-10-23 20:00:14,421 [bic.py] => training => Task 2, Epoch 16/150 => Loss 0.937, Train_accy 99.590, Test_accy 38.760
2024-10-23 20:00:15,575 [bic.py] => training => Task 2, Epoch 17/150 => Loss 0.937, Train_accy 99.570, Test_accy 39.910
2024-10-23 20:00:16,678 [bic.py] => training => Task 2, Epoch 18/150 => Loss 0.936, Train_accy 99.740, Test_accy 42.060
2024-10-23 20:00:17,834 [bic.py] => training => Task 2, Epoch 19/150 => Loss 0.935, Train_accy 99.900, Test_accy 47.370
2024-10-23 20:00:18,928 [bic.py] => training => Task 2, Epoch 20/150 => Loss 0.935, Train_accy 99.640, Test_accy 40.200
2024-10-23 20:00:20,011 [bic.py] => training => Task 2, Epoch 21/150 => Loss 0.934, Train_accy 99.860, Test_accy 43.800
2024-10-23 20:00:21,042 [bic.py] => training => Task 2, Epoch 22/150 => Loss 0.934, Train_accy 99.690, Test_accy 47.220
2024-10-23 20:00:22,152 [bic.py] => training => Task 2, Epoch 23/150 => Loss 0.936, Train_accy 99.780, Test_accy 42.720
2024-10-23 20:00:23,206 [bic.py] => training => Task 2, Epoch 24/150 => Loss 0.935, Train_accy 99.590, Test_accy 37.690
2024-10-23 20:00:24,314 [bic.py] => training => Task 2, Epoch 25/150 => Loss 0.936, Train_accy 99.450, Test_accy 40.300
2024-10-23 20:00:25,419 [bic.py] => training => Task 2, Epoch 26/150 => Loss 0.936, Train_accy 99.930, Test_accy 45.610
2024-10-23 20:00:26,476 [bic.py] => training => Task 2, Epoch 27/150 => Loss 0.935, Train_accy 99.590, Test_accy 36.630
2024-10-23 20:00:27,536 [bic.py] => training => Task 2, Epoch 28/150 => Loss 0.934, Train_accy 99.590, Test_accy 45.330
2024-10-23 20:00:28,600 [bic.py] => training => Task 2, Epoch 29/150 => Loss 0.934, Train_accy 99.830, Test_accy 38.700
2024-10-23 20:00:29,651 [bic.py] => training => Task 2, Epoch 30/150 => Loss 0.933, Train_accy 99.740, Test_accy 44.330
2024-10-23 20:00:30,732 [bic.py] => training => Task 2, Epoch 31/150 => Loss 0.932, Train_accy 99.570, Test_accy 42.170
2024-10-23 20:00:31,827 [bic.py] => training => Task 2, Epoch 32/150 => Loss 0.934, Train_accy 99.660, Test_accy 43.650
2024-10-23 20:00:32,941 [bic.py] => training => Task 2, Epoch 33/150 => Loss 0.933, Train_accy 99.330, Test_accy 35.300
2024-10-23 20:00:34,125 [bic.py] => training => Task 2, Epoch 34/150 => Loss 0.934, Train_accy 99.640, Test_accy 43.130
2024-10-23 20:00:35,221 [bic.py] => training => Task 2, Epoch 35/150 => Loss 0.933, Train_accy 99.710, Test_accy 41.170
2024-10-23 20:00:36,243 [bic.py] => training => Task 2, Epoch 36/150 => Loss 0.933, Train_accy 99.590, Test_accy 37.370
2024-10-23 20:00:37,278 [bic.py] => training => Task 2, Epoch 37/150 => Loss 0.933, Train_accy 99.590, Test_accy 39.090
2024-10-23 20:00:38,294 [bic.py] => training => Task 2, Epoch 38/150 => Loss 0.934, Train_accy 99.380, Test_accy 38.330
2024-10-23 20:00:39,398 [bic.py] => training => Task 2, Epoch 39/150 => Loss 0.936, Train_accy 99.760, Test_accy 41.300
2024-10-23 20:00:40,486 [bic.py] => training => Task 2, Epoch 40/150 => Loss 0.935, Train_accy 99.620, Test_accy 42.370
2024-10-23 20:00:41,624 [bic.py] => training => Task 2, Epoch 41/150 => Loss 0.934, Train_accy 99.620, Test_accy 38.560
2024-10-23 20:00:42,647 [bic.py] => training => Task 2, Epoch 42/150 => Loss 0.934, Train_accy 99.590, Test_accy 42.330
2024-10-23 20:00:43,679 [bic.py] => training => Task 2, Epoch 43/150 => Loss 0.933, Train_accy 99.400, Test_accy 42.130
2024-10-23 20:00:44,746 [bic.py] => training => Task 2, Epoch 44/150 => Loss 0.933, Train_accy 99.660, Test_accy 39.540
2024-10-23 20:00:45,802 [bic.py] => training => Task 2, Epoch 45/150 => Loss 0.934, Train_accy 99.640, Test_accy 43.690
2024-10-23 20:00:46,928 [bic.py] => training => Task 2, Epoch 46/150 => Loss 0.933, Train_accy 99.380, Test_accy 40.190
2024-10-23 20:00:48,026 [bic.py] => training => Task 2, Epoch 47/150 => Loss 0.932, Train_accy 99.740, Test_accy 41.560
2024-10-23 20:00:49,141 [bic.py] => training => Task 2, Epoch 48/150 => Loss 0.933, Train_accy 99.470, Test_accy 37.690
2024-10-23 20:00:50,196 [bic.py] => training => Task 2, Epoch 49/150 => Loss 0.934, Train_accy 99.710, Test_accy 41.220
2024-10-23 20:00:51,291 [bic.py] => training => Task 2, Epoch 50/150 => Loss 0.934, Train_accy 99.740, Test_accy 39.410
2024-10-23 20:00:52,355 [bic.py] => training => Task 2, Epoch 51/150 => Loss 0.932, Train_accy 99.740, Test_accy 39.890
2024-10-23 20:00:53,444 [bic.py] => training => Task 2, Epoch 52/150 => Loss 0.931, Train_accy 99.690, Test_accy 39.870
2024-10-23 20:00:54,484 [bic.py] => training => Task 2, Epoch 53/150 => Loss 0.931, Train_accy 99.660, Test_accy 39.960
2024-10-23 20:00:55,588 [bic.py] => training => Task 2, Epoch 54/150 => Loss 0.931, Train_accy 99.660, Test_accy 40.110
2024-10-23 20:00:56,667 [bic.py] => training => Task 2, Epoch 55/150 => Loss 0.930, Train_accy 99.660, Test_accy 40.500
2024-10-23 20:00:57,770 [bic.py] => training => Task 2, Epoch 56/150 => Loss 0.930, Train_accy 99.660, Test_accy 41.260
2024-10-23 20:00:58,825 [bic.py] => training => Task 2, Epoch 57/150 => Loss 0.930, Train_accy 99.660, Test_accy 40.150
2024-10-23 20:00:59,868 [bic.py] => training => Task 2, Epoch 58/150 => Loss 0.930, Train_accy 99.760, Test_accy 41.670
2024-10-23 20:01:00,881 [bic.py] => training => Task 2, Epoch 59/150 => Loss 0.931, Train_accy 99.690, Test_accy 40.610
2024-10-23 20:01:01,986 [bic.py] => training => Task 2, Epoch 60/150 => Loss 0.931, Train_accy 99.690, Test_accy 41.260
2024-10-23 20:01:03,016 [bic.py] => training => Task 2, Epoch 61/150 => Loss 0.930, Train_accy 99.690, Test_accy 40.780
2024-10-23 20:01:04,117 [bic.py] => training => Task 2, Epoch 62/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.610
2024-10-23 20:01:05,187 [bic.py] => training => Task 2, Epoch 63/150 => Loss 0.931, Train_accy 99.620, Test_accy 39.040
2024-10-23 20:01:06,256 [bic.py] => training => Task 2, Epoch 64/150 => Loss 0.931, Train_accy 99.690, Test_accy 40.810
2024-10-23 20:01:07,361 [bic.py] => training => Task 2, Epoch 65/150 => Loss 0.930, Train_accy 99.660, Test_accy 40.150
2024-10-23 20:01:08,423 [bic.py] => training => Task 2, Epoch 66/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.260
2024-10-23 20:01:09,513 [bic.py] => training => Task 2, Epoch 67/150 => Loss 0.930, Train_accy 99.660, Test_accy 40.110
2024-10-23 20:01:10,591 [bic.py] => training => Task 2, Epoch 68/150 => Loss 0.930, Train_accy 99.690, Test_accy 40.170
2024-10-23 20:01:11,680 [bic.py] => training => Task 2, Epoch 69/150 => Loss 0.929, Train_accy 99.740, Test_accy 40.830
2024-10-23 20:01:12,754 [bic.py] => training => Task 2, Epoch 70/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.190
2024-10-23 20:01:13,863 [bic.py] => training => Task 2, Epoch 71/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.870
2024-10-23 20:01:14,934 [bic.py] => training => Task 2, Epoch 72/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.070
2024-10-23 20:01:16,027 [bic.py] => training => Task 2, Epoch 73/150 => Loss 0.930, Train_accy 99.660, Test_accy 40.190
2024-10-23 20:01:17,099 [bic.py] => training => Task 2, Epoch 74/150 => Loss 0.931, Train_accy 99.660, Test_accy 39.850
2024-10-23 20:01:18,091 [bic.py] => training => Task 2, Epoch 75/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.040
2024-10-23 20:01:19,071 [bic.py] => training => Task 2, Epoch 76/150 => Loss 0.930, Train_accy 99.570, Test_accy 39.520
2024-10-23 20:01:20,077 [bic.py] => training => Task 2, Epoch 77/150 => Loss 0.931, Train_accy 99.710, Test_accy 40.310
2024-10-23 20:01:21,074 [bic.py] => training => Task 2, Epoch 78/150 => Loss 0.930, Train_accy 99.690, Test_accy 40.940
2024-10-23 20:01:22,052 [bic.py] => training => Task 2, Epoch 79/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.940
2024-10-23 20:01:23,051 [bic.py] => training => Task 2, Epoch 80/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.000
2024-10-23 20:01:24,027 [bic.py] => training => Task 2, Epoch 81/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.110
2024-10-23 20:01:25,039 [bic.py] => training => Task 2, Epoch 82/150 => Loss 0.930, Train_accy 99.690, Test_accy 41.020
2024-10-23 20:01:26,033 [bic.py] => training => Task 2, Epoch 83/150 => Loss 0.930, Train_accy 99.690, Test_accy 40.150
2024-10-23 20:01:27,120 [bic.py] => training => Task 2, Epoch 84/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.130
2024-10-23 20:01:28,209 [bic.py] => training => Task 2, Epoch 85/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.800
2024-10-23 20:01:29,285 [bic.py] => training => Task 2, Epoch 86/150 => Loss 0.930, Train_accy 99.760, Test_accy 41.650
2024-10-23 20:01:30,364 [bic.py] => training => Task 2, Epoch 87/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.200
2024-10-23 20:01:31,519 [bic.py] => training => Task 2, Epoch 88/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.260
2024-10-23 20:01:32,623 [bic.py] => training => Task 2, Epoch 89/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.130
2024-10-23 20:01:33,675 [bic.py] => training => Task 2, Epoch 90/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.540
2024-10-23 20:01:34,700 [bic.py] => training => Task 2, Epoch 91/150 => Loss 0.929, Train_accy 99.710, Test_accy 41.110
2024-10-23 20:01:35,776 [bic.py] => training => Task 2, Epoch 92/150 => Loss 0.929, Train_accy 99.710, Test_accy 41.500
2024-10-23 20:01:36,843 [bic.py] => training => Task 2, Epoch 93/150 => Loss 0.931, Train_accy 99.620, Test_accy 39.800
2024-10-23 20:01:37,906 [bic.py] => training => Task 2, Epoch 94/150 => Loss 0.931, Train_accy 99.660, Test_accy 40.560
2024-10-23 20:01:39,025 [bic.py] => training => Task 2, Epoch 95/150 => Loss 0.929, Train_accy 99.760, Test_accy 41.430
2024-10-23 20:01:40,096 [bic.py] => training => Task 2, Epoch 96/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.090
2024-10-23 20:01:41,142 [bic.py] => training => Task 2, Epoch 97/150 => Loss 0.930, Train_accy 99.640, Test_accy 40.910
2024-10-23 20:01:42,180 [bic.py] => training => Task 2, Epoch 98/150 => Loss 0.929, Train_accy 99.640, Test_accy 40.070
2024-10-23 20:01:43,284 [bic.py] => training => Task 2, Epoch 99/150 => Loss 0.930, Train_accy 99.640, Test_accy 40.570
2024-10-23 20:01:44,397 [bic.py] => training => Task 2, Epoch 100/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.300
2024-10-23 20:01:45,475 [bic.py] => training => Task 2, Epoch 101/150 => Loss 0.930, Train_accy 99.640, Test_accy 40.760
2024-10-23 20:01:46,464 [bic.py] => training => Task 2, Epoch 102/150 => Loss 0.930, Train_accy 99.620, Test_accy 40.020
2024-10-23 20:01:47,498 [bic.py] => training => Task 2, Epoch 103/150 => Loss 0.931, Train_accy 99.710, Test_accy 41.520
2024-10-23 20:01:48,572 [bic.py] => training => Task 2, Epoch 104/150 => Loss 0.930, Train_accy 99.640, Test_accy 40.650
2024-10-23 20:01:49,601 [bic.py] => training => Task 2, Epoch 105/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.430
2024-10-23 20:01:50,579 [bic.py] => training => Task 2, Epoch 106/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.170
2024-10-23 20:01:51,598 [bic.py] => training => Task 2, Epoch 107/150 => Loss 0.929, Train_accy 99.690, Test_accy 40.500
2024-10-23 20:01:52,715 [bic.py] => training => Task 2, Epoch 108/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.090
2024-10-23 20:01:53,811 [bic.py] => training => Task 2, Epoch 109/150 => Loss 0.929, Train_accy 99.710, Test_accy 41.410
2024-10-23 20:01:54,853 [bic.py] => training => Task 2, Epoch 110/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.670
2024-10-23 20:01:55,888 [bic.py] => training => Task 2, Epoch 111/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.200
2024-10-23 20:01:56,930 [bic.py] => training => Task 2, Epoch 112/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.500
2024-10-23 20:01:57,932 [bic.py] => training => Task 2, Epoch 113/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.200
2024-10-23 20:01:58,981 [bic.py] => training => Task 2, Epoch 114/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.960
2024-10-23 20:02:00,040 [bic.py] => training => Task 2, Epoch 115/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.200
2024-10-23 20:02:01,098 [bic.py] => training => Task 2, Epoch 116/150 => Loss 0.929, Train_accy 99.740, Test_accy 40.630
2024-10-23 20:02:02,084 [bic.py] => training => Task 2, Epoch 117/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.740
2024-10-23 20:02:03,158 [bic.py] => training => Task 2, Epoch 118/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.260
2024-10-23 20:02:04,129 [bic.py] => training => Task 2, Epoch 119/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.070
2024-10-23 20:02:05,145 [bic.py] => training => Task 2, Epoch 120/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.520
2024-10-23 20:02:06,134 [bic.py] => training => Task 2, Epoch 121/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.890
2024-10-23 20:02:07,138 [bic.py] => training => Task 2, Epoch 122/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.430
2024-10-23 20:02:08,277 [bic.py] => training => Task 2, Epoch 123/150 => Loss 0.930, Train_accy 99.740, Test_accy 40.520
2024-10-23 20:02:09,386 [bic.py] => training => Task 2, Epoch 124/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.740
2024-10-23 20:02:10,428 [bic.py] => training => Task 2, Epoch 125/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.740
2024-10-23 20:02:11,529 [bic.py] => training => Task 2, Epoch 126/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.960
2024-10-23 20:02:12,587 [bic.py] => training => Task 2, Epoch 127/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.800
2024-10-23 20:02:13,668 [bic.py] => training => Task 2, Epoch 128/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.460
2024-10-23 20:02:14,753 [bic.py] => training => Task 2, Epoch 129/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.670
2024-10-23 20:02:15,828 [bic.py] => training => Task 2, Epoch 130/150 => Loss 0.929, Train_accy 99.740, Test_accy 41.260
2024-10-23 20:02:16,891 [bic.py] => training => Task 2, Epoch 131/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.830
2024-10-23 20:02:17,957 [bic.py] => training => Task 2, Epoch 132/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.150
2024-10-23 20:02:19,033 [bic.py] => training => Task 2, Epoch 133/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.740
2024-10-23 20:02:20,118 [bic.py] => training => Task 2, Epoch 134/150 => Loss 0.930, Train_accy 99.710, Test_accy 41.170
2024-10-23 20:02:21,166 [bic.py] => training => Task 2, Epoch 135/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.960
2024-10-23 20:02:22,213 [bic.py] => training => Task 2, Epoch 136/150 => Loss 0.929, Train_accy 99.740, Test_accy 41.280
2024-10-23 20:02:23,256 [bic.py] => training => Task 2, Epoch 137/150 => Loss 0.929, Train_accy 99.740, Test_accy 40.980
2024-10-23 20:02:24,327 [bic.py] => training => Task 2, Epoch 138/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.220
2024-10-23 20:02:25,382 [bic.py] => training => Task 2, Epoch 139/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.590
2024-10-23 20:02:26,451 [bic.py] => training => Task 2, Epoch 140/150 => Loss 0.930, Train_accy 99.690, Test_accy 40.690
2024-10-23 20:02:27,533 [bic.py] => training => Task 2, Epoch 141/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.910
2024-10-23 20:02:28,597 [bic.py] => training => Task 2, Epoch 142/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.850
2024-10-23 20:02:29,612 [bic.py] => training => Task 2, Epoch 143/150 => Loss 0.930, Train_accy 99.740, Test_accy 41.040
2024-10-23 20:02:30,623 [bic.py] => training => Task 2, Epoch 144/150 => Loss 0.929, Train_accy 99.710, Test_accy 41.350
2024-10-23 20:02:31,725 [bic.py] => training => Task 2, Epoch 145/150 => Loss 0.930, Train_accy 99.740, Test_accy 40.980
2024-10-23 20:02:32,776 [bic.py] => training => Task 2, Epoch 146/150 => Loss 0.930, Train_accy 99.710, Test_accy 40.280
2024-10-23 20:02:33,764 [bic.py] => training => Task 2, Epoch 147/150 => Loss 0.931, Train_accy 99.710, Test_accy 41.150
2024-10-23 20:02:34,758 [bic.py] => training => Task 2, Epoch 148/150 => Loss 0.929, Train_accy 99.740, Test_accy 41.430
2024-10-23 20:02:35,817 [bic.py] => training => Task 2, Epoch 149/150 => Loss 0.929, Train_accy 99.710, Test_accy 40.570
2024-10-23 20:02:36,930 [bic.py] => training => Task 2, Epoch 150/150 => Loss 0.929, Train_accy 99.710, Test_accy 41.370
2024-10-23 20:02:37,189 [bic.py] => bias_correction => Task 2, Epoch 1/150 => Loss 1.991, Train_accy 61.110, Test_accy 40.390
2024-10-23 20:02:37,402 [bic.py] => bias_correction => Task 2, Epoch 2/150 => Loss 1.983, Train_accy 61.110, Test_accy 40.260
2024-10-23 20:02:37,611 [bic.py] => bias_correction => Task 2, Epoch 3/150 => Loss 1.965, Train_accy 61.110, Test_accy 40.980
2024-10-23 20:02:37,825 [bic.py] => bias_correction => Task 2, Epoch 4/150 => Loss 1.934, Train_accy 61.110, Test_accy 43.670
2024-10-23 20:02:38,031 [bic.py] => bias_correction => Task 2, Epoch 5/150 => Loss 1.885, Train_accy 66.670, Test_accy 48.430
2024-10-23 20:02:38,249 [bic.py] => bias_correction => Task 2, Epoch 6/150 => Loss 1.816, Train_accy 72.220, Test_accy 55.670
2024-10-23 20:02:38,465 [bic.py] => bias_correction => Task 2, Epoch 7/150 => Loss 1.748, Train_accy 72.220, Test_accy 54.800
2024-10-23 20:02:38,681 [bic.py] => bias_correction => Task 2, Epoch 8/150 => Loss 1.748, Train_accy 66.670, Test_accy 50.690
2024-10-23 20:02:38,898 [bic.py] => bias_correction => Task 2, Epoch 9/150 => Loss 1.784, Train_accy 55.560, Test_accy 47.720
2024-10-23 20:02:39,112 [bic.py] => bias_correction => Task 2, Epoch 10/150 => Loss 1.807, Train_accy 55.560, Test_accy 48.000
2024-10-23 20:02:39,328 [bic.py] => bias_correction => Task 2, Epoch 11/150 => Loss 1.817, Train_accy 55.560, Test_accy 48.170
2024-10-23 20:02:39,546 [bic.py] => bias_correction => Task 2, Epoch 12/150 => Loss 1.821, Train_accy 55.560, Test_accy 48.150
2024-10-23 20:02:39,759 [bic.py] => bias_correction => Task 2, Epoch 13/150 => Loss 1.823, Train_accy 55.560, Test_accy 48.200
2024-10-23 20:02:39,981 [bic.py] => bias_correction => Task 2, Epoch 14/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.240
2024-10-23 20:02:40,200 [bic.py] => bias_correction => Task 2, Epoch 15/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.190
2024-10-23 20:02:40,413 [bic.py] => bias_correction => Task 2, Epoch 16/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.170
2024-10-23 20:02:40,621 [bic.py] => bias_correction => Task 2, Epoch 17/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.170
2024-10-23 20:02:40,851 [bic.py] => bias_correction => Task 2, Epoch 18/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.110
2024-10-23 20:02:41,061 [bic.py] => bias_correction => Task 2, Epoch 19/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.110
2024-10-23 20:02:41,278 [bic.py] => bias_correction => Task 2, Epoch 20/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.040
2024-10-23 20:02:41,487 [bic.py] => bias_correction => Task 2, Epoch 21/150 => Loss 1.824, Train_accy 55.560, Test_accy 48.000
2024-10-23 20:02:41,702 [bic.py] => bias_correction => Task 2, Epoch 22/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.930
2024-10-23 20:02:41,914 [bic.py] => bias_correction => Task 2, Epoch 23/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.910
2024-10-23 20:02:42,127 [bic.py] => bias_correction => Task 2, Epoch 24/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.910
2024-10-23 20:02:42,338 [bic.py] => bias_correction => Task 2, Epoch 25/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.910
2024-10-23 20:02:42,550 [bic.py] => bias_correction => Task 2, Epoch 26/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.850
2024-10-23 20:02:42,774 [bic.py] => bias_correction => Task 2, Epoch 27/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.800
2024-10-23 20:02:42,984 [bic.py] => bias_correction => Task 2, Epoch 28/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.760
2024-10-23 20:02:43,210 [bic.py] => bias_correction => Task 2, Epoch 29/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.800
2024-10-23 20:02:43,454 [bic.py] => bias_correction => Task 2, Epoch 30/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.800
2024-10-23 20:02:43,669 [bic.py] => bias_correction => Task 2, Epoch 31/150 => Loss 1.823, Train_accy 55.560, Test_accy 47.800
2024-10-23 20:02:43,897 [bic.py] => bias_correction => Task 2, Epoch 32/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.720
2024-10-23 20:02:44,117 [bic.py] => bias_correction => Task 2, Epoch 33/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.700
2024-10-23 20:02:44,344 [bic.py] => bias_correction => Task 2, Epoch 34/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.700
2024-10-23 20:02:44,561 [bic.py] => bias_correction => Task 2, Epoch 35/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.690
2024-10-23 20:02:44,780 [bic.py] => bias_correction => Task 2, Epoch 36/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.670
2024-10-23 20:02:44,996 [bic.py] => bias_correction => Task 2, Epoch 37/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.650
2024-10-23 20:02:45,213 [bic.py] => bias_correction => Task 2, Epoch 38/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.690
2024-10-23 20:02:45,431 [bic.py] => bias_correction => Task 2, Epoch 39/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.650
2024-10-23 20:02:45,646 [bic.py] => bias_correction => Task 2, Epoch 40/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.630
2024-10-23 20:02:45,859 [bic.py] => bias_correction => Task 2, Epoch 41/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.630
2024-10-23 20:02:46,069 [bic.py] => bias_correction => Task 2, Epoch 42/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:46,286 [bic.py] => bias_correction => Task 2, Epoch 43/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:46,498 [bic.py] => bias_correction => Task 2, Epoch 44/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:46,712 [bic.py] => bias_correction => Task 2, Epoch 45/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:46,944 [bic.py] => bias_correction => Task 2, Epoch 46/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:47,166 [bic.py] => bias_correction => Task 2, Epoch 47/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:47,379 [bic.py] => bias_correction => Task 2, Epoch 48/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:47,595 [bic.py] => bias_correction => Task 2, Epoch 49/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.610
2024-10-23 20:02:47,810 [bic.py] => bias_correction => Task 2, Epoch 50/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.590
2024-10-23 20:02:48,040 [bic.py] => bias_correction => Task 2, Epoch 51/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:48,272 [bic.py] => bias_correction => Task 2, Epoch 52/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:48,488 [bic.py] => bias_correction => Task 2, Epoch 53/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:48,705 [bic.py] => bias_correction => Task 2, Epoch 54/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:48,921 [bic.py] => bias_correction => Task 2, Epoch 55/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:49,140 [bic.py] => bias_correction => Task 2, Epoch 56/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:49,369 [bic.py] => bias_correction => Task 2, Epoch 57/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:49,581 [bic.py] => bias_correction => Task 2, Epoch 58/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:49,798 [bic.py] => bias_correction => Task 2, Epoch 59/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:50,011 [bic.py] => bias_correction => Task 2, Epoch 60/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:50,239 [bic.py] => bias_correction => Task 2, Epoch 61/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:50,464 [bic.py] => bias_correction => Task 2, Epoch 62/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:50,685 [bic.py] => bias_correction => Task 2, Epoch 63/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:50,898 [bic.py] => bias_correction => Task 2, Epoch 64/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:51,117 [bic.py] => bias_correction => Task 2, Epoch 65/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:51,325 [bic.py] => bias_correction => Task 2, Epoch 66/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:51,547 [bic.py] => bias_correction => Task 2, Epoch 67/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:51,759 [bic.py] => bias_correction => Task 2, Epoch 68/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:51,973 [bic.py] => bias_correction => Task 2, Epoch 69/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:52,187 [bic.py] => bias_correction => Task 2, Epoch 70/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:52,400 [bic.py] => bias_correction => Task 2, Epoch 71/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:52,632 [bic.py] => bias_correction => Task 2, Epoch 72/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:52,868 [bic.py] => bias_correction => Task 2, Epoch 73/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:53,095 [bic.py] => bias_correction => Task 2, Epoch 74/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:53,334 [bic.py] => bias_correction => Task 2, Epoch 75/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:53,597 [bic.py] => bias_correction => Task 2, Epoch 76/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:53,861 [bic.py] => bias_correction => Task 2, Epoch 77/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:54,129 [bic.py] => bias_correction => Task 2, Epoch 78/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:54,523 [bic.py] => bias_correction => Task 2, Epoch 79/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:54,834 [bic.py] => bias_correction => Task 2, Epoch 80/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:55,105 [bic.py] => bias_correction => Task 2, Epoch 81/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:55,374 [bic.py] => bias_correction => Task 2, Epoch 82/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:55,641 [bic.py] => bias_correction => Task 2, Epoch 83/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:55,906 [bic.py] => bias_correction => Task 2, Epoch 84/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:56,167 [bic.py] => bias_correction => Task 2, Epoch 85/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:56,431 [bic.py] => bias_correction => Task 2, Epoch 86/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:56,684 [bic.py] => bias_correction => Task 2, Epoch 87/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:56,904 [bic.py] => bias_correction => Task 2, Epoch 88/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:57,121 [bic.py] => bias_correction => Task 2, Epoch 89/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:57,339 [bic.py] => bias_correction => Task 2, Epoch 90/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:57,547 [bic.py] => bias_correction => Task 2, Epoch 91/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:57,756 [bic.py] => bias_correction => Task 2, Epoch 92/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:57,969 [bic.py] => bias_correction => Task 2, Epoch 93/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:58,177 [bic.py] => bias_correction => Task 2, Epoch 94/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.560
2024-10-23 20:02:58,396 [bic.py] => bias_correction => Task 2, Epoch 95/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.560
2024-10-23 20:02:58,608 [bic.py] => bias_correction => Task 2, Epoch 96/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:58,818 [bic.py] => bias_correction => Task 2, Epoch 97/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:59,024 [bic.py] => bias_correction => Task 2, Epoch 98/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:59,234 [bic.py] => bias_correction => Task 2, Epoch 99/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.570
2024-10-23 20:02:59,444 [bic.py] => bias_correction => Task 2, Epoch 100/150 => Loss 1.822, Train_accy 55.560, Test_accy 47.560
2024-10-23 20:02:59,445 [base.py] => Reducing exemplars...(22 per classes)
2024-10-23 20:03:00,841 [base.py] => Constructing exemplars...(22 per classes)
2024-10-23 20:03:02,356 [bic.py] => Parameters of bias layer:
2024-10-23 20:03:02,357 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:03:02,357 [bic.py] => 1 => -0.859, -0.584
2024-10-23 20:03:02,357 [bic.py] => 2 => -0.628, -0.728
2024-10-23 20:03:02,358 [trainer.py] => All params: 3848527
2024-10-23 20:03:02,846 [bic.py] => Exemplar size: 198
2024-10-23 20:03:02,846 [trainer.py] => CNN: {'total': 47.56, '00-04': 85.6, '05-06': 0.0, '07-08': 0.0, 'old': 61.14, 'new': 0.0}
2024-10-23 20:03:02,846 [trainer.py] => NME: {'total': 54.81, '00-04': 59.7, '05-06': 1.25, '07-08': 96.17, 'old': 43.0, 'new': 96.17}
2024-10-23 20:03:02,846 [trainer.py] => CNN top1 curve: [89.93, 63.19, 47.56]
2024-10-23 20:03:02,846 [trainer.py] => CNN top5 curve: [100.0, 71.52, 55.83]
2024-10-23 20:03:02,846 [trainer.py] => NME top1 curve: [90.0, 74.71, 54.81]
2024-10-23 20:03:02,846 [trainer.py] => NME top5 curve: [100.0, 98.88, 81.56]

2024-10-23 20:03:02,847 [trainer.py] => Average Accuracy (CNN): 66.89333333333333
2024-10-23 20:03:02,847 [trainer.py] => Average Accuracy (NME): 73.17333333333333
2024-10-23 20:03:02,847 [trainer.py] => Forgetting (CNN): 2.1650000000000063
