2024-09-02 15:22:45,141 [trainer.py] => config: ./exps/podnet.json
2024-09-02 15:22:45,141 [trainer.py] => prefix: reproduce
2024-09-02 15:22:45,141 [trainer.py] => dataset: hrrp9
2024-09-02 15:22:45,141 [trainer.py] => memory_size: 500
2024-09-02 15:22:45,141 [trainer.py] => memory_per_class: 20
2024-09-02 15:22:45,141 [trainer.py] => fixed_memory: False
2024-09-02 15:22:45,141 [trainer.py] => shuffle: True
2024-09-02 15:22:45,141 [trainer.py] => init_cls: 5
2024-09-02 15:22:45,141 [trainer.py] => increment: 2
2024-09-02 15:22:45,141 [trainer.py] => model_name: podnet
2024-09-02 15:22:45,141 [trainer.py] => convnet_type: resnet18
2024-09-02 15:22:45,141 [trainer.py] => init_train: True
2024-09-02 15:22:45,141 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-02 15:22:45,141 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-02 15:22:45,141 [trainer.py] => device: [device(type='cuda', index=6)]
2024-09-02 15:22:45,141 [trainer.py] => seed: 1993
2024-09-02 15:22:45,141 [trainer.py] => pod: w
2024-09-02 15:22:45,628 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-02 15:22:45,727 [trainer.py] => All params: 3843904
2024-09-02 15:22:45,727 [trainer.py] => Trainable params: 3843904
2024-09-02 15:22:45,728 [podnet.py] => Learning on 0-5
2024-09-02 15:22:45,764 [podnet.py] => Adaptive factor: 0
2024-09-02 15:22:48,997 [podnet.py] => Task 0, Epoch 1/300 (LR 0.10000) => LSC_loss 1.56, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 41.02, Test_acc 43.47
2024-09-02 15:22:51,724 [podnet.py] => Task 0, Epoch 2/300 (LR 0.09999) => LSC_loss 1.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 60.86, Test_acc 32.63
2024-09-02 15:22:54,370 [podnet.py] => Task 0, Epoch 3/300 (LR 0.09998) => LSC_loss 0.73, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.47, Test_acc 36.30
2024-09-02 15:22:57,338 [podnet.py] => Task 0, Epoch 4/300 (LR 0.09996) => LSC_loss 0.51, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.33, Test_acc 59.63
2024-09-02 15:23:00,320 [podnet.py] => Task 0, Epoch 5/300 (LR 0.09993) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.73, Test_acc 55.37
2024-09-02 15:23:03,070 [podnet.py] => Task 0, Epoch 6/300 (LR 0.09990) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.02, Test_acc 72.20
2024-09-02 15:23:05,676 [podnet.py] => Task 0, Epoch 7/300 (LR 0.09987) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.42, Test_acc 67.40
2024-09-02 15:23:08,009 [podnet.py] => Task 0, Epoch 8/300 (LR 0.09982) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.66, Test_acc 74.30
2024-09-02 15:23:10,183 [podnet.py] => Task 0, Epoch 9/300 (LR 0.09978) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.07, Test_acc 74.60
2024-09-02 15:23:12,717 [podnet.py] => Task 0, Epoch 10/300 (LR 0.09973) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.47, Test_acc 78.70
2024-09-02 15:23:15,257 [podnet.py] => Task 0, Epoch 11/300 (LR 0.09967) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 70.47
2024-09-02 15:23:17,738 [podnet.py] => Task 0, Epoch 12/300 (LR 0.09961) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.31, Test_acc 82.27
2024-09-02 15:23:20,041 [podnet.py] => Task 0, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.29, Test_acc 82.53
2024-09-02 15:23:22,307 [podnet.py] => Task 0, Epoch 14/300 (LR 0.09946) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.08, Test_acc 67.27
2024-09-02 15:23:24,784 [podnet.py] => Task 0, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.94, Test_acc 79.93
2024-09-02 15:23:27,600 [podnet.py] => Task 0, Epoch 16/300 (LR 0.09930) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.08, Test_acc 83.07
2024-09-02 15:23:30,207 [podnet.py] => Task 0, Epoch 17/300 (LR 0.09921) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.57, Test_acc 72.60
2024-09-02 15:23:32,897 [podnet.py] => Task 0, Epoch 18/300 (LR 0.09911) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.56, Test_acc 80.30
2024-09-02 15:23:35,621 [podnet.py] => Task 0, Epoch 19/300 (LR 0.09901) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 81.57
2024-09-02 15:23:38,042 [podnet.py] => Task 0, Epoch 20/300 (LR 0.09891) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 79.03
2024-09-02 15:23:40,672 [podnet.py] => Task 0, Epoch 21/300 (LR 0.09880) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.36, Test_acc 83.07
2024-09-02 15:23:43,181 [podnet.py] => Task 0, Epoch 22/300 (LR 0.09868) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.83, Test_acc 74.17
2024-09-02 15:23:45,716 [podnet.py] => Task 0, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 82.63
2024-09-02 15:23:48,106 [podnet.py] => Task 0, Epoch 24/300 (LR 0.09843) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 82.83
2024-09-02 15:23:50,547 [podnet.py] => Task 0, Epoch 25/300 (LR 0.09830) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.27, Test_acc 84.33
2024-09-02 15:23:53,012 [podnet.py] => Task 0, Epoch 26/300 (LR 0.09816) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.83, Test_acc 85.20
2024-09-02 15:23:55,396 [podnet.py] => Task 0, Epoch 27/300 (LR 0.09801) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 85.90
2024-09-02 15:23:58,032 [podnet.py] => Task 0, Epoch 28/300 (LR 0.09787) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.15, Test_acc 74.20
2024-09-02 15:24:00,575 [podnet.py] => Task 0, Epoch 29/300 (LR 0.09771) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 82.03
2024-09-02 15:24:03,050 [podnet.py] => Task 0, Epoch 30/300 (LR 0.09755) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 76.93
2024-09-02 15:24:05,502 [podnet.py] => Task 0, Epoch 31/300 (LR 0.09739) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.02, Test_acc 79.40
2024-09-02 15:24:08,180 [podnet.py] => Task 0, Epoch 32/300 (LR 0.09722) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.66, Test_acc 77.10
2024-09-02 15:24:10,817 [podnet.py] => Task 0, Epoch 33/300 (LR 0.09704) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.02, Test_acc 79.23
2024-09-02 15:24:13,371 [podnet.py] => Task 0, Epoch 34/300 (LR 0.09686) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.07, Test_acc 86.00
2024-09-02 15:24:15,753 [podnet.py] => Task 0, Epoch 35/300 (LR 0.09668) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 74.73
2024-09-02 15:24:18,193 [podnet.py] => Task 0, Epoch 36/300 (LR 0.09649) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.14, Test_acc 79.27
2024-09-02 15:24:20,630 [podnet.py] => Task 0, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.44, Test_acc 84.97
2024-09-02 15:24:23,185 [podnet.py] => Task 0, Epoch 38/300 (LR 0.09609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.08, Test_acc 84.70
2024-09-02 15:24:25,657 [podnet.py] => Task 0, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.69, Test_acc 82.83
2024-09-02 15:24:28,195 [podnet.py] => Task 0, Epoch 40/300 (LR 0.09568) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 75.70
2024-09-02 15:24:30,701 [podnet.py] => Task 0, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.97, Test_acc 83.57
2024-09-02 15:24:33,306 [podnet.py] => Task 0, Epoch 42/300 (LR 0.09524) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 82.43
2024-09-02 15:24:35,873 [podnet.py] => Task 0, Epoch 43/300 (LR 0.09502) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.89, Test_acc 86.70
2024-09-02 15:24:38,397 [podnet.py] => Task 0, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.76, Test_acc 71.70
2024-09-02 15:24:40,850 [podnet.py] => Task 0, Epoch 45/300 (LR 0.09455) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 84.30
2024-09-02 15:24:43,501 [podnet.py] => Task 0, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 80.70
2024-09-02 15:24:45,924 [podnet.py] => Task 0, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.17, Test_acc 84.67
2024-09-02 15:24:48,281 [podnet.py] => Task 0, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.20, Test_acc 83.63
2024-09-02 15:24:50,505 [podnet.py] => Task 0, Epoch 49/300 (LR 0.09356) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 85.03
2024-09-02 15:24:52,951 [podnet.py] => Task 0, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.65, Test_acc 82.57
2024-09-02 15:24:55,397 [podnet.py] => Task 0, Epoch 51/300 (LR 0.09304) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.39, Test_acc 88.17
2024-09-02 15:24:57,827 [podnet.py] => Task 0, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.86, Test_acc 80.73
2024-09-02 15:25:00,401 [podnet.py] => Task 0, Epoch 53/300 (LR 0.09249) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 78.07
2024-09-02 15:25:02,868 [podnet.py] => Task 0, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.67
2024-09-02 15:25:05,249 [podnet.py] => Task 0, Epoch 55/300 (LR 0.09193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.26, Test_acc 82.83
2024-09-02 15:25:07,842 [podnet.py] => Task 0, Epoch 56/300 (LR 0.09165) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.01, Test_acc 82.33
2024-09-02 15:25:10,268 [podnet.py] => Task 0, Epoch 57/300 (LR 0.09135) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.60, Test_acc 82.83
2024-09-02 15:25:12,787 [podnet.py] => Task 0, Epoch 58/300 (LR 0.09106) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.50, Test_acc 84.40
2024-09-02 15:25:15,336 [podnet.py] => Task 0, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.01, Test_acc 70.30
2024-09-02 15:25:17,822 [podnet.py] => Task 0, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 82.83
2024-09-02 15:25:20,276 [podnet.py] => Task 0, Epoch 61/300 (LR 0.09014) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.69, Test_acc 83.20
2024-09-02 15:25:22,728 [podnet.py] => Task 0, Epoch 62/300 (LR 0.08983) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.30, Test_acc 86.53
2024-09-02 15:25:25,010 [podnet.py] => Task 0, Epoch 63/300 (LR 0.08951) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.41, Test_acc 84.83
2024-09-02 15:25:27,466 [podnet.py] => Task 0, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 84.63
2024-09-02 15:25:29,750 [podnet.py] => Task 0, Epoch 65/300 (LR 0.08886) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 81.80
2024-09-02 15:25:32,163 [podnet.py] => Task 0, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 81.17
2024-09-02 15:25:34,492 [podnet.py] => Task 0, Epoch 67/300 (LR 0.08819) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 82.20
2024-09-02 15:25:36,937 [podnet.py] => Task 0, Epoch 68/300 (LR 0.08785) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.91, Test_acc 83.43
2024-09-02 15:25:39,442 [podnet.py] => Task 0, Epoch 69/300 (LR 0.08751) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.09, Test_acc 84.27
2024-09-02 15:25:41,919 [podnet.py] => Task 0, Epoch 70/300 (LR 0.08716) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.47, Test_acc 84.80
2024-09-02 15:25:44,371 [podnet.py] => Task 0, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 88.13
2024-09-02 15:25:46,839 [podnet.py] => Task 0, Epoch 72/300 (LR 0.08645) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 87.83
2024-09-02 15:25:49,251 [podnet.py] => Task 0, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.82, Test_acc 87.00
2024-09-02 15:25:51,713 [podnet.py] => Task 0, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.41, Test_acc 87.03
2024-09-02 15:25:54,242 [podnet.py] => Task 0, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.78, Test_acc 86.63
2024-09-02 15:25:56,581 [podnet.py] => Task 0, Epoch 76/300 (LR 0.08498) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.71, Test_acc 78.20
2024-09-02 15:25:59,071 [podnet.py] => Task 0, Epoch 77/300 (LR 0.08461) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 84.30
2024-09-02 15:26:01,386 [podnet.py] => Task 0, Epoch 78/300 (LR 0.08423) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.25, Test_acc 86.53
2024-09-02 15:26:03,919 [podnet.py] => Task 0, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.88, Test_acc 80.93
2024-09-02 15:26:06,268 [podnet.py] => Task 0, Epoch 80/300 (LR 0.08346) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.19, Test_acc 83.10
2024-09-02 15:26:08,888 [podnet.py] => Task 0, Epoch 81/300 (LR 0.08307) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.09, Test_acc 86.57
2024-09-02 15:26:11,411 [podnet.py] => Task 0, Epoch 82/300 (LR 0.08267) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 86.83
2024-09-02 15:26:13,884 [podnet.py] => Task 0, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.72, Test_acc 84.97
2024-09-02 15:26:16,516 [podnet.py] => Task 0, Epoch 84/300 (LR 0.08187) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.52, Test_acc 80.90
2024-09-02 15:26:18,939 [podnet.py] => Task 0, Epoch 85/300 (LR 0.08147) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.01, Test_acc 86.27
2024-09-02 15:26:21,369 [podnet.py] => Task 0, Epoch 86/300 (LR 0.08106) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.85, Test_acc 80.87
2024-09-02 15:26:23,774 [podnet.py] => Task 0, Epoch 87/300 (LR 0.08065) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.98, Test_acc 78.57
2024-09-02 15:26:26,227 [podnet.py] => Task 0, Epoch 88/300 (LR 0.08023) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.55, Test_acc 85.57
2024-09-02 15:26:28,547 [podnet.py] => Task 0, Epoch 89/300 (LR 0.07981) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.10, Test_acc 87.87
2024-09-02 15:26:30,961 [podnet.py] => Task 0, Epoch 90/300 (LR 0.07939) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.83
2024-09-02 15:26:33,400 [podnet.py] => Task 0, Epoch 91/300 (LR 0.07896) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.42, Test_acc 82.47
2024-09-02 15:26:35,754 [podnet.py] => Task 0, Epoch 92/300 (LR 0.07854) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.95, Test_acc 86.23
2024-09-02 15:26:38,012 [podnet.py] => Task 0, Epoch 93/300 (LR 0.07810) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 87.07
2024-09-02 15:26:40,332 [podnet.py] => Task 0, Epoch 94/300 (LR 0.07767) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.24, Test_acc 84.03
2024-09-02 15:26:42,687 [podnet.py] => Task 0, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.64, Test_acc 80.70
2024-09-02 15:26:45,020 [podnet.py] => Task 0, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 85.07
2024-09-02 15:26:47,463 [podnet.py] => Task 0, Epoch 97/300 (LR 0.07635) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.31, Test_acc 79.37
2024-09-02 15:26:49,999 [podnet.py] => Task 0, Epoch 98/300 (LR 0.07590) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 87.33
2024-09-02 15:26:52,404 [podnet.py] => Task 0, Epoch 99/300 (LR 0.07545) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.21, Test_acc 84.17
2024-09-02 15:26:54,873 [podnet.py] => Task 0, Epoch 100/300 (LR 0.07500) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 85.00
2024-09-02 15:26:57,314 [podnet.py] => Task 0, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.81, Test_acc 82.50
2024-09-02 15:26:59,697 [podnet.py] => Task 0, Epoch 102/300 (LR 0.07409) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.54, Test_acc 83.40
2024-09-02 15:27:02,094 [podnet.py] => Task 0, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.89, Test_acc 83.40
2024-09-02 15:27:04,395 [podnet.py] => Task 0, Epoch 104/300 (LR 0.07316) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.00, Test_acc 80.57
2024-09-02 15:27:06,807 [podnet.py] => Task 0, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.07, Test_acc 88.03
2024-09-02 15:27:09,310 [podnet.py] => Task 0, Epoch 106/300 (LR 0.07223) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 85.80
2024-09-02 15:27:11,917 [podnet.py] => Task 0, Epoch 107/300 (LR 0.07176) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.17, Test_acc 80.70
2024-09-02 15:27:14,242 [podnet.py] => Task 0, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 85.73
2024-09-02 15:27:16,651 [podnet.py] => Task 0, Epoch 109/300 (LR 0.07081) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.50
2024-09-02 15:27:19,189 [podnet.py] => Task 0, Epoch 110/300 (LR 0.07034) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.49, Test_acc 87.13
2024-09-02 15:27:21,699 [podnet.py] => Task 0, Epoch 111/300 (LR 0.06986) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.58, Test_acc 87.13
2024-09-02 15:27:24,060 [podnet.py] => Task 0, Epoch 112/300 (LR 0.06938) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.84, Test_acc 84.77
2024-09-02 15:27:26,608 [podnet.py] => Task 0, Epoch 113/300 (LR 0.06889) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.13, Test_acc 85.40
2024-09-02 15:27:28,977 [podnet.py] => Task 0, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.80, Test_acc 83.33
2024-09-02 15:27:31,336 [podnet.py] => Task 0, Epoch 115/300 (LR 0.06792) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 84.27
2024-09-02 15:27:33,699 [podnet.py] => Task 0, Epoch 116/300 (LR 0.06743) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.03, Test_acc 84.73
2024-09-02 15:27:36,123 [podnet.py] => Task 0, Epoch 117/300 (LR 0.06694) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.29, Test_acc 79.07
2024-09-02 15:27:38,465 [podnet.py] => Task 0, Epoch 118/300 (LR 0.06644) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 84.63
2024-09-02 15:27:40,835 [podnet.py] => Task 0, Epoch 119/300 (LR 0.06595) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 84.53
2024-09-02 15:27:43,231 [podnet.py] => Task 0, Epoch 120/300 (LR 0.06545) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.43, Test_acc 83.80
2024-09-02 15:27:45,641 [podnet.py] => Task 0, Epoch 121/300 (LR 0.06495) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.73, Test_acc 87.63
2024-09-02 15:27:48,175 [podnet.py] => Task 0, Epoch 122/300 (LR 0.06445) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 83.27
2024-09-02 15:27:50,460 [podnet.py] => Task 0, Epoch 123/300 (LR 0.06395) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 82.97
2024-09-02 15:27:52,802 [podnet.py] => Task 0, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.60, Test_acc 83.40
2024-09-02 15:27:55,172 [podnet.py] => Task 0, Epoch 125/300 (LR 0.06294) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.22, Test_acc 83.77
2024-09-02 15:27:57,553 [podnet.py] => Task 0, Epoch 126/300 (LR 0.06243) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.20, Test_acc 86.57
2024-09-02 15:27:59,964 [podnet.py] => Task 0, Epoch 127/300 (LR 0.06193) => LSC_loss 0.10, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.36, Test_acc 86.00
2024-09-02 15:28:02,372 [podnet.py] => Task 0, Epoch 128/300 (LR 0.06142) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.84, Test_acc 84.60
2024-09-02 15:28:04,767 [podnet.py] => Task 0, Epoch 129/300 (LR 0.06091) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 87.97
2024-09-02 15:28:07,109 [podnet.py] => Task 0, Epoch 130/300 (LR 0.06040) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 82.23
2024-09-02 15:28:09,477 [podnet.py] => Task 0, Epoch 131/300 (LR 0.05988) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 86.90
2024-09-02 15:28:11,980 [podnet.py] => Task 0, Epoch 132/300 (LR 0.05937) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 89.73
2024-09-02 15:28:14,394 [podnet.py] => Task 0, Epoch 133/300 (LR 0.05885) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.57
2024-09-02 15:28:16,832 [podnet.py] => Task 0, Epoch 134/300 (LR 0.05834) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.87
2024-09-02 15:28:19,110 [podnet.py] => Task 0, Epoch 135/300 (LR 0.05782) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.44, Test_acc 85.53
2024-09-02 15:28:21,462 [podnet.py] => Task 0, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.63, Test_acc 79.13
2024-09-02 15:28:23,956 [podnet.py] => Task 0, Epoch 137/300 (LR 0.05679) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.71, Test_acc 88.00
2024-09-02 15:28:26,459 [podnet.py] => Task 0, Epoch 138/300 (LR 0.05627) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.33
2024-09-02 15:28:28,772 [podnet.py] => Task 0, Epoch 139/300 (LR 0.05575) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 88.17
2024-09-02 15:28:31,082 [podnet.py] => Task 0, Epoch 140/300 (LR 0.05523) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.62, Test_acc 82.47
2024-09-02 15:28:33,413 [podnet.py] => Task 0, Epoch 141/300 (LR 0.05471) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.61, Test_acc 84.93
2024-09-02 15:28:35,831 [podnet.py] => Task 0, Epoch 142/300 (LR 0.05418) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.70, Test_acc 84.13
2024-09-02 15:28:38,330 [podnet.py] => Task 0, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.75, Test_acc 84.60
2024-09-02 15:28:40,823 [podnet.py] => Task 0, Epoch 144/300 (LR 0.05314) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 87.83
2024-09-02 15:28:43,299 [podnet.py] => Task 0, Epoch 145/300 (LR 0.05262) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.45, Test_acc 86.60
2024-09-02 15:28:45,776 [podnet.py] => Task 0, Epoch 146/300 (LR 0.05209) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 81.50
2024-09-02 15:28:48,290 [podnet.py] => Task 0, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.53, Test_acc 86.77
2024-09-02 15:28:50,791 [podnet.py] => Task 0, Epoch 148/300 (LR 0.05105) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.37, Test_acc 84.77
2024-09-02 15:28:53,224 [podnet.py] => Task 0, Epoch 149/300 (LR 0.05052) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 85.70
2024-09-02 15:28:55,678 [podnet.py] => Task 0, Epoch 150/300 (LR 0.05000) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 86.57
2024-09-02 15:28:58,202 [podnet.py] => Task 0, Epoch 151/300 (LR 0.04948) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.81, Test_acc 84.43
2024-09-02 15:29:00,800 [podnet.py] => Task 0, Epoch 152/300 (LR 0.04895) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 88.60
2024-09-02 15:29:03,430 [podnet.py] => Task 0, Epoch 153/300 (LR 0.04843) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 87.07
2024-09-02 15:29:05,875 [podnet.py] => Task 0, Epoch 154/300 (LR 0.04791) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 87.57
2024-09-02 15:29:08,314 [podnet.py] => Task 0, Epoch 155/300 (LR 0.04738) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.14, Test_acc 81.10
2024-09-02 15:29:10,836 [podnet.py] => Task 0, Epoch 156/300 (LR 0.04686) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.67, Test_acc 88.10
2024-09-02 15:29:13,406 [podnet.py] => Task 0, Epoch 157/300 (LR 0.04634) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.75, Test_acc 86.87
2024-09-02 15:29:15,995 [podnet.py] => Task 0, Epoch 158/300 (LR 0.04582) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 88.53
2024-09-02 15:29:18,258 [podnet.py] => Task 0, Epoch 159/300 (LR 0.04529) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.43
2024-09-02 15:29:20,364 [podnet.py] => Task 0, Epoch 160/300 (LR 0.04477) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 86.20
2024-09-02 15:29:22,479 [podnet.py] => Task 0, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.68, Test_acc 84.87
2024-09-02 15:29:24,231 [podnet.py] => Task 0, Epoch 162/300 (LR 0.04373) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.52, Test_acc 88.27
2024-09-02 15:29:25,904 [podnet.py] => Task 0, Epoch 163/300 (LR 0.04321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 85.63
2024-09-02 15:29:27,471 [podnet.py] => Task 0, Epoch 164/300 (LR 0.04270) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.51, Test_acc 83.27
2024-09-02 15:29:29,018 [podnet.py] => Task 0, Epoch 165/300 (LR 0.04218) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.63, Test_acc 85.37
2024-09-02 15:29:30,984 [podnet.py] => Task 0, Epoch 166/300 (LR 0.04166) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.33, Test_acc 89.13
2024-09-02 15:29:32,870 [podnet.py] => Task 0, Epoch 167/300 (LR 0.04115) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.61, Test_acc 86.80
2024-09-02 15:29:34,671 [podnet.py] => Task 0, Epoch 168/300 (LR 0.04063) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.17
2024-09-02 15:29:36,437 [podnet.py] => Task 0, Epoch 169/300 (LR 0.04012) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.03
2024-09-02 15:29:38,386 [podnet.py] => Task 0, Epoch 170/300 (LR 0.03960) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.88, Test_acc 89.47
2024-09-02 15:29:40,447 [podnet.py] => Task 0, Epoch 171/300 (LR 0.03909) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.13
2024-09-02 15:29:42,412 [podnet.py] => Task 0, Epoch 172/300 (LR 0.03858) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.91, Test_acc 89.47
2024-09-02 15:29:44,320 [podnet.py] => Task 0, Epoch 173/300 (LR 0.03807) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 88.13
2024-09-02 15:29:46,065 [podnet.py] => Task 0, Epoch 174/300 (LR 0.03757) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 84.43
2024-09-02 15:29:47,856 [podnet.py] => Task 0, Epoch 175/300 (LR 0.03706) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.57, Test_acc 86.30
2024-09-02 15:29:49,703 [podnet.py] => Task 0, Epoch 176/300 (LR 0.03655) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 81.37
2024-09-02 15:29:51,648 [podnet.py] => Task 0, Epoch 177/300 (LR 0.03605) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.73, Test_acc 85.23
2024-09-02 15:29:53,609 [podnet.py] => Task 0, Epoch 178/300 (LR 0.03555) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 85.83
2024-09-02 15:29:55,766 [podnet.py] => Task 0, Epoch 179/300 (LR 0.03505) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.55, Test_acc 83.43
2024-09-02 15:29:57,630 [podnet.py] => Task 0, Epoch 180/300 (LR 0.03455) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 88.90
2024-09-02 15:29:59,572 [podnet.py] => Task 0, Epoch 181/300 (LR 0.03405) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 88.60
2024-09-02 15:30:01,375 [podnet.py] => Task 0, Epoch 182/300 (LR 0.03356) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.73
2024-09-02 15:30:03,436 [podnet.py] => Task 0, Epoch 183/300 (LR 0.03306) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.73
2024-09-02 15:30:05,567 [podnet.py] => Task 0, Epoch 184/300 (LR 0.03257) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.11, Test_acc 88.17
2024-09-02 15:30:07,429 [podnet.py] => Task 0, Epoch 185/300 (LR 0.03208) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 87.47
2024-09-02 15:30:09,384 [podnet.py] => Task 0, Epoch 186/300 (LR 0.03159) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 79.03
2024-09-02 15:30:11,164 [podnet.py] => Task 0, Epoch 187/300 (LR 0.03111) => LSC_loss 0.09, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.53, Test_acc 84.80
2024-09-02 15:30:13,039 [podnet.py] => Task 0, Epoch 188/300 (LR 0.03062) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.47, Test_acc 85.53
2024-09-02 15:30:15,245 [podnet.py] => Task 0, Epoch 189/300 (LR 0.03014) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.35, Test_acc 88.90
2024-09-02 15:30:17,428 [podnet.py] => Task 0, Epoch 190/300 (LR 0.02966) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.69, Test_acc 86.80
2024-09-02 15:30:19,755 [podnet.py] => Task 0, Epoch 191/300 (LR 0.02919) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 88.20
2024-09-02 15:30:22,139 [podnet.py] => Task 0, Epoch 192/300 (LR 0.02871) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.13, Test_acc 86.90
2024-09-02 15:30:24,153 [podnet.py] => Task 0, Epoch 193/300 (LR 0.02824) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.89, Test_acc 89.30
2024-09-02 15:30:25,985 [podnet.py] => Task 0, Epoch 194/300 (LR 0.02777) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.92, Test_acc 90.27
2024-09-02 15:30:27,875 [podnet.py] => Task 0, Epoch 195/300 (LR 0.02730) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.47
2024-09-02 15:30:29,803 [podnet.py] => Task 0, Epoch 196/300 (LR 0.02684) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.73
2024-09-02 15:30:31,789 [podnet.py] => Task 0, Epoch 197/300 (LR 0.02637) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.63
2024-09-02 15:30:33,965 [podnet.py] => Task 0, Epoch 198/300 (LR 0.02591) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.23
2024-09-02 15:30:36,131 [podnet.py] => Task 0, Epoch 199/300 (LR 0.02545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.60
2024-09-02 15:30:38,069 [podnet.py] => Task 0, Epoch 200/300 (LR 0.02500) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.67
2024-09-02 15:30:40,045 [podnet.py] => Task 0, Epoch 201/300 (LR 0.02455) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.67
2024-09-02 15:30:41,959 [podnet.py] => Task 0, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 88.40
2024-09-02 15:30:43,873 [podnet.py] => Task 0, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.02, Test_acc 88.30
2024-09-02 15:30:45,864 [podnet.py] => Task 0, Epoch 204/300 (LR 0.02321) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.79, Test_acc 87.87
2024-09-02 15:30:48,055 [podnet.py] => Task 0, Epoch 205/300 (LR 0.02277) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.74, Test_acc 88.73
2024-09-02 15:30:49,964 [podnet.py] => Task 0, Epoch 206/300 (LR 0.02233) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.93, Test_acc 90.10
2024-09-02 15:30:52,095 [podnet.py] => Task 0, Epoch 207/300 (LR 0.02190) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.13
2024-09-02 15:30:54,096 [podnet.py] => Task 0, Epoch 208/300 (LR 0.02146) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 88.40
2024-09-02 15:30:56,460 [podnet.py] => Task 0, Epoch 209/300 (LR 0.02104) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 89.43
2024-09-02 15:30:58,662 [podnet.py] => Task 0, Epoch 210/300 (LR 0.02061) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.49, Test_acc 86.40
2024-09-02 15:31:00,651 [podnet.py] => Task 0, Epoch 211/300 (LR 0.02019) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 86.90
2024-09-02 15:31:02,444 [podnet.py] => Task 0, Epoch 212/300 (LR 0.01977) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.85, Test_acc 86.67
2024-09-02 15:31:04,214 [podnet.py] => Task 0, Epoch 213/300 (LR 0.01935) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.37
2024-09-02 15:31:06,351 [podnet.py] => Task 0, Epoch 214/300 (LR 0.01894) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.77, Test_acc 89.67
2024-09-02 15:31:08,422 [podnet.py] => Task 0, Epoch 215/300 (LR 0.01853) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 89.77
2024-09-02 15:31:10,437 [podnet.py] => Task 0, Epoch 216/300 (LR 0.01813) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.20
2024-09-02 15:31:12,335 [podnet.py] => Task 0, Epoch 217/300 (LR 0.01773) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 87.83
2024-09-02 15:31:14,237 [podnet.py] => Task 0, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.16, Test_acc 89.30
2024-09-02 15:31:16,234 [podnet.py] => Task 0, Epoch 219/300 (LR 0.01693) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.86, Test_acc 88.13
2024-09-02 15:31:18,251 [podnet.py] => Task 0, Epoch 220/300 (LR 0.01654) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.87, Test_acc 89.87
2024-09-02 15:31:20,388 [podnet.py] => Task 0, Epoch 221/300 (LR 0.01616) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.98, Test_acc 89.27
2024-09-02 15:31:22,547 [podnet.py] => Task 0, Epoch 222/300 (LR 0.01577) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:31:24,361 [podnet.py] => Task 0, Epoch 223/300 (LR 0.01539) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 15:31:26,484 [podnet.py] => Task 0, Epoch 224/300 (LR 0.01502) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:31:28,601 [podnet.py] => Task 0, Epoch 225/300 (LR 0.01464) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:31:30,892 [podnet.py] => Task 0, Epoch 226/300 (LR 0.01428) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:31:33,215 [podnet.py] => Task 0, Epoch 227/300 (LR 0.01391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.43
2024-09-02 15:31:35,283 [podnet.py] => Task 0, Epoch 228/300 (LR 0.01355) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.33
2024-09-02 15:31:37,202 [podnet.py] => Task 0, Epoch 229/300 (LR 0.01320) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:31:39,135 [podnet.py] => Task 0, Epoch 230/300 (LR 0.01284) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.13
2024-09-02 15:31:40,952 [podnet.py] => Task 0, Epoch 231/300 (LR 0.01249) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.00
2024-09-02 15:31:43,069 [podnet.py] => Task 0, Epoch 232/300 (LR 0.01215) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 88.90
2024-09-02 15:31:44,794 [podnet.py] => Task 0, Epoch 233/300 (LR 0.01181) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.95, Test_acc 89.07
2024-09-02 15:31:46,637 [podnet.py] => Task 0, Epoch 234/300 (LR 0.01147) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.10
2024-09-02 15:31:48,564 [podnet.py] => Task 0, Epoch 235/300 (LR 0.01114) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 90.03
2024-09-02 15:31:50,548 [podnet.py] => Task 0, Epoch 236/300 (LR 0.01082) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.83, Test_acc 89.43
2024-09-02 15:31:52,896 [podnet.py] => Task 0, Epoch 237/300 (LR 0.01049) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 15:31:55,156 [podnet.py] => Task 0, Epoch 238/300 (LR 0.01017) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:31:57,391 [podnet.py] => Task 0, Epoch 239/300 (LR 0.00986) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.97
2024-09-02 15:31:59,412 [podnet.py] => Task 0, Epoch 240/300 (LR 0.00955) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:32:01,396 [podnet.py] => Task 0, Epoch 241/300 (LR 0.00924) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 15:32:03,457 [podnet.py] => Task 0, Epoch 242/300 (LR 0.00894) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.33
2024-09-02 15:32:05,318 [podnet.py] => Task 0, Epoch 243/300 (LR 0.00865) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 15:32:07,186 [podnet.py] => Task 0, Epoch 244/300 (LR 0.00835) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:32:09,093 [podnet.py] => Task 0, Epoch 245/300 (LR 0.00807) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.73
2024-09-02 15:32:11,101 [podnet.py] => Task 0, Epoch 246/300 (LR 0.00778) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 15:32:13,143 [podnet.py] => Task 0, Epoch 247/300 (LR 0.00751) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:32:15,017 [podnet.py] => Task 0, Epoch 248/300 (LR 0.00723) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.80
2024-09-02 15:32:17,178 [podnet.py] => Task 0, Epoch 249/300 (LR 0.00696) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.87
2024-09-02 15:32:19,335 [podnet.py] => Task 0, Epoch 250/300 (LR 0.00670) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:32:21,575 [podnet.py] => Task 0, Epoch 251/300 (LR 0.00644) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.70
2024-09-02 15:32:23,637 [podnet.py] => Task 0, Epoch 252/300 (LR 0.00618) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:32:25,783 [podnet.py] => Task 0, Epoch 253/300 (LR 0.00593) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.60
2024-09-02 15:32:27,910 [podnet.py] => Task 0, Epoch 254/300 (LR 0.00569) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:32:29,966 [podnet.py] => Task 0, Epoch 255/300 (LR 0.00545) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 15:32:31,665 [podnet.py] => Task 0, Epoch 256/300 (LR 0.00521) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 15:32:33,621 [podnet.py] => Task 0, Epoch 257/300 (LR 0.00498) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 90.57
2024-09-02 15:32:35,412 [podnet.py] => Task 0, Epoch 258/300 (LR 0.00476) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.97, Test_acc 89.87
2024-09-02 15:32:37,188 [podnet.py] => Task 0, Epoch 259/300 (LR 0.00454) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.73
2024-09-02 15:32:38,999 [podnet.py] => Task 0, Epoch 260/300 (LR 0.00432) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.77
2024-09-02 15:32:40,773 [podnet.py] => Task 0, Epoch 261/300 (LR 0.00411) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.83
2024-09-02 15:32:42,702 [podnet.py] => Task 0, Epoch 262/300 (LR 0.00391) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:32:44,541 [podnet.py] => Task 0, Epoch 263/300 (LR 0.00371) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.94, Test_acc 88.80
2024-09-02 15:32:46,307 [podnet.py] => Task 0, Epoch 264/300 (LR 0.00351) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 15:32:48,133 [podnet.py] => Task 0, Epoch 265/300 (LR 0.00332) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 15:32:49,957 [podnet.py] => Task 0, Epoch 266/300 (LR 0.00314) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.47
2024-09-02 15:32:51,979 [podnet.py] => Task 0, Epoch 267/300 (LR 0.00296) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:32:54,177 [podnet.py] => Task 0, Epoch 268/300 (LR 0.00278) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:32:56,087 [podnet.py] => Task 0, Epoch 269/300 (LR 0.00261) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:32:57,946 [podnet.py] => Task 0, Epoch 270/300 (LR 0.00245) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.63
2024-09-02 15:32:59,788 [podnet.py] => Task 0, Epoch 271/300 (LR 0.00229) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:33:01,692 [podnet.py] => Task 0, Epoch 272/300 (LR 0.00213) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.90
2024-09-02 15:33:03,571 [podnet.py] => Task 0, Epoch 273/300 (LR 0.00199) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.67
2024-09-02 15:33:05,310 [podnet.py] => Task 0, Epoch 274/300 (LR 0.00184) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.93
2024-09-02 15:33:07,060 [podnet.py] => Task 0, Epoch 275/300 (LR 0.00170) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:33:08,775 [podnet.py] => Task 0, Epoch 276/300 (LR 0.00157) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.40
2024-09-02 15:33:10,531 [podnet.py] => Task 0, Epoch 277/300 (LR 0.00144) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:33:12,299 [podnet.py] => Task 0, Epoch 278/300 (LR 0.00132) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.70
2024-09-02 15:33:14,191 [podnet.py] => Task 0, Epoch 279/300 (LR 0.00120) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.96, Test_acc 88.97
2024-09-02 15:33:15,992 [podnet.py] => Task 0, Epoch 280/300 (LR 0.00109) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:33:17,964 [podnet.py] => Task 0, Epoch 281/300 (LR 0.00099) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 15:33:19,915 [podnet.py] => Task 0, Epoch 282/300 (LR 0.00089) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 15:33:21,883 [podnet.py] => Task 0, Epoch 283/300 (LR 0.00079) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.20
2024-09-02 15:33:23,749 [podnet.py] => Task 0, Epoch 284/300 (LR 0.00070) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.67
2024-09-02 15:33:26,108 [podnet.py] => Task 0, Epoch 285/300 (LR 0.00062) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.53
2024-09-02 15:33:28,296 [podnet.py] => Task 0, Epoch 286/300 (LR 0.00054) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.57
2024-09-02 15:33:30,212 [podnet.py] => Task 0, Epoch 287/300 (LR 0.00046) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.17
2024-09-02 15:33:32,020 [podnet.py] => Task 0, Epoch 288/300 (LR 0.00039) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:33:33,802 [podnet.py] => Task 0, Epoch 289/300 (LR 0.00033) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.23
2024-09-02 15:33:35,568 [podnet.py] => Task 0, Epoch 290/300 (LR 0.00027) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:33:37,587 [podnet.py] => Task 0, Epoch 291/300 (LR 0.00022) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.43
2024-09-02 15:33:39,480 [podnet.py] => Task 0, Epoch 292/300 (LR 0.00018) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:33:41,260 [podnet.py] => Task 0, Epoch 293/300 (LR 0.00013) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.97
2024-09-02 15:33:43,124 [podnet.py] => Task 0, Epoch 294/300 (LR 0.00010) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.30
2024-09-02 15:33:44,938 [podnet.py] => Task 0, Epoch 295/300 (LR 0.00007) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:33:47,039 [podnet.py] => Task 0, Epoch 296/300 (LR 0.00004) => LSC_loss 0.01, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.99, Test_acc 89.17
2024-09-02 15:33:49,064 [podnet.py] => Task 0, Epoch 297/300 (LR 0.00002) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.87
2024-09-02 15:33:51,058 [podnet.py] => Task 0, Epoch 298/300 (LR 0.00001) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.13
2024-09-02 15:33:52,994 [podnet.py] => Task 0, Epoch 299/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 89.50
2024-09-02 15:33:55,021 [podnet.py] => Task 0, Epoch 300/300 (LR 0.00000) => LSC_loss 0.00, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 100.00, Test_acc 88.90
2024-09-02 15:33:55,022 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 15:33:55,022 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 15:34:01,032 [podnet.py] => Exemplar size: 500
2024-09-02 15:34:01,032 [trainer.py] => CNN: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 15:34:01,032 [trainer.py] => NME: {'total': 88.9, '00-04': 88.9, 'old': 0, 'new': 88.9}
2024-09-02 15:34:01,032 [trainer.py] => CNN top1 curve: [88.9]
2024-09-02 15:34:01,032 [trainer.py] => CNN top5 curve: [100.0]
2024-09-02 15:34:01,032 [trainer.py] => NME top1 curve: [88.9]
2024-09-02 15:34:01,032 [trainer.py] => NME top5 curve: [100.0]

2024-09-02 15:34:01,032 [trainer.py] => Average Accuracy (CNN): 88.9
2024-09-02 15:34:01,032 [trainer.py] => Average Accuracy (NME): 88.9
2024-09-02 15:34:01,033 [trainer.py] => All params: 3869505
2024-09-02 15:34:01,033 [trainer.py] => Trainable params: 3869505
2024-09-02 15:34:01,034 [podnet.py] => Learning on 5-7
2024-09-02 15:34:01,054 [podnet.py] => Adaptive factor: 1.8708286933869707
2024-09-02 15:34:02,905 [podnet.py] => Task 1, Epoch 1/300 (LR 0.10000) => LSC_loss 1.11, Spatial_loss 0.70, Flat_loss 0.75, Train_acc 73.13, Test_acc 17.43
2024-09-02 15:34:04,544 [podnet.py] => Task 1, Epoch 2/300 (LR 0.09999) => LSC_loss 0.51, Spatial_loss 0.58, Flat_loss 0.53, Train_acc 87.60, Test_acc 19.67
2024-09-02 15:34:06,070 [podnet.py] => Task 1, Epoch 3/300 (LR 0.09998) => LSC_loss 0.44, Spatial_loss 0.55, Flat_loss 0.47, Train_acc 89.09, Test_acc 36.31
2024-09-02 15:34:07,533 [podnet.py] => Task 1, Epoch 4/300 (LR 0.09996) => LSC_loss 0.41, Spatial_loss 0.55, Flat_loss 0.45, Train_acc 89.49, Test_acc 36.17
2024-09-02 15:34:09,066 [podnet.py] => Task 1, Epoch 5/300 (LR 0.09993) => LSC_loss 0.27, Spatial_loss 0.47, Flat_loss 0.38, Train_acc 93.56, Test_acc 45.81
2024-09-02 15:34:10,736 [podnet.py] => Task 1, Epoch 6/300 (LR 0.09990) => LSC_loss 0.22, Spatial_loss 0.45, Flat_loss 0.35, Train_acc 94.80, Test_acc 49.24
2024-09-02 15:34:12,372 [podnet.py] => Task 1, Epoch 7/300 (LR 0.09987) => LSC_loss 0.18, Spatial_loss 0.41, Flat_loss 0.32, Train_acc 95.98, Test_acc 55.83
2024-09-02 15:34:14,066 [podnet.py] => Task 1, Epoch 8/300 (LR 0.09982) => LSC_loss 0.14, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 96.91, Test_acc 58.45
2024-09-02 15:34:15,621 [podnet.py] => Task 1, Epoch 9/300 (LR 0.09978) => LSC_loss 0.12, Spatial_loss 0.35, Flat_loss 0.27, Train_acc 97.89, Test_acc 59.45
2024-09-02 15:34:17,292 [podnet.py] => Task 1, Epoch 10/300 (LR 0.09973) => LSC_loss 0.11, Spatial_loss 0.34, Flat_loss 0.26, Train_acc 98.40, Test_acc 60.26
2024-09-02 15:34:18,976 [podnet.py] => Task 1, Epoch 11/300 (LR 0.09967) => LSC_loss 0.11, Spatial_loss 0.33, Flat_loss 0.25, Train_acc 98.38, Test_acc 61.57
2024-09-02 15:34:20,563 [podnet.py] => Task 1, Epoch 12/300 (LR 0.09961) => LSC_loss 0.12, Spatial_loss 0.36, Flat_loss 0.27, Train_acc 97.56, Test_acc 60.10
2024-09-02 15:34:22,240 [podnet.py] => Task 1, Epoch 13/300 (LR 0.09954) => LSC_loss 0.09, Spatial_loss 0.33, Flat_loss 0.25, Train_acc 98.53, Test_acc 61.50
2024-09-02 15:34:24,098 [podnet.py] => Task 1, Epoch 14/300 (LR 0.09946) => LSC_loss 0.08, Spatial_loss 0.30, Flat_loss 0.23, Train_acc 99.27, Test_acc 56.81
2024-09-02 15:34:25,902 [podnet.py] => Task 1, Epoch 15/300 (LR 0.09938) => LSC_loss 0.08, Spatial_loss 0.30, Flat_loss 0.22, Train_acc 99.47, Test_acc 60.79
2024-09-02 15:34:27,671 [podnet.py] => Task 1, Epoch 16/300 (LR 0.09930) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.22, Train_acc 99.40, Test_acc 65.21
2024-09-02 15:34:29,468 [podnet.py] => Task 1, Epoch 17/300 (LR 0.09921) => LSC_loss 0.07, Spatial_loss 0.27, Flat_loss 0.21, Train_acc 99.60, Test_acc 58.52
2024-09-02 15:34:31,228 [podnet.py] => Task 1, Epoch 18/300 (LR 0.09911) => LSC_loss 0.19, Spatial_loss 0.39, Flat_loss 0.29, Train_acc 95.44, Test_acc 42.57
2024-09-02 15:34:33,007 [podnet.py] => Task 1, Epoch 19/300 (LR 0.09901) => LSC_loss 0.22, Spatial_loss 0.46, Flat_loss 0.34, Train_acc 93.93, Test_acc 47.67
2024-09-02 15:34:34,751 [podnet.py] => Task 1, Epoch 20/300 (LR 0.09891) => LSC_loss 0.13, Spatial_loss 0.41, Flat_loss 0.30, Train_acc 96.98, Test_acc 52.05
2024-09-02 15:34:36,480 [podnet.py] => Task 1, Epoch 21/300 (LR 0.09880) => LSC_loss 0.11, Spatial_loss 0.38, Flat_loss 0.28, Train_acc 97.73, Test_acc 63.12
2024-09-02 15:34:38,265 [podnet.py] => Task 1, Epoch 22/300 (LR 0.09868) => LSC_loss 0.07, Spatial_loss 0.31, Flat_loss 0.23, Train_acc 99.47, Test_acc 65.62
2024-09-02 15:34:40,292 [podnet.py] => Task 1, Epoch 23/300 (LR 0.09856) => LSC_loss 0.06, Spatial_loss 0.28, Flat_loss 0.21, Train_acc 99.76, Test_acc 68.90
2024-09-02 15:34:42,422 [podnet.py] => Task 1, Epoch 24/300 (LR 0.09843) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.82, Test_acc 62.52
2024-09-02 15:34:44,313 [podnet.py] => Task 1, Epoch 25/300 (LR 0.09830) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.87, Test_acc 62.10
2024-09-02 15:34:45,993 [podnet.py] => Task 1, Epoch 26/300 (LR 0.09816) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.19, Train_acc 99.73, Test_acc 64.43
2024-09-02 15:34:47,736 [podnet.py] => Task 1, Epoch 27/300 (LR 0.09801) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.71, Test_acc 61.33
2024-09-02 15:34:49,252 [podnet.py] => Task 1, Epoch 28/300 (LR 0.09787) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.19, Train_acc 99.73, Test_acc 65.40
2024-09-02 15:34:50,775 [podnet.py] => Task 1, Epoch 29/300 (LR 0.09771) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.89, Test_acc 66.14
2024-09-02 15:34:52,378 [podnet.py] => Task 1, Epoch 30/300 (LR 0.09755) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.82, Test_acc 65.55
2024-09-02 15:34:54,187 [podnet.py] => Task 1, Epoch 31/300 (LR 0.09739) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.82, Test_acc 66.74
2024-09-02 15:34:55,986 [podnet.py] => Task 1, Epoch 32/300 (LR 0.09722) => LSC_loss 0.06, Spatial_loss 0.24, Flat_loss 0.18, Train_acc 99.80, Test_acc 60.52
2024-09-02 15:34:57,730 [podnet.py] => Task 1, Epoch 33/300 (LR 0.09704) => LSC_loss 0.26, Spatial_loss 0.47, Flat_loss 0.34, Train_acc 92.71, Test_acc 45.52
2024-09-02 15:34:59,407 [podnet.py] => Task 1, Epoch 34/300 (LR 0.09686) => LSC_loss 0.30, Spatial_loss 0.51, Flat_loss 0.38, Train_acc 92.00, Test_acc 50.07
2024-09-02 15:35:01,190 [podnet.py] => Task 1, Epoch 35/300 (LR 0.09668) => LSC_loss 0.14, Spatial_loss 0.43, Flat_loss 0.32, Train_acc 96.64, Test_acc 57.95
2024-09-02 15:35:02,764 [podnet.py] => Task 1, Epoch 36/300 (LR 0.09649) => LSC_loss 0.08, Spatial_loss 0.36, Flat_loss 0.27, Train_acc 98.56, Test_acc 61.05
2024-09-02 15:35:04,469 [podnet.py] => Task 1, Epoch 37/300 (LR 0.09629) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.23, Train_acc 99.56, Test_acc 61.71
2024-09-02 15:35:06,053 [podnet.py] => Task 1, Epoch 38/300 (LR 0.09609) => LSC_loss 0.06, Spatial_loss 0.28, Flat_loss 0.20, Train_acc 99.78, Test_acc 69.83
2024-09-02 15:35:07,621 [podnet.py] => Task 1, Epoch 39/300 (LR 0.09589) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.91, Test_acc 66.43
2024-09-02 15:35:09,485 [podnet.py] => Task 1, Epoch 40/300 (LR 0.09568) => LSC_loss 0.07, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.71, Test_acc 61.48
2024-09-02 15:35:11,292 [podnet.py] => Task 1, Epoch 41/300 (LR 0.09546) => LSC_loss 0.09, Spatial_loss 0.32, Flat_loss 0.24, Train_acc 98.76, Test_acc 63.26
2024-09-02 15:35:13,007 [podnet.py] => Task 1, Epoch 42/300 (LR 0.09524) => LSC_loss 0.08, Spatial_loss 0.33, Flat_loss 0.23, Train_acc 98.84, Test_acc 62.50
2024-09-02 15:35:14,854 [podnet.py] => Task 1, Epoch 43/300 (LR 0.09502) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.20, Train_acc 99.73, Test_acc 69.36
2024-09-02 15:35:16,392 [podnet.py] => Task 1, Epoch 44/300 (LR 0.09479) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.87, Test_acc 63.31
2024-09-02 15:35:17,903 [podnet.py] => Task 1, Epoch 45/300 (LR 0.09455) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.84, Test_acc 67.83
2024-09-02 15:35:19,504 [podnet.py] => Task 1, Epoch 46/300 (LR 0.09431) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.80, Test_acc 68.64
2024-09-02 15:35:21,065 [podnet.py] => Task 1, Epoch 47/300 (LR 0.09407) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.87, Test_acc 69.48
2024-09-02 15:35:22,547 [podnet.py] => Task 1, Epoch 48/300 (LR 0.09382) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.17, Train_acc 99.87, Test_acc 65.90
2024-09-02 15:35:24,044 [podnet.py] => Task 1, Epoch 49/300 (LR 0.09356) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.89, Test_acc 67.79
2024-09-02 15:35:25,600 [podnet.py] => Task 1, Epoch 50/300 (LR 0.09330) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.93, Test_acc 68.31
2024-09-02 15:35:27,180 [podnet.py] => Task 1, Epoch 51/300 (LR 0.09304) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.89, Test_acc 67.17
2024-09-02 15:35:28,867 [podnet.py] => Task 1, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.93, Test_acc 66.26
2024-09-02 15:35:30,375 [podnet.py] => Task 1, Epoch 53/300 (LR 0.09249) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.80, Test_acc 66.24
2024-09-02 15:35:31,967 [podnet.py] => Task 1, Epoch 54/300 (LR 0.09222) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.71, Test_acc 67.02
2024-09-02 15:35:33,640 [podnet.py] => Task 1, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.17, Train_acc 99.80, Test_acc 67.81
2024-09-02 15:35:35,374 [podnet.py] => Task 1, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.87, Test_acc 69.31
2024-09-02 15:35:37,095 [podnet.py] => Task 1, Epoch 57/300 (LR 0.09135) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.91, Test_acc 64.83
2024-09-02 15:35:38,862 [podnet.py] => Task 1, Epoch 58/300 (LR 0.09106) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 100.00, Test_acc 70.02
2024-09-02 15:35:40,626 [podnet.py] => Task 1, Epoch 59/300 (LR 0.09076) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 68.48
2024-09-02 15:35:42,350 [podnet.py] => Task 1, Epoch 60/300 (LR 0.09045) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.98, Test_acc 67.12
2024-09-02 15:35:43,941 [podnet.py] => Task 1, Epoch 61/300 (LR 0.09014) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.15, Train_acc 99.89, Test_acc 71.19
2024-09-02 15:35:45,640 [podnet.py] => Task 1, Epoch 62/300 (LR 0.08983) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 68.19
2024-09-02 15:35:47,301 [podnet.py] => Task 1, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.73, Test_acc 69.69
2024-09-02 15:35:48,997 [podnet.py] => Task 1, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.87, Test_acc 68.55
2024-09-02 15:35:50,639 [podnet.py] => Task 1, Epoch 65/300 (LR 0.08886) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.84, Test_acc 64.36
2024-09-02 15:35:52,174 [podnet.py] => Task 1, Epoch 66/300 (LR 0.08853) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.87, Test_acc 64.36
2024-09-02 15:35:53,969 [podnet.py] => Task 1, Epoch 67/300 (LR 0.08819) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 67.29
2024-09-02 15:35:55,483 [podnet.py] => Task 1, Epoch 68/300 (LR 0.08785) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.07
2024-09-02 15:35:57,323 [podnet.py] => Task 1, Epoch 69/300 (LR 0.08751) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 100.00, Test_acc 65.86
2024-09-02 15:35:59,279 [podnet.py] => Task 1, Epoch 70/300 (LR 0.08716) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 100.00, Test_acc 70.05
2024-09-02 15:36:00,965 [podnet.py] => Task 1, Epoch 71/300 (LR 0.08680) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.98, Test_acc 65.07
2024-09-02 15:36:02,665 [podnet.py] => Task 1, Epoch 72/300 (LR 0.08645) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.80, Test_acc 65.19
2024-09-02 15:36:04,261 [podnet.py] => Task 1, Epoch 73/300 (LR 0.08609) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.91, Test_acc 66.52
2024-09-02 15:36:05,796 [podnet.py] => Task 1, Epoch 74/300 (LR 0.08572) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 59.93
2024-09-02 15:36:07,386 [podnet.py] => Task 1, Epoch 75/300 (LR 0.08536) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 65.38
2024-09-02 15:36:08,989 [podnet.py] => Task 1, Epoch 76/300 (LR 0.08498) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 67.55
2024-09-02 15:36:10,528 [podnet.py] => Task 1, Epoch 77/300 (LR 0.08461) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.96, Test_acc 64.86
2024-09-02 15:36:12,069 [podnet.py] => Task 1, Epoch 78/300 (LR 0.08423) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.91, Test_acc 67.17
2024-09-02 15:36:13,549 [podnet.py] => Task 1, Epoch 79/300 (LR 0.08384) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.93, Test_acc 65.81
2024-09-02 15:36:15,073 [podnet.py] => Task 1, Epoch 80/300 (LR 0.08346) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.87, Test_acc 63.69
2024-09-02 15:36:16,652 [podnet.py] => Task 1, Epoch 81/300 (LR 0.08307) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 64.31
2024-09-02 15:36:18,492 [podnet.py] => Task 1, Epoch 82/300 (LR 0.08267) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 59.52
2024-09-02 15:36:20,138 [podnet.py] => Task 1, Epoch 83/300 (LR 0.08227) => LSC_loss 0.22, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 94.60, Test_acc 32.24
2024-09-02 15:36:21,914 [podnet.py] => Task 1, Epoch 84/300 (LR 0.08187) => LSC_loss 0.38, Spatial_loss 0.54, Flat_loss 0.41, Train_acc 90.98, Test_acc 36.19
2024-09-02 15:36:23,582 [podnet.py] => Task 1, Epoch 85/300 (LR 0.08147) => LSC_loss 0.25, Spatial_loss 0.50, Flat_loss 0.38, Train_acc 93.18, Test_acc 47.79
2024-09-02 15:36:25,153 [podnet.py] => Task 1, Epoch 86/300 (LR 0.08106) => LSC_loss 0.14, Spatial_loss 0.43, Flat_loss 0.32, Train_acc 96.09, Test_acc 63.69
2024-09-02 15:36:26,683 [podnet.py] => Task 1, Epoch 87/300 (LR 0.08065) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.25, Train_acc 98.71, Test_acc 60.52
2024-09-02 15:36:28,193 [podnet.py] => Task 1, Epoch 88/300 (LR 0.08023) => LSC_loss 0.06, Spatial_loss 0.30, Flat_loss 0.22, Train_acc 99.67, Test_acc 64.12
2024-09-02 15:36:29,842 [podnet.py] => Task 1, Epoch 89/300 (LR 0.07981) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.82, Test_acc 67.83
2024-09-02 15:36:31,401 [podnet.py] => Task 1, Epoch 90/300 (LR 0.07939) => LSC_loss 0.06, Spatial_loss 0.25, Flat_loss 0.18, Train_acc 99.69, Test_acc 63.36
2024-09-02 15:36:33,174 [podnet.py] => Task 1, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.91, Test_acc 66.74
2024-09-02 15:36:34,691 [podnet.py] => Task 1, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.16, Train_acc 99.91, Test_acc 69.33
2024-09-02 15:36:36,218 [podnet.py] => Task 1, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.98, Test_acc 64.29
2024-09-02 15:36:37,703 [podnet.py] => Task 1, Epoch 94/300 (LR 0.07767) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.89, Test_acc 65.64
2024-09-02 15:36:39,206 [podnet.py] => Task 1, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.93, Test_acc 64.86
2024-09-02 15:36:40,740 [podnet.py] => Task 1, Epoch 96/300 (LR 0.07679) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.14, Train_acc 99.96, Test_acc 66.55
2024-09-02 15:36:42,269 [podnet.py] => Task 1, Epoch 97/300 (LR 0.07635) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.14, Train_acc 99.96, Test_acc 70.07
2024-09-02 15:36:43,769 [podnet.py] => Task 1, Epoch 98/300 (LR 0.07590) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.91, Test_acc 68.76
2024-09-02 15:36:45,269 [podnet.py] => Task 1, Epoch 99/300 (LR 0.07545) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.89, Test_acc 70.50
2024-09-02 15:36:46,880 [podnet.py] => Task 1, Epoch 100/300 (LR 0.07500) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.98, Test_acc 67.00
2024-09-02 15:36:48,806 [podnet.py] => Task 1, Epoch 101/300 (LR 0.07455) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.84, Test_acc 65.88
2024-09-02 15:36:50,542 [podnet.py] => Task 1, Epoch 102/300 (LR 0.07409) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.98, Test_acc 70.05
2024-09-02 15:36:52,185 [podnet.py] => Task 1, Epoch 103/300 (LR 0.07363) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 68.57
2024-09-02 15:36:53,862 [podnet.py] => Task 1, Epoch 104/300 (LR 0.07316) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 69.48
2024-09-02 15:36:55,356 [podnet.py] => Task 1, Epoch 105/300 (LR 0.07270) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 69.48
2024-09-02 15:36:56,791 [podnet.py] => Task 1, Epoch 106/300 (LR 0.07223) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 70.33
2024-09-02 15:36:58,393 [podnet.py] => Task 1, Epoch 107/300 (LR 0.07176) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.91, Test_acc 70.14
2024-09-02 15:36:59,923 [podnet.py] => Task 1, Epoch 108/300 (LR 0.07129) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.91, Test_acc 66.95
2024-09-02 15:37:01,408 [podnet.py] => Task 1, Epoch 109/300 (LR 0.07081) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.73, Test_acc 61.26
2024-09-02 15:37:03,156 [podnet.py] => Task 1, Epoch 110/300 (LR 0.07034) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 65.57
2024-09-02 15:37:04,785 [podnet.py] => Task 1, Epoch 111/300 (LR 0.06986) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 67.67
2024-09-02 15:37:06,528 [podnet.py] => Task 1, Epoch 112/300 (LR 0.06938) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 100.00, Test_acc 68.57
2024-09-02 15:37:08,242 [podnet.py] => Task 1, Epoch 113/300 (LR 0.06889) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.89, Test_acc 70.24
2024-09-02 15:37:09,719 [podnet.py] => Task 1, Epoch 114/300 (LR 0.06841) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 71.79
2024-09-02 15:37:11,413 [podnet.py] => Task 1, Epoch 115/300 (LR 0.06792) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.78, Test_acc 66.36
2024-09-02 15:37:13,126 [podnet.py] => Task 1, Epoch 116/300 (LR 0.06743) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.12, Train_acc 99.98, Test_acc 68.00
2024-09-02 15:37:14,590 [podnet.py] => Task 1, Epoch 117/300 (LR 0.06694) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 63.48
2024-09-02 15:37:16,239 [podnet.py] => Task 1, Epoch 118/300 (LR 0.06644) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.12, Train_acc 99.96, Test_acc 67.43
2024-09-02 15:37:17,958 [podnet.py] => Task 1, Epoch 119/300 (LR 0.06595) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 67.10
2024-09-02 15:37:19,610 [podnet.py] => Task 1, Epoch 120/300 (LR 0.06545) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 69.05
2024-09-02 15:37:21,075 [podnet.py] => Task 1, Epoch 121/300 (LR 0.06495) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.24
2024-09-02 15:37:22,595 [podnet.py] => Task 1, Epoch 122/300 (LR 0.06445) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.96, Test_acc 69.12
2024-09-02 15:37:24,161 [podnet.py] => Task 1, Epoch 123/300 (LR 0.06395) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.93, Test_acc 61.50
2024-09-02 15:37:25,815 [podnet.py] => Task 1, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.80, Test_acc 64.60
2024-09-02 15:37:27,427 [podnet.py] => Task 1, Epoch 125/300 (LR 0.06294) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 63.71
2024-09-02 15:37:29,125 [podnet.py] => Task 1, Epoch 126/300 (LR 0.06243) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.87, Test_acc 68.52
2024-09-02 15:37:30,718 [podnet.py] => Task 1, Epoch 127/300 (LR 0.06193) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.57
2024-09-02 15:37:32,388 [podnet.py] => Task 1, Epoch 128/300 (LR 0.06142) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.96, Test_acc 68.93
2024-09-02 15:37:34,181 [podnet.py] => Task 1, Epoch 129/300 (LR 0.06091) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.36
2024-09-02 15:37:35,816 [podnet.py] => Task 1, Epoch 130/300 (LR 0.06040) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.93, Test_acc 63.10
2024-09-02 15:37:37,396 [podnet.py] => Task 1, Epoch 131/300 (LR 0.05988) => LSC_loss 0.12, Spatial_loss 0.33, Flat_loss 0.23, Train_acc 97.33, Test_acc 47.31
2024-09-02 15:37:38,962 [podnet.py] => Task 1, Epoch 132/300 (LR 0.05937) => LSC_loss 0.19, Spatial_loss 0.39, Flat_loss 0.30, Train_acc 95.13, Test_acc 47.17
2024-09-02 15:37:40,518 [podnet.py] => Task 1, Epoch 133/300 (LR 0.05885) => LSC_loss 0.19, Spatial_loss 0.44, Flat_loss 0.33, Train_acc 95.04, Test_acc 53.31
2024-09-02 15:37:42,225 [podnet.py] => Task 1, Epoch 134/300 (LR 0.05834) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.25, Train_acc 98.49, Test_acc 67.88
2024-09-02 15:37:43,789 [podnet.py] => Task 1, Epoch 135/300 (LR 0.05782) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.19, Train_acc 99.71, Test_acc 65.43
2024-09-02 15:37:45,301 [podnet.py] => Task 1, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.17, Train_acc 99.82, Test_acc 67.48
2024-09-02 15:37:46,830 [podnet.py] => Task 1, Epoch 137/300 (LR 0.05679) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.82, Test_acc 68.38
2024-09-02 15:37:48,356 [podnet.py] => Task 1, Epoch 138/300 (LR 0.05627) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.15, Train_acc 99.91, Test_acc 66.64
2024-09-02 15:37:50,057 [podnet.py] => Task 1, Epoch 139/300 (LR 0.05575) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.87, Test_acc 70.02
2024-09-02 15:37:51,754 [podnet.py] => Task 1, Epoch 140/300 (LR 0.05523) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.93, Test_acc 68.95
2024-09-02 15:37:53,357 [podnet.py] => Task 1, Epoch 141/300 (LR 0.05471) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:37:55,042 [podnet.py] => Task 1, Epoch 142/300 (LR 0.05418) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 68.55
2024-09-02 15:37:56,808 [podnet.py] => Task 1, Epoch 143/300 (LR 0.05366) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.91, Test_acc 64.21
2024-09-02 15:37:58,530 [podnet.py] => Task 1, Epoch 144/300 (LR 0.05314) => LSC_loss 0.07, Spatial_loss 0.30, Flat_loss 0.21, Train_acc 98.96, Test_acc 64.36
2024-09-02 15:38:00,269 [podnet.py] => Task 1, Epoch 145/300 (LR 0.05262) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.16, Train_acc 99.82, Test_acc 67.62
2024-09-02 15:38:01,888 [podnet.py] => Task 1, Epoch 146/300 (LR 0.05209) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.14, Train_acc 99.96, Test_acc 68.48
2024-09-02 15:38:03,577 [podnet.py] => Task 1, Epoch 147/300 (LR 0.05157) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.96, Test_acc 69.50
2024-09-02 15:38:05,215 [podnet.py] => Task 1, Epoch 148/300 (LR 0.05105) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.13, Train_acc 99.93, Test_acc 68.07
2024-09-02 15:38:06,885 [podnet.py] => Task 1, Epoch 149/300 (LR 0.05052) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 70.19
2024-09-02 15:38:08,378 [podnet.py] => Task 1, Epoch 150/300 (LR 0.05000) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.88
2024-09-02 15:38:09,926 [podnet.py] => Task 1, Epoch 151/300 (LR 0.04948) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 99.96, Test_acc 69.02
2024-09-02 15:38:11,535 [podnet.py] => Task 1, Epoch 152/300 (LR 0.04895) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 68.83
2024-09-02 15:38:13,381 [podnet.py] => Task 1, Epoch 153/300 (LR 0.04843) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.93, Test_acc 70.79
2024-09-02 15:38:15,218 [podnet.py] => Task 1, Epoch 154/300 (LR 0.04791) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.52
2024-09-02 15:38:16,825 [podnet.py] => Task 1, Epoch 155/300 (LR 0.04738) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.96, Test_acc 69.67
2024-09-02 15:38:18,402 [podnet.py] => Task 1, Epoch 156/300 (LR 0.04686) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 70.93
2024-09-02 15:38:19,964 [podnet.py] => Task 1, Epoch 157/300 (LR 0.04634) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 70.93
2024-09-02 15:38:21,520 [podnet.py] => Task 1, Epoch 158/300 (LR 0.04582) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.74
2024-09-02 15:38:23,401 [podnet.py] => Task 1, Epoch 159/300 (LR 0.04529) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.33
2024-09-02 15:38:24,870 [podnet.py] => Task 1, Epoch 160/300 (LR 0.04477) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.05
2024-09-02 15:38:26,377 [podnet.py] => Task 1, Epoch 161/300 (LR 0.04425) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 68.21
2024-09-02 15:38:27,834 [podnet.py] => Task 1, Epoch 162/300 (LR 0.04373) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.38
2024-09-02 15:38:29,444 [podnet.py] => Task 1, Epoch 163/300 (LR 0.04321) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 70.31
2024-09-02 15:38:30,920 [podnet.py] => Task 1, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.91, Test_acc 62.19
2024-09-02 15:38:32,369 [podnet.py] => Task 1, Epoch 165/300 (LR 0.04218) => LSC_loss 0.11, Spatial_loss 0.36, Flat_loss 0.26, Train_acc 97.00, Test_acc 50.14
2024-09-02 15:38:33,924 [podnet.py] => Task 1, Epoch 166/300 (LR 0.04166) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.20, Train_acc 99.53, Test_acc 68.24
2024-09-02 15:38:35,416 [podnet.py] => Task 1, Epoch 167/300 (LR 0.04115) => LSC_loss 0.06, Spatial_loss 0.21, Flat_loss 0.16, Train_acc 99.82, Test_acc 62.26
2024-09-02 15:38:36,947 [podnet.py] => Task 1, Epoch 168/300 (LR 0.04063) => LSC_loss 0.06, Spatial_loss 0.25, Flat_loss 0.19, Train_acc 99.36, Test_acc 68.95
2024-09-02 15:38:38,883 [podnet.py] => Task 1, Epoch 169/300 (LR 0.04012) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.15, Train_acc 99.82, Test_acc 66.83
2024-09-02 15:38:40,549 [podnet.py] => Task 1, Epoch 170/300 (LR 0.03960) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.14, Train_acc 100.00, Test_acc 69.31
2024-09-02 15:38:42,065 [podnet.py] => Task 1, Epoch 171/300 (LR 0.03909) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 99.98, Test_acc 68.74
2024-09-02 15:38:43,427 [podnet.py] => Task 1, Epoch 172/300 (LR 0.03858) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.13, Train_acc 99.93, Test_acc 69.52
2024-09-02 15:38:44,971 [podnet.py] => Task 1, Epoch 173/300 (LR 0.03807) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 100.00, Test_acc 67.48
2024-09-02 15:38:46,655 [podnet.py] => Task 1, Epoch 174/300 (LR 0.03757) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.45
2024-09-02 15:38:48,247 [podnet.py] => Task 1, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.13, Train_acc 100.00, Test_acc 69.52
2024-09-02 15:38:49,789 [podnet.py] => Task 1, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.12, Train_acc 99.98, Test_acc 72.50
2024-09-02 15:38:51,249 [podnet.py] => Task 1, Epoch 177/300 (LR 0.03605) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 68.64
2024-09-02 15:38:52,762 [podnet.py] => Task 1, Epoch 178/300 (LR 0.03555) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 99.98, Test_acc 69.76
2024-09-02 15:38:54,576 [podnet.py] => Task 1, Epoch 179/300 (LR 0.03505) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.12, Train_acc 100.00, Test_acc 71.62
2024-09-02 15:38:56,314 [podnet.py] => Task 1, Epoch 180/300 (LR 0.03455) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.07
2024-09-02 15:38:57,869 [podnet.py] => Task 1, Epoch 181/300 (LR 0.03405) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.45
2024-09-02 15:38:59,548 [podnet.py] => Task 1, Epoch 182/300 (LR 0.03356) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.38
2024-09-02 15:39:01,131 [podnet.py] => Task 1, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.07
2024-09-02 15:39:02,894 [podnet.py] => Task 1, Epoch 184/300 (LR 0.03257) => LSC_loss 0.04, Spatial_loss 0.15, Flat_loss 0.11, Train_acc 99.98, Test_acc 69.21
2024-09-02 15:39:04,340 [podnet.py] => Task 1, Epoch 185/300 (LR 0.03208) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:39:06,128 [podnet.py] => Task 1, Epoch 186/300 (LR 0.03159) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:39:07,761 [podnet.py] => Task 1, Epoch 187/300 (LR 0.03111) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.14
2024-09-02 15:39:09,093 [podnet.py] => Task 1, Epoch 188/300 (LR 0.03062) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.45
2024-09-02 15:39:10,660 [podnet.py] => Task 1, Epoch 189/300 (LR 0.03014) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:39:11,937 [podnet.py] => Task 1, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.19
2024-09-02 15:39:13,333 [podnet.py] => Task 1, Epoch 191/300 (LR 0.02919) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 70.10
2024-09-02 15:39:14,928 [podnet.py] => Task 1, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.36
2024-09-02 15:39:16,502 [podnet.py] => Task 1, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.88
2024-09-02 15:39:18,070 [podnet.py] => Task 1, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.00
2024-09-02 15:39:19,599 [podnet.py] => Task 1, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 68.26
2024-09-02 15:39:21,160 [podnet.py] => Task 1, Epoch 196/300 (LR 0.02684) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 99.98, Test_acc 68.55
2024-09-02 15:39:22,590 [podnet.py] => Task 1, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.52
2024-09-02 15:39:24,082 [podnet.py] => Task 1, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:39:25,596 [podnet.py] => Task 1, Epoch 199/300 (LR 0.02545) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.86
2024-09-02 15:39:27,323 [podnet.py] => Task 1, Epoch 200/300 (LR 0.02500) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.52
2024-09-02 15:39:29,229 [podnet.py] => Task 1, Epoch 201/300 (LR 0.02455) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.45
2024-09-02 15:39:30,713 [podnet.py] => Task 1, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 69.00
2024-09-02 15:39:31,986 [podnet.py] => Task 1, Epoch 203/300 (LR 0.02365) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.48
2024-09-02 15:39:33,426 [podnet.py] => Task 1, Epoch 204/300 (LR 0.02321) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.67
2024-09-02 15:39:34,906 [podnet.py] => Task 1, Epoch 205/300 (LR 0.02277) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 68.05
2024-09-02 15:39:36,838 [podnet.py] => Task 1, Epoch 206/300 (LR 0.02233) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 99.98, Test_acc 72.21
2024-09-02 15:39:38,209 [podnet.py] => Task 1, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:39:39,734 [podnet.py] => Task 1, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:39:41,339 [podnet.py] => Task 1, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.62
2024-09-02 15:39:42,859 [podnet.py] => Task 1, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 69.40
2024-09-02 15:39:44,398 [podnet.py] => Task 1, Epoch 211/300 (LR 0.02019) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.98
2024-09-02 15:39:45,865 [podnet.py] => Task 1, Epoch 212/300 (LR 0.01977) => LSC_loss 0.04, Spatial_loss 0.13, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:39:47,425 [podnet.py] => Task 1, Epoch 213/300 (LR 0.01935) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.52
2024-09-02 15:39:49,380 [podnet.py] => Task 1, Epoch 214/300 (LR 0.01894) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.95
2024-09-02 15:39:51,191 [podnet.py] => Task 1, Epoch 215/300 (LR 0.01853) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 99.96, Test_acc 67.86
2024-09-02 15:39:53,094 [podnet.py] => Task 1, Epoch 216/300 (LR 0.01813) => LSC_loss 0.04, Spatial_loss 0.14, Flat_loss 0.12, Train_acc 99.93, Test_acc 69.69
2024-09-02 15:39:54,477 [podnet.py] => Task 1, Epoch 217/300 (LR 0.01773) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.11, Train_acc 100.00, Test_acc 70.90
2024-09-02 15:39:55,794 [podnet.py] => Task 1, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:39:57,371 [podnet.py] => Task 1, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.00
2024-09-02 15:39:58,861 [podnet.py] => Task 1, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:40:00,292 [podnet.py] => Task 1, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.64
2024-09-02 15:40:01,594 [podnet.py] => Task 1, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:40:03,430 [podnet.py] => Task 1, Epoch 223/300 (LR 0.01539) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.00
2024-09-02 15:40:05,162 [podnet.py] => Task 1, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.71
2024-09-02 15:40:06,651 [podnet.py] => Task 1, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.12, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.64
2024-09-02 15:40:08,025 [podnet.py] => Task 1, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.29
2024-09-02 15:40:09,507 [podnet.py] => Task 1, Epoch 227/300 (LR 0.01391) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.64
2024-09-02 15:40:11,104 [podnet.py] => Task 1, Epoch 228/300 (LR 0.01355) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.57
2024-09-02 15:40:13,092 [podnet.py] => Task 1, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.05
2024-09-02 15:40:14,511 [podnet.py] => Task 1, Epoch 230/300 (LR 0.01284) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.00
2024-09-02 15:40:16,030 [podnet.py] => Task 1, Epoch 231/300 (LR 0.01249) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.50
2024-09-02 15:40:17,665 [podnet.py] => Task 1, Epoch 232/300 (LR 0.01215) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:40:19,365 [podnet.py] => Task 1, Epoch 233/300 (LR 0.01181) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.10
2024-09-02 15:40:20,822 [podnet.py] => Task 1, Epoch 234/300 (LR 0.01147) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.74
2024-09-02 15:40:22,705 [podnet.py] => Task 1, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.57
2024-09-02 15:40:24,101 [podnet.py] => Task 1, Epoch 236/300 (LR 0.01082) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:40:25,642 [podnet.py] => Task 1, Epoch 237/300 (LR 0.01049) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.26
2024-09-02 15:40:27,310 [podnet.py] => Task 1, Epoch 238/300 (LR 0.01017) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.71
2024-09-02 15:40:29,141 [podnet.py] => Task 1, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.43
2024-09-02 15:40:30,814 [podnet.py] => Task 1, Epoch 240/300 (LR 0.00955) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.48
2024-09-02 15:40:32,713 [podnet.py] => Task 1, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.90
2024-09-02 15:40:34,220 [podnet.py] => Task 1, Epoch 242/300 (LR 0.00894) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.55
2024-09-02 15:40:35,810 [podnet.py] => Task 1, Epoch 243/300 (LR 0.00865) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.71
2024-09-02 15:40:37,338 [podnet.py] => Task 1, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.81
2024-09-02 15:40:39,056 [podnet.py] => Task 1, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.14
2024-09-02 15:40:40,591 [podnet.py] => Task 1, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:40:42,323 [podnet.py] => Task 1, Epoch 247/300 (LR 0.00751) => LSC_loss 0.03, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:40:43,949 [podnet.py] => Task 1, Epoch 248/300 (LR 0.00723) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.12
2024-09-02 15:40:45,365 [podnet.py] => Task 1, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.83
2024-09-02 15:40:46,949 [podnet.py] => Task 1, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:40:48,656 [podnet.py] => Task 1, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.50
2024-09-02 15:40:50,131 [podnet.py] => Task 1, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.74
2024-09-02 15:40:51,609 [podnet.py] => Task 1, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.69
2024-09-02 15:40:52,997 [podnet.py] => Task 1, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.11, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.57
2024-09-02 15:40:54,651 [podnet.py] => Task 1, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.79
2024-09-02 15:40:56,451 [podnet.py] => Task 1, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:40:58,004 [podnet.py] => Task 1, Epoch 257/300 (LR 0.00498) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:40:59,603 [podnet.py] => Task 1, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.60
2024-09-02 15:41:01,081 [podnet.py] => Task 1, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.50
2024-09-02 15:41:02,547 [podnet.py] => Task 1, Epoch 260/300 (LR 0.00432) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.81
2024-09-02 15:41:04,410 [podnet.py] => Task 1, Epoch 261/300 (LR 0.00411) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.36
2024-09-02 15:41:05,863 [podnet.py] => Task 1, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.88
2024-09-02 15:41:07,408 [podnet.py] => Task 1, Epoch 263/300 (LR 0.00371) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.10
2024-09-02 15:41:09,161 [podnet.py] => Task 1, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.31
2024-09-02 15:41:10,528 [podnet.py] => Task 1, Epoch 265/300 (LR 0.00332) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.45
2024-09-02 15:41:12,122 [podnet.py] => Task 1, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.19
2024-09-02 15:41:13,886 [podnet.py] => Task 1, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.24
2024-09-02 15:41:15,478 [podnet.py] => Task 1, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 70.98
2024-09-02 15:41:17,019 [podnet.py] => Task 1, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:41:18,509 [podnet.py] => Task 1, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:41:20,199 [podnet.py] => Task 1, Epoch 271/300 (LR 0.00229) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.36
2024-09-02 15:41:21,895 [podnet.py] => Task 1, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.74
2024-09-02 15:41:23,429 [podnet.py] => Task 1, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 99.98, Test_acc 70.38
2024-09-02 15:41:25,120 [podnet.py] => Task 1, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.19
2024-09-02 15:41:26,570 [podnet.py] => Task 1, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.26
2024-09-02 15:41:27,866 [podnet.py] => Task 1, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.93
2024-09-02 15:41:29,438 [podnet.py] => Task 1, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:41:31,292 [podnet.py] => Task 1, Epoch 278/300 (LR 0.00132) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.90
2024-09-02 15:41:32,773 [podnet.py] => Task 1, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.07
2024-09-02 15:41:34,103 [podnet.py] => Task 1, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:41:35,439 [podnet.py] => Task 1, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.83
2024-09-02 15:41:37,056 [podnet.py] => Task 1, Epoch 282/300 (LR 0.00089) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.10
2024-09-02 15:41:38,545 [podnet.py] => Task 1, Epoch 283/300 (LR 0.00079) => LSC_loss 0.03, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.38
2024-09-02 15:41:40,078 [podnet.py] => Task 1, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:41:41,701 [podnet.py] => Task 1, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.81
2024-09-02 15:41:43,321 [podnet.py] => Task 1, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:41:44,770 [podnet.py] => Task 1, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.62
2024-09-02 15:41:46,263 [podnet.py] => Task 1, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.69
2024-09-02 15:41:47,940 [podnet.py] => Task 1, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.67
2024-09-02 15:41:49,509 [podnet.py] => Task 1, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.55
2024-09-02 15:41:50,804 [podnet.py] => Task 1, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.50
2024-09-02 15:41:52,399 [podnet.py] => Task 1, Epoch 292/300 (LR 0.00018) => LSC_loss 0.03, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.83
2024-09-02 15:41:53,691 [podnet.py] => Task 1, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.71
2024-09-02 15:41:55,328 [podnet.py] => Task 1, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.95
2024-09-02 15:41:56,822 [podnet.py] => Task 1, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.09, Train_acc 100.00, Test_acc 72.21
2024-09-02 15:41:58,143 [podnet.py] => Task 1, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.98
2024-09-02 15:41:59,564 [podnet.py] => Task 1, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.76
2024-09-02 15:42:01,271 [podnet.py] => Task 1, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.09, Flat_loss 0.09, Train_acc 100.00, Test_acc 71.79
2024-09-02 15:42:02,604 [podnet.py] => Task 1, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 71.60
2024-09-02 15:42:04,147 [podnet.py] => Task 1, Epoch 300/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.10, Flat_loss 0.10, Train_acc 100.00, Test_acc 72.17
2024-09-02 15:42:04,148 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 15:42:04,148 [base.py] => Reducing exemplars...(100 per classes)
2024-09-02 15:42:05,254 [base.py] => Constructing exemplars...(100 per classes)
2024-09-02 15:42:07,209 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 15:42:08,348 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 15:42:10,894 [podnet.py] => Exemplar size: 497
2024-09-02 15:42:10,894 [trainer.py] => CNN: {'total': 72.17, '00-04': 62.63, '05-06': 96.0, 'old': 62.63, 'new': 96.0}
2024-09-02 15:42:10,894 [trainer.py] => NME: {'total': 76.4, '00-04': 78.03, '05-06': 72.33, 'old': 78.03, 'new': 72.33}
2024-09-02 15:42:10,894 [trainer.py] => CNN top1 curve: [88.9, 72.17]
2024-09-02 15:42:10,894 [trainer.py] => CNN top5 curve: [100.0, 98.02]
2024-09-02 15:42:10,894 [trainer.py] => NME top1 curve: [88.9, 76.4]
2024-09-02 15:42:10,894 [trainer.py] => NME top5 curve: [100.0, 98.05]

2024-09-02 15:42:10,894 [trainer.py] => Average Accuracy (CNN): 80.535
2024-09-02 15:42:10,894 [trainer.py] => Average Accuracy (NME): 82.65
2024-09-02 15:42:10,895 [trainer.py] => All params: 3879745
2024-09-02 15:42:10,895 [trainer.py] => Trainable params: 3879745
2024-09-02 15:42:10,896 [podnet.py] => Learning on 7-9
2024-09-02 15:42:10,913 [podnet.py] => Adaptive factor: 2.1213203435596424
2024-09-02 15:42:12,681 [podnet.py] => Task 2, Epoch 1/300 (LR 0.10000) => LSC_loss 1.68, Spatial_loss 0.83, Flat_loss 1.06, Train_acc 76.30, Test_acc 21.80
2024-09-02 15:42:14,210 [podnet.py] => Task 2, Epoch 2/300 (LR 0.09999) => LSC_loss 0.89, Spatial_loss 0.68, Flat_loss 0.86, Train_acc 87.53, Test_acc 21.50
2024-09-02 15:42:15,907 [podnet.py] => Task 2, Epoch 3/300 (LR 0.09998) => LSC_loss 0.75, Spatial_loss 0.66, Flat_loss 0.74, Train_acc 87.19, Test_acc 20.15
2024-09-02 15:42:17,557 [podnet.py] => Task 2, Epoch 4/300 (LR 0.09996) => LSC_loss 0.59, Spatial_loss 0.62, Flat_loss 0.66, Train_acc 89.08, Test_acc 32.67
2024-09-02 15:42:19,310 [podnet.py] => Task 2, Epoch 5/300 (LR 0.09993) => LSC_loss 0.51, Spatial_loss 0.61, Flat_loss 0.60, Train_acc 89.70, Test_acc 31.13
2024-09-02 15:42:21,036 [podnet.py] => Task 2, Epoch 6/300 (LR 0.09990) => LSC_loss 0.44, Spatial_loss 0.58, Flat_loss 0.56, Train_acc 90.53, Test_acc 36.02
2024-09-02 15:42:22,925 [podnet.py] => Task 2, Epoch 7/300 (LR 0.09987) => LSC_loss 0.41, Spatial_loss 0.58, Flat_loss 0.55, Train_acc 91.59, Test_acc 32.91
2024-09-02 15:42:24,857 [podnet.py] => Task 2, Epoch 8/300 (LR 0.09982) => LSC_loss 0.32, Spatial_loss 0.56, Flat_loss 0.51, Train_acc 92.93, Test_acc 46.43
2024-09-02 15:42:26,476 [podnet.py] => Task 2, Epoch 9/300 (LR 0.09978) => LSC_loss 0.25, Spatial_loss 0.52, Flat_loss 0.48, Train_acc 94.71, Test_acc 46.11
2024-09-02 15:42:28,059 [podnet.py] => Task 2, Epoch 10/300 (LR 0.09973) => LSC_loss 0.27, Spatial_loss 0.55, Flat_loss 0.49, Train_acc 94.00, Test_acc 31.54
2024-09-02 15:42:29,622 [podnet.py] => Task 2, Epoch 11/300 (LR 0.09967) => LSC_loss 0.22, Spatial_loss 0.53, Flat_loss 0.47, Train_acc 95.73, Test_acc 49.39
2024-09-02 15:42:31,183 [podnet.py] => Task 2, Epoch 12/300 (LR 0.09961) => LSC_loss 0.21, Spatial_loss 0.53, Flat_loss 0.47, Train_acc 95.71, Test_acc 48.07
2024-09-02 15:42:32,789 [podnet.py] => Task 2, Epoch 13/300 (LR 0.09954) => LSC_loss 0.22, Spatial_loss 0.54, Flat_loss 0.46, Train_acc 95.00, Test_acc 53.07
2024-09-02 15:42:34,420 [podnet.py] => Task 2, Epoch 14/300 (LR 0.09946) => LSC_loss 0.17, Spatial_loss 0.49, Flat_loss 0.44, Train_acc 96.95, Test_acc 42.11
2024-09-02 15:42:36,311 [podnet.py] => Task 2, Epoch 15/300 (LR 0.09938) => LSC_loss 0.24, Spatial_loss 0.56, Flat_loss 0.47, Train_acc 94.53, Test_acc 32.94
2024-09-02 15:42:37,774 [podnet.py] => Task 2, Epoch 16/300 (LR 0.09930) => LSC_loss 0.28, Spatial_loss 0.60, Flat_loss 0.48, Train_acc 93.71, Test_acc 47.70
2024-09-02 15:42:39,331 [podnet.py] => Task 2, Epoch 17/300 (LR 0.09921) => LSC_loss 0.18, Spatial_loss 0.53, Flat_loss 0.44, Train_acc 96.51, Test_acc 52.46
2024-09-02 15:42:40,958 [podnet.py] => Task 2, Epoch 18/300 (LR 0.09911) => LSC_loss 0.13, Spatial_loss 0.50, Flat_loss 0.42, Train_acc 97.80, Test_acc 54.22
2024-09-02 15:42:42,630 [podnet.py] => Task 2, Epoch 19/300 (LR 0.09901) => LSC_loss 0.10, Spatial_loss 0.46, Flat_loss 0.40, Train_acc 98.87, Test_acc 55.61
2024-09-02 15:42:44,214 [podnet.py] => Task 2, Epoch 20/300 (LR 0.09891) => LSC_loss 0.08, Spatial_loss 0.43, Flat_loss 0.38, Train_acc 99.51, Test_acc 61.56
2024-09-02 15:42:45,768 [podnet.py] => Task 2, Epoch 21/300 (LR 0.09880) => LSC_loss 0.07, Spatial_loss 0.41, Flat_loss 0.36, Train_acc 99.53, Test_acc 55.89
2024-09-02 15:42:47,392 [podnet.py] => Task 2, Epoch 22/300 (LR 0.09868) => LSC_loss 0.07, Spatial_loss 0.40, Flat_loss 0.35, Train_acc 99.80, Test_acc 60.96
2024-09-02 15:42:48,890 [podnet.py] => Task 2, Epoch 23/300 (LR 0.09856) => LSC_loss 0.07, Spatial_loss 0.39, Flat_loss 0.34, Train_acc 99.87, Test_acc 62.85
2024-09-02 15:42:50,511 [podnet.py] => Task 2, Epoch 24/300 (LR 0.09843) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.34, Train_acc 99.84, Test_acc 59.28
2024-09-02 15:42:52,134 [podnet.py] => Task 2, Epoch 25/300 (LR 0.09830) => LSC_loss 0.06, Spatial_loss 0.37, Flat_loss 0.33, Train_acc 99.89, Test_acc 59.44
2024-09-02 15:42:53,592 [podnet.py] => Task 2, Epoch 26/300 (LR 0.09816) => LSC_loss 0.07, Spatial_loss 0.36, Flat_loss 0.32, Train_acc 99.87, Test_acc 61.61
2024-09-02 15:42:55,012 [podnet.py] => Task 2, Epoch 27/300 (LR 0.09801) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.32, Train_acc 99.71, Test_acc 55.81
2024-09-02 15:42:56,810 [podnet.py] => Task 2, Epoch 28/300 (LR 0.09787) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.31, Train_acc 99.80, Test_acc 56.78
2024-09-02 15:42:58,224 [podnet.py] => Task 2, Epoch 29/300 (LR 0.09771) => LSC_loss 0.10, Spatial_loss 0.41, Flat_loss 0.35, Train_acc 98.64, Test_acc 42.72
2024-09-02 15:42:59,798 [podnet.py] => Task 2, Epoch 30/300 (LR 0.09755) => LSC_loss 0.12, Spatial_loss 0.46, Flat_loss 0.37, Train_acc 97.73, Test_acc 46.33
2024-09-02 15:43:01,303 [podnet.py] => Task 2, Epoch 31/300 (LR 0.09739) => LSC_loss 0.11, Spatial_loss 0.44, Flat_loss 0.36, Train_acc 98.18, Test_acc 56.85
2024-09-02 15:43:02,934 [podnet.py] => Task 2, Epoch 32/300 (LR 0.09722) => LSC_loss 0.08, Spatial_loss 0.42, Flat_loss 0.35, Train_acc 98.84, Test_acc 54.04
2024-09-02 15:43:04,629 [podnet.py] => Task 2, Epoch 33/300 (LR 0.09704) => LSC_loss 0.06, Spatial_loss 0.37, Flat_loss 0.32, Train_acc 99.71, Test_acc 60.11
2024-09-02 15:43:06,685 [podnet.py] => Task 2, Epoch 34/300 (LR 0.09686) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.30, Train_acc 99.93, Test_acc 62.43
2024-09-02 15:43:08,366 [podnet.py] => Task 2, Epoch 35/300 (LR 0.09668) => LSC_loss 0.05, Spatial_loss 0.34, Flat_loss 0.30, Train_acc 99.91, Test_acc 62.93
2024-09-02 15:43:10,349 [podnet.py] => Task 2, Epoch 36/300 (LR 0.09649) => LSC_loss 0.05, Spatial_loss 0.33, Flat_loss 0.29, Train_acc 99.98, Test_acc 62.17
2024-09-02 15:43:12,355 [podnet.py] => Task 2, Epoch 37/300 (LR 0.09629) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.28, Train_acc 99.91, Test_acc 61.41
2024-09-02 15:43:14,138 [podnet.py] => Task 2, Epoch 38/300 (LR 0.09609) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.28, Train_acc 99.98, Test_acc 62.72
2024-09-02 15:43:15,802 [podnet.py] => Task 2, Epoch 39/300 (LR 0.09589) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.28, Train_acc 99.89, Test_acc 55.00
2024-09-02 15:43:17,365 [podnet.py] => Task 2, Epoch 40/300 (LR 0.09568) => LSC_loss 0.12, Spatial_loss 0.42, Flat_loss 0.35, Train_acc 97.93, Test_acc 56.28
2024-09-02 15:43:18,899 [podnet.py] => Task 2, Epoch 41/300 (LR 0.09546) => LSC_loss 0.11, Spatial_loss 0.43, Flat_loss 0.35, Train_acc 98.11, Test_acc 49.87
2024-09-02 15:43:20,455 [podnet.py] => Task 2, Epoch 42/300 (LR 0.09524) => LSC_loss 0.09, Spatial_loss 0.41, Flat_loss 0.34, Train_acc 98.58, Test_acc 48.02
2024-09-02 15:43:22,367 [podnet.py] => Task 2, Epoch 43/300 (LR 0.09502) => LSC_loss 0.19, Spatial_loss 0.49, Flat_loss 0.39, Train_acc 96.15, Test_acc 46.19
2024-09-02 15:43:24,450 [podnet.py] => Task 2, Epoch 44/300 (LR 0.09479) => LSC_loss 0.20, Spatial_loss 0.53, Flat_loss 0.40, Train_acc 95.15, Test_acc 51.85
2024-09-02 15:43:26,483 [podnet.py] => Task 2, Epoch 45/300 (LR 0.09455) => LSC_loss 0.09, Spatial_loss 0.43, Flat_loss 0.34, Train_acc 98.82, Test_acc 61.39
2024-09-02 15:43:28,152 [podnet.py] => Task 2, Epoch 46/300 (LR 0.09431) => LSC_loss 0.06, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.84, Test_acc 61.85
2024-09-02 15:43:29,980 [podnet.py] => Task 2, Epoch 47/300 (LR 0.09407) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.29, Train_acc 99.91, Test_acc 62.13
2024-09-02 15:43:31,862 [podnet.py] => Task 2, Epoch 48/300 (LR 0.09382) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.28, Train_acc 99.87, Test_acc 64.28
2024-09-02 15:43:34,018 [podnet.py] => Task 2, Epoch 49/300 (LR 0.09356) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.27, Train_acc 99.91, Test_acc 61.74
2024-09-02 15:43:35,774 [podnet.py] => Task 2, Epoch 50/300 (LR 0.09330) => LSC_loss 0.06, Spatial_loss 0.32, Flat_loss 0.26, Train_acc 99.96, Test_acc 64.07
2024-09-02 15:43:37,358 [podnet.py] => Task 2, Epoch 51/300 (LR 0.09304) => LSC_loss 0.07, Spatial_loss 0.37, Flat_loss 0.29, Train_acc 99.33, Test_acc 62.89
2024-09-02 15:43:38,978 [podnet.py] => Task 2, Epoch 52/300 (LR 0.09277) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.27, Train_acc 99.89, Test_acc 61.15
2024-09-02 15:43:40,638 [podnet.py] => Task 2, Epoch 53/300 (LR 0.09249) => LSC_loss 0.06, Spatial_loss 0.31, Flat_loss 0.26, Train_acc 99.91, Test_acc 60.31
2024-09-02 15:43:42,389 [podnet.py] => Task 2, Epoch 54/300 (LR 0.09222) => LSC_loss 0.06, Spatial_loss 0.35, Flat_loss 0.29, Train_acc 99.78, Test_acc 60.43
2024-09-02 15:43:44,033 [podnet.py] => Task 2, Epoch 55/300 (LR 0.09193) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.26, Train_acc 99.98, Test_acc 62.00
2024-09-02 15:43:45,820 [podnet.py] => Task 2, Epoch 56/300 (LR 0.09165) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.98, Test_acc 61.04
2024-09-02 15:43:47,417 [podnet.py] => Task 2, Epoch 57/300 (LR 0.09135) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.25, Train_acc 99.98, Test_acc 62.07
2024-09-02 15:43:48,818 [podnet.py] => Task 2, Epoch 58/300 (LR 0.09106) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.25, Train_acc 100.00, Test_acc 62.30
2024-09-02 15:43:50,213 [podnet.py] => Task 2, Epoch 59/300 (LR 0.09076) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 99.98, Test_acc 63.87
2024-09-02 15:43:51,853 [podnet.py] => Task 2, Epoch 60/300 (LR 0.09045) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 100.00, Test_acc 63.02
2024-09-02 15:43:53,456 [podnet.py] => Task 2, Epoch 61/300 (LR 0.09014) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.24, Train_acc 100.00, Test_acc 65.06
2024-09-02 15:43:54,886 [podnet.py] => Task 2, Epoch 62/300 (LR 0.08983) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.00
2024-09-02 15:43:56,458 [podnet.py] => Task 2, Epoch 63/300 (LR 0.08951) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.89
2024-09-02 15:43:58,154 [podnet.py] => Task 2, Epoch 64/300 (LR 0.08918) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.93, Test_acc 57.74
2024-09-02 15:43:59,771 [podnet.py] => Task 2, Epoch 65/300 (LR 0.08886) => LSC_loss 0.08, Spatial_loss 0.35, Flat_loss 0.28, Train_acc 99.36, Test_acc 47.89
2024-09-02 15:44:01,411 [podnet.py] => Task 2, Epoch 66/300 (LR 0.08853) => LSC_loss 0.53, Spatial_loss 0.63, Flat_loss 0.49, Train_acc 89.55, Test_acc 28.76
2024-09-02 15:44:03,033 [podnet.py] => Task 2, Epoch 67/300 (LR 0.08819) => LSC_loss 0.35, Spatial_loss 0.60, Flat_loss 0.45, Train_acc 92.48, Test_acc 33.69
2024-09-02 15:44:04,565 [podnet.py] => Task 2, Epoch 68/300 (LR 0.08785) => LSC_loss 0.18, Spatial_loss 0.50, Flat_loss 0.39, Train_acc 96.44, Test_acc 52.48
2024-09-02 15:44:06,419 [podnet.py] => Task 2, Epoch 69/300 (LR 0.08751) => LSC_loss 0.23, Spatial_loss 0.56, Flat_loss 0.41, Train_acc 94.89, Test_acc 49.48
2024-09-02 15:44:08,512 [podnet.py] => Task 2, Epoch 70/300 (LR 0.08716) => LSC_loss 0.15, Spatial_loss 0.49, Flat_loss 0.38, Train_acc 97.22, Test_acc 59.48
2024-09-02 15:44:10,375 [podnet.py] => Task 2, Epoch 71/300 (LR 0.08680) => LSC_loss 0.09, Spatial_loss 0.44, Flat_loss 0.34, Train_acc 98.91, Test_acc 56.63
2024-09-02 15:44:12,222 [podnet.py] => Task 2, Epoch 72/300 (LR 0.08645) => LSC_loss 0.06, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.76, Test_acc 57.94
2024-09-02 15:44:13,707 [podnet.py] => Task 2, Epoch 73/300 (LR 0.08609) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.29, Train_acc 99.58, Test_acc 58.94
2024-09-02 15:44:15,354 [podnet.py] => Task 2, Epoch 74/300 (LR 0.08572) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.28, Train_acc 99.89, Test_acc 61.46
2024-09-02 15:44:16,930 [podnet.py] => Task 2, Epoch 75/300 (LR 0.08536) => LSC_loss 0.06, Spatial_loss 0.33, Flat_loss 0.26, Train_acc 99.89, Test_acc 60.07
2024-09-02 15:44:18,589 [podnet.py] => Task 2, Epoch 76/300 (LR 0.08498) => LSC_loss 0.05, Spatial_loss 0.32, Flat_loss 0.26, Train_acc 99.96, Test_acc 62.31
2024-09-02 15:44:20,329 [podnet.py] => Task 2, Epoch 77/300 (LR 0.08461) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 100.00, Test_acc 61.52
2024-09-02 15:44:22,112 [podnet.py] => Task 2, Epoch 78/300 (LR 0.08423) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.98, Test_acc 63.13
2024-09-02 15:44:24,010 [podnet.py] => Task 2, Epoch 79/300 (LR 0.08384) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.93, Test_acc 63.81
2024-09-02 15:44:26,198 [podnet.py] => Task 2, Epoch 80/300 (LR 0.08346) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.25, Train_acc 99.89, Test_acc 61.46
2024-09-02 15:44:27,751 [podnet.py] => Task 2, Epoch 81/300 (LR 0.08307) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 100.00, Test_acc 62.02
2024-09-02 15:44:29,380 [podnet.py] => Task 2, Epoch 82/300 (LR 0.08267) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.24, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:44:30,985 [podnet.py] => Task 2, Epoch 83/300 (LR 0.08227) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.23, Train_acc 100.00, Test_acc 62.69
2024-09-02 15:44:32,469 [podnet.py] => Task 2, Epoch 84/300 (LR 0.08187) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.98, Test_acc 62.94
2024-09-02 15:44:34,095 [podnet.py] => Task 2, Epoch 85/300 (LR 0.08147) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.02
2024-09-02 15:44:35,715 [podnet.py] => Task 2, Epoch 86/300 (LR 0.08106) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 100.00, Test_acc 61.94
2024-09-02 15:44:37,451 [podnet.py] => Task 2, Epoch 87/300 (LR 0.08065) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.91, Test_acc 60.72
2024-09-02 15:44:39,075 [podnet.py] => Task 2, Epoch 88/300 (LR 0.08023) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.96, Test_acc 61.06
2024-09-02 15:44:40,931 [podnet.py] => Task 2, Epoch 89/300 (LR 0.07981) => LSC_loss 0.06, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.62, Test_acc 63.67
2024-09-02 15:44:42,801 [podnet.py] => Task 2, Epoch 90/300 (LR 0.07939) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.84, Test_acc 62.83
2024-09-02 15:44:44,415 [podnet.py] => Task 2, Epoch 91/300 (LR 0.07896) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.93, Test_acc 60.61
2024-09-02 15:44:46,161 [podnet.py] => Task 2, Epoch 92/300 (LR 0.07854) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 99.98, Test_acc 62.52
2024-09-02 15:44:47,725 [podnet.py] => Task 2, Epoch 93/300 (LR 0.07810) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.96, Test_acc 61.94
2024-09-02 15:44:49,356 [podnet.py] => Task 2, Epoch 94/300 (LR 0.07767) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 99.96, Test_acc 62.85
2024-09-02 15:44:51,179 [podnet.py] => Task 2, Epoch 95/300 (LR 0.07723) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.89, Test_acc 62.33
2024-09-02 15:44:53,113 [podnet.py] => Task 2, Epoch 96/300 (LR 0.07679) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.22, Train_acc 99.96, Test_acc 61.72
2024-09-02 15:44:54,825 [podnet.py] => Task 2, Epoch 97/300 (LR 0.07635) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.28
2024-09-02 15:44:56,522 [podnet.py] => Task 2, Epoch 98/300 (LR 0.07590) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:44:58,388 [podnet.py] => Task 2, Epoch 99/300 (LR 0.07545) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 62.54
2024-09-02 15:45:00,046 [podnet.py] => Task 2, Epoch 100/300 (LR 0.07500) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 100.00, Test_acc 60.37
2024-09-02 15:45:01,705 [podnet.py] => Task 2, Epoch 101/300 (LR 0.07455) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.94
2024-09-02 15:45:03,426 [podnet.py] => Task 2, Epoch 102/300 (LR 0.07409) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.39
2024-09-02 15:45:05,128 [podnet.py] => Task 2, Epoch 103/300 (LR 0.07363) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 61.15
2024-09-02 15:45:06,877 [podnet.py] => Task 2, Epoch 104/300 (LR 0.07316) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.26
2024-09-02 15:45:09,003 [podnet.py] => Task 2, Epoch 105/300 (LR 0.07270) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 60.19
2024-09-02 15:45:10,825 [podnet.py] => Task 2, Epoch 106/300 (LR 0.07223) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.83
2024-09-02 15:45:12,292 [podnet.py] => Task 2, Epoch 107/300 (LR 0.07176) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.50
2024-09-02 15:45:14,138 [podnet.py] => Task 2, Epoch 108/300 (LR 0.07129) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.85
2024-09-02 15:45:15,791 [podnet.py] => Task 2, Epoch 109/300 (LR 0.07081) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 60.76
2024-09-02 15:45:17,541 [podnet.py] => Task 2, Epoch 110/300 (LR 0.07034) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 61.11
2024-09-02 15:45:19,131 [podnet.py] => Task 2, Epoch 111/300 (LR 0.06986) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.24, Train_acc 99.49, Test_acc 54.81
2024-09-02 15:45:20,953 [podnet.py] => Task 2, Epoch 112/300 (LR 0.06938) => LSC_loss 0.16, Spatial_loss 0.39, Flat_loss 0.31, Train_acc 96.53, Test_acc 36.30
2024-09-02 15:45:22,808 [podnet.py] => Task 2, Epoch 113/300 (LR 0.06889) => LSC_loss 0.24, Spatial_loss 0.51, Flat_loss 0.39, Train_acc 94.71, Test_acc 43.69
2024-09-02 15:45:24,591 [podnet.py] => Task 2, Epoch 114/300 (LR 0.06841) => LSC_loss 0.27, Spatial_loss 0.55, Flat_loss 0.40, Train_acc 94.24, Test_acc 48.67
2024-09-02 15:45:26,012 [podnet.py] => Task 2, Epoch 115/300 (LR 0.06792) => LSC_loss 0.18, Spatial_loss 0.49, Flat_loss 0.36, Train_acc 96.66, Test_acc 55.85
2024-09-02 15:45:27,385 [podnet.py] => Task 2, Epoch 116/300 (LR 0.06743) => LSC_loss 0.16, Spatial_loss 0.49, Flat_loss 0.37, Train_acc 96.71, Test_acc 56.83
2024-09-02 15:45:29,400 [podnet.py] => Task 2, Epoch 117/300 (LR 0.06694) => LSC_loss 0.09, Spatial_loss 0.42, Flat_loss 0.32, Train_acc 98.71, Test_acc 63.02
2024-09-02 15:45:31,261 [podnet.py] => Task 2, Epoch 118/300 (LR 0.06644) => LSC_loss 0.07, Spatial_loss 0.38, Flat_loss 0.30, Train_acc 99.44, Test_acc 62.83
2024-09-02 15:45:33,107 [podnet.py] => Task 2, Epoch 119/300 (LR 0.06595) => LSC_loss 0.06, Spatial_loss 0.34, Flat_loss 0.27, Train_acc 99.78, Test_acc 64.41
2024-09-02 15:45:34,756 [podnet.py] => Task 2, Epoch 120/300 (LR 0.06545) => LSC_loss 0.05, Spatial_loss 0.31, Flat_loss 0.25, Train_acc 99.98, Test_acc 64.46
2024-09-02 15:45:36,503 [podnet.py] => Task 2, Epoch 121/300 (LR 0.06495) => LSC_loss 0.05, Spatial_loss 0.30, Flat_loss 0.24, Train_acc 99.96, Test_acc 62.96
2024-09-02 15:45:37,997 [podnet.py] => Task 2, Epoch 122/300 (LR 0.06445) => LSC_loss 0.05, Spatial_loss 0.29, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:45:39,496 [podnet.py] => Task 2, Epoch 123/300 (LR 0.06395) => LSC_loss 0.05, Spatial_loss 0.28, Flat_loss 0.23, Train_acc 100.00, Test_acc 64.26
2024-09-02 15:45:40,872 [podnet.py] => Task 2, Epoch 124/300 (LR 0.06345) => LSC_loss 0.05, Spatial_loss 0.27, Flat_loss 0.22, Train_acc 100.00, Test_acc 63.33
2024-09-02 15:45:42,715 [podnet.py] => Task 2, Epoch 125/300 (LR 0.06294) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.96, Test_acc 62.50
2024-09-02 15:45:44,823 [podnet.py] => Task 2, Epoch 126/300 (LR 0.06243) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 100.00, Test_acc 62.74
2024-09-02 15:45:46,575 [podnet.py] => Task 2, Epoch 127/300 (LR 0.06193) => LSC_loss 0.05, Spatial_loss 0.26, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.04
2024-09-02 15:45:47,974 [podnet.py] => Task 2, Epoch 128/300 (LR 0.06142) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 62.48
2024-09-02 15:45:49,499 [podnet.py] => Task 2, Epoch 129/300 (LR 0.06091) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.93
2024-09-02 15:45:50,883 [podnet.py] => Task 2, Epoch 130/300 (LR 0.06040) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.43
2024-09-02 15:45:52,434 [podnet.py] => Task 2, Epoch 131/300 (LR 0.05988) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.04
2024-09-02 15:45:54,040 [podnet.py] => Task 2, Epoch 132/300 (LR 0.05937) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 100.00, Test_acc 64.69
2024-09-02 15:45:55,447 [podnet.py] => Task 2, Epoch 133/300 (LR 0.05885) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.74
2024-09-02 15:45:57,066 [podnet.py] => Task 2, Epoch 134/300 (LR 0.05834) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.98, Test_acc 59.56
2024-09-02 15:45:58,774 [podnet.py] => Task 2, Epoch 135/300 (LR 0.05782) => LSC_loss 0.05, Spatial_loss 0.25, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.52
2024-09-02 15:46:00,262 [podnet.py] => Task 2, Epoch 136/300 (LR 0.05730) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.98, Test_acc 63.02
2024-09-02 15:46:01,867 [podnet.py] => Task 2, Epoch 137/300 (LR 0.05679) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 63.59
2024-09-02 15:46:03,677 [podnet.py] => Task 2, Epoch 138/300 (LR 0.05627) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:46:05,277 [podnet.py] => Task 2, Epoch 139/300 (LR 0.05575) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 64.39
2024-09-02 15:46:06,950 [podnet.py] => Task 2, Epoch 140/300 (LR 0.05523) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 62.76
2024-09-02 15:46:08,586 [podnet.py] => Task 2, Epoch 141/300 (LR 0.05471) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.69
2024-09-02 15:46:10,146 [podnet.py] => Task 2, Epoch 142/300 (LR 0.05418) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 64.93
2024-09-02 15:46:11,641 [podnet.py] => Task 2, Epoch 143/300 (LR 0.05366) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 100.00, Test_acc 62.11
2024-09-02 15:46:13,432 [podnet.py] => Task 2, Epoch 144/300 (LR 0.05314) => LSC_loss 0.05, Spatial_loss 0.24, Flat_loss 0.20, Train_acc 99.91, Test_acc 64.65
2024-09-02 15:46:14,880 [podnet.py] => Task 2, Epoch 145/300 (LR 0.05262) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.98, Test_acc 61.28
2024-09-02 15:46:16,374 [podnet.py] => Task 2, Epoch 146/300 (LR 0.05209) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.96, Test_acc 63.15
2024-09-02 15:46:17,963 [podnet.py] => Task 2, Epoch 147/300 (LR 0.05157) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 61.94
2024-09-02 15:46:19,417 [podnet.py] => Task 2, Epoch 148/300 (LR 0.05105) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.91, Test_acc 62.24
2024-09-02 15:46:20,975 [podnet.py] => Task 2, Epoch 149/300 (LR 0.05052) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.39
2024-09-02 15:46:22,688 [podnet.py] => Task 2, Epoch 150/300 (LR 0.05000) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.26
2024-09-02 15:46:24,265 [podnet.py] => Task 2, Epoch 151/300 (LR 0.04948) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 63.81
2024-09-02 15:46:25,821 [podnet.py] => Task 2, Epoch 152/300 (LR 0.04895) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.19
2024-09-02 15:46:27,537 [podnet.py] => Task 2, Epoch 153/300 (LR 0.04843) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 62.30
2024-09-02 15:46:29,322 [podnet.py] => Task 2, Epoch 154/300 (LR 0.04791) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.20, Train_acc 99.96, Test_acc 63.94
2024-09-02 15:46:31,595 [podnet.py] => Task 2, Epoch 155/300 (LR 0.04738) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 62.63
2024-09-02 15:46:33,321 [podnet.py] => Task 2, Epoch 156/300 (LR 0.04686) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.07
2024-09-02 15:46:35,396 [podnet.py] => Task 2, Epoch 157/300 (LR 0.04634) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:46:37,258 [podnet.py] => Task 2, Epoch 158/300 (LR 0.04582) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 62.31
2024-09-02 15:46:39,002 [podnet.py] => Task 2, Epoch 159/300 (LR 0.04529) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.78
2024-09-02 15:46:40,474 [podnet.py] => Task 2, Epoch 160/300 (LR 0.04477) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 99.98, Test_acc 60.89
2024-09-02 15:46:42,136 [podnet.py] => Task 2, Epoch 161/300 (LR 0.04425) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.67
2024-09-02 15:46:43,718 [podnet.py] => Task 2, Epoch 162/300 (LR 0.04373) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.65
2024-09-02 15:46:45,534 [podnet.py] => Task 2, Epoch 163/300 (LR 0.04321) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.46
2024-09-02 15:46:47,285 [podnet.py] => Task 2, Epoch 164/300 (LR 0.04270) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.93
2024-09-02 15:46:49,136 [podnet.py] => Task 2, Epoch 165/300 (LR 0.04218) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.98, Test_acc 62.37
2024-09-02 15:46:50,568 [podnet.py] => Task 2, Epoch 166/300 (LR 0.04166) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:46:52,039 [podnet.py] => Task 2, Epoch 167/300 (LR 0.04115) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.54
2024-09-02 15:46:53,528 [podnet.py] => Task 2, Epoch 168/300 (LR 0.04063) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.22
2024-09-02 15:46:55,210 [podnet.py] => Task 2, Epoch 169/300 (LR 0.04012) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.91
2024-09-02 15:46:56,888 [podnet.py] => Task 2, Epoch 170/300 (LR 0.03960) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.57
2024-09-02 15:46:58,531 [podnet.py] => Task 2, Epoch 171/300 (LR 0.03909) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.17
2024-09-02 15:47:00,089 [podnet.py] => Task 2, Epoch 172/300 (LR 0.03858) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.72
2024-09-02 15:47:01,785 [podnet.py] => Task 2, Epoch 173/300 (LR 0.03807) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.70
2024-09-02 15:47:03,402 [podnet.py] => Task 2, Epoch 174/300 (LR 0.03757) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.63
2024-09-02 15:47:04,972 [podnet.py] => Task 2, Epoch 175/300 (LR 0.03706) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.76
2024-09-02 15:47:07,251 [podnet.py] => Task 2, Epoch 176/300 (LR 0.03655) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:47:09,022 [podnet.py] => Task 2, Epoch 177/300 (LR 0.03605) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.96, Test_acc 63.31
2024-09-02 15:47:10,992 [podnet.py] => Task 2, Epoch 178/300 (LR 0.03555) => LSC_loss 0.06, Spatial_loss 0.27, Flat_loss 0.23, Train_acc 99.49, Test_acc 58.59
2024-09-02 15:47:12,505 [podnet.py] => Task 2, Epoch 179/300 (LR 0.03505) => LSC_loss 0.06, Spatial_loss 0.26, Flat_loss 0.22, Train_acc 99.69, Test_acc 58.78
2024-09-02 15:47:13,878 [podnet.py] => Task 2, Epoch 180/300 (LR 0.03455) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.20, Train_acc 100.00, Test_acc 63.07
2024-09-02 15:47:15,531 [podnet.py] => Task 2, Epoch 181/300 (LR 0.03405) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 100.00, Test_acc 63.39
2024-09-02 15:47:17,268 [podnet.py] => Task 2, Epoch 182/300 (LR 0.03356) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.96
2024-09-02 15:47:19,198 [podnet.py] => Task 2, Epoch 183/300 (LR 0.03306) => LSC_loss 0.04, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.89
2024-09-02 15:47:21,016 [podnet.py] => Task 2, Epoch 184/300 (LR 0.03257) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.17
2024-09-02 15:47:22,821 [podnet.py] => Task 2, Epoch 185/300 (LR 0.03208) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.96
2024-09-02 15:47:24,330 [podnet.py] => Task 2, Epoch 186/300 (LR 0.03159) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:47:26,018 [podnet.py] => Task 2, Epoch 187/300 (LR 0.03111) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:47:27,522 [podnet.py] => Task 2, Epoch 188/300 (LR 0.03062) => LSC_loss 0.05, Spatial_loss 0.21, Flat_loss 0.19, Train_acc 99.98, Test_acc 63.00
2024-09-02 15:47:29,219 [podnet.py] => Task 2, Epoch 189/300 (LR 0.03014) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.26
2024-09-02 15:47:30,786 [podnet.py] => Task 2, Epoch 190/300 (LR 0.02966) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.85
2024-09-02 15:47:32,407 [podnet.py] => Task 2, Epoch 191/300 (LR 0.02919) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.06
2024-09-02 15:47:33,987 [podnet.py] => Task 2, Epoch 192/300 (LR 0.02871) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.74
2024-09-02 15:47:35,597 [podnet.py] => Task 2, Epoch 193/300 (LR 0.02824) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 62.85
2024-09-02 15:47:37,078 [podnet.py] => Task 2, Epoch 194/300 (LR 0.02777) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.43
2024-09-02 15:47:38,764 [podnet.py] => Task 2, Epoch 195/300 (LR 0.02730) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.46
2024-09-02 15:47:40,395 [podnet.py] => Task 2, Epoch 196/300 (LR 0.02684) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:47:41,835 [podnet.py] => Task 2, Epoch 197/300 (LR 0.02637) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 62.33
2024-09-02 15:47:43,917 [podnet.py] => Task 2, Epoch 198/300 (LR 0.02591) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.22
2024-09-02 15:47:45,504 [podnet.py] => Task 2, Epoch 199/300 (LR 0.02545) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 63.44
2024-09-02 15:47:47,729 [podnet.py] => Task 2, Epoch 200/300 (LR 0.02500) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.78
2024-09-02 15:47:49,413 [podnet.py] => Task 2, Epoch 201/300 (LR 0.02455) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:47:50,977 [podnet.py] => Task 2, Epoch 202/300 (LR 0.02410) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.98
2024-09-02 15:47:52,654 [podnet.py] => Task 2, Epoch 203/300 (LR 0.02365) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 64.61
2024-09-02 15:47:54,591 [podnet.py] => Task 2, Epoch 204/300 (LR 0.02321) => LSC_loss 0.05, Spatial_loss 0.22, Flat_loss 0.19, Train_acc 99.84, Test_acc 63.89
2024-09-02 15:47:56,330 [podnet.py] => Task 2, Epoch 205/300 (LR 0.02277) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.98, Test_acc 62.56
2024-09-02 15:47:58,410 [podnet.py] => Task 2, Epoch 206/300 (LR 0.02233) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.69
2024-09-02 15:48:00,053 [podnet.py] => Task 2, Epoch 207/300 (LR 0.02190) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.09
2024-09-02 15:48:02,002 [podnet.py] => Task 2, Epoch 208/300 (LR 0.02146) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.89
2024-09-02 15:48:04,002 [podnet.py] => Task 2, Epoch 209/300 (LR 0.02104) => LSC_loss 0.04, Spatial_loss 0.20, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.91
2024-09-02 15:48:05,720 [podnet.py] => Task 2, Epoch 210/300 (LR 0.02061) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.52
2024-09-02 15:48:07,077 [podnet.py] => Task 2, Epoch 211/300 (LR 0.02019) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.37
2024-09-02 15:48:09,433 [podnet.py] => Task 2, Epoch 212/300 (LR 0.01977) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.20
2024-09-02 15:48:11,599 [podnet.py] => Task 2, Epoch 213/300 (LR 0.01935) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.98, Test_acc 62.81
2024-09-02 15:48:13,587 [podnet.py] => Task 2, Epoch 214/300 (LR 0.01894) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.57
2024-09-02 15:48:15,478 [podnet.py] => Task 2, Epoch 215/300 (LR 0.01853) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.48
2024-09-02 15:48:17,175 [podnet.py] => Task 2, Epoch 216/300 (LR 0.01813) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 99.98, Test_acc 64.30
2024-09-02 15:48:18,708 [podnet.py] => Task 2, Epoch 217/300 (LR 0.01773) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 99.96, Test_acc 63.78
2024-09-02 15:48:20,418 [podnet.py] => Task 2, Epoch 218/300 (LR 0.01733) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.39
2024-09-02 15:48:22,479 [podnet.py] => Task 2, Epoch 219/300 (LR 0.01693) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.54
2024-09-02 15:48:24,231 [podnet.py] => Task 2, Epoch 220/300 (LR 0.01654) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 62.91
2024-09-02 15:48:26,159 [podnet.py] => Task 2, Epoch 221/300 (LR 0.01616) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.11
2024-09-02 15:48:28,382 [podnet.py] => Task 2, Epoch 222/300 (LR 0.01577) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 63.31
2024-09-02 15:48:30,293 [podnet.py] => Task 2, Epoch 223/300 (LR 0.01539) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.57
2024-09-02 15:48:32,048 [podnet.py] => Task 2, Epoch 224/300 (LR 0.01502) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:48:33,738 [podnet.py] => Task 2, Epoch 225/300 (LR 0.01464) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:48:35,756 [podnet.py] => Task 2, Epoch 226/300 (LR 0.01428) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.33
2024-09-02 15:48:37,519 [podnet.py] => Task 2, Epoch 227/300 (LR 0.01391) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.22
2024-09-02 15:48:39,356 [podnet.py] => Task 2, Epoch 228/300 (LR 0.01355) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.17, Train_acc 99.98, Test_acc 64.93
2024-09-02 15:48:40,852 [podnet.py] => Task 2, Epoch 229/300 (LR 0.01320) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.98, Test_acc 63.46
2024-09-02 15:48:42,529 [podnet.py] => Task 2, Epoch 230/300 (LR 0.01284) => LSC_loss 0.06, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 99.91, Test_acc 55.98
2024-09-02 15:48:44,326 [podnet.py] => Task 2, Epoch 231/300 (LR 0.01249) => LSC_loss 0.07, Spatial_loss 0.29, Flat_loss 0.26, Train_acc 99.15, Test_acc 60.87
2024-09-02 15:48:46,119 [podnet.py] => Task 2, Epoch 232/300 (LR 0.01215) => LSC_loss 0.05, Spatial_loss 0.23, Flat_loss 0.21, Train_acc 99.98, Test_acc 63.48
2024-09-02 15:48:47,817 [podnet.py] => Task 2, Epoch 233/300 (LR 0.01181) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.19, Train_acc 100.00, Test_acc 64.67
2024-09-02 15:48:49,575 [podnet.py] => Task 2, Epoch 234/300 (LR 0.01147) => LSC_loss 0.05, Spatial_loss 0.20, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.81
2024-09-02 15:48:51,220 [podnet.py] => Task 2, Epoch 235/300 (LR 0.01114) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.93
2024-09-02 15:48:53,528 [podnet.py] => Task 2, Epoch 236/300 (LR 0.01082) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.20
2024-09-02 15:48:55,470 [podnet.py] => Task 2, Epoch 237/300 (LR 0.01049) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.09
2024-09-02 15:48:57,653 [podnet.py] => Task 2, Epoch 238/300 (LR 0.01017) => LSC_loss 0.05, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 63.93
2024-09-02 15:49:00,047 [podnet.py] => Task 2, Epoch 239/300 (LR 0.00986) => LSC_loss 0.04, Spatial_loss 0.19, Flat_loss 0.18, Train_acc 100.00, Test_acc 64.19
2024-09-02 15:49:02,347 [podnet.py] => Task 2, Epoch 240/300 (LR 0.00955) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.17
2024-09-02 15:49:04,753 [podnet.py] => Task 2, Epoch 241/300 (LR 0.00924) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:49:07,087 [podnet.py] => Task 2, Epoch 242/300 (LR 0.00894) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.52
2024-09-02 15:49:08,926 [podnet.py] => Task 2, Epoch 243/300 (LR 0.00865) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:49:11,324 [podnet.py] => Task 2, Epoch 244/300 (LR 0.00835) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.50
2024-09-02 15:49:13,607 [podnet.py] => Task 2, Epoch 245/300 (LR 0.00807) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:49:15,670 [podnet.py] => Task 2, Epoch 246/300 (LR 0.00778) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.72
2024-09-02 15:49:17,956 [podnet.py] => Task 2, Epoch 247/300 (LR 0.00751) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:49:20,265 [podnet.py] => Task 2, Epoch 248/300 (LR 0.00723) => LSC_loss 0.05, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.46
2024-09-02 15:49:22,420 [podnet.py] => Task 2, Epoch 249/300 (LR 0.00696) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:49:24,240 [podnet.py] => Task 2, Epoch 250/300 (LR 0.00670) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.50
2024-09-02 15:49:26,442 [podnet.py] => Task 2, Epoch 251/300 (LR 0.00644) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.24
2024-09-02 15:49:28,971 [podnet.py] => Task 2, Epoch 252/300 (LR 0.00618) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:49:31,044 [podnet.py] => Task 2, Epoch 253/300 (LR 0.00593) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.91
2024-09-02 15:49:33,309 [podnet.py] => Task 2, Epoch 254/300 (LR 0.00569) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.61
2024-09-02 15:49:35,477 [podnet.py] => Task 2, Epoch 255/300 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:49:37,854 [podnet.py] => Task 2, Epoch 256/300 (LR 0.00521) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.91
2024-09-02 15:49:40,077 [podnet.py] => Task 2, Epoch 257/300 (LR 0.00498) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:49:42,345 [podnet.py] => Task 2, Epoch 258/300 (LR 0.00476) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:49:44,718 [podnet.py] => Task 2, Epoch 259/300 (LR 0.00454) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.22
2024-09-02 15:49:47,102 [podnet.py] => Task 2, Epoch 260/300 (LR 0.00432) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.06
2024-09-02 15:49:49,503 [podnet.py] => Task 2, Epoch 261/300 (LR 0.00411) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.80
2024-09-02 15:49:51,819 [podnet.py] => Task 2, Epoch 262/300 (LR 0.00391) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.26
2024-09-02 15:49:53,892 [podnet.py] => Task 2, Epoch 263/300 (LR 0.00371) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.50
2024-09-02 15:49:56,171 [podnet.py] => Task 2, Epoch 264/300 (LR 0.00351) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.44
2024-09-02 15:49:58,345 [podnet.py] => Task 2, Epoch 265/300 (LR 0.00332) => LSC_loss 0.05, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.78
2024-09-02 15:50:00,442 [podnet.py] => Task 2, Epoch 266/300 (LR 0.00314) => LSC_loss 0.04, Spatial_loss 0.18, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:50:02,381 [podnet.py] => Task 2, Epoch 267/300 (LR 0.00296) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.65
2024-09-02 15:50:04,373 [podnet.py] => Task 2, Epoch 268/300 (LR 0.00278) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.37
2024-09-02 15:50:06,783 [podnet.py] => Task 2, Epoch 269/300 (LR 0.00261) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:50:09,042 [podnet.py] => Task 2, Epoch 270/300 (LR 0.00245) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.83
2024-09-02 15:50:11,155 [podnet.py] => Task 2, Epoch 271/300 (LR 0.00229) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:50:13,493 [podnet.py] => Task 2, Epoch 272/300 (LR 0.00213) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:50:15,855 [podnet.py] => Task 2, Epoch 273/300 (LR 0.00199) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:50:17,788 [podnet.py] => Task 2, Epoch 274/300 (LR 0.00184) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.89
2024-09-02 15:50:20,225 [podnet.py] => Task 2, Epoch 275/300 (LR 0.00170) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.26
2024-09-02 15:50:22,480 [podnet.py] => Task 2, Epoch 276/300 (LR 0.00157) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:50:24,801 [podnet.py] => Task 2, Epoch 277/300 (LR 0.00144) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:50:26,451 [podnet.py] => Task 2, Epoch 278/300 (LR 0.00132) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.33
2024-09-02 15:50:28,716 [podnet.py] => Task 2, Epoch 279/300 (LR 0.00120) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 64.54
2024-09-02 15:50:31,089 [podnet.py] => Task 2, Epoch 280/300 (LR 0.00109) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.24
2024-09-02 15:50:33,101 [podnet.py] => Task 2, Epoch 281/300 (LR 0.00099) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.63
2024-09-02 15:50:35,290 [podnet.py] => Task 2, Epoch 282/300 (LR 0.00089) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.04
2024-09-02 15:50:37,548 [podnet.py] => Task 2, Epoch 283/300 (LR 0.00079) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.87
2024-09-02 15:50:39,638 [podnet.py] => Task 2, Epoch 284/300 (LR 0.00070) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.09
2024-09-02 15:50:41,840 [podnet.py] => Task 2, Epoch 285/300 (LR 0.00062) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:50:44,073 [podnet.py] => Task 2, Epoch 286/300 (LR 0.00054) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.35
2024-09-02 15:50:45,982 [podnet.py] => Task 2, Epoch 287/300 (LR 0.00046) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.11
2024-09-02 15:50:48,219 [podnet.py] => Task 2, Epoch 288/300 (LR 0.00039) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.96
2024-09-02 15:50:50,214 [podnet.py] => Task 2, Epoch 289/300 (LR 0.00033) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.94
2024-09-02 15:50:52,581 [podnet.py] => Task 2, Epoch 290/300 (LR 0.00027) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.70
2024-09-02 15:50:54,776 [podnet.py] => Task 2, Epoch 291/300 (LR 0.00022) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.17, Train_acc 100.00, Test_acc 65.00
2024-09-02 15:50:57,057 [podnet.py] => Task 2, Epoch 292/300 (LR 0.00018) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.15
2024-09-02 15:50:59,443 [podnet.py] => Task 2, Epoch 293/300 (LR 0.00013) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.17
2024-09-02 15:51:01,718 [podnet.py] => Task 2, Epoch 294/300 (LR 0.00010) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.11
2024-09-02 15:51:03,083 [podnet.py] => Task 2, Epoch 295/300 (LR 0.00007) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.98
2024-09-02 15:51:04,701 [podnet.py] => Task 2, Epoch 296/300 (LR 0.00004) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 64.93
2024-09-02 15:51:06,760 [podnet.py] => Task 2, Epoch 297/300 (LR 0.00002) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.28
2024-09-02 15:51:09,073 [podnet.py] => Task 2, Epoch 298/300 (LR 0.00001) => LSC_loss 0.04, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.02
2024-09-02 15:51:11,229 [podnet.py] => Task 2, Epoch 299/300 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.17, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.43
2024-09-02 15:51:13,537 [podnet.py] => Task 2, Epoch 300/300 (LR 0.00000) => LSC_loss 0.05, Spatial_loss 0.16, Flat_loss 0.16, Train_acc 100.00, Test_acc 65.09
2024-09-02 15:51:13,538 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2024-09-02 15:51:13,538 [base.py] => Reducing exemplars...(71 per classes)
2024-09-02 15:51:15,001 [base.py] => Constructing exemplars...(71 per classes)
2024-09-02 15:51:16,744 [base.py] => Reducing exemplars...(55 per classes)
2024-09-02 15:51:18,273 [base.py] => Constructing exemplars...(55 per classes)
2024-09-02 15:51:20,697 [podnet.py] => Exemplar size: 495
2024-09-02 15:51:20,698 [trainer.py] => CNN: {'total': 65.09, '00-04': 57.57, '05-06': 51.42, '07-08': 97.58, 'old': 55.81, 'new': 97.58}
2024-09-02 15:51:20,698 [trainer.py] => NME: {'total': 66.31, '00-04': 70.83, '05-06': 43.08, '07-08': 78.25, 'old': 62.9, 'new': 78.25}
2024-09-02 15:51:20,698 [trainer.py] => CNN top1 curve: [88.9, 72.17, 65.09]
2024-09-02 15:51:20,698 [trainer.py] => CNN top5 curve: [100.0, 98.02, 91.8]
2024-09-02 15:51:20,698 [trainer.py] => NME top1 curve: [88.9, 76.4, 66.31]
2024-09-02 15:51:20,698 [trainer.py] => NME top5 curve: [100.0, 98.05, 93.43]

2024-09-02 15:51:20,698 [trainer.py] => Average Accuracy (CNN): 75.38666666666667
2024-09-02 15:51:20,698 [trainer.py] => Average Accuracy (NME): 77.20333333333333
2024-09-02 15:51:20,699 [trainer.py] => Forgetting (CNN): 37.955
