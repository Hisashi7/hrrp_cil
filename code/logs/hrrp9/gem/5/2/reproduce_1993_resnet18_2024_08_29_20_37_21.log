2024-08-29 20:37:21,800 [trainer.py] => config: ./exps/gem.json
2024-08-29 20:37:21,800 [trainer.py] => prefix: reproduce
2024-08-29 20:37:21,800 [trainer.py] => dataset: hrrp9
2024-08-29 20:37:21,800 [trainer.py] => memory_size: 500
2024-08-29 20:37:21,800 [trainer.py] => memory_per_class: 20
2024-08-29 20:37:21,800 [trainer.py] => fixed_memory: False
2024-08-29 20:37:21,800 [trainer.py] => shuffle: True
2024-08-29 20:37:21,800 [trainer.py] => init_cls: 5
2024-08-29 20:37:21,800 [trainer.py] => increment: 2
2024-08-29 20:37:21,800 [trainer.py] => model_name: gem
2024-08-29 20:37:21,800 [trainer.py] => convnet_type: resnet18
2024-08-29 20:37:21,800 [trainer.py] => init_train: False
2024-08-29 20:37:21,801 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-08-29 20:37:21,801 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-08-29 20:37:21,801 [trainer.py] => device: [device(type='cuda', index=6)]
2024-08-29 20:37:21,801 [trainer.py] => seed: 1993
2024-08-29 20:37:22,306 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-08-29 20:37:24,385 [trainer.py] => All params: 3843904
2024-08-29 20:37:24,386 [trainer.py] => Trainable params: 3843904
2024-08-29 20:37:24,389 [gem.py] => Learning on 0-5
2024-08-29 20:37:26,131 [gem.py] => init_train?---False
2024-08-29 20:37:29,147 [base.py] => Reducing exemplars...(100 per classes)
2024-08-29 20:37:29,147 [base.py] => Constructing exemplars...(100 per classes)
2024-08-29 20:37:37,615 [gem.py] => Exemplar size: 500
2024-08-29 20:37:37,615 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-08-29 20:37:37,615 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-08-29 20:37:37,615 [trainer.py] => CNN top1 curve: [89.93]
2024-08-29 20:37:37,615 [trainer.py] => CNN top5 curve: [100.0]
2024-08-29 20:37:37,616 [trainer.py] => NME top1 curve: [90.0]
2024-08-29 20:37:37,616 [trainer.py] => NME top5 curve: [100.0]

2024-08-29 20:37:37,616 [trainer.py] => Average Accuracy (CNN): 89.93
2024-08-29 20:37:37,616 [trainer.py] => Average Accuracy (NME): 90.0
2024-08-29 20:37:37,616 [trainer.py] => All params: 3846469
2024-08-29 20:37:37,616 [trainer.py] => Trainable params: 3846469
2024-08-29 20:37:37,617 [gem.py] => Learning on 5-7
2024-08-29 20:37:40,513 [gem.py] => Task 1, Epoch 1/150 => Loss 0.194, Train_accy 92.15, Test_accy 52.24
2024-08-29 20:37:50,794 [gem.py] => Task 1, Epoch 6/150 => Loss 0.003, Train_accy 99.95, Test_accy 51.74
2024-08-29 20:38:03,065 [gem.py] => Task 1, Epoch 11/150 => Loss 0.000, Train_accy 100.00, Test_accy 48.60
2024-08-29 20:38:17,448 [gem.py] => Task 1, Epoch 16/150 => Loss 0.000, Train_accy 100.00, Test_accy 48.45
2024-08-29 20:38:32,178 [gem.py] => Task 1, Epoch 21/150 => Loss 0.000, Train_accy 100.00, Test_accy 48.55
2024-08-29 20:38:45,844 [gem.py] => Task 1, Epoch 26/150 => Loss 0.000, Train_accy 100.00, Test_accy 47.48
2024-08-29 20:39:01,619 [gem.py] => Task 1, Epoch 31/150 => Loss 0.000, Train_accy 100.00, Test_accy 47.36
2024-08-29 20:39:14,589 [gem.py] => Task 1, Epoch 36/150 => Loss 0.000, Train_accy 100.00, Test_accy 46.00
2024-08-29 20:39:28,606 [gem.py] => Task 1, Epoch 41/150 => Loss 0.000, Train_accy 100.00, Test_accy 45.60
2024-08-29 20:39:44,187 [gem.py] => Task 1, Epoch 46/150 => Loss 0.000, Train_accy 100.00, Test_accy 44.38
2024-08-29 20:39:59,379 [gem.py] => Task 1, Epoch 51/150 => Loss 0.000, Train_accy 100.00, Test_accy 44.31
2024-08-29 20:40:15,561 [gem.py] => Task 1, Epoch 56/150 => Loss 0.000, Train_accy 100.00, Test_accy 42.67
2024-08-29 20:40:32,227 [gem.py] => Task 1, Epoch 61/150 => Loss 0.000, Train_accy 100.00, Test_accy 42.43
2024-08-29 20:40:48,736 [gem.py] => Task 1, Epoch 66/150 => Loss 0.000, Train_accy 100.00, Test_accy 41.38
2024-08-29 20:41:04,821 [gem.py] => Task 1, Epoch 71/150 => Loss 0.000, Train_accy 100.00, Test_accy 40.81
2024-08-29 20:41:20,640 [gem.py] => Task 1, Epoch 76/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.79
2024-08-29 20:41:37,298 [gem.py] => Task 1, Epoch 81/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.52
2024-08-29 20:41:54,457 [gem.py] => Task 1, Epoch 86/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.90
2024-08-29 20:42:11,057 [gem.py] => Task 1, Epoch 91/150 => Loss 0.000, Train_accy 100.00, Test_accy 40.00
2024-08-29 20:42:27,586 [gem.py] => Task 1, Epoch 96/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.86
2024-08-29 20:42:44,102 [gem.py] => Task 1, Epoch 101/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.29
2024-08-29 20:42:59,512 [gem.py] => Task 1, Epoch 106/150 => Loss 0.000, Train_accy 100.00, Test_accy 38.88
2024-08-29 20:43:15,083 [gem.py] => Task 1, Epoch 111/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.02
2024-08-29 20:43:30,854 [gem.py] => Task 1, Epoch 116/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.29
2024-08-29 20:43:47,201 [gem.py] => Task 1, Epoch 121/150 => Loss 0.000, Train_accy 100.00, Test_accy 38.83
2024-08-29 20:44:02,303 [gem.py] => Task 1, Epoch 126/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.55
2024-08-29 20:44:18,185 [gem.py] => Task 1, Epoch 131/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.38
2024-08-29 20:44:33,661 [gem.py] => Task 1, Epoch 136/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.50
2024-08-29 20:44:48,904 [gem.py] => Task 1, Epoch 141/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.69
2024-08-29 20:45:04,414 [gem.py] => Task 1, Epoch 146/150 => Loss 0.000, Train_accy 100.00, Test_accy 39.52
2024-08-29 20:45:16,554 [gem.py] => Task 1, Epoch 150/150 => Loss 0.000, Train_accy 100.00
2024-08-29 20:45:16,563 [base.py] => Reducing exemplars...(71 per classes)
2024-08-29 20:45:18,468 [base.py] => Constructing exemplars...(71 per classes)
2024-08-29 20:45:22,683 [gem.py] => Exemplar size: 497
2024-08-29 20:45:22,684 [trainer.py] => CNN: {'total': 38.19, '00-04': 14.83, '05-06': 96.58, 'old': 14.83, 'new': 96.58}
2024-08-29 20:45:22,685 [trainer.py] => NME: {'total': 57.81, '00-04': 47.57, '05-06': 83.42, 'old': 47.57, 'new': 83.42}
2024-08-29 20:45:22,685 [trainer.py] => CNN top1 curve: [89.93, 38.19]
2024-08-29 20:45:22,685 [trainer.py] => CNN top5 curve: [100.0, 97.45]
2024-08-29 20:45:22,685 [trainer.py] => NME top1 curve: [90.0, 57.81]
2024-08-29 20:45:22,685 [trainer.py] => NME top5 curve: [100.0, 96.02]

2024-08-29 20:45:22,686 [trainer.py] => Average Accuracy (CNN): 64.06
2024-08-29 20:45:22,686 [trainer.py] => Average Accuracy (NME): 73.905
2024-08-29 20:45:22,687 [trainer.py] => All params: 3847495
2024-08-29 20:45:22,687 [trainer.py] => Trainable params: 3847495
2024-08-29 20:45:22,688 [gem.py] => Learning on 7-9
2024-08-29 20:45:26,236 [gem.py] => Task 2, Epoch 1/150 => Loss 0.185, Train_accy 92.88, Test_accy 21.65
2024-08-29 20:45:41,195 [gem.py] => Task 2, Epoch 6/150 => Loss 0.019, Train_accy 99.50, Test_accy 23.89
2024-08-29 20:45:56,858 [gem.py] => Task 2, Epoch 11/150 => Loss 0.002, Train_accy 99.98, Test_accy 23.44
2024-08-29 20:46:11,256 [gem.py] => Task 2, Epoch 16/150 => Loss 0.002, Train_accy 99.98, Test_accy 24.22
2024-08-29 20:46:26,882 [gem.py] => Task 2, Epoch 21/150 => Loss 0.066, Train_accy 97.75, Test_accy 14.83
2024-08-29 20:46:41,566 [gem.py] => Task 2, Epoch 26/150 => Loss 0.003, Train_accy 99.95, Test_accy 23.85
2024-08-29 20:47:00,013 [gem.py] => Task 2, Epoch 31/150 => Loss 0.001, Train_accy 100.00, Test_accy 23.69
2024-08-29 20:47:18,138 [gem.py] => Task 2, Epoch 36/150 => Loss 0.000, Train_accy 100.00, Test_accy 23.09
2024-08-29 20:47:36,357 [gem.py] => Task 2, Epoch 41/150 => Loss 0.000, Train_accy 100.00, Test_accy 23.28
2024-08-29 20:47:53,972 [gem.py] => Task 2, Epoch 46/150 => Loss 0.009, Train_accy 99.70, Test_accy 22.83
2024-08-29 20:48:08,011 [gem.py] => Task 2, Epoch 51/150 => Loss 0.008, Train_accy 99.80, Test_accy 23.33
2024-08-29 20:48:25,522 [gem.py] => Task 2, Epoch 56/150 => Loss 0.001, Train_accy 100.00, Test_accy 22.57
2024-08-29 20:48:44,374 [gem.py] => Task 2, Epoch 61/150 => Loss 0.001, Train_accy 99.98, Test_accy 22.96
2024-08-29 20:49:04,669 [gem.py] => Task 2, Epoch 66/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.78
2024-08-29 20:49:24,074 [gem.py] => Task 2, Epoch 71/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.44
2024-08-29 20:49:44,299 [gem.py] => Task 2, Epoch 76/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.69
2024-08-29 20:50:05,618 [gem.py] => Task 2, Epoch 81/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.52
2024-08-29 20:50:25,986 [gem.py] => Task 2, Epoch 86/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.59
2024-08-29 20:50:46,132 [gem.py] => Task 2, Epoch 91/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.54
2024-08-29 20:51:06,744 [gem.py] => Task 2, Epoch 96/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.43
2024-08-29 20:51:26,403 [gem.py] => Task 2, Epoch 101/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.37
2024-08-29 20:51:47,318 [gem.py] => Task 2, Epoch 106/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.59
2024-08-29 20:52:08,257 [gem.py] => Task 2, Epoch 111/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.56
2024-08-29 20:52:29,070 [gem.py] => Task 2, Epoch 116/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.44
2024-08-29 20:52:50,740 [gem.py] => Task 2, Epoch 121/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.44
2024-08-29 20:53:10,312 [gem.py] => Task 2, Epoch 126/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.50
2024-08-29 20:53:32,134 [gem.py] => Task 2, Epoch 131/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.52
2024-08-29 20:53:52,070 [gem.py] => Task 2, Epoch 136/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.46
2024-08-29 20:54:12,112 [gem.py] => Task 2, Epoch 141/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.54
2024-08-29 20:54:33,030 [gem.py] => Task 2, Epoch 146/150 => Loss 0.000, Train_accy 100.00, Test_accy 22.52
2024-08-29 20:54:49,233 [gem.py] => Task 2, Epoch 150/150 => Loss 0.000, Train_accy 100.00
2024-08-29 20:54:49,241 [base.py] => Reducing exemplars...(55 per classes)
2024-08-29 20:54:52,328 [base.py] => Constructing exemplars...(55 per classes)
2024-08-29 20:54:56,551 [gem.py] => Exemplar size: 495
2024-08-29 20:54:56,551 [trainer.py] => CNN: {'total': 22.56, '00-04': 1.23, '05-06': 1.5, '07-08': 96.92, 'old': 1.31, 'new': 96.92}
2024-08-29 20:54:56,551 [trainer.py] => NME: {'total': 33.3, '00-04': 20.13, '05-06': 17.58, '07-08': 81.92, 'old': 19.4, 'new': 81.92}
2024-08-29 20:54:56,551 [trainer.py] => CNN top1 curve: [89.93, 38.19, 22.56]
2024-08-29 20:54:56,551 [trainer.py] => CNN top5 curve: [100.0, 97.45, 85.15]
2024-08-29 20:54:56,551 [trainer.py] => NME top1 curve: [90.0, 57.81, 33.3]
2024-08-29 20:54:56,551 [trainer.py] => NME top5 curve: [100.0, 96.02, 84.35]

2024-08-29 20:54:56,551 [trainer.py] => Average Accuracy (CNN): 50.22666666666667
2024-08-29 20:54:56,551 [trainer.py] => Average Accuracy (NME): 60.370000000000005
2024-08-29 20:54:56,552 [trainer.py] => Forgetting (CNN): 91.89
