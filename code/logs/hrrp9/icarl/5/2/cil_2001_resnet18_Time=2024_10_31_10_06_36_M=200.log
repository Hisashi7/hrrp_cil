2024-10-31 10:06:36,565 [trainer.py] => config: ./exps/icarl.json
2024-10-31 10:06:36,566 [trainer.py] => prefix: cil
2024-10-31 10:06:36,566 [trainer.py] => dataset: hrrp9
2024-10-31 10:06:36,566 [trainer.py] => memory_size: 200
2024-10-31 10:06:36,566 [trainer.py] => memory_per_class: 20
2024-10-31 10:06:36,566 [trainer.py] => fixed_memory: False
2024-10-31 10:06:36,567 [trainer.py] => shuffle: True
2024-10-31 10:06:36,567 [trainer.py] => init_cls: 5
2024-10-31 10:06:36,567 [trainer.py] => increment: 2
2024-10-31 10:06:36,567 [trainer.py] => model_name: icarl
2024-10-31 10:06:36,567 [trainer.py] => convnet_type: resnet18
2024-10-31 10:06:36,567 [trainer.py] => device: [device(type='cuda', index=1)]
2024-10-31 10:06:36,568 [trainer.py] => init_train: False
2024-10-31 10:06:36,568 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_42503.pth
2024-10-31 10:06:36,568 [trainer.py] => fc_path2: checkpoints/init_train/fc_42503.pth
2024-10-31 10:06:36,568 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_35172.pth
2024-10-31 10:06:36,568 [trainer.py] => fc_path: checkpoints/init_train/fc_35172.pth
2024-10-31 10:06:36,569 [trainer.py] => seed2: [1993]
2024-10-31 10:06:36,569 [trainer.py] => seed: 2001
2024-10-31 10:06:36,569 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2024-10-31 10:06:36,569 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2024-10-31 10:06:36,569 [trainer.py] => init_epoch: 0
2024-10-31 10:06:36,569 [trainer.py] => init_lr: 0.1
2024-10-31 10:06:36,570 [trainer.py] => init_milestones: [60, 120, 170]
2024-10-31 10:06:36,570 [trainer.py] => init_lr_decay: 0.1
2024-10-31 10:06:36,570 [trainer.py] => init_weight_decay: 0.0005
2024-10-31 10:06:36,570 [trainer.py] => epochs: 150
2024-10-31 10:06:36,570 [trainer.py] => lrate: 0.1
2024-10-31 10:06:36,570 [trainer.py] => milestones: [80, 120]
2024-10-31 10:06:36,571 [trainer.py] => lrate_decay: 0.1
2024-10-31 10:06:36,571 [trainer.py] => momentum: 0.9
2024-10-31 10:06:36,578 [trainer.py] => batch_size: 128
2024-10-31 10:06:36,578 [trainer.py] => weight_decay: 0.0002
2024-10-31 10:06:36,578 [trainer.py] => num_workers: 8
2024-10-31 10:06:36,578 [trainer.py] => T: 2
2024-10-31 10:06:38,058 [data_manager.py] => [3, 5, 1, 7, 2, 8, 6, 4, 0]
2024-10-31 10:06:39,196 [trainer.py] => All params: 3843904
2024-10-31 10:06:39,197 [trainer.py] => Trainable params: 3843904
2024-10-31 10:06:39,202 [icarl.py] => Learning on 0-5
2024-10-31 10:06:39,758 [icarl.py] => init_train?---False
2024-10-31 10:06:41,838 [base.py] => Reducing exemplars...(40 per classes)
2024-10-31 10:06:41,839 [base.py] => Constructing exemplars...(40 per classes)
2024-10-31 10:06:52,309 [trainer.py] => All params: 3846469
2024-10-31 10:06:55,128 [icarl.py] => Exemplar size: 200
2024-10-31 10:06:55,135 [trainer.py] => CNN: {'total': 90.13, '00-04': 90.13, 'old': 0, 'new': 90.13}
2024-10-31 10:06:55,136 [trainer.py] => NME: {'total': 89.5, '00-04': 89.5, 'old': 0, 'new': 89.5}
2024-10-31 10:06:55,137 [trainer.py] => CNN top1 curve: [90.13]
2024-10-31 10:06:55,140 [trainer.py] => CNN top5 curve: [100.0]
2024-10-31 10:06:55,140 [trainer.py] => NME top1 curve: [89.5]
2024-10-31 10:06:55,141 [trainer.py] => NME top5 curve: [100.0]

2024-10-31 10:06:55,142 [trainer.py] => Average Accuracy (CNN): 90.13
2024-10-31 10:06:55,143 [trainer.py] => Average Accuracy (NME): 89.5
2024-10-31 10:06:55,144 [trainer.py] => All params: 3846469
2024-10-31 10:06:55,147 [trainer.py] => Trainable params: 3846469
2024-10-31 10:06:55,158 [icarl.py] => Learning on 5-7
2024-10-31 10:06:59,776 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.299, Train_accy 69.86, Test_accy 17.62
2024-10-31 10:07:14,093 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.236, Train_accy 98.48, Test_accy 54.64
2024-10-31 10:07:27,913 [icarl.py] => Task 1, Epoch 11/150 => Loss 1.092, Train_accy 100.00, Test_accy 65.67
2024-10-31 10:07:41,172 [icarl.py] => Task 1, Epoch 16/150 => Loss 1.074, Train_accy 100.00, Test_accy 62.88
2024-10-31 10:07:54,873 [icarl.py] => Task 1, Epoch 21/150 => Loss 1.067, Train_accy 100.00, Test_accy 58.33
2024-10-31 10:08:07,884 [icarl.py] => Task 1, Epoch 26/150 => Loss 1.064, Train_accy 100.00, Test_accy 64.10
2024-10-31 10:08:21,408 [icarl.py] => Task 1, Epoch 31/150 => Loss 1.063, Train_accy 100.00, Test_accy 65.10
2024-10-31 10:08:34,947 [icarl.py] => Task 1, Epoch 36/150 => Loss 1.064, Train_accy 100.00, Test_accy 64.36
2024-10-31 10:08:46,821 [icarl.py] => Task 1, Epoch 41/150 => Loss 1.061, Train_accy 100.00, Test_accy 64.40
2024-10-31 10:08:56,901 [icarl.py] => Task 1, Epoch 46/150 => Loss 1.060, Train_accy 100.00, Test_accy 63.00
2024-10-31 10:09:04,980 [icarl.py] => Task 1, Epoch 51/150 => Loss 1.061, Train_accy 100.00, Test_accy 66.02
2024-10-31 10:09:13,359 [icarl.py] => Task 1, Epoch 56/150 => Loss 1.061, Train_accy 100.00, Test_accy 60.64
2024-10-31 10:09:21,773 [icarl.py] => Task 1, Epoch 61/150 => Loss 1.058, Train_accy 100.00, Test_accy 61.76
2024-10-31 10:09:30,076 [icarl.py] => Task 1, Epoch 66/150 => Loss 1.059, Train_accy 100.00, Test_accy 59.48
2024-10-31 10:09:38,888 [icarl.py] => Task 1, Epoch 71/150 => Loss 1.059, Train_accy 100.00, Test_accy 63.33
2024-10-31 10:09:47,439 [icarl.py] => Task 1, Epoch 76/150 => Loss 1.058, Train_accy 100.00, Test_accy 66.69
2024-10-31 10:09:55,481 [icarl.py] => Task 1, Epoch 81/150 => Loss 1.056, Train_accy 100.00, Test_accy 61.21
2024-10-31 10:10:03,569 [icarl.py] => Task 1, Epoch 86/150 => Loss 1.053, Train_accy 100.00, Test_accy 61.40
2024-10-31 10:10:11,713 [icarl.py] => Task 1, Epoch 91/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.40
2024-10-31 10:10:20,481 [icarl.py] => Task 1, Epoch 96/150 => Loss 1.053, Train_accy 100.00, Test_accy 62.12
2024-10-31 10:10:28,906 [icarl.py] => Task 1, Epoch 101/150 => Loss 1.053, Train_accy 100.00, Test_accy 61.52
2024-10-31 10:10:36,776 [icarl.py] => Task 1, Epoch 106/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.88
2024-10-31 10:10:44,635 [icarl.py] => Task 1, Epoch 111/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.71
2024-10-31 10:10:53,036 [icarl.py] => Task 1, Epoch 116/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.00
2024-10-31 10:11:00,702 [icarl.py] => Task 1, Epoch 121/150 => Loss 1.053, Train_accy 100.00, Test_accy 60.29
2024-10-31 10:11:08,877 [icarl.py] => Task 1, Epoch 126/150 => Loss 1.052, Train_accy 100.00, Test_accy 62.05
2024-10-31 10:11:16,675 [icarl.py] => Task 1, Epoch 131/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.00
2024-10-31 10:11:25,152 [icarl.py] => Task 1, Epoch 136/150 => Loss 1.051, Train_accy 100.00, Test_accy 62.14
2024-10-31 10:11:33,634 [icarl.py] => Task 1, Epoch 141/150 => Loss 1.051, Train_accy 100.00, Test_accy 61.64
2024-10-31 10:11:41,856 [icarl.py] => Task 1, Epoch 146/150 => Loss 1.052, Train_accy 100.00, Test_accy 61.55
2024-10-31 10:11:47,773 [icarl.py] => Task 1, Epoch 150/150 => Loss 1.052, Train_accy 100.00
2024-10-31 10:11:47,774 [base.py] => Reducing exemplars...(28 per classes)
2024-10-31 10:11:49,615 [base.py] => Constructing exemplars...(28 per classes)
2024-10-31 10:11:52,060 [trainer.py] => All params: 3847495
2024-10-31 10:11:54,078 [icarl.py] => Exemplar size: 196
2024-10-31 10:11:54,078 [trainer.py] => CNN: {'total': 62.0, '00-04': 48.73, '05-06': 95.17, 'old': 48.73, 'new': 95.17}
2024-10-31 10:11:54,078 [trainer.py] => NME: {'total': 76.88, '00-04': 70.57, '05-06': 92.67, 'old': 70.57, 'new': 92.67}
2024-10-31 10:11:54,078 [trainer.py] => CNN top1 curve: [90.13, 62.0]
2024-10-31 10:11:54,079 [trainer.py] => CNN top5 curve: [100.0, 98.86]
2024-10-31 10:11:54,079 [trainer.py] => NME top1 curve: [89.5, 76.88]
2024-10-31 10:11:54,079 [trainer.py] => NME top5 curve: [100.0, 99.05]

2024-10-31 10:11:54,079 [trainer.py] => Average Accuracy (CNN): 76.065
2024-10-31 10:11:54,079 [trainer.py] => Average Accuracy (NME): 83.19
2024-10-31 10:11:54,080 [trainer.py] => All params: 3847495
2024-10-31 10:11:54,080 [trainer.py] => Trainable params: 3847495
2024-10-31 10:11:54,082 [icarl.py] => Learning on 7-9
2024-10-31 10:11:56,913 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.902, Train_accy 70.73, Test_accy 11.28
2024-10-31 10:12:05,482 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.658, Train_accy 92.30, Test_accy 12.83
2024-10-31 10:12:14,388 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.413, Train_accy 95.47, Test_accy 33.52
2024-10-31 10:12:22,319 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.289, Train_accy 98.02, Test_accy 38.35
2024-10-31 10:12:30,273 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.147, Train_accy 100.00, Test_accy 47.00
2024-10-31 10:12:39,082 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.118, Train_accy 100.00, Test_accy 41.04
2024-10-31 10:12:47,332 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.108, Train_accy 100.00, Test_accy 38.94
2024-10-31 10:12:56,894 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.098, Train_accy 100.00, Test_accy 39.00
2024-10-31 10:13:05,625 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.099, Train_accy 99.98, Test_accy 41.50
2024-10-31 10:13:14,157 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.091, Train_accy 100.00, Test_accy 40.63
2024-10-31 10:13:23,021 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.090, Train_accy 100.00, Test_accy 41.20
2024-10-31 10:13:32,175 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.089, Train_accy 100.00, Test_accy 37.78
2024-10-31 10:13:41,358 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.090, Train_accy 100.00, Test_accy 39.98
2024-10-31 10:13:50,436 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.088, Train_accy 100.00, Test_accy 38.13
2024-10-31 10:13:59,096 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.087, Train_accy 100.00, Test_accy 34.59
2024-10-31 10:14:08,465 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.085, Train_accy 100.00, Test_accy 38.33
2024-10-31 10:14:16,842 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.085, Train_accy 100.00, Test_accy 36.70
2024-10-31 10:14:25,604 [icarl.py] => Task 2, Epoch 86/150 => Loss 1.079, Train_accy 100.00, Test_accy 36.20
2024-10-31 10:14:34,854 [icarl.py] => Task 2, Epoch 91/150 => Loss 1.080, Train_accy 100.00, Test_accy 35.98
2024-10-31 10:14:44,035 [icarl.py] => Task 2, Epoch 96/150 => Loss 1.079, Train_accy 100.00, Test_accy 35.56
2024-10-31 10:14:53,324 [icarl.py] => Task 2, Epoch 101/150 => Loss 1.078, Train_accy 100.00, Test_accy 35.91
2024-10-31 10:15:02,377 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.078, Train_accy 100.00, Test_accy 36.33
2024-10-31 10:15:10,820 [icarl.py] => Task 2, Epoch 111/150 => Loss 1.079, Train_accy 100.00, Test_accy 35.67
2024-10-31 10:15:19,857 [icarl.py] => Task 2, Epoch 116/150 => Loss 1.078, Train_accy 100.00, Test_accy 35.63
2024-10-31 10:15:28,448 [icarl.py] => Task 2, Epoch 121/150 => Loss 1.078, Train_accy 100.00, Test_accy 35.89
2024-10-31 10:15:37,716 [icarl.py] => Task 2, Epoch 126/150 => Loss 1.077, Train_accy 100.00, Test_accy 35.56
2024-10-31 10:15:46,712 [icarl.py] => Task 2, Epoch 131/150 => Loss 1.079, Train_accy 100.00, Test_accy 36.04
2024-10-31 10:15:56,659 [icarl.py] => Task 2, Epoch 136/150 => Loss 1.077, Train_accy 100.00, Test_accy 35.94
2024-10-31 10:16:06,190 [icarl.py] => Task 2, Epoch 141/150 => Loss 1.078, Train_accy 100.00, Test_accy 36.83
2024-10-31 10:16:15,120 [icarl.py] => Task 2, Epoch 146/150 => Loss 1.078, Train_accy 100.00, Test_accy 36.37
2024-10-31 10:16:21,702 [icarl.py] => Task 2, Epoch 150/150 => Loss 1.078, Train_accy 100.00
2024-10-31 10:16:21,703 [base.py] => Reducing exemplars...(22 per classes)
2024-10-31 10:16:24,557 [base.py] => Constructing exemplars...(22 per classes)
2024-10-31 10:16:27,273 [trainer.py] => All params: 3848521
2024-10-31 10:16:29,293 [icarl.py] => Exemplar size: 198
2024-10-31 10:16:29,293 [trainer.py] => CNN: {'total': 35.72, '00-04': 22.03, '05-06': 16.5, '07-08': 89.17, 'old': 20.45, 'new': 89.17}
2024-10-31 10:16:29,293 [trainer.py] => NME: {'total': 55.15, '00-04': 49.1, '05-06': 42.83, '07-08': 82.58, 'old': 47.31, 'new': 82.58}
2024-10-31 10:16:29,294 [trainer.py] => CNN top1 curve: [90.13, 62.0, 35.72]
2024-10-31 10:16:29,294 [trainer.py] => CNN top5 curve: [100.0, 98.86, 92.17]
2024-10-31 10:16:29,294 [trainer.py] => NME top1 curve: [89.5, 76.88, 55.15]
2024-10-31 10:16:29,294 [trainer.py] => NME top5 curve: [100.0, 99.05, 95.11]

2024-10-31 10:16:29,294 [trainer.py] => Average Accuracy (CNN): 62.61666666666667
2024-10-31 10:16:29,294 [trainer.py] => Average Accuracy (NME): 73.84333333333333
2024-10-31 10:16:29,295 [trainer.py] => Forgetting (CNN): 73.38499999999999
