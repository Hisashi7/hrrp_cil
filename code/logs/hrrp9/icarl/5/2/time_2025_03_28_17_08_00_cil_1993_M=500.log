2025-03-28 17:08:00,349 [trainer.py] => config: ./exps/icarl.json
2025-03-28 17:08:00,350 [trainer.py] => prefix: cil
2025-03-28 17:08:00,350 [trainer.py] => dataset: hrrp9
2025-03-28 17:08:00,350 [trainer.py] => memory_size: 500
2025-03-28 17:08:00,350 [trainer.py] => memory_per_class: 20
2025-03-28 17:08:00,350 [trainer.py] => fixed_memory: False
2025-03-28 17:08:00,350 [trainer.py] => shuffle: True
2025-03-28 17:08:00,350 [trainer.py] => init_cls: 5
2025-03-28 17:08:00,350 [trainer.py] => increment: 2
2025-03-28 17:08:00,350 [trainer.py] => model_name: icarl
2025-03-28 17:08:00,350 [trainer.py] => convnet_type: resnet18
2025-03-28 17:08:00,350 [trainer.py] => device: [device(type='cuda', index=1)]
2025-03-28 17:08:00,350 [trainer.py] => init_train: False
2025-03-28 17:08:00,350 [trainer.py] => seed: 1993
2025-03-28 17:08:00,350 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2025-03-28 17:08:00,350 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2025-03-28 17:08:00,350 [trainer.py] => convnet_path2: checkpoints/init_train/resnet18_35172.pth
2025-03-28 17:08:00,350 [trainer.py] => fc_path2: checkpoints/init_train/fc_35172.pth
2025-03-28 17:08:00,350 [trainer.py] => seed2: [2001]
2025-03-28 17:08:00,350 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_42871.pth
2025-03-28 17:08:00,350 [trainer.py] => fc_path1: checkpoints/init_train/fc_42871.pth
2025-03-28 17:08:00,350 [trainer.py] => init_epoch: 0
2025-03-28 17:08:00,350 [trainer.py] => init_lr: 0.1
2025-03-28 17:08:00,350 [trainer.py] => init_milestones: [60, 120, 170]
2025-03-28 17:08:00,351 [trainer.py] => init_lr_decay: 0.1
2025-03-28 17:08:00,351 [trainer.py] => init_weight_decay: 0.0005
2025-03-28 17:08:00,351 [trainer.py] => epochs: 150
2025-03-28 17:08:00,351 [trainer.py] => lrate: 0.1
2025-03-28 17:08:00,351 [trainer.py] => milestones: [80, 120]
2025-03-28 17:08:00,351 [trainer.py] => lrate_decay: 0.1
2025-03-28 17:08:00,351 [trainer.py] => momentum: 0.9
2025-03-28 17:08:00,351 [trainer.py] => batch_size: 128
2025-03-28 17:08:00,351 [trainer.py] => weight_decay: 0.0002
2025-03-28 17:08:00,351 [trainer.py] => num_workers: 8
2025-03-28 17:08:00,351 [trainer.py] => T: 2
2025-03-28 17:08:00,913 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2025-03-28 17:08:01,294 [trainer.py] => All params: 3843904
2025-03-28 17:08:01,294 [trainer.py] => Trainable params: 3843904
2025-03-28 17:08:01,297 [icarl.py] => Learning on 0-5
2025-03-28 17:08:01,568 [icarl.py] => init_train?---False
2025-03-28 17:08:02,297 [base.py] => Reducing exemplars...(100 per classes)
2025-03-28 17:08:02,298 [base.py] => Constructing exemplars...(100 per classes)
2025-03-28 17:08:06,843 [trainer.py] => task:0 training time:5.55s
2025-03-28 17:08:06,844 [trainer.py] => All params: 3846469
2025-03-28 17:08:07,807 [icarl.py] => Exemplar size: 500
2025-03-28 17:08:07,807 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2025-03-28 17:08:07,807 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2025-03-28 17:08:07,807 [trainer.py] => CNN top1 curve: [89.93]
2025-03-28 17:08:07,807 [trainer.py] => CNN top5 curve: [100.0]
2025-03-28 17:08:07,807 [trainer.py] => NME top1 curve: [90.0]
2025-03-28 17:08:07,807 [trainer.py] => NME top5 curve: [100.0]

2025-03-28 17:08:07,808 [trainer.py] => Average Accuracy (CNN): 89.93
2025-03-28 17:08:07,808 [trainer.py] => Average Accuracy (NME): 90.0
2025-03-28 17:08:07,808 [trainer.py] => All params: 3846469
2025-03-28 17:08:07,808 [trainer.py] => Trainable params: 3846469
2025-03-28 17:08:07,809 [icarl.py] => Learning on 5-7
2025-03-28 17:08:09,360 [icarl.py] => Task 1, Epoch 1/150 => Loss 2.015, Train_accy 75.98, Test_accy 47.52
2025-03-28 17:08:14,205 [icarl.py] => Task 1, Epoch 6/150 => Loss 1.015, Train_accy 98.84, Test_accy 62.31
2025-03-28 17:08:18,972 [icarl.py] => Task 1, Epoch 11/150 => Loss 0.931, Train_accy 100.00, Test_accy 66.31
2025-03-28 17:08:24,042 [icarl.py] => Task 1, Epoch 16/150 => Loss 0.925, Train_accy 100.00, Test_accy 67.57
2025-03-28 17:08:29,165 [icarl.py] => Task 1, Epoch 21/150 => Loss 0.959, Train_accy 99.84, Test_accy 71.95
2025-03-28 17:08:34,405 [icarl.py] => Task 1, Epoch 26/150 => Loss 0.937, Train_accy 99.96, Test_accy 68.83
2025-03-28 17:08:39,480 [icarl.py] => Task 1, Epoch 31/150 => Loss 0.941, Train_accy 99.96, Test_accy 65.21
2025-03-28 17:08:44,678 [icarl.py] => Task 1, Epoch 36/150 => Loss 0.925, Train_accy 100.00, Test_accy 67.07
2025-03-28 17:08:49,693 [icarl.py] => Task 1, Epoch 41/150 => Loss 0.919, Train_accy 100.00, Test_accy 68.69
2025-03-28 17:08:55,095 [icarl.py] => Task 1, Epoch 46/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.17
2025-03-28 17:09:00,200 [icarl.py] => Task 1, Epoch 51/150 => Loss 0.911, Train_accy 100.00, Test_accy 66.07
2025-03-28 17:09:05,351 [icarl.py] => Task 1, Epoch 56/150 => Loss 0.913, Train_accy 100.00, Test_accy 65.93
2025-03-28 17:09:10,547 [icarl.py] => Task 1, Epoch 61/150 => Loss 0.913, Train_accy 100.00, Test_accy 65.81
2025-03-28 17:09:15,929 [icarl.py] => Task 1, Epoch 66/150 => Loss 0.908, Train_accy 100.00, Test_accy 69.71
2025-03-28 17:09:21,123 [icarl.py] => Task 1, Epoch 71/150 => Loss 0.914, Train_accy 100.00, Test_accy 68.64
2025-03-28 17:09:26,474 [icarl.py] => Task 1, Epoch 76/150 => Loss 0.909, Train_accy 100.00, Test_accy 67.71
2025-03-28 17:09:31,792 [icarl.py] => Task 1, Epoch 81/150 => Loss 0.957, Train_accy 99.13, Test_accy 67.24
2025-03-28 17:09:36,937 [icarl.py] => Task 1, Epoch 86/150 => Loss 0.910, Train_accy 100.00, Test_accy 67.36
2025-03-28 17:09:42,076 [icarl.py] => Task 1, Epoch 91/150 => Loss 0.907, Train_accy 100.00, Test_accy 68.90
2025-03-28 17:09:47,458 [icarl.py] => Task 1, Epoch 96/150 => Loss 0.906, Train_accy 100.00, Test_accy 68.62
2025-03-28 17:09:52,498 [icarl.py] => Task 1, Epoch 101/150 => Loss 0.905, Train_accy 100.00, Test_accy 69.10
2025-03-28 17:09:57,901 [icarl.py] => Task 1, Epoch 106/150 => Loss 0.908, Train_accy 100.00, Test_accy 68.33
2025-03-28 17:10:03,210 [icarl.py] => Task 1, Epoch 111/150 => Loss 0.907, Train_accy 100.00, Test_accy 68.90
2025-03-28 17:10:08,448 [icarl.py] => Task 1, Epoch 116/150 => Loss 0.902, Train_accy 100.00, Test_accy 68.36
2025-03-28 17:10:14,113 [icarl.py] => Task 1, Epoch 121/150 => Loss 0.903, Train_accy 100.00, Test_accy 68.90
2025-03-28 17:10:19,444 [icarl.py] => Task 1, Epoch 126/150 => Loss 0.905, Train_accy 100.00, Test_accy 68.48
2025-03-28 17:10:24,735 [icarl.py] => Task 1, Epoch 131/150 => Loss 0.906, Train_accy 100.00, Test_accy 69.71
2025-03-28 17:10:30,051 [icarl.py] => Task 1, Epoch 136/150 => Loss 0.907, Train_accy 100.00, Test_accy 68.74
2025-03-28 17:10:35,499 [icarl.py] => Task 1, Epoch 141/150 => Loss 0.911, Train_accy 100.00, Test_accy 68.74
2025-03-28 17:10:40,796 [icarl.py] => Task 1, Epoch 146/150 => Loss 0.907, Train_accy 100.00, Test_accy 68.90
2025-03-28 17:10:44,575 [icarl.py] => Task 1, Epoch 150/150 => Loss 0.904, Train_accy 100.00
2025-03-28 17:10:44,575 [icarl.py] => 100 epoches training time:103.20s
2025-03-28 17:10:44,575 [icarl.py] => Average training time of single epoch:0.94s
2025-03-28 17:10:44,576 [base.py] => Reducing exemplars...(71 per classes)
2025-03-28 17:10:45,827 [base.py] => Constructing exemplars...(71 per classes)
2025-03-28 17:10:47,638 [trainer.py] => task:1 training time:159.83s
2025-03-28 17:10:47,639 [trainer.py] => All params: 3847495
2025-03-28 17:10:48,757 [icarl.py] => Exemplar size: 497
2025-03-28 17:10:48,757 [trainer.py] => CNN: {'total': 68.69, '00-04': 57.33, '05-06': 97.08, 'old': 57.33, 'new': 97.08}
2025-03-28 17:10:48,758 [trainer.py] => NME: {'total': 77.33, '00-04': 70.87, '05-06': 93.5, 'old': 70.87, 'new': 93.5}
2025-03-28 17:10:48,758 [trainer.py] => CNN top1 curve: [89.93, 68.69]
2025-03-28 17:10:48,758 [trainer.py] => CNN top5 curve: [100.0, 98.83]
2025-03-28 17:10:48,758 [trainer.py] => NME top1 curve: [90.0, 77.33]
2025-03-28 17:10:48,758 [trainer.py] => NME top5 curve: [100.0, 98.93]

2025-03-28 17:10:48,758 [trainer.py] => Average Accuracy (CNN): 79.31
2025-03-28 17:10:48,758 [trainer.py] => Average Accuracy (NME): 83.66499999999999
2025-03-28 17:10:48,758 [trainer.py] => All params: 3847495
2025-03-28 17:10:48,759 [trainer.py] => Trainable params: 3847495
2025-03-28 17:10:48,760 [icarl.py] => Learning on 7-9
2025-03-28 17:10:50,443 [icarl.py] => Task 2, Epoch 1/150 => Loss 2.693, Train_accy 75.76, Test_accy 18.48
2025-03-28 17:10:55,801 [icarl.py] => Task 2, Epoch 6/150 => Loss 1.310, Train_accy 95.46, Test_accy 51.63
2025-03-28 17:11:01,305 [icarl.py] => Task 2, Epoch 11/150 => Loss 1.051, Train_accy 99.98, Test_accy 66.69
2025-03-28 17:11:06,791 [icarl.py] => Task 2, Epoch 16/150 => Loss 1.016, Train_accy 100.00, Test_accy 67.13
2025-03-28 17:11:12,206 [icarl.py] => Task 2, Epoch 21/150 => Loss 1.011, Train_accy 100.00, Test_accy 68.19
2025-03-28 17:11:17,735 [icarl.py] => Task 2, Epoch 26/150 => Loss 1.011, Train_accy 100.00, Test_accy 67.02
2025-03-28 17:11:23,198 [icarl.py] => Task 2, Epoch 31/150 => Loss 1.012, Train_accy 99.98, Test_accy 64.87
2025-03-28 17:11:28,525 [icarl.py] => Task 2, Epoch 36/150 => Loss 1.010, Train_accy 100.00, Test_accy 66.56
2025-03-28 17:11:34,007 [icarl.py] => Task 2, Epoch 41/150 => Loss 1.002, Train_accy 100.00, Test_accy 67.06
2025-03-28 17:11:39,364 [icarl.py] => Task 2, Epoch 46/150 => Loss 1.004, Train_accy 100.00, Test_accy 67.00
2025-03-28 17:11:44,925 [icarl.py] => Task 2, Epoch 51/150 => Loss 1.005, Train_accy 100.00, Test_accy 68.96
2025-03-28 17:11:50,305 [icarl.py] => Task 2, Epoch 56/150 => Loss 1.004, Train_accy 100.00, Test_accy 68.39
2025-03-28 17:11:55,794 [icarl.py] => Task 2, Epoch 61/150 => Loss 1.014, Train_accy 99.98, Test_accy 65.15
2025-03-28 17:12:01,284 [icarl.py] => Task 2, Epoch 66/150 => Loss 1.001, Train_accy 100.00, Test_accy 67.33
2025-03-28 17:12:06,670 [icarl.py] => Task 2, Epoch 71/150 => Loss 1.005, Train_accy 100.00, Test_accy 65.33
2025-03-28 17:12:11,995 [icarl.py] => Task 2, Epoch 76/150 => Loss 1.014, Train_accy 99.96, Test_accy 63.74
2025-03-28 17:12:17,516 [icarl.py] => Task 2, Epoch 81/150 => Loss 1.002, Train_accy 100.00, Test_accy 65.09
2025-03-28 17:12:22,885 [icarl.py] => Task 2, Epoch 86/150 => Loss 0.996, Train_accy 100.00, Test_accy 65.80
2025-03-28 17:12:28,326 [icarl.py] => Task 2, Epoch 91/150 => Loss 0.996, Train_accy 100.00, Test_accy 67.26
2025-03-28 17:12:33,728 [icarl.py] => Task 2, Epoch 96/150 => Loss 0.998, Train_accy 100.00, Test_accy 67.69
2025-03-28 17:12:38,988 [icarl.py] => Task 2, Epoch 101/150 => Loss 0.995, Train_accy 100.00, Test_accy 65.72
2025-03-28 17:12:44,589 [icarl.py] => Task 2, Epoch 106/150 => Loss 1.003, Train_accy 100.00, Test_accy 67.46
2025-03-28 17:12:50,072 [icarl.py] => Task 2, Epoch 111/150 => Loss 0.994, Train_accy 100.00, Test_accy 65.91
2025-03-28 17:12:55,405 [icarl.py] => Task 2, Epoch 116/150 => Loss 0.991, Train_accy 100.00, Test_accy 67.50
2025-03-28 17:13:00,762 [icarl.py] => Task 2, Epoch 121/150 => Loss 0.992, Train_accy 100.00, Test_accy 64.96
2025-03-28 17:13:06,233 [icarl.py] => Task 2, Epoch 126/150 => Loss 0.998, Train_accy 100.00, Test_accy 66.04
2025-03-28 17:13:11,730 [icarl.py] => Task 2, Epoch 131/150 => Loss 0.996, Train_accy 100.00, Test_accy 65.57
2025-03-28 17:13:17,219 [icarl.py] => Task 2, Epoch 136/150 => Loss 0.998, Train_accy 100.00, Test_accy 66.67
2025-03-28 17:13:22,572 [icarl.py] => Task 2, Epoch 141/150 => Loss 0.993, Train_accy 100.00, Test_accy 65.04
2025-03-28 17:13:28,108 [icarl.py] => Task 2, Epoch 146/150 => Loss 0.995, Train_accy 100.00, Test_accy 65.20
2025-03-28 17:13:32,244 [icarl.py] => Task 2, Epoch 150/150 => Loss 0.990, Train_accy 100.00
2025-03-28 17:13:32,244 [icarl.py] => 100 epoches training time:108.61s
2025-03-28 17:13:32,244 [icarl.py] => Average training time of single epoch:0.97s
2025-03-28 17:13:32,245 [base.py] => Reducing exemplars...(55 per classes)
2025-03-28 17:13:33,924 [base.py] => Constructing exemplars...(55 per classes)
2025-03-28 17:13:35,643 [trainer.py] => task:2 training time:166.88s
2025-03-28 17:13:35,644 [trainer.py] => All params: 3848521
2025-03-28 17:13:36,936 [icarl.py] => Exemplar size: 495
2025-03-28 17:13:36,936 [trainer.py] => CNN: {'total': 67.3, '00-04': 53.1, '05-06': 72.83, '07-08': 97.25, 'old': 58.74, 'new': 97.25}
2025-03-28 17:13:36,937 [trainer.py] => NME: {'total': 74.89, '00-04': 64.37, '05-06': 84.08, '07-08': 92.0, 'old': 70.0, 'new': 92.0}
2025-03-28 17:13:36,937 [trainer.py] => CNN top1 curve: [89.93, 68.69, 67.3]
2025-03-28 17:13:36,937 [trainer.py] => CNN top5 curve: [100.0, 98.83, 96.2]
2025-03-28 17:13:36,937 [trainer.py] => NME top1 curve: [90.0, 77.33, 74.89]
2025-03-28 17:13:36,937 [trainer.py] => NME top5 curve: [100.0, 98.93, 97.7]

2025-03-28 17:13:36,937 [trainer.py] => Average Accuracy (CNN): 75.30666666666667
2025-03-28 17:13:36,937 [trainer.py] => Average Accuracy (NME): 80.74
2025-03-28 17:13:36,937 [trainer.py] => Time consumed in all training process:335.64s
2025-03-28 17:13:36,937 [trainer.py] => Average Time consumed in single task:110.75s
2025-03-28 17:13:36,978 [trainer.py] => Model state dict saved successfully at: saved_pth/hrrp9/icarl/time_2025_03_28_17_08_00_cil_1993_M=500.pth
2025-03-28 17:13:36,979 [trainer.py] => Forgetting (CNN): 30.540000000000003
