2024-10-17 17:10:23,201 [trainer.py] => config: ./exps/bic.json
2024-10-17 17:10:23,201 [trainer.py] => prefix: cil
2024-10-17 17:10:23,201 [trainer.py] => dataset: hrrp9
2024-10-17 17:10:23,202 [trainer.py] => memory_size: 500
2024-10-17 17:10:23,202 [trainer.py] => memory_per_class: 20
2024-10-17 17:10:23,202 [trainer.py] => fixed_memory: False
2024-10-17 17:10:23,202 [trainer.py] => shuffle: True
2024-10-17 17:10:23,202 [trainer.py] => init_cls: 5
2024-10-17 17:10:23,202 [trainer.py] => increment: 2
2024-10-17 17:10:23,202 [trainer.py] => model_name: bic
2024-10-17 17:10:23,202 [trainer.py] => convnet_type: resnet18
2024-10-17 17:10:23,202 [trainer.py] => device: [device(type='cuda', index=1)]
2024-10-17 17:10:23,202 [trainer.py] => init_train: False
2024-10-17 17:10:23,202 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-17 17:10:23,202 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-17 17:10:23,202 [trainer.py] => seed: 1993
2024-10-17 17:10:23,202 [trainer.py] => init_epochs: 0
2024-10-17 17:10:23,202 [trainer.py] => epochs: 150
2024-10-17 17:10:23,202 [trainer.py] => lrate: 0.1
2024-10-17 17:10:23,202 [trainer.py] => milestones: [80, 120]
2024-10-17 17:10:23,202 [trainer.py] => lrate_decay: 0.1
2024-10-17 17:10:23,202 [trainer.py] => momentum: 0.9
2024-10-17 17:10:23,202 [trainer.py] => batch_size: 128
2024-10-17 17:10:23,202 [trainer.py] => split_ratio: 0.1
2024-10-17 17:10:23,202 [trainer.py] => weight_decay: 0.0002
2024-10-17 17:10:23,202 [trainer.py] => num_workers: 0
2024-10-17 17:10:23,202 [trainer.py] => T: 2
2024-10-17 17:10:23,846 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-17 17:10:24,365 [trainer.py] => All params: 3843904
2024-10-17 17:10:24,365 [trainer.py] => Trainable params: 3843904
2024-10-17 17:10:24,370 [bic.py] => Learning on 0-5
2024-10-17 17:10:24,412 [bic.py] => Parameters of bias layer:
2024-10-17 17:10:24,413 [bic.py] => 0 => 1.000, 0.000
2024-10-17 17:10:24,596 [base.py] => Reducing exemplars...(100 per classes)
2024-10-17 17:10:24,596 [base.py] => Constructing exemplars...(100 per classes)
2024-10-17 17:10:30,619 [bic.py] => Parameters of bias layer:
2024-10-17 17:10:30,621 [bic.py] => 0 => 1.000, 0.000
2024-10-17 17:10:30,622 [trainer.py] => All params: 3846471
2024-10-17 17:10:30,992 [bic.py] => Exemplar size: 500
2024-10-17 17:10:30,993 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-17 17:10:30,993 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-17 17:10:30,993 [trainer.py] => CNN top1 curve: [89.93]
2024-10-17 17:10:30,993 [trainer.py] => CNN top5 curve: [100.0]
2024-10-17 17:10:30,993 [trainer.py] => NME top1 curve: [90.0]
2024-10-17 17:10:30,993 [trainer.py] => NME top5 curve: [100.0]

2024-10-17 17:10:30,993 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-17 17:10:30,993 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-17 17:10:30,993 [trainer.py] => All params: 3846471
2024-10-17 17:10:30,994 [trainer.py] => Trainable params: 3846471
2024-10-17 17:10:30,995 [bic.py] => Learning on 5-7
2024-10-17 17:10:31,005 [bic.py] => Stage1 dset: 4430, Stage2 dset: 70
2024-10-17 17:10:31,005 [bic.py] => Lambda: 0.714
2024-10-17 17:10:31,010 [bic.py] => Parameters of bias layer:
2024-10-17 17:10:31,010 [bic.py] => 0 => 1.000, 0.000
2024-10-17 17:10:31,010 [bic.py] => 1 => 1.000, 0.000
2024-10-17 17:10:32,315 [bic.py] => training => Task 1, Epoch 1/150 => Loss 1.008, Train_accy 88.870, Test_accy 41.950
2024-10-17 17:10:33,418 [bic.py] => training => Task 1, Epoch 2/150 => Loss 0.758, Train_accy 96.570, Test_accy 55.900
2024-10-17 17:10:34,433 [bic.py] => training => Task 1, Epoch 3/150 => Loss 0.705, Train_accy 98.940, Test_accy 62.450
2024-10-17 17:10:35,474 [bic.py] => training => Task 1, Epoch 4/150 => Loss 0.688, Train_accy 99.640, Test_accy 60.860
2024-10-17 17:10:36,523 [bic.py] => training => Task 1, Epoch 5/150 => Loss 0.681, Train_accy 99.890, Test_accy 62.740
2024-10-17 17:10:37,542 [bic.py] => training => Task 1, Epoch 6/150 => Loss 0.671, Train_accy 99.950, Test_accy 64.000
2024-10-17 17:10:38,522 [bic.py] => training => Task 1, Epoch 7/150 => Loss 0.669, Train_accy 100.000, Test_accy 61.690
2024-10-17 17:10:39,554 [bic.py] => training => Task 1, Epoch 8/150 => Loss 0.668, Train_accy 100.000, Test_accy 63.450
2024-10-17 17:10:40,471 [bic.py] => training => Task 1, Epoch 9/150 => Loss 0.665, Train_accy 100.000, Test_accy 63.330
2024-10-17 17:10:41,562 [bic.py] => training => Task 1, Epoch 10/150 => Loss 0.664, Train_accy 100.000, Test_accy 65.000
2024-10-17 17:10:42,698 [bic.py] => training => Task 1, Epoch 11/150 => Loss 0.663, Train_accy 99.980, Test_accy 64.020
2024-10-17 17:10:43,716 [bic.py] => training => Task 1, Epoch 12/150 => Loss 0.663, Train_accy 100.000, Test_accy 60.480
2024-10-17 17:10:44,770 [bic.py] => training => Task 1, Epoch 13/150 => Loss 0.664, Train_accy 99.980, Test_accy 58.480
2024-10-17 17:10:45,783 [bic.py] => training => Task 1, Epoch 14/150 => Loss 0.660, Train_accy 100.000, Test_accy 65.020
2024-10-17 17:10:46,800 [bic.py] => training => Task 1, Epoch 15/150 => Loss 0.661, Train_accy 100.000, Test_accy 61.600
2024-10-17 17:10:47,860 [bic.py] => training => Task 1, Epoch 16/150 => Loss 0.661, Train_accy 100.000, Test_accy 68.100
2024-10-17 17:10:48,886 [bic.py] => training => Task 1, Epoch 17/150 => Loss 0.660, Train_accy 100.000, Test_accy 65.670
2024-10-17 17:10:49,961 [bic.py] => training => Task 1, Epoch 18/150 => Loss 0.659, Train_accy 100.000, Test_accy 61.290
2024-10-17 17:10:50,967 [bic.py] => training => Task 1, Epoch 19/150 => Loss 0.659, Train_accy 100.000, Test_accy 64.930
2024-10-17 17:10:52,068 [bic.py] => training => Task 1, Epoch 20/150 => Loss 0.661, Train_accy 99.980, Test_accy 63.430
2024-10-17 17:10:53,109 [bic.py] => training => Task 1, Epoch 21/150 => Loss 0.658, Train_accy 100.000, Test_accy 66.260
2024-10-17 17:10:54,125 [bic.py] => training => Task 1, Epoch 22/150 => Loss 0.658, Train_accy 100.000, Test_accy 67.380
2024-10-17 17:10:55,066 [bic.py] => training => Task 1, Epoch 23/150 => Loss 0.659, Train_accy 100.000, Test_accy 66.120
2024-10-17 17:10:56,059 [bic.py] => training => Task 1, Epoch 24/150 => Loss 0.659, Train_accy 100.000, Test_accy 66.400
2024-10-17 17:10:56,988 [bic.py] => training => Task 1, Epoch 25/150 => Loss 0.659, Train_accy 100.000, Test_accy 63.950
2024-10-17 17:10:57,904 [bic.py] => training => Task 1, Epoch 26/150 => Loss 0.658, Train_accy 100.000, Test_accy 65.900
2024-10-17 17:10:58,822 [bic.py] => training => Task 1, Epoch 27/150 => Loss 0.658, Train_accy 100.000, Test_accy 68.050
2024-10-17 17:10:59,795 [bic.py] => training => Task 1, Epoch 28/150 => Loss 0.659, Train_accy 100.000, Test_accy 63.100
2024-10-17 17:11:00,812 [bic.py] => training => Task 1, Epoch 29/150 => Loss 0.658, Train_accy 100.000, Test_accy 67.100
2024-10-17 17:11:01,811 [bic.py] => training => Task 1, Epoch 30/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:11:02,795 [bic.py] => training => Task 1, Epoch 31/150 => Loss 0.657, Train_accy 100.000, Test_accy 64.810
2024-10-17 17:11:03,846 [bic.py] => training => Task 1, Epoch 32/150 => Loss 0.658, Train_accy 100.000, Test_accy 67.500
2024-10-17 17:11:04,889 [bic.py] => training => Task 1, Epoch 33/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.210
2024-10-17 17:11:05,964 [bic.py] => training => Task 1, Epoch 34/150 => Loss 0.656, Train_accy 100.000, Test_accy 69.450
2024-10-17 17:11:06,965 [bic.py] => training => Task 1, Epoch 35/150 => Loss 0.656, Train_accy 100.000, Test_accy 68.240
2024-10-17 17:11:07,915 [bic.py] => training => Task 1, Epoch 36/150 => Loss 0.657, Train_accy 100.000, Test_accy 68.500
2024-10-17 17:11:09,048 [bic.py] => training => Task 1, Epoch 37/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.690
2024-10-17 17:11:10,064 [bic.py] => training => Task 1, Epoch 38/150 => Loss 0.658, Train_accy 100.000, Test_accy 65.760
2024-10-17 17:11:11,100 [bic.py] => training => Task 1, Epoch 39/150 => Loss 0.658, Train_accy 100.000, Test_accy 69.600
2024-10-17 17:11:12,100 [bic.py] => training => Task 1, Epoch 40/150 => Loss 0.657, Train_accy 100.000, Test_accy 65.450
2024-10-17 17:11:13,157 [bic.py] => training => Task 1, Epoch 41/150 => Loss 0.658, Train_accy 100.000, Test_accy 67.740
2024-10-17 17:11:14,176 [bic.py] => training => Task 1, Epoch 42/150 => Loss 0.657, Train_accy 100.000, Test_accy 69.240
2024-10-17 17:11:15,191 [bic.py] => training => Task 1, Epoch 43/150 => Loss 0.658, Train_accy 100.000, Test_accy 66.310
2024-10-17 17:11:16,174 [bic.py] => training => Task 1, Epoch 44/150 => Loss 0.658, Train_accy 100.000, Test_accy 65.570
2024-10-17 17:11:17,166 [bic.py] => training => Task 1, Epoch 45/150 => Loss 0.657, Train_accy 100.000, Test_accy 62.570
2024-10-17 17:11:18,181 [bic.py] => training => Task 1, Epoch 46/150 => Loss 0.657, Train_accy 100.000, Test_accy 68.170
2024-10-17 17:11:19,203 [bic.py] => training => Task 1, Epoch 47/150 => Loss 0.658, Train_accy 100.000, Test_accy 64.810
2024-10-17 17:11:20,159 [bic.py] => training => Task 1, Epoch 48/150 => Loss 0.656, Train_accy 100.000, Test_accy 68.430
2024-10-17 17:11:21,140 [bic.py] => training => Task 1, Epoch 49/150 => Loss 0.656, Train_accy 100.000, Test_accy 66.000
2024-10-17 17:11:22,072 [bic.py] => training => Task 1, Epoch 50/150 => Loss 0.656, Train_accy 100.000, Test_accy 67.790
2024-10-17 17:11:22,996 [bic.py] => training => Task 1, Epoch 51/150 => Loss 0.655, Train_accy 100.000, Test_accy 67.740
2024-10-17 17:11:23,918 [bic.py] => training => Task 1, Epoch 52/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:11:24,892 [bic.py] => training => Task 1, Epoch 53/150 => Loss 0.656, Train_accy 100.000, Test_accy 66.520
2024-10-17 17:11:25,913 [bic.py] => training => Task 1, Epoch 54/150 => Loss 0.657, Train_accy 100.000, Test_accy 69.930
2024-10-17 17:11:26,955 [bic.py] => training => Task 1, Epoch 55/150 => Loss 0.655, Train_accy 100.000, Test_accy 66.690
2024-10-17 17:11:28,101 [bic.py] => training => Task 1, Epoch 56/150 => Loss 0.657, Train_accy 100.000, Test_accy 68.690
2024-10-17 17:11:29,178 [bic.py] => training => Task 1, Epoch 57/150 => Loss 0.656, Train_accy 100.000, Test_accy 66.600
2024-10-17 17:11:30,172 [bic.py] => training => Task 1, Epoch 58/150 => Loss 0.657, Train_accy 100.000, Test_accy 64.880
2024-10-17 17:11:31,176 [bic.py] => training => Task 1, Epoch 59/150 => Loss 0.658, Train_accy 100.000, Test_accy 61.360
2024-10-17 17:11:32,182 [bic.py] => training => Task 1, Epoch 60/150 => Loss 0.657, Train_accy 100.000, Test_accy 68.950
2024-10-17 17:11:33,129 [bic.py] => training => Task 1, Epoch 61/150 => Loss 0.657, Train_accy 100.000, Test_accy 62.260
2024-10-17 17:11:34,120 [bic.py] => training => Task 1, Epoch 62/150 => Loss 0.657, Train_accy 100.000, Test_accy 70.210
2024-10-17 17:11:35,122 [bic.py] => training => Task 1, Epoch 63/150 => Loss 0.657, Train_accy 100.000, Test_accy 65.210
2024-10-17 17:11:36,108 [bic.py] => training => Task 1, Epoch 64/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.810
2024-10-17 17:11:37,082 [bic.py] => training => Task 1, Epoch 65/150 => Loss 0.657, Train_accy 100.000, Test_accy 67.290
2024-10-17 17:11:38,092 [bic.py] => training => Task 1, Epoch 66/150 => Loss 0.656, Train_accy 100.000, Test_accy 66.520
2024-10-17 17:11:39,114 [bic.py] => training => Task 1, Epoch 67/150 => Loss 0.657, Train_accy 100.000, Test_accy 64.500
2024-10-17 17:11:40,123 [bic.py] => training => Task 1, Epoch 68/150 => Loss 0.656, Train_accy 100.000, Test_accy 65.430
2024-10-17 17:11:41,107 [bic.py] => training => Task 1, Epoch 69/150 => Loss 0.657, Train_accy 100.000, Test_accy 65.120
2024-10-17 17:11:42,123 [bic.py] => training => Task 1, Epoch 70/150 => Loss 0.658, Train_accy 100.000, Test_accy 68.760
2024-10-17 17:11:43,156 [bic.py] => training => Task 1, Epoch 71/150 => Loss 0.656, Train_accy 100.000, Test_accy 67.120
2024-10-17 17:11:44,195 [bic.py] => training => Task 1, Epoch 72/150 => Loss 0.655, Train_accy 100.000, Test_accy 64.520
2024-10-17 17:11:45,154 [bic.py] => training => Task 1, Epoch 73/150 => Loss 0.658, Train_accy 100.000, Test_accy 68.950
2024-10-17 17:11:46,206 [bic.py] => training => Task 1, Epoch 74/150 => Loss 0.657, Train_accy 100.000, Test_accy 62.380
2024-10-17 17:11:47,118 [bic.py] => training => Task 1, Epoch 75/150 => Loss 0.656, Train_accy 100.000, Test_accy 67.830
2024-10-17 17:11:48,069 [bic.py] => training => Task 1, Epoch 76/150 => Loss 0.656, Train_accy 100.000, Test_accy 65.550
2024-10-17 17:11:48,988 [bic.py] => training => Task 1, Epoch 77/150 => Loss 0.655, Train_accy 100.000, Test_accy 66.570
2024-10-17 17:11:49,908 [bic.py] => training => Task 1, Epoch 78/150 => Loss 0.655, Train_accy 100.000, Test_accy 63.600
2024-10-17 17:11:50,856 [bic.py] => training => Task 1, Epoch 79/150 => Loss 0.656, Train_accy 100.000, Test_accy 67.170
2024-10-17 17:11:51,779 [bic.py] => training => Task 1, Epoch 80/150 => Loss 0.655, Train_accy 100.000, Test_accy 67.500
2024-10-17 17:11:52,689 [bic.py] => training => Task 1, Epoch 81/150 => Loss 0.655, Train_accy 100.000, Test_accy 66.830
2024-10-17 17:11:53,633 [bic.py] => training => Task 1, Epoch 82/150 => Loss 0.654, Train_accy 100.000, Test_accy 66.570
2024-10-17 17:11:54,568 [bic.py] => training => Task 1, Epoch 83/150 => Loss 0.653, Train_accy 100.000, Test_accy 67.570
2024-10-17 17:11:55,495 [bic.py] => training => Task 1, Epoch 84/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.430
2024-10-17 17:11:56,401 [bic.py] => training => Task 1, Epoch 85/150 => Loss 0.653, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:11:57,330 [bic.py] => training => Task 1, Epoch 86/150 => Loss 0.653, Train_accy 100.000, Test_accy 66.500
2024-10-17 17:11:58,260 [bic.py] => training => Task 1, Epoch 87/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.860
2024-10-17 17:11:59,166 [bic.py] => training => Task 1, Epoch 88/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.740
2024-10-17 17:12:00,182 [bic.py] => training => Task 1, Epoch 89/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.380
2024-10-17 17:12:01,224 [bic.py] => training => Task 1, Epoch 90/150 => Loss 0.653, Train_accy 100.000, Test_accy 66.880
2024-10-17 17:12:02,245 [bic.py] => training => Task 1, Epoch 91/150 => Loss 0.652, Train_accy 100.000, Test_accy 68.310
2024-10-17 17:12:03,264 [bic.py] => training => Task 1, Epoch 92/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.830
2024-10-17 17:12:04,209 [bic.py] => training => Task 1, Epoch 93/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.020
2024-10-17 17:12:05,141 [bic.py] => training => Task 1, Epoch 94/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.260
2024-10-17 17:12:06,106 [bic.py] => training => Task 1, Epoch 95/150 => Loss 0.653, Train_accy 100.000, Test_accy 66.930
2024-10-17 17:12:07,128 [bic.py] => training => Task 1, Epoch 96/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.570
2024-10-17 17:12:08,072 [bic.py] => training => Task 1, Epoch 97/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.710
2024-10-17 17:12:09,006 [bic.py] => training => Task 1, Epoch 98/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.950
2024-10-17 17:12:09,938 [bic.py] => training => Task 1, Epoch 99/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.290
2024-10-17 17:12:10,865 [bic.py] => training => Task 1, Epoch 100/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.120
2024-10-17 17:12:11,868 [bic.py] => training => Task 1, Epoch 101/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.210
2024-10-17 17:12:12,848 [bic.py] => training => Task 1, Epoch 102/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.120
2024-10-17 17:12:13,863 [bic.py] => training => Task 1, Epoch 103/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.050
2024-10-17 17:12:14,867 [bic.py] => training => Task 1, Epoch 104/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.310
2024-10-17 17:12:15,977 [bic.py] => training => Task 1, Epoch 105/150 => Loss 0.653, Train_accy 100.000, Test_accy 66.380
2024-10-17 17:12:16,992 [bic.py] => training => Task 1, Epoch 106/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.550
2024-10-17 17:12:18,139 [bic.py] => training => Task 1, Epoch 107/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.900
2024-10-17 17:12:19,171 [bic.py] => training => Task 1, Epoch 108/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.380
2024-10-17 17:12:20,213 [bic.py] => training => Task 1, Epoch 109/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.600
2024-10-17 17:12:21,248 [bic.py] => training => Task 1, Epoch 110/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.380
2024-10-17 17:12:22,263 [bic.py] => training => Task 1, Epoch 111/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.860
2024-10-17 17:12:23,195 [bic.py] => training => Task 1, Epoch 112/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.210
2024-10-17 17:12:24,119 [bic.py] => training => Task 1, Epoch 113/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.380
2024-10-17 17:12:25,110 [bic.py] => training => Task 1, Epoch 114/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.500
2024-10-17 17:12:26,063 [bic.py] => training => Task 1, Epoch 115/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.240
2024-10-17 17:12:27,116 [bic.py] => training => Task 1, Epoch 116/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.170
2024-10-17 17:12:28,158 [bic.py] => training => Task 1, Epoch 117/150 => Loss 0.652, Train_accy 100.000, Test_accy 65.670
2024-10-17 17:12:29,189 [bic.py] => training => Task 1, Epoch 118/150 => Loss 0.651, Train_accy 100.000, Test_accy 65.690
2024-10-17 17:12:30,251 [bic.py] => training => Task 1, Epoch 119/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.950
2024-10-17 17:12:31,264 [bic.py] => training => Task 1, Epoch 120/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.310
2024-10-17 17:12:32,234 [bic.py] => training => Task 1, Epoch 121/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.310
2024-10-17 17:12:33,281 [bic.py] => training => Task 1, Epoch 122/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.710
2024-10-17 17:12:34,264 [bic.py] => training => Task 1, Epoch 123/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:12:35,167 [bic.py] => training => Task 1, Epoch 124/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.930
2024-10-17 17:12:36,086 [bic.py] => training => Task 1, Epoch 125/150 => Loss 0.652, Train_accy 100.000, Test_accy 68.120
2024-10-17 17:12:37,066 [bic.py] => training => Task 1, Epoch 126/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:12:38,125 [bic.py] => training => Task 1, Epoch 127/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.240
2024-10-17 17:12:39,155 [bic.py] => training => Task 1, Epoch 128/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.210
2024-10-17 17:12:40,095 [bic.py] => training => Task 1, Epoch 129/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.480
2024-10-17 17:12:41,144 [bic.py] => training => Task 1, Epoch 130/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.640
2024-10-17 17:12:42,232 [bic.py] => training => Task 1, Epoch 131/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.810
2024-10-17 17:12:43,217 [bic.py] => training => Task 1, Epoch 132/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.190
2024-10-17 17:12:44,224 [bic.py] => training => Task 1, Epoch 133/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.670
2024-10-17 17:12:45,319 [bic.py] => training => Task 1, Epoch 134/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.120
2024-10-17 17:12:46,338 [bic.py] => training => Task 1, Epoch 135/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.670
2024-10-17 17:12:47,389 [bic.py] => training => Task 1, Epoch 136/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.100
2024-10-17 17:12:48,412 [bic.py] => training => Task 1, Epoch 137/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.710
2024-10-17 17:12:49,436 [bic.py] => training => Task 1, Epoch 138/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.050
2024-10-17 17:12:50,422 [bic.py] => training => Task 1, Epoch 139/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.670
2024-10-17 17:12:51,432 [bic.py] => training => Task 1, Epoch 140/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.380
2024-10-17 17:12:52,438 [bic.py] => training => Task 1, Epoch 141/150 => Loss 0.650, Train_accy 100.000, Test_accy 67.550
2024-10-17 17:12:53,437 [bic.py] => training => Task 1, Epoch 142/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.550
2024-10-17 17:12:54,497 [bic.py] => training => Task 1, Epoch 143/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.790
2024-10-17 17:12:55,509 [bic.py] => training => Task 1, Epoch 144/150 => Loss 0.651, Train_accy 100.000, Test_accy 66.670
2024-10-17 17:12:56,563 [bic.py] => training => Task 1, Epoch 145/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.140
2024-10-17 17:12:57,607 [bic.py] => training => Task 1, Epoch 146/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.570
2024-10-17 17:12:58,605 [bic.py] => training => Task 1, Epoch 147/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.570
2024-10-17 17:12:59,664 [bic.py] => training => Task 1, Epoch 148/150 => Loss 0.651, Train_accy 100.000, Test_accy 67.380
2024-10-17 17:13:00,718 [bic.py] => training => Task 1, Epoch 149/150 => Loss 0.652, Train_accy 100.000, Test_accy 67.360
2024-10-17 17:13:01,745 [bic.py] => training => Task 1, Epoch 150/150 => Loss 0.652, Train_accy 100.000, Test_accy 66.480
