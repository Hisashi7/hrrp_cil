2024-10-23 20:26:08,240 [trainer.py] => config: ./exps/bic.json
2024-10-23 20:26:08,241 [trainer.py] => prefix: cil
2024-10-23 20:26:08,241 [trainer.py] => dataset: hrrp9
2024-10-23 20:26:08,241 [trainer.py] => memory_size: 400
2024-10-23 20:26:08,241 [trainer.py] => memory_per_class: 20
2024-10-23 20:26:08,241 [trainer.py] => fixed_memory: False
2024-10-23 20:26:08,241 [trainer.py] => shuffle: True
2024-10-23 20:26:08,241 [trainer.py] => init_cls: 5
2024-10-23 20:26:08,241 [trainer.py] => increment: 2
2024-10-23 20:26:08,241 [trainer.py] => model_name: bic
2024-10-23 20:26:08,241 [trainer.py] => convnet_type: resnet18
2024-10-23 20:26:08,241 [trainer.py] => device: [device(type='cuda', index=3)]
2024-10-23 20:26:08,241 [trainer.py] => init_train: False
2024-10-23 20:26:08,241 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-10-23 20:26:08,241 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-10-23 20:26:08,241 [trainer.py] => convnet_path1: checkpoints/init_train/resnet18_35172.pth
2024-10-23 20:26:08,241 [trainer.py] => fc_path1: checkpoints/init_train/fc_35172.pth
2024-10-23 20:26:08,241 [trainer.py] => seed: 1993
2024-10-23 20:26:08,241 [trainer.py] => init_epochs: 0
2024-10-23 20:26:08,241 [trainer.py] => epochs: 150
2024-10-23 20:26:08,241 [trainer.py] => lrate: 0.1
2024-10-23 20:26:08,242 [trainer.py] => milestones: [50, 80, 120]
2024-10-23 20:26:08,242 [trainer.py] => lrate_decay: 0.1
2024-10-23 20:26:08,242 [trainer.py] => momentum: 0.9
2024-10-23 20:26:08,242 [trainer.py] => batch_size: 128
2024-10-23 20:26:08,242 [trainer.py] => split_ratio: 0.1
2024-10-23 20:26:08,242 [trainer.py] => weight_decay: 0.0002
2024-10-23 20:26:08,242 [trainer.py] => num_workers: 0
2024-10-23 20:26:08,242 [trainer.py] => T: 2
2024-10-23 20:26:08,242 [trainer.py] => bc_lrate: 0.001
2024-10-23 20:26:08,242 [trainer.py] => bc_epochs: [100, 100, 7]
2024-10-23 20:26:08,888 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-10-23 20:26:09,340 [trainer.py] => All params: 3843904
2024-10-23 20:26:09,340 [trainer.py] => Trainable params: 3843904
2024-10-23 20:26:09,363 [bic.py] => Learning on 0-5
2024-10-23 20:26:09,426 [bic.py] => Parameters of bias layer:
2024-10-23 20:26:09,427 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:26:09,619 [base.py] => Reducing exemplars...(80 per classes)
2024-10-23 20:26:09,620 [base.py] => Constructing exemplars...(80 per classes)
2024-10-23 20:26:14,780 [bic.py] => Parameters of bias layer:
2024-10-23 20:26:14,781 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:26:14,782 [trainer.py] => All params: 3846471
2024-10-23 20:26:15,254 [bic.py] => Exemplar size: 400
2024-10-23 20:26:15,254 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-10-23 20:26:15,254 [trainer.py] => NME: {'total': 90.0, '00-04': 90.0, 'old': 0, 'new': 90.0}
2024-10-23 20:26:15,254 [trainer.py] => CNN top1 curve: [89.93]
2024-10-23 20:26:15,254 [trainer.py] => CNN top5 curve: [100.0]
2024-10-23 20:26:15,254 [trainer.py] => NME top1 curve: [90.0]
2024-10-23 20:26:15,254 [trainer.py] => NME top5 curve: [100.0]

2024-10-23 20:26:15,254 [trainer.py] => Average Accuracy (CNN): 89.93
2024-10-23 20:26:15,254 [trainer.py] => Average Accuracy (NME): 90.0
2024-10-23 20:26:15,255 [trainer.py] => All params: 3846471
2024-10-23 20:26:15,255 [trainer.py] => Trainable params: 3846471
2024-10-23 20:26:15,256 [bic.py] => Learning on 5-7
2024-10-23 20:26:15,266 [bic.py] => Stage1 dset: 4344, Stage2 dset: 56
2024-10-23 20:26:15,266 [bic.py] => Lambda: 0.714
2024-10-23 20:26:15,273 [bic.py] => Parameters of bias layer:
2024-10-23 20:26:15,273 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:26:15,273 [bic.py] => 1 => 1.000, 0.000
2024-10-23 20:26:16,499 [bic.py] => training => Task 1, Epoch 1/150 => Loss 1.031, Train_accy 87.450, Test_accy 34.260
2024-10-23 20:26:17,441 [bic.py] => training => Task 1, Epoch 2/150 => Loss 0.762, Train_accy 97.030, Test_accy 55.980
2024-10-23 20:26:18,449 [bic.py] => training => Task 1, Epoch 3/150 => Loss 0.716, Train_accy 98.830, Test_accy 55.260
2024-10-23 20:26:19,403 [bic.py] => training => Task 1, Epoch 4/150 => Loss 0.698, Train_accy 99.330, Test_accy 58.070
2024-10-23 20:26:20,343 [bic.py] => training => Task 1, Epoch 5/150 => Loss 0.689, Train_accy 99.860, Test_accy 58.210
2024-10-23 20:26:21,262 [bic.py] => training => Task 1, Epoch 6/150 => Loss 0.684, Train_accy 99.980, Test_accy 59.640
2024-10-23 20:26:22,286 [bic.py] => training => Task 1, Epoch 7/150 => Loss 0.677, Train_accy 100.000, Test_accy 58.670
2024-10-23 20:26:23,302 [bic.py] => training => Task 1, Epoch 8/150 => Loss 0.674, Train_accy 100.000, Test_accy 58.810
2024-10-23 20:26:24,299 [bic.py] => training => Task 1, Epoch 9/150 => Loss 0.674, Train_accy 100.000, Test_accy 60.330
2024-10-23 20:26:25,348 [bic.py] => training => Task 1, Epoch 10/150 => Loss 0.675, Train_accy 100.000, Test_accy 60.670
2024-10-23 20:26:26,340 [bic.py] => training => Task 1, Epoch 11/150 => Loss 0.674, Train_accy 100.000, Test_accy 60.070
2024-10-23 20:26:27,347 [bic.py] => training => Task 1, Epoch 12/150 => Loss 0.672, Train_accy 100.000, Test_accy 60.290
2024-10-23 20:26:28,358 [bic.py] => training => Task 1, Epoch 13/150 => Loss 0.671, Train_accy 100.000, Test_accy 59.670
2024-10-23 20:26:29,354 [bic.py] => training => Task 1, Epoch 14/150 => Loss 0.670, Train_accy 100.000, Test_accy 57.670
2024-10-23 20:26:30,320 [bic.py] => training => Task 1, Epoch 15/150 => Loss 0.670, Train_accy 100.000, Test_accy 60.000
2024-10-23 20:26:31,331 [bic.py] => training => Task 1, Epoch 16/150 => Loss 0.669, Train_accy 100.000, Test_accy 62.330
2024-10-23 20:26:32,346 [bic.py] => training => Task 1, Epoch 17/150 => Loss 0.670, Train_accy 100.000, Test_accy 60.210
2024-10-23 20:26:33,336 [bic.py] => training => Task 1, Epoch 18/150 => Loss 0.669, Train_accy 100.000, Test_accy 62.000
2024-10-23 20:26:34,368 [bic.py] => training => Task 1, Epoch 19/150 => Loss 0.667, Train_accy 100.000, Test_accy 60.830
2024-10-23 20:26:35,385 [bic.py] => training => Task 1, Epoch 20/150 => Loss 0.667, Train_accy 100.000, Test_accy 61.900
2024-10-23 20:26:36,400 [bic.py] => training => Task 1, Epoch 21/150 => Loss 0.667, Train_accy 100.000, Test_accy 62.210
2024-10-23 20:26:37,411 [bic.py] => training => Task 1, Epoch 22/150 => Loss 0.667, Train_accy 100.000, Test_accy 63.190
2024-10-23 20:26:38,445 [bic.py] => training => Task 1, Epoch 23/150 => Loss 0.667, Train_accy 100.000, Test_accy 62.050
2024-10-23 20:26:39,435 [bic.py] => training => Task 1, Epoch 24/150 => Loss 0.670, Train_accy 100.000, Test_accy 62.430
2024-10-23 20:26:40,455 [bic.py] => training => Task 1, Epoch 25/150 => Loss 0.669, Train_accy 100.000, Test_accy 58.620
2024-10-23 20:26:41,441 [bic.py] => training => Task 1, Epoch 26/150 => Loss 0.668, Train_accy 100.000, Test_accy 63.170
2024-10-23 20:26:42,433 [bic.py] => training => Task 1, Epoch 27/150 => Loss 0.669, Train_accy 100.000, Test_accy 62.070
2024-10-23 20:26:43,500 [bic.py] => training => Task 1, Epoch 28/150 => Loss 0.667, Train_accy 100.000, Test_accy 63.500
2024-10-23 20:26:44,493 [bic.py] => training => Task 1, Epoch 29/150 => Loss 0.666, Train_accy 100.000, Test_accy 64.210
2024-10-23 20:26:45,521 [bic.py] => training => Task 1, Epoch 30/150 => Loss 0.667, Train_accy 100.000, Test_accy 61.690
2024-10-23 20:26:46,519 [bic.py] => training => Task 1, Epoch 31/150 => Loss 0.667, Train_accy 100.000, Test_accy 61.100
2024-10-23 20:26:47,552 [bic.py] => training => Task 1, Epoch 32/150 => Loss 0.666, Train_accy 100.000, Test_accy 61.450
2024-10-23 20:26:48,621 [bic.py] => training => Task 1, Epoch 33/150 => Loss 0.667, Train_accy 100.000, Test_accy 62.360
2024-10-23 20:26:49,616 [bic.py] => training => Task 1, Epoch 34/150 => Loss 0.667, Train_accy 100.000, Test_accy 63.140
2024-10-23 20:26:50,673 [bic.py] => training => Task 1, Epoch 35/150 => Loss 0.665, Train_accy 100.000, Test_accy 63.600
2024-10-23 20:26:51,691 [bic.py] => training => Task 1, Epoch 36/150 => Loss 0.666, Train_accy 100.000, Test_accy 66.170
2024-10-23 20:26:52,682 [bic.py] => training => Task 1, Epoch 37/150 => Loss 0.666, Train_accy 100.000, Test_accy 62.260
2024-10-23 20:26:53,712 [bic.py] => training => Task 1, Epoch 38/150 => Loss 0.667, Train_accy 100.000, Test_accy 61.000
2024-10-23 20:26:54,663 [bic.py] => training => Task 1, Epoch 39/150 => Loss 0.667, Train_accy 100.000, Test_accy 65.980
2024-10-23 20:26:55,611 [bic.py] => training => Task 1, Epoch 40/150 => Loss 0.667, Train_accy 100.000, Test_accy 63.050
2024-10-23 20:26:56,621 [bic.py] => training => Task 1, Epoch 41/150 => Loss 0.667, Train_accy 100.000, Test_accy 61.190
2024-10-23 20:26:57,535 [bic.py] => training => Task 1, Epoch 42/150 => Loss 0.666, Train_accy 100.000, Test_accy 62.760
2024-10-23 20:26:58,459 [bic.py] => training => Task 1, Epoch 43/150 => Loss 0.666, Train_accy 100.000, Test_accy 59.430
2024-10-23 20:26:59,376 [bic.py] => training => Task 1, Epoch 44/150 => Loss 0.667, Train_accy 100.000, Test_accy 65.400
2024-10-23 20:27:00,414 [bic.py] => training => Task 1, Epoch 45/150 => Loss 0.666, Train_accy 100.000, Test_accy 64.070
2024-10-23 20:27:01,383 [bic.py] => training => Task 1, Epoch 46/150 => Loss 0.666, Train_accy 100.000, Test_accy 60.550
2024-10-23 20:27:02,401 [bic.py] => training => Task 1, Epoch 47/150 => Loss 0.665, Train_accy 100.000, Test_accy 64.170
2024-10-23 20:27:03,396 [bic.py] => training => Task 1, Epoch 48/150 => Loss 0.666, Train_accy 100.000, Test_accy 65.550
2024-10-23 20:27:04,387 [bic.py] => training => Task 1, Epoch 49/150 => Loss 0.667, Train_accy 100.000, Test_accy 62.830
2024-10-23 20:27:05,314 [bic.py] => training => Task 1, Epoch 50/150 => Loss 0.667, Train_accy 100.000, Test_accy 63.140
2024-10-23 20:27:06,263 [bic.py] => training => Task 1, Epoch 51/150 => Loss 0.664, Train_accy 100.000, Test_accy 64.210
2024-10-23 20:27:07,162 [bic.py] => training => Task 1, Epoch 52/150 => Loss 0.663, Train_accy 100.000, Test_accy 64.500
2024-10-23 20:27:08,209 [bic.py] => training => Task 1, Epoch 53/150 => Loss 0.663, Train_accy 100.000, Test_accy 64.290
2024-10-23 20:27:09,137 [bic.py] => training => Task 1, Epoch 54/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.100
2024-10-23 20:27:10,066 [bic.py] => training => Task 1, Epoch 55/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.120
2024-10-23 20:27:11,072 [bic.py] => training => Task 1, Epoch 56/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.020
2024-10-23 20:27:12,079 [bic.py] => training => Task 1, Epoch 57/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.140
2024-10-23 20:27:13,088 [bic.py] => training => Task 1, Epoch 58/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.550
2024-10-23 20:27:14,077 [bic.py] => training => Task 1, Epoch 59/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.120
2024-10-23 20:27:15,012 [bic.py] => training => Task 1, Epoch 60/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.020
2024-10-23 20:27:16,088 [bic.py] => training => Task 1, Epoch 61/150 => Loss 0.663, Train_accy 100.000, Test_accy 64.120
2024-10-23 20:27:17,151 [bic.py] => training => Task 1, Epoch 62/150 => Loss 0.662, Train_accy 100.000, Test_accy 65.120
2024-10-23 20:27:18,210 [bic.py] => training => Task 1, Epoch 63/150 => Loss 0.662, Train_accy 100.000, Test_accy 63.740
2024-10-23 20:27:19,205 [bic.py] => training => Task 1, Epoch 64/150 => Loss 0.662, Train_accy 100.000, Test_accy 63.860
2024-10-23 20:27:20,204 [bic.py] => training => Task 1, Epoch 65/150 => Loss 0.662, Train_accy 100.000, Test_accy 63.950
2024-10-23 20:27:21,262 [bic.py] => training => Task 1, Epoch 66/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.000
2024-10-23 20:27:22,285 [bic.py] => training => Task 1, Epoch 67/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.810
2024-10-23 20:27:23,266 [bic.py] => training => Task 1, Epoch 68/150 => Loss 0.662, Train_accy 100.000, Test_accy 63.860
2024-10-23 20:27:24,228 [bic.py] => training => Task 1, Epoch 69/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.830
2024-10-23 20:27:25,194 [bic.py] => training => Task 1, Epoch 70/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.120
2024-10-23 20:27:26,166 [bic.py] => training => Task 1, Epoch 71/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.930
2024-10-23 20:27:27,118 [bic.py] => training => Task 1, Epoch 72/150 => Loss 0.662, Train_accy 100.000, Test_accy 63.760
2024-10-23 20:27:28,065 [bic.py] => training => Task 1, Epoch 73/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.710
2024-10-23 20:27:29,042 [bic.py] => training => Task 1, Epoch 74/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.240
2024-10-23 20:27:30,023 [bic.py] => training => Task 1, Epoch 75/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.500
2024-10-23 20:27:31,054 [bic.py] => training => Task 1, Epoch 76/150 => Loss 0.662, Train_accy 100.000, Test_accy 65.170
2024-10-23 20:27:32,057 [bic.py] => training => Task 1, Epoch 77/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.670
2024-10-23 20:27:33,102 [bic.py] => training => Task 1, Epoch 78/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.170
2024-10-23 20:27:34,152 [bic.py] => training => Task 1, Epoch 79/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:27:35,141 [bic.py] => training => Task 1, Epoch 80/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.830
2024-10-23 20:27:36,171 [bic.py] => training => Task 1, Epoch 81/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:27:37,185 [bic.py] => training => Task 1, Epoch 82/150 => Loss 0.662, Train_accy 100.000, Test_accy 65.000
2024-10-23 20:27:38,276 [bic.py] => training => Task 1, Epoch 83/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:27:39,349 [bic.py] => training => Task 1, Epoch 84/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.790
2024-10-23 20:27:40,292 [bic.py] => training => Task 1, Epoch 85/150 => Loss 0.663, Train_accy 100.000, Test_accy 64.790
2024-10-23 20:27:41,276 [bic.py] => training => Task 1, Epoch 86/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.050
2024-10-23 20:27:42,258 [bic.py] => training => Task 1, Epoch 87/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.140
2024-10-23 20:27:43,295 [bic.py] => training => Task 1, Epoch 88/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:27:44,347 [bic.py] => training => Task 1, Epoch 89/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.380
2024-10-23 20:27:45,392 [bic.py] => training => Task 1, Epoch 90/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.520
2024-10-23 20:27:46,451 [bic.py] => training => Task 1, Epoch 91/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.360
2024-10-23 20:27:47,470 [bic.py] => training => Task 1, Epoch 92/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.740
2024-10-23 20:27:48,517 [bic.py] => training => Task 1, Epoch 93/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.620
2024-10-23 20:27:49,562 [bic.py] => training => Task 1, Epoch 94/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.020
2024-10-23 20:27:50,601 [bic.py] => training => Task 1, Epoch 95/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.620
2024-10-23 20:27:51,628 [bic.py] => training => Task 1, Epoch 96/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.740
2024-10-23 20:27:52,625 [bic.py] => training => Task 1, Epoch 97/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.710
2024-10-23 20:27:53,572 [bic.py] => training => Task 1, Epoch 98/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.400
2024-10-23 20:27:54,578 [bic.py] => training => Task 1, Epoch 99/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.210
2024-10-23 20:27:55,623 [bic.py] => training => Task 1, Epoch 100/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:27:56,721 [bic.py] => training => Task 1, Epoch 101/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:27:57,759 [bic.py] => training => Task 1, Epoch 102/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.570
2024-10-23 20:27:58,789 [bic.py] => training => Task 1, Epoch 103/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.480
2024-10-23 20:27:59,800 [bic.py] => training => Task 1, Epoch 104/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:28:00,865 [bic.py] => training => Task 1, Epoch 105/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.190
2024-10-23 20:28:01,918 [bic.py] => training => Task 1, Epoch 106/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.260
2024-10-23 20:28:02,968 [bic.py] => training => Task 1, Epoch 107/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.550
2024-10-23 20:28:03,989 [bic.py] => training => Task 1, Epoch 108/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.760
2024-10-23 20:28:05,013 [bic.py] => training => Task 1, Epoch 109/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.520
2024-10-23 20:28:06,105 [bic.py] => training => Task 1, Epoch 110/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.330
2024-10-23 20:28:07,153 [bic.py] => training => Task 1, Epoch 111/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.190
2024-10-23 20:28:08,158 [bic.py] => training => Task 1, Epoch 112/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.620
2024-10-23 20:28:09,321 [bic.py] => training => Task 1, Epoch 113/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.640
2024-10-23 20:28:10,242 [bic.py] => training => Task 1, Epoch 114/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.670
2024-10-23 20:28:11,280 [bic.py] => training => Task 1, Epoch 115/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.670
2024-10-23 20:28:12,346 [bic.py] => training => Task 1, Epoch 116/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:28:13,399 [bic.py] => training => Task 1, Epoch 117/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.640
2024-10-23 20:28:14,546 [bic.py] => training => Task 1, Epoch 118/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.290
2024-10-23 20:28:15,618 [bic.py] => training => Task 1, Epoch 119/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.740
2024-10-23 20:28:16,680 [bic.py] => training => Task 1, Epoch 120/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.400
2024-10-23 20:28:17,728 [bic.py] => training => Task 1, Epoch 121/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.520
2024-10-23 20:28:18,849 [bic.py] => training => Task 1, Epoch 122/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.760
2024-10-23 20:28:20,071 [bic.py] => training => Task 1, Epoch 123/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.830
2024-10-23 20:28:21,270 [bic.py] => training => Task 1, Epoch 124/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:28:22,367 [bic.py] => training => Task 1, Epoch 125/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:28:23,390 [bic.py] => training => Task 1, Epoch 126/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.570
2024-10-23 20:28:24,536 [bic.py] => training => Task 1, Epoch 127/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.620
2024-10-23 20:28:25,697 [bic.py] => training => Task 1, Epoch 128/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:28:26,854 [bic.py] => training => Task 1, Epoch 129/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.360
2024-10-23 20:28:27,951 [bic.py] => training => Task 1, Epoch 130/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.810
2024-10-23 20:28:29,117 [bic.py] => training => Task 1, Epoch 131/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.520
2024-10-23 20:28:30,230 [bic.py] => training => Task 1, Epoch 132/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:28:31,452 [bic.py] => training => Task 1, Epoch 133/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:28:32,601 [bic.py] => training => Task 1, Epoch 134/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:28:33,673 [bic.py] => training => Task 1, Epoch 135/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:28:34,768 [bic.py] => training => Task 1, Epoch 136/150 => Loss 0.661, Train_accy 100.000, Test_accy 65.290
2024-10-23 20:28:35,838 [bic.py] => training => Task 1, Epoch 137/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.240
2024-10-23 20:28:37,016 [bic.py] => training => Task 1, Epoch 138/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.830
2024-10-23 20:28:38,201 [bic.py] => training => Task 1, Epoch 139/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:28:39,323 [bic.py] => training => Task 1, Epoch 140/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.980
2024-10-23 20:28:40,369 [bic.py] => training => Task 1, Epoch 141/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.690
2024-10-23 20:28:41,512 [bic.py] => training => Task 1, Epoch 142/150 => Loss 0.661, Train_accy 100.000, Test_accy 63.980
2024-10-23 20:28:42,740 [bic.py] => training => Task 1, Epoch 143/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.640
2024-10-23 20:28:43,819 [bic.py] => training => Task 1, Epoch 144/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.450
2024-10-23 20:28:44,845 [bic.py] => training => Task 1, Epoch 145/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.670
2024-10-23 20:28:45,878 [bic.py] => training => Task 1, Epoch 146/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.760
2024-10-23 20:28:46,954 [bic.py] => training => Task 1, Epoch 147/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.640
2024-10-23 20:28:48,088 [bic.py] => training => Task 1, Epoch 148/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.310
2024-10-23 20:28:49,211 [bic.py] => training => Task 1, Epoch 149/150 => Loss 0.661, Train_accy 100.000, Test_accy 64.360
2024-10-23 20:28:50,331 [bic.py] => training => Task 1, Epoch 150/150 => Loss 0.662, Train_accy 100.000, Test_accy 64.360
2024-10-23 20:28:50,557 [bic.py] => bias_correction => Task 1, Epoch 1/100 => Loss 1.516, Train_accy 80.360, Test_accy 65.170
2024-10-23 20:28:50,763 [bic.py] => bias_correction => Task 1, Epoch 2/100 => Loss 1.494, Train_accy 80.360, Test_accy 68.000
2024-10-23 20:28:50,979 [bic.py] => bias_correction => Task 1, Epoch 3/100 => Loss 1.454, Train_accy 83.930, Test_accy 72.020
2024-10-23 20:28:51,186 [bic.py] => bias_correction => Task 1, Epoch 4/100 => Loss 1.397, Train_accy 91.070, Test_accy 77.170
2024-10-23 20:28:51,393 [bic.py] => bias_correction => Task 1, Epoch 5/100 => Loss 1.331, Train_accy 96.430, Test_accy 78.430
2024-10-23 20:28:51,597 [bic.py] => bias_correction => Task 1, Epoch 6/100 => Loss 1.304, Train_accy 85.710, Test_accy 74.360
2024-10-23 20:28:51,824 [bic.py] => bias_correction => Task 1, Epoch 7/100 => Loss 1.341, Train_accy 80.360, Test_accy 69.830
2024-10-23 20:28:52,087 [bic.py] => bias_correction => Task 1, Epoch 8/100 => Loss 1.384, Train_accy 76.790, Test_accy 68.290
2024-10-23 20:28:52,279 [bic.py] => bias_correction => Task 1, Epoch 9/100 => Loss 1.401, Train_accy 78.570, Test_accy 68.570
2024-10-23 20:28:52,464 [bic.py] => bias_correction => Task 1, Epoch 10/100 => Loss 1.397, Train_accy 80.360, Test_accy 70.690
2024-10-23 20:28:52,657 [bic.py] => bias_correction => Task 1, Epoch 11/100 => Loss 1.374, Train_accy 91.070, Test_accy 74.790
2024-10-23 20:28:52,857 [bic.py] => bias_correction => Task 1, Epoch 12/100 => Loss 1.332, Train_accy 92.860, Test_accy 77.880
2024-10-23 20:28:53,052 [bic.py] => bias_correction => Task 1, Epoch 13/100 => Loss 1.301, Train_accy 92.860, Test_accy 77.860
2024-10-23 20:28:53,246 [bic.py] => bias_correction => Task 1, Epoch 14/100 => Loss 1.307, Train_accy 89.290, Test_accy 74.860
2024-10-23 20:28:53,445 [bic.py] => bias_correction => Task 1, Epoch 15/100 => Loss 1.332, Train_accy 83.930, Test_accy 73.550
2024-10-23 20:28:53,632 [bic.py] => bias_correction => Task 1, Epoch 16/100 => Loss 1.348, Train_accy 83.930, Test_accy 73.520
2024-10-23 20:28:53,822 [bic.py] => bias_correction => Task 1, Epoch 17/100 => Loss 1.346, Train_accy 89.290, Test_accy 74.740
2024-10-23 20:28:54,032 [bic.py] => bias_correction => Task 1, Epoch 18/100 => Loss 1.330, Train_accy 91.070, Test_accy 77.520
2024-10-23 20:28:54,213 [bic.py] => bias_correction => Task 1, Epoch 19/100 => Loss 1.308, Train_accy 94.640, Test_accy 78.330
2024-10-23 20:28:54,398 [bic.py] => bias_correction => Task 1, Epoch 20/100 => Loss 1.296, Train_accy 92.860, Test_accy 77.670
2024-10-23 20:28:54,674 [bic.py] => bias_correction => Task 1, Epoch 21/100 => Loss 1.303, Train_accy 92.860, Test_accy 76.100
2024-10-23 20:28:54,896 [bic.py] => bias_correction => Task 1, Epoch 22/100 => Loss 1.316, Train_accy 92.860, Test_accy 75.570
2024-10-23 20:28:55,093 [bic.py] => bias_correction => Task 1, Epoch 23/100 => Loss 1.321, Train_accy 92.860, Test_accy 76.240
2024-10-23 20:28:55,280 [bic.py] => bias_correction => Task 1, Epoch 24/100 => Loss 1.313, Train_accy 92.860, Test_accy 77.670
2024-10-23 20:28:55,469 [bic.py] => bias_correction => Task 1, Epoch 25/100 => Loss 1.300, Train_accy 94.640, Test_accy 78.550
2024-10-23 20:28:55,675 [bic.py] => bias_correction => Task 1, Epoch 26/100 => Loss 1.293, Train_accy 89.290, Test_accy 78.290
2024-10-23 20:28:55,868 [bic.py] => bias_correction => Task 1, Epoch 27/100 => Loss 1.295, Train_accy 91.070, Test_accy 77.640
2024-10-23 20:28:56,060 [bic.py] => bias_correction => Task 1, Epoch 28/100 => Loss 1.302, Train_accy 91.070, Test_accy 77.050
2024-10-23 20:28:56,254 [bic.py] => bias_correction => Task 1, Epoch 29/100 => Loss 1.305, Train_accy 91.070, Test_accy 77.640
2024-10-23 20:28:56,448 [bic.py] => bias_correction => Task 1, Epoch 30/100 => Loss 1.302, Train_accy 89.290, Test_accy 78.240
2024-10-23 20:28:56,641 [bic.py] => bias_correction => Task 1, Epoch 31/100 => Loss 1.295, Train_accy 94.640, Test_accy 78.620
2024-10-23 20:28:56,833 [bic.py] => bias_correction => Task 1, Epoch 32/100 => Loss 1.290, Train_accy 94.640, Test_accy 78.640
2024-10-23 20:28:57,036 [bic.py] => bias_correction => Task 1, Epoch 33/100 => Loss 1.290, Train_accy 92.860, Test_accy 77.950
2024-10-23 20:28:57,275 [bic.py] => bias_correction => Task 1, Epoch 34/100 => Loss 1.294, Train_accy 91.070, Test_accy 77.860
2024-10-23 20:28:57,482 [bic.py] => bias_correction => Task 1, Epoch 35/100 => Loss 1.296, Train_accy 92.860, Test_accy 78.070
2024-10-23 20:28:57,674 [bic.py] => bias_correction => Task 1, Epoch 36/100 => Loss 1.294, Train_accy 92.860, Test_accy 78.400
2024-10-23 20:28:57,864 [bic.py] => bias_correction => Task 1, Epoch 37/100 => Loss 1.290, Train_accy 94.640, Test_accy 78.900
2024-10-23 20:28:58,060 [bic.py] => bias_correction => Task 1, Epoch 38/100 => Loss 1.287, Train_accy 94.640, Test_accy 78.810
2024-10-23 20:28:58,261 [bic.py] => bias_correction => Task 1, Epoch 39/100 => Loss 1.287, Train_accy 92.860, Test_accy 78.830
2024-10-23 20:28:58,498 [bic.py] => bias_correction => Task 1, Epoch 40/100 => Loss 1.289, Train_accy 89.290, Test_accy 78.950
2024-10-23 20:28:58,722 [bic.py] => bias_correction => Task 1, Epoch 41/100 => Loss 1.290, Train_accy 91.070, Test_accy 78.980
2024-10-23 20:28:58,944 [bic.py] => bias_correction => Task 1, Epoch 42/100 => Loss 1.289, Train_accy 94.640, Test_accy 79.050
2024-10-23 20:28:59,156 [bic.py] => bias_correction => Task 1, Epoch 43/100 => Loss 1.287, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:28:59,382 [bic.py] => bias_correction => Task 1, Epoch 44/100 => Loss 1.285, Train_accy 94.640, Test_accy 79.020
2024-10-23 20:28:59,616 [bic.py] => bias_correction => Task 1, Epoch 45/100 => Loss 1.285, Train_accy 94.640, Test_accy 78.950
2024-10-23 20:28:59,843 [bic.py] => bias_correction => Task 1, Epoch 46/100 => Loss 1.285, Train_accy 94.640, Test_accy 78.810
2024-10-23 20:29:00,091 [bic.py] => bias_correction => Task 1, Epoch 47/100 => Loss 1.286, Train_accy 94.640, Test_accy 78.860
2024-10-23 20:29:00,283 [bic.py] => bias_correction => Task 1, Epoch 48/100 => Loss 1.285, Train_accy 94.640, Test_accy 79.190
2024-10-23 20:29:00,525 [bic.py] => bias_correction => Task 1, Epoch 49/100 => Loss 1.284, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:00,742 [bic.py] => bias_correction => Task 1, Epoch 50/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:00,968 [bic.py] => bias_correction => Task 1, Epoch 51/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:01,209 [bic.py] => bias_correction => Task 1, Epoch 52/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.290
2024-10-23 20:29:01,461 [bic.py] => bias_correction => Task 1, Epoch 53/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.290
2024-10-23 20:29:01,683 [bic.py] => bias_correction => Task 1, Epoch 54/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.290
2024-10-23 20:29:01,892 [bic.py] => bias_correction => Task 1, Epoch 55/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.290
2024-10-23 20:29:02,149 [bic.py] => bias_correction => Task 1, Epoch 56/100 => Loss 1.283, Train_accy 94.640, Test_accy 79.290
2024-10-23 20:29:02,342 [bic.py] => bias_correction => Task 1, Epoch 57/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.330
2024-10-23 20:29:02,534 [bic.py] => bias_correction => Task 1, Epoch 58/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:02,776 [bic.py] => bias_correction => Task 1, Epoch 59/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:02,996 [bic.py] => bias_correction => Task 1, Epoch 60/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.330
2024-10-23 20:29:03,221 [bic.py] => bias_correction => Task 1, Epoch 61/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:03,442 [bic.py] => bias_correction => Task 1, Epoch 62/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.310
2024-10-23 20:29:03,628 [bic.py] => bias_correction => Task 1, Epoch 63/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.260
2024-10-23 20:29:03,852 [bic.py] => bias_correction => Task 1, Epoch 64/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.190
2024-10-23 20:29:04,085 [bic.py] => bias_correction => Task 1, Epoch 65/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:04,327 [bic.py] => bias_correction => Task 1, Epoch 66/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:04,552 [bic.py] => bias_correction => Task 1, Epoch 67/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.260
2024-10-23 20:29:04,775 [bic.py] => bias_correction => Task 1, Epoch 68/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.190
2024-10-23 20:29:04,999 [bic.py] => bias_correction => Task 1, Epoch 69/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:05,241 [bic.py] => bias_correction => Task 1, Epoch 70/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.190
2024-10-23 20:29:05,480 [bic.py] => bias_correction => Task 1, Epoch 71/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.190
2024-10-23 20:29:05,717 [bic.py] => bias_correction => Task 1, Epoch 72/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:05,936 [bic.py] => bias_correction => Task 1, Epoch 73/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:06,149 [bic.py] => bias_correction => Task 1, Epoch 74/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:06,369 [bic.py] => bias_correction => Task 1, Epoch 75/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:06,610 [bic.py] => bias_correction => Task 1, Epoch 76/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:06,848 [bic.py] => bias_correction => Task 1, Epoch 77/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:07,067 [bic.py] => bias_correction => Task 1, Epoch 78/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:07,296 [bic.py] => bias_correction => Task 1, Epoch 79/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:07,528 [bic.py] => bias_correction => Task 1, Epoch 80/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:07,749 [bic.py] => bias_correction => Task 1, Epoch 81/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:07,966 [bic.py] => bias_correction => Task 1, Epoch 82/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:08,202 [bic.py] => bias_correction => Task 1, Epoch 83/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:08,515 [bic.py] => bias_correction => Task 1, Epoch 84/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:08,794 [bic.py] => bias_correction => Task 1, Epoch 85/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.100
2024-10-23 20:29:09,016 [bic.py] => bias_correction => Task 1, Epoch 86/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.120
2024-10-23 20:29:09,236 [bic.py] => bias_correction => Task 1, Epoch 87/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:09,471 [bic.py] => bias_correction => Task 1, Epoch 88/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.170
2024-10-23 20:29:09,682 [bic.py] => bias_correction => Task 1, Epoch 89/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:09,895 [bic.py] => bias_correction => Task 1, Epoch 90/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:10,107 [bic.py] => bias_correction => Task 1, Epoch 91/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:10,329 [bic.py] => bias_correction => Task 1, Epoch 92/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.210
2024-10-23 20:29:10,544 [bic.py] => bias_correction => Task 1, Epoch 93/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:10,785 [bic.py] => bias_correction => Task 1, Epoch 94/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:11,000 [bic.py] => bias_correction => Task 1, Epoch 95/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:11,226 [bic.py] => bias_correction => Task 1, Epoch 96/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:11,444 [bic.py] => bias_correction => Task 1, Epoch 97/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:11,645 [bic.py] => bias_correction => Task 1, Epoch 98/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:11,856 [bic.py] => bias_correction => Task 1, Epoch 99/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:12,060 [bic.py] => bias_correction => Task 1, Epoch 100/100 => Loss 1.282, Train_accy 94.640, Test_accy 79.240
2024-10-23 20:29:12,060 [base.py] => Reducing exemplars...(57 per classes)
2024-10-23 20:29:13,074 [base.py] => Constructing exemplars...(57 per classes)
2024-10-23 20:29:15,120 [bic.py] => Parameters of bias layer:
2024-10-23 20:29:15,120 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:29:15,121 [bic.py] => 1 => 0.545, -1.127
2024-10-23 20:29:15,122 [trainer.py] => All params: 3847499
2024-10-23 20:29:15,644 [bic.py] => Exemplar size: 399
2024-10-23 20:29:15,645 [trainer.py] => CNN: {'total': 79.24, '00-04': 79.8, '05-06': 77.83, 'old': 79.8, 'new': 77.83}
2024-10-23 20:29:15,645 [trainer.py] => NME: {'total': 77.21, '00-04': 70.73, '05-06': 93.42, 'old': 70.73, 'new': 93.42}
2024-10-23 20:29:15,645 [trainer.py] => CNN top1 curve: [89.93, 79.24]
2024-10-23 20:29:15,645 [trainer.py] => CNN top5 curve: [100.0, 98.83]
2024-10-23 20:29:15,645 [trainer.py] => NME top1 curve: [90.0, 77.21]
2024-10-23 20:29:15,645 [trainer.py] => NME top5 curve: [100.0, 98.98]

2024-10-23 20:29:15,645 [trainer.py] => Average Accuracy (CNN): 84.58500000000001
2024-10-23 20:29:15,645 [trainer.py] => Average Accuracy (NME): 83.60499999999999
2024-10-23 20:29:15,646 [trainer.py] => All params: 3847499
2024-10-23 20:29:15,646 [trainer.py] => Trainable params: 3847499
2024-10-23 20:29:15,648 [bic.py] => Learning on 7-9
2024-10-23 20:29:15,665 [bic.py] => Stage1 dset: 4354, Stage2 dset: 45
2024-10-23 20:29:15,665 [bic.py] => Lambda: 0.778
2024-10-23 20:29:15,680 [bic.py] => Parameters of bias layer:
2024-10-23 20:29:15,680 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:29:15,681 [bic.py] => 1 => 0.545, -1.127
2024-10-23 20:29:15,681 [bic.py] => 2 => 1.000, 0.000
2024-10-23 20:29:17,234 [bic.py] => training => Task 2, Epoch 1/150 => Loss 1.285, Train_accy 79.100, Test_accy 25.350
2024-10-23 20:29:18,651 [bic.py] => training => Task 2, Epoch 2/150 => Loss 1.233, Train_accy 80.000, Test_accy 37.930
2024-10-23 20:29:20,334 [bic.py] => training => Task 2, Epoch 3/150 => Loss 1.162, Train_accy 80.090, Test_accy 34.690
2024-10-23 20:29:21,710 [bic.py] => training => Task 2, Epoch 4/150 => Loss 1.331, Train_accy 89.920, Test_accy 29.410
2024-10-23 20:29:23,133 [bic.py] => training => Task 2, Epoch 5/150 => Loss 1.249, Train_accy 81.580, Test_accy 35.240
2024-10-23 20:29:24,467 [bic.py] => training => Task 2, Epoch 6/150 => Loss 1.276, Train_accy 48.090, Test_accy 11.690
2024-10-23 20:29:25,777 [bic.py] => training => Task 2, Epoch 7/150 => Loss 1.286, Train_accy 56.500, Test_accy 30.980
2024-10-23 20:29:27,171 [bic.py] => training => Task 2, Epoch 8/150 => Loss 1.280, Train_accy 91.040, Test_accy 29.670
2024-10-23 20:29:28,526 [bic.py] => training => Task 2, Epoch 9/150 => Loss 1.209, Train_accy 93.750, Test_accy 39.650
2024-10-23 20:29:29,893 [bic.py] => training => Task 2, Epoch 10/150 => Loss 1.175, Train_accy 95.360, Test_accy 49.560
2024-10-23 20:29:31,240 [bic.py] => training => Task 2, Epoch 11/150 => Loss 1.186, Train_accy 90.190, Test_accy 36.070
2024-10-23 20:29:32,826 [bic.py] => training => Task 2, Epoch 12/150 => Loss 1.188, Train_accy 95.270, Test_accy 44.520
2024-10-23 20:29:34,308 [bic.py] => training => Task 2, Epoch 13/150 => Loss 1.133, Train_accy 97.270, Test_accy 51.980
2024-10-23 20:29:35,737 [bic.py] => training => Task 2, Epoch 14/150 => Loss 1.121, Train_accy 98.190, Test_accy 51.700
2024-10-23 20:29:37,257 [bic.py] => training => Task 2, Epoch 15/150 => Loss 1.121, Train_accy 96.260, Test_accy 50.220
2024-10-23 20:29:38,673 [bic.py] => training => Task 2, Epoch 16/150 => Loss 1.194, Train_accy 90.610, Test_accy 37.590
2024-10-23 20:29:40,036 [bic.py] => training => Task 2, Epoch 17/150 => Loss 1.206, Train_accy 95.250, Test_accy 43.190
2024-10-23 20:29:41,451 [bic.py] => training => Task 2, Epoch 18/150 => Loss 1.163, Train_accy 49.060, Test_accy 12.520
2024-10-23 20:29:42,906 [bic.py] => training => Task 2, Epoch 19/150 => Loss 1.268, Train_accy 76.730, Test_accy 47.590
2024-10-23 20:29:44,339 [bic.py] => training => Task 2, Epoch 20/150 => Loss 1.192, Train_accy 90.840, Test_accy 43.540
2024-10-23 20:29:45,831 [bic.py] => training => Task 2, Epoch 21/150 => Loss 1.171, Train_accy 97.010, Test_accy 48.430
2024-10-23 20:29:47,266 [bic.py] => training => Task 2, Epoch 22/150 => Loss 1.125, Train_accy 94.100, Test_accy 49.560
2024-10-23 20:29:48,638 [bic.py] => training => Task 2, Epoch 23/150 => Loss 1.141, Train_accy 98.230, Test_accy 55.130
2024-10-23 20:29:49,905 [bic.py] => training => Task 2, Epoch 24/150 => Loss 1.122, Train_accy 97.630, Test_accy 54.760
2024-10-23 20:29:51,245 [bic.py] => training => Task 2, Epoch 25/150 => Loss 1.159, Train_accy 97.570, Test_accy 54.930
2024-10-23 20:29:52,762 [bic.py] => training => Task 2, Epoch 26/150 => Loss 1.117, Train_accy 95.770, Test_accy 55.850
2024-10-23 20:29:54,362 [bic.py] => training => Task 2, Epoch 27/150 => Loss 1.131, Train_accy 96.900, Test_accy 44.980
2024-10-23 20:29:55,748 [bic.py] => training => Task 2, Epoch 28/150 => Loss 1.119, Train_accy 88.560, Test_accy 45.370
2024-10-23 20:29:57,095 [bic.py] => training => Task 2, Epoch 29/150 => Loss 1.181, Train_accy 95.800, Test_accy 55.000
2024-10-23 20:29:58,543 [bic.py] => training => Task 2, Epoch 30/150 => Loss 1.148, Train_accy 98.900, Test_accy 56.190
2024-10-23 20:29:59,956 [bic.py] => training => Task 2, Epoch 31/150 => Loss 1.106, Train_accy 99.520, Test_accy 55.300
2024-10-23 20:30:01,360 [bic.py] => training => Task 2, Epoch 32/150 => Loss 1.103, Train_accy 99.040, Test_accy 56.310
2024-10-23 20:30:02,896 [bic.py] => training => Task 2, Epoch 33/150 => Loss 1.106, Train_accy 99.560, Test_accy 58.220
2024-10-23 20:30:04,337 [bic.py] => training => Task 2, Epoch 34/150 => Loss 1.091, Train_accy 99.680, Test_accy 58.960
2024-10-23 20:30:05,678 [bic.py] => training => Task 2, Epoch 35/150 => Loss 1.084, Train_accy 99.750, Test_accy 57.330
2024-10-23 20:30:06,962 [bic.py] => training => Task 2, Epoch 36/150 => Loss 1.077, Train_accy 99.840, Test_accy 59.930
2024-10-23 20:30:08,325 [bic.py] => training => Task 2, Epoch 37/150 => Loss 1.076, Train_accy 99.930, Test_accy 58.220
2024-10-23 20:30:09,751 [bic.py] => training => Task 2, Epoch 38/150 => Loss 1.103, Train_accy 96.990, Test_accy 56.110
2024-10-23 20:30:11,180 [bic.py] => training => Task 2, Epoch 39/150 => Loss 1.146, Train_accy 88.030, Test_accy 52.260
2024-10-23 20:30:12,607 [bic.py] => training => Task 2, Epoch 40/150 => Loss 1.175, Train_accy 96.970, Test_accy 55.830
2024-10-23 20:30:13,904 [bic.py] => training => Task 2, Epoch 41/150 => Loss 1.108, Train_accy 99.270, Test_accy 61.350
2024-10-23 20:30:15,228 [bic.py] => training => Task 2, Epoch 42/150 => Loss 1.116, Train_accy 99.330, Test_accy 56.200
2024-10-23 20:30:16,445 [bic.py] => training => Task 2, Epoch 43/150 => Loss 1.087, Train_accy 99.790, Test_accy 60.720
2024-10-23 20:30:17,746 [bic.py] => training => Task 2, Epoch 44/150 => Loss 1.080, Train_accy 99.890, Test_accy 59.090
2024-10-23 20:30:18,972 [bic.py] => training => Task 2, Epoch 45/150 => Loss 1.083, Train_accy 99.720, Test_accy 54.370
2024-10-23 20:30:20,203 [bic.py] => training => Task 2, Epoch 46/150 => Loss 1.109, Train_accy 99.700, Test_accy 59.810
2024-10-23 20:30:21,482 [bic.py] => training => Task 2, Epoch 47/150 => Loss 1.112, Train_accy 99.610, Test_accy 56.810
2024-10-23 20:30:22,746 [bic.py] => training => Task 2, Epoch 48/150 => Loss 1.103, Train_accy 99.610, Test_accy 57.240
2024-10-23 20:30:23,981 [bic.py] => training => Task 2, Epoch 49/150 => Loss 1.095, Train_accy 99.930, Test_accy 59.560
2024-10-23 20:30:25,316 [bic.py] => training => Task 2, Epoch 50/150 => Loss 1.081, Train_accy 99.890, Test_accy 59.720
2024-10-23 20:30:26,566 [bic.py] => training => Task 2, Epoch 51/150 => Loss 1.071, Train_accy 99.980, Test_accy 59.460
2024-10-23 20:30:27,840 [bic.py] => training => Task 2, Epoch 52/150 => Loss 1.086, Train_accy 99.980, Test_accy 58.310
2024-10-23 20:30:29,118 [bic.py] => training => Task 2, Epoch 53/150 => Loss 1.073, Train_accy 99.930, Test_accy 62.630
2024-10-23 20:30:30,295 [bic.py] => training => Task 2, Epoch 54/150 => Loss 1.078, Train_accy 99.930, Test_accy 57.670
2024-10-23 20:30:31,579 [bic.py] => training => Task 2, Epoch 55/150 => Loss 1.081, Train_accy 99.950, Test_accy 61.980
2024-10-23 20:30:32,817 [bic.py] => training => Task 2, Epoch 56/150 => Loss 1.073, Train_accy 99.930, Test_accy 61.330
2024-10-23 20:30:34,129 [bic.py] => training => Task 2, Epoch 57/150 => Loss 1.074, Train_accy 99.950, Test_accy 61.200
2024-10-23 20:30:35,409 [bic.py] => training => Task 2, Epoch 58/150 => Loss 1.071, Train_accy 99.890, Test_accy 57.590
2024-10-23 20:30:36,706 [bic.py] => training => Task 2, Epoch 59/150 => Loss 1.079, Train_accy 99.950, Test_accy 63.060
2024-10-23 20:30:37,976 [bic.py] => training => Task 2, Epoch 60/150 => Loss 1.086, Train_accy 99.910, Test_accy 63.460
2024-10-23 20:30:39,208 [bic.py] => training => Task 2, Epoch 61/150 => Loss 1.074, Train_accy 99.950, Test_accy 61.200
2024-10-23 20:30:40,422 [bic.py] => training => Task 2, Epoch 62/150 => Loss 1.075, Train_accy 99.840, Test_accy 60.350
2024-10-23 20:30:41,753 [bic.py] => training => Task 2, Epoch 63/150 => Loss 1.070, Train_accy 99.950, Test_accy 59.370
2024-10-23 20:30:42,964 [bic.py] => training => Task 2, Epoch 64/150 => Loss 1.065, Train_accy 99.980, Test_accy 61.330
2024-10-23 20:30:44,106 [bic.py] => training => Task 2, Epoch 65/150 => Loss 1.060, Train_accy 100.000, Test_accy 60.590
2024-10-23 20:30:45,368 [bic.py] => training => Task 2, Epoch 66/150 => Loss 1.063, Train_accy 99.980, Test_accy 60.330
2024-10-23 20:30:46,592 [bic.py] => training => Task 2, Epoch 67/150 => Loss 1.064, Train_accy 100.000, Test_accy 61.150
2024-10-23 20:30:47,857 [bic.py] => training => Task 2, Epoch 68/150 => Loss 1.102, Train_accy 99.980, Test_accy 59.940
2024-10-23 20:30:49,119 [bic.py] => training => Task 2, Epoch 69/150 => Loss 1.084, Train_accy 99.910, Test_accy 57.410
2024-10-23 20:30:50,322 [bic.py] => training => Task 2, Epoch 70/150 => Loss 1.070, Train_accy 99.950, Test_accy 59.670
2024-10-23 20:30:51,507 [bic.py] => training => Task 2, Epoch 71/150 => Loss 1.067, Train_accy 99.980, Test_accy 60.590
2024-10-23 20:30:52,768 [bic.py] => training => Task 2, Epoch 72/150 => Loss 1.068, Train_accy 100.000, Test_accy 61.260
2024-10-23 20:30:53,939 [bic.py] => training => Task 2, Epoch 73/150 => Loss 1.068, Train_accy 100.000, Test_accy 60.850
2024-10-23 20:30:55,285 [bic.py] => training => Task 2, Epoch 74/150 => Loss 1.064, Train_accy 100.000, Test_accy 59.060
2024-10-23 20:30:56,582 [bic.py] => training => Task 2, Epoch 75/150 => Loss 1.061, Train_accy 100.000, Test_accy 59.910
2024-10-23 20:30:58,184 [bic.py] => training => Task 2, Epoch 76/150 => Loss 1.066, Train_accy 100.000, Test_accy 59.480
2024-10-23 20:30:59,419 [bic.py] => training => Task 2, Epoch 77/150 => Loss 1.072, Train_accy 100.000, Test_accy 62.240
2024-10-23 20:31:00,616 [bic.py] => training => Task 2, Epoch 78/150 => Loss 1.072, Train_accy 99.980, Test_accy 58.350
2024-10-23 20:31:01,865 [bic.py] => training => Task 2, Epoch 79/150 => Loss 1.061, Train_accy 100.000, Test_accy 60.310
2024-10-23 20:31:03,132 [bic.py] => training => Task 2, Epoch 80/150 => Loss 1.076, Train_accy 100.000, Test_accy 60.300
2024-10-23 20:31:04,393 [bic.py] => training => Task 2, Epoch 81/150 => Loss 1.071, Train_accy 100.000, Test_accy 59.780
2024-10-23 20:31:05,607 [bic.py] => training => Task 2, Epoch 82/150 => Loss 1.065, Train_accy 99.980, Test_accy 61.560
2024-10-23 20:31:06,973 [bic.py] => training => Task 2, Epoch 83/150 => Loss 1.074, Train_accy 100.000, Test_accy 60.260
2024-10-23 20:31:08,201 [bic.py] => training => Task 2, Epoch 84/150 => Loss 1.072, Train_accy 100.000, Test_accy 59.830
2024-10-23 20:31:09,388 [bic.py] => training => Task 2, Epoch 85/150 => Loss 1.051, Train_accy 100.000, Test_accy 60.430
2024-10-23 20:31:10,744 [bic.py] => training => Task 2, Epoch 86/150 => Loss 1.062, Train_accy 100.000, Test_accy 60.910
2024-10-23 20:31:12,067 [bic.py] => training => Task 2, Epoch 87/150 => Loss 1.055, Train_accy 100.000, Test_accy 60.220
2024-10-23 20:31:13,320 [bic.py] => training => Task 2, Epoch 88/150 => Loss 1.061, Train_accy 100.000, Test_accy 60.800
2024-10-23 20:31:14,560 [bic.py] => training => Task 2, Epoch 89/150 => Loss 1.061, Train_accy 100.000, Test_accy 60.980
2024-10-23 20:31:15,818 [bic.py] => training => Task 2, Epoch 90/150 => Loss 1.079, Train_accy 100.000, Test_accy 59.110
2024-10-23 20:31:17,045 [bic.py] => training => Task 2, Epoch 91/150 => Loss 1.053, Train_accy 100.000, Test_accy 60.960
2024-10-23 20:31:18,287 [bic.py] => training => Task 2, Epoch 92/150 => Loss 1.067, Train_accy 100.000, Test_accy 59.350
2024-10-23 20:31:19,521 [bic.py] => training => Task 2, Epoch 93/150 => Loss 1.060, Train_accy 100.000, Test_accy 59.260
2024-10-23 20:31:20,641 [bic.py] => training => Task 2, Epoch 94/150 => Loss 1.049, Train_accy 100.000, Test_accy 61.150
2024-10-23 20:31:21,890 [bic.py] => training => Task 2, Epoch 95/150 => Loss 1.064, Train_accy 100.000, Test_accy 61.440
2024-10-23 20:31:23,142 [bic.py] => training => Task 2, Epoch 96/150 => Loss 1.053, Train_accy 100.000, Test_accy 62.000
2024-10-23 20:31:24,268 [bic.py] => training => Task 2, Epoch 97/150 => Loss 1.102, Train_accy 100.000, Test_accy 58.110
2024-10-23 20:31:25,424 [bic.py] => training => Task 2, Epoch 98/150 => Loss 1.060, Train_accy 100.000, Test_accy 62.430
2024-10-23 20:31:26,541 [bic.py] => training => Task 2, Epoch 99/150 => Loss 1.060, Train_accy 100.000, Test_accy 59.940
2024-10-23 20:31:27,689 [bic.py] => training => Task 2, Epoch 100/150 => Loss 1.062, Train_accy 100.000, Test_accy 60.350
2024-10-23 20:31:28,931 [bic.py] => training => Task 2, Epoch 101/150 => Loss 1.060, Train_accy 99.980, Test_accy 60.830
2024-10-23 20:31:30,187 [bic.py] => training => Task 2, Epoch 102/150 => Loss 1.060, Train_accy 100.000, Test_accy 62.200
2024-10-23 20:31:31,366 [bic.py] => training => Task 2, Epoch 103/150 => Loss 1.061, Train_accy 100.000, Test_accy 60.720
2024-10-23 20:31:32,591 [bic.py] => training => Task 2, Epoch 104/150 => Loss 1.075, Train_accy 100.000, Test_accy 57.590
2024-10-23 20:31:33,791 [bic.py] => training => Task 2, Epoch 105/150 => Loss 1.068, Train_accy 99.980, Test_accy 58.960
2024-10-23 20:31:34,972 [bic.py] => training => Task 2, Epoch 106/150 => Loss 1.053, Train_accy 100.000, Test_accy 60.330
2024-10-23 20:31:36,192 [bic.py] => training => Task 2, Epoch 107/150 => Loss 1.051, Train_accy 100.000, Test_accy 61.870
2024-10-23 20:31:37,303 [bic.py] => training => Task 2, Epoch 108/150 => Loss 1.067, Train_accy 100.000, Test_accy 60.300
2024-10-23 20:31:38,545 [bic.py] => training => Task 2, Epoch 109/150 => Loss 1.072, Train_accy 100.000, Test_accy 61.940
2024-10-23 20:31:39,715 [bic.py] => training => Task 2, Epoch 110/150 => Loss 1.060, Train_accy 99.980, Test_accy 63.090
2024-10-23 20:31:40,978 [bic.py] => training => Task 2, Epoch 111/150 => Loss 1.072, Train_accy 100.000, Test_accy 57.780
2024-10-23 20:31:42,231 [bic.py] => training => Task 2, Epoch 112/150 => Loss 1.108, Train_accy 100.000, Test_accy 58.590
2024-10-23 20:31:43,458 [bic.py] => training => Task 2, Epoch 113/150 => Loss 1.068, Train_accy 100.000, Test_accy 61.590
2024-10-23 20:31:44,651 [bic.py] => training => Task 2, Epoch 114/150 => Loss 1.069, Train_accy 100.000, Test_accy 62.690
2024-10-23 20:31:45,958 [bic.py] => training => Task 2, Epoch 115/150 => Loss 1.062, Train_accy 100.000, Test_accy 61.060
2024-10-23 20:31:47,214 [bic.py] => training => Task 2, Epoch 116/150 => Loss 1.062, Train_accy 100.000, Test_accy 63.610
2024-10-23 20:31:48,437 [bic.py] => training => Task 2, Epoch 117/150 => Loss 1.057, Train_accy 100.000, Test_accy 63.370
2024-10-23 20:31:49,693 [bic.py] => training => Task 2, Epoch 118/150 => Loss 1.060, Train_accy 100.000, Test_accy 61.440
2024-10-23 20:31:50,868 [bic.py] => training => Task 2, Epoch 119/150 => Loss 1.051, Train_accy 100.000, Test_accy 62.130
2024-10-23 20:31:52,084 [bic.py] => training => Task 2, Epoch 120/150 => Loss 1.053, Train_accy 100.000, Test_accy 61.560
2024-10-23 20:31:53,290 [bic.py] => training => Task 2, Epoch 121/150 => Loss 1.052, Train_accy 100.000, Test_accy 61.800
2024-10-23 20:31:54,535 [bic.py] => training => Task 2, Epoch 122/150 => Loss 1.059, Train_accy 100.000, Test_accy 60.890
2024-10-23 20:31:55,748 [bic.py] => training => Task 2, Epoch 123/150 => Loss 1.059, Train_accy 100.000, Test_accy 62.720
2024-10-23 20:31:56,989 [bic.py] => training => Task 2, Epoch 124/150 => Loss 1.068, Train_accy 100.000, Test_accy 61.500
2024-10-23 20:31:58,319 [bic.py] => training => Task 2, Epoch 125/150 => Loss 1.056, Train_accy 100.000, Test_accy 61.330
2024-10-23 20:31:59,621 [bic.py] => training => Task 2, Epoch 126/150 => Loss 1.062, Train_accy 100.000, Test_accy 59.760
2024-10-23 20:32:01,002 [bic.py] => training => Task 2, Epoch 127/150 => Loss 1.064, Train_accy 100.000, Test_accy 58.060
2024-10-23 20:32:02,302 [bic.py] => training => Task 2, Epoch 128/150 => Loss 1.066, Train_accy 99.980, Test_accy 63.020
2024-10-23 20:32:03,564 [bic.py] => training => Task 2, Epoch 129/150 => Loss 1.069, Train_accy 100.000, Test_accy 61.520
2024-10-23 20:32:04,796 [bic.py] => training => Task 2, Epoch 130/150 => Loss 1.068, Train_accy 100.000, Test_accy 59.690
2024-10-23 20:32:06,141 [bic.py] => training => Task 2, Epoch 131/150 => Loss 1.065, Train_accy 100.000, Test_accy 62.060
2024-10-23 20:32:07,365 [bic.py] => training => Task 2, Epoch 132/150 => Loss 1.081, Train_accy 100.000, Test_accy 61.130
2024-10-23 20:32:08,665 [bic.py] => training => Task 2, Epoch 133/150 => Loss 1.057, Train_accy 100.000, Test_accy 61.430
2024-10-23 20:32:09,948 [bic.py] => training => Task 2, Epoch 134/150 => Loss 1.062, Train_accy 100.000, Test_accy 63.440
2024-10-23 20:32:11,246 [bic.py] => training => Task 2, Epoch 135/150 => Loss 1.070, Train_accy 100.000, Test_accy 62.650
2024-10-23 20:32:12,472 [bic.py] => training => Task 2, Epoch 136/150 => Loss 1.071, Train_accy 100.000, Test_accy 61.610
2024-10-23 20:32:13,600 [bic.py] => training => Task 2, Epoch 137/150 => Loss 1.079, Train_accy 100.000, Test_accy 63.190
2024-10-23 20:32:14,909 [bic.py] => training => Task 2, Epoch 138/150 => Loss 1.071, Train_accy 100.000, Test_accy 63.200
2024-10-23 20:32:16,081 [bic.py] => training => Task 2, Epoch 139/150 => Loss 1.057, Train_accy 100.000, Test_accy 62.830
2024-10-23 20:32:17,292 [bic.py] => training => Task 2, Epoch 140/150 => Loss 1.073, Train_accy 100.000, Test_accy 62.930
2024-10-23 20:32:18,433 [bic.py] => training => Task 2, Epoch 141/150 => Loss 1.053, Train_accy 100.000, Test_accy 62.240
2024-10-23 20:32:19,664 [bic.py] => training => Task 2, Epoch 142/150 => Loss 1.063, Train_accy 100.000, Test_accy 62.410
2024-10-23 20:32:20,920 [bic.py] => training => Task 2, Epoch 143/150 => Loss 1.063, Train_accy 100.000, Test_accy 60.430
2024-10-23 20:32:22,105 [bic.py] => training => Task 2, Epoch 144/150 => Loss 1.077, Train_accy 100.000, Test_accy 60.170
2024-10-23 20:32:23,289 [bic.py] => training => Task 2, Epoch 145/150 => Loss 1.083, Train_accy 100.000, Test_accy 58.130
2024-10-23 20:32:24,524 [bic.py] => training => Task 2, Epoch 146/150 => Loss 1.079, Train_accy 100.000, Test_accy 62.800
2024-10-23 20:32:25,713 [bic.py] => training => Task 2, Epoch 147/150 => Loss 1.079, Train_accy 100.000, Test_accy 58.370
2024-10-23 20:32:26,922 [bic.py] => training => Task 2, Epoch 148/150 => Loss 1.066, Train_accy 100.000, Test_accy 61.390
2024-10-23 20:32:28,124 [bic.py] => training => Task 2, Epoch 149/150 => Loss 1.067, Train_accy 100.000, Test_accy 60.020
2024-10-23 20:32:29,348 [bic.py] => training => Task 2, Epoch 150/150 => Loss 1.060, Train_accy 100.000, Test_accy 60.440
2024-10-23 20:32:29,632 [bic.py] => bias_correction => Task 2, Epoch 1/7 => Loss 1.955, Train_accy 62.220, Test_accy 58.690
2024-10-23 20:32:29,894 [bic.py] => bias_correction => Task 2, Epoch 2/7 => Loss 1.949, Train_accy 62.220, Test_accy 57.520
2024-10-23 20:32:30,160 [bic.py] => bias_correction => Task 2, Epoch 3/7 => Loss 1.937, Train_accy 62.220, Test_accy 57.190
2024-10-23 20:32:30,406 [bic.py] => bias_correction => Task 2, Epoch 4/7 => Loss 1.919, Train_accy 62.220, Test_accy 57.810
2024-10-23 20:32:30,638 [bic.py] => bias_correction => Task 2, Epoch 5/7 => Loss 1.891, Train_accy 64.440, Test_accy 59.610
2024-10-23 20:32:30,899 [bic.py] => bias_correction => Task 2, Epoch 6/7 => Loss 1.850, Train_accy 71.110, Test_accy 63.150
2024-10-23 20:32:31,172 [bic.py] => bias_correction => Task 2, Epoch 7/7 => Loss 1.790, Train_accy 73.330, Test_accy 66.980
2024-10-23 20:32:31,173 [base.py] => Reducing exemplars...(44 per classes)
2024-10-23 20:32:32,611 [base.py] => Constructing exemplars...(44 per classes)
2024-10-23 20:32:34,311 [bic.py] => Parameters of bias layer:
2024-10-23 20:32:34,311 [bic.py] => 0 => 1.000, 0.000
2024-10-23 20:32:34,311 [bic.py] => 1 => 0.545, -1.127
2024-10-23 20:32:34,311 [bic.py] => 2 => 0.359, -0.131
2024-10-23 20:32:34,312 [trainer.py] => All params: 3848527
2024-10-23 20:32:35,030 [bic.py] => Exemplar size: 396
2024-10-23 20:32:35,030 [trainer.py] => CNN: {'total': 66.98, '00-04': 60.8, '05-06': 60.08, '07-08': 89.33, 'old': 60.6, 'new': 89.33}
2024-10-23 20:32:35,031 [trainer.py] => NME: {'total': 69.56, '00-04': 59.13, '05-06': 72.0, '07-08': 93.17, 'old': 62.81, 'new': 93.17}
2024-10-23 20:32:35,031 [trainer.py] => CNN top1 curve: [89.93, 79.24, 66.98]
2024-10-23 20:32:35,031 [trainer.py] => CNN top5 curve: [100.0, 98.83, 94.57]
2024-10-23 20:32:35,031 [trainer.py] => NME top1 curve: [90.0, 77.21, 69.56]
2024-10-23 20:32:35,031 [trainer.py] => NME top5 curve: [100.0, 98.98, 96.61]

2024-10-23 20:32:35,031 [trainer.py] => Average Accuracy (CNN): 78.71666666666668
2024-10-23 20:32:35,031 [trainer.py] => Average Accuracy (NME): 78.92333333333333
2024-10-23 20:32:35,032 [trainer.py] => Forgetting (CNN): 23.440000000000005
