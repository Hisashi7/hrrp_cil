2024-08-21 16:16:39,036 [trainer.py] => config: ./exps/foster.json
2024-08-21 16:16:39,037 [trainer.py] => prefix: cil
2024-08-21 16:16:39,037 [trainer.py] => dataset: hrrp9
2024-08-21 16:16:39,037 [trainer.py] => memory_size: 500
2024-08-21 16:16:39,037 [trainer.py] => memory_per_class: 20
2024-08-21 16:16:39,037 [trainer.py] => fixed_memory: False
2024-08-21 16:16:39,037 [trainer.py] => shuffle: True
2024-08-21 16:16:39,037 [trainer.py] => init_cls: 5
2024-08-21 16:16:39,037 [trainer.py] => increment: 2
2024-08-21 16:16:39,037 [trainer.py] => model_name: foster
2024-08-21 16:16:39,037 [trainer.py] => convnet_type: resnet18
2024-08-21 16:16:39,037 [trainer.py] => init_train: False
2024-08-21 16:16:39,037 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-08-21 16:16:39,037 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-08-21 16:16:39,037 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-21 16:16:39,037 [trainer.py] => seed: 1993
2024-08-21 16:16:39,037 [trainer.py] => beta1: 0.96
2024-08-21 16:16:39,037 [trainer.py] => beta2: 0.97
2024-08-21 16:16:39,037 [trainer.py] => oofc: ft
2024-08-21 16:16:39,037 [trainer.py] => is_teacher_wa: True
2024-08-21 16:16:39,037 [trainer.py] => is_student_wa: True
2024-08-21 16:16:39,037 [trainer.py] => lambda_okd: 1
2024-08-21 16:16:39,037 [trainer.py] => wa_value: 1
2024-08-21 16:16:39,037 [trainer.py] => init_epochs: 0
2024-08-21 16:16:39,038 [trainer.py] => init_lr: 0.1
2024-08-21 16:16:39,038 [trainer.py] => init_weight_decay: 0.0005
2024-08-21 16:16:39,038 [trainer.py] => boosting_epochs: 170
2024-08-21 16:16:39,038 [trainer.py] => compression_epochs: 130
2024-08-21 16:16:39,038 [trainer.py] => lr: 0.1
2024-08-21 16:16:39,038 [trainer.py] => batch_size: 128
2024-08-21 16:16:39,038 [trainer.py] => weight_decay: 0.0005
2024-08-21 16:16:39,038 [trainer.py] => num_workers: 8
2024-08-21 16:16:39,038 [trainer.py] => T: 2
2024-08-21 16:16:39,852 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-08-21 16:16:39,899 [trainer.py] => All params: 0
2024-08-21 16:16:39,899 [trainer.py] => Trainable params: 0
2024-08-21 16:16:42,067 [foster.py] => Learning on 0-5
2024-08-21 16:16:42,068 [foster.py] => All params: 3849034
2024-08-21 16:16:42,068 [foster.py] => Trainable params: 3849034
2024-08-21 16:16:42,142 [foster.py] => init_train?---False
2024-08-21 16:16:45,884 [base.py] => Reducing exemplars...(100 per classes)
2024-08-21 16:16:45,884 [base.py] => Constructing exemplars...(100 per classes)
2024-08-21 16:16:56,792 [foster.py] => Exemplar size: 500
2024-08-21 16:16:56,792 [trainer.py] => CNN: {'total': 92.89, '00-04': 92.89, 'old': 0, 'new': 92.89}
2024-08-21 16:16:56,792 [trainer.py] => NME: {'total': 92.95, '00-04': 92.95, 'old': 0, 'new': 92.95}
2024-08-21 16:16:56,792 [trainer.py] => CNN top1 curve: [92.89]
2024-08-21 16:16:56,792 [trainer.py] => CNN top5 curve: [100.0]
2024-08-21 16:16:56,792 [trainer.py] => NME top1 curve: [92.95]
2024-08-21 16:16:56,792 [trainer.py] => NME top5 curve: [100.0]

2024-08-21 16:16:56,792 [trainer.py] => Average Accuracy (CNN): 92.89
2024-08-21 16:16:56,792 [trainer.py] => Average Accuracy (NME): 92.95
2024-08-21 16:16:56,793 [trainer.py] => All params: 3849034
2024-08-21 16:16:56,793 [trainer.py] => Trainable params: 3849034
2024-08-21 16:16:56,839 [foster.py] => Learning on 5-7
2024-08-21 16:16:56,840 [foster.py] => All params: 7701139
2024-08-21 16:16:56,840 [foster.py] => Trainable params: 3854670
2024-08-21 16:16:56,912 [foster.py] => per cls weights : [1.00484344 1.00484344 1.00484344 1.00484344 1.00484344 0.98789141
 0.98789141]
2024-08-21 16:23:43,329 [foster.py] => Task 1, Epoch 170/170 => Loss 0.900, Loss_clf 0.001, Loss_fe 0.001, Loss_kd 0.641, Train_accy 100.00
2024-08-21 16:23:43,336 [inc_net.py] => align weights, gamma = 1.036030888557434 
2024-08-21 16:23:43,339 [foster.py] => per cls weights : [1.01377356 1.01377356 1.01377356 1.01377356 1.01377356 0.96556609
 0.96556609]
2024-08-21 16:28:54,932 [foster.py] => SNet: Task 1, Epoch 130/130 => Loss 0.180,  Train_accy 100.00
2024-08-21 16:28:54,938 [inc_net.py] => align weights, gamma = 0.9975622296333313 
2024-08-21 16:28:56,731 [foster.py] => darknet eval: 
2024-08-21 16:28:56,732 [foster.py] => CNN top1 curve: 78.6
2024-08-21 16:28:56,733 [foster.py] => CNN top5 curve: 99.32
2024-08-21 16:28:56,734 [base.py] => Reducing exemplars...(71 per classes)
2024-08-21 16:29:00,194 [base.py] => Constructing exemplars...(71 per classes)
2024-08-21 16:29:09,835 [foster.py] => Exemplar size: 497
2024-08-21 16:29:09,835 [trainer.py] => CNN: {'total': 79.57, '00-04': 74.77, '05-06': 98.4, 'old': 74.77, 'new': 98.4}
2024-08-21 16:29:09,835 [trainer.py] => NME: {'total': 82.28, '00-04': 78.66, '05-06': 96.52, 'old': 78.66, 'new': 96.52}
2024-08-21 16:29:09,835 [trainer.py] => CNN top1 curve: [92.89, 79.57]
2024-08-21 16:29:09,835 [trainer.py] => CNN top5 curve: [100.0, 99.37]
2024-08-21 16:29:09,835 [trainer.py] => NME top1 curve: [92.95, 82.28]
2024-08-21 16:29:09,836 [trainer.py] => NME top5 curve: [100.0, 99.42]

2024-08-21 16:29:09,836 [trainer.py] => Average Accuracy (CNN): 86.22999999999999
2024-08-21 16:29:09,836 [trainer.py] => Average Accuracy (NME): 87.61500000000001
2024-08-21 16:29:09,837 [trainer.py] => All params: 7701139
2024-08-21 16:29:09,837 [trainer.py] => Trainable params: 3854670
2024-08-21 16:29:09,885 [foster.py] => Learning on 7-9
2024-08-21 16:29:09,886 [foster.py] => All params: 7705241
2024-08-21 16:29:09,886 [foster.py] => Trainable params: 3857746
2024-08-21 16:29:09,965 [foster.py] => per cls weights : [1.01239929 1.01239929 1.01239929 1.01239929 1.01239929 1.01239929
 1.01239929 0.95660248 0.95660248]
2024-08-21 16:36:07,519 [foster.py] => Task 2, Epoch 170/170 => Loss 0.954, Loss_clf 0.001, Loss_fe 0.001, Loss_kd 0.741, Train_accy 100.00
2024-08-21 16:36:07,521 [inc_net.py] => align weights, gamma = 1.0196082592010498 
2024-08-21 16:36:07,522 [foster.py] => per cls weights : [1.02623168 1.02623168 1.02623168 1.02623168 1.02623168 1.02623168
 1.02623168 0.90818914 0.90818914]
2024-08-21 16:41:27,170 [foster.py] => SNet: Task 2, Epoch 130/130 => Loss 0.211,  Train_accy 100.00
2024-08-21 16:41:27,170 [inc_net.py] => align weights, gamma = 1.0125280618667603 
2024-08-21 16:41:29,171 [foster.py] => darknet eval: 
2024-08-21 16:41:29,172 [foster.py] => CNN top1 curve: 64.7
2024-08-21 16:41:29,172 [foster.py] => CNN top5 curve: 97.09
2024-08-21 16:41:29,173 [base.py] => Reducing exemplars...(55 per classes)
2024-08-21 16:41:33,657 [base.py] => Constructing exemplars...(55 per classes)
2024-08-21 16:41:43,405 [foster.py] => Exemplar size: 495
2024-08-21 16:41:43,405 [trainer.py] => CNN: {'total': 64.08, '00-04': 49.41, '05-06': 87.08, '07-08': 98.56, 'old': 57.05, 'new': 98.56}
2024-08-21 16:41:43,405 [trainer.py] => NME: {'total': 70.29, '00-04': 60.29, '05-06': 82.55, '07-08': 97.2, 'old': 64.81, 'new': 97.2}
2024-08-21 16:41:43,405 [trainer.py] => CNN top1 curve: [92.89, 79.57, 64.08]
2024-08-21 16:41:43,405 [trainer.py] => CNN top5 curve: [100.0, 99.37, 96.98]
2024-08-21 16:41:43,405 [trainer.py] => NME top1 curve: [92.95, 82.28, 70.29]
2024-08-21 16:41:43,405 [trainer.py] => NME top5 curve: [100.0, 99.42, 97.59]

2024-08-21 16:41:43,405 [trainer.py] => Average Accuracy (CNN): 78.84666666666665
2024-08-21 16:41:43,405 [trainer.py] => Average Accuracy (NME): 81.84000000000002
2024-08-21 16:41:43,406 [trainer.py] => Forgetting (CNN): 27.400000000000006
