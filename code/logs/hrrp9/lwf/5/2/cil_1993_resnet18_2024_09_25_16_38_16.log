2024-09-25 16:38:16,292 [trainer.py] => config: ./exps/lwf.json
2024-09-25 16:38:16,292 [trainer.py] => prefix: cil
2024-09-25 16:38:16,293 [trainer.py] => dataset: hrrp9
2024-09-25 16:38:16,293 [trainer.py] => memory_size: 500
2024-09-25 16:38:16,293 [trainer.py] => memory_per_class: 20
2024-09-25 16:38:16,293 [trainer.py] => fixed_memory: False
2024-09-25 16:38:16,293 [trainer.py] => shuffle: True
2024-09-25 16:38:16,294 [trainer.py] => init_cls: 5
2024-09-25 16:38:16,294 [trainer.py] => increment: 2
2024-09-25 16:38:16,294 [trainer.py] => model_name: lwf
2024-09-25 16:38:16,294 [trainer.py] => convnet_type: resnet18
2024-09-25 16:38:16,294 [trainer.py] => device: [device(type='cuda', index=1)]
2024-09-25 16:38:16,295 [trainer.py] => init_train: False
2024-09-25 16:38:16,295 [trainer.py] => convnet_path: checkpoints/init_train/resnet18_42503.pth
2024-09-25 16:38:16,295 [trainer.py] => fc_path: checkpoints/init_train/fc_42503.pth
2024-09-25 16:38:16,295 [trainer.py] => seed: 1993
2024-09-25 16:38:16,295 [trainer.py] => epochs: 150
2024-09-25 16:38:16,295 [trainer.py] => lrate: 0.1
2024-09-25 16:38:16,296 [trainer.py] => milestones: [30, 50, 80, 120]
2024-09-25 16:38:16,296 [trainer.py] => lrate_decay: 0.1
2024-09-25 16:38:16,296 [trainer.py] => batch_size: 128
2024-09-25 16:38:16,296 [trainer.py] => weight_decay: 0.0002
2024-09-25 16:38:16,296 [trainer.py] => momentum: 0
2024-09-25 16:38:16,297 [trainer.py] => num_workers: 4
2024-09-25 16:38:16,297 [trainer.py] => T: 2
2024-09-25 16:38:16,297 [trainer.py] => lamda: 0.5
2024-09-25 16:38:16,977 [data_manager.py] => [4, 2, 5, 0, 3, 6, 7, 8, 1]
2024-09-25 16:38:17,473 [trainer.py] => All params: 3843904
2024-09-25 16:38:17,474 [trainer.py] => Trainable params: 3843904
2024-09-25 16:38:17,498 [lwf.py] => Learning on 0-5
2024-09-25 16:38:17,726 [lwf.py] => init_train?---False
2024-09-25 16:38:18,833 [trainer.py] => No NME accuracy.
2024-09-25 16:38:18,834 [trainer.py] => CNN: {'total': 89.93, '00-04': 89.93, 'old': 0, 'new': 89.93}
2024-09-25 16:38:18,834 [trainer.py] => CNN top1 curve: [89.93]
2024-09-25 16:38:18,834 [trainer.py] => CNN top5 curve: [100.0]

2024-09-25 16:38:18,834 [trainer.py] => Average Accuracy (CNN): 89.93
2024-09-25 16:38:18,834 [trainer.py] => All params: 3846469
2024-09-25 16:38:18,835 [trainer.py] => Trainable params: 3846469
2024-09-25 16:38:18,836 [lwf.py] => Learning on 5-7
2024-09-25 16:38:24,288 [lwf.py] => Task 1, Epoch 5/150 => Loss 0.529, Train_accy 31.78, Test_accy 69.40
2024-09-25 16:38:29,578 [lwf.py] => Task 1, Epoch 10/150 => Loss 0.506, Train_accy 46.55, Test_accy 71.50
2024-09-25 16:38:34,815 [lwf.py] => Task 1, Epoch 15/150 => Loss 0.504, Train_accy 52.90, Test_accy 71.62
2024-09-25 16:38:39,823 [lwf.py] => Task 1, Epoch 20/150 => Loss 0.502, Train_accy 55.62, Test_accy 73.45
2024-09-25 16:38:44,956 [lwf.py] => Task 1, Epoch 25/150 => Loss 0.498, Train_accy 58.40, Test_accy 72.40
2024-09-25 16:38:49,939 [lwf.py] => Task 1, Epoch 30/150 => Loss 0.498, Train_accy 60.35, Test_accy 73.24
2024-09-25 16:38:55,012 [lwf.py] => Task 1, Epoch 35/150 => Loss 0.496, Train_accy 61.08, Test_accy 72.81
2024-09-25 16:39:00,193 [lwf.py] => Task 1, Epoch 40/150 => Loss 0.494, Train_accy 61.22, Test_accy 72.79
2024-09-25 16:39:05,383 [lwf.py] => Task 1, Epoch 45/150 => Loss 0.499, Train_accy 62.22, Test_accy 72.55
2024-09-25 16:39:10,542 [lwf.py] => Task 1, Epoch 50/150 => Loss 0.495, Train_accy 61.70, Test_accy 72.64
2024-09-25 16:39:15,585 [lwf.py] => Task 1, Epoch 55/150 => Loss 0.498, Train_accy 61.95, Test_accy 72.83
2024-09-25 16:39:20,655 [lwf.py] => Task 1, Epoch 60/150 => Loss 0.496, Train_accy 62.35, Test_accy 72.71
2024-09-25 16:39:25,842 [lwf.py] => Task 1, Epoch 65/150 => Loss 0.498, Train_accy 62.30, Test_accy 72.48
2024-09-25 16:39:31,031 [lwf.py] => Task 1, Epoch 70/150 => Loss 0.496, Train_accy 62.08, Test_accy 72.98
2024-09-25 16:39:36,322 [lwf.py] => Task 1, Epoch 75/150 => Loss 0.497, Train_accy 61.92, Test_accy 72.76
2024-09-25 16:39:41,673 [lwf.py] => Task 1, Epoch 80/150 => Loss 0.496, Train_accy 62.35, Test_accy 72.86
2024-09-25 16:39:46,896 [lwf.py] => Task 1, Epoch 85/150 => Loss 0.498, Train_accy 61.68, Test_accy 72.69
2024-09-25 16:39:52,110 [lwf.py] => Task 1, Epoch 90/150 => Loss 0.495, Train_accy 62.45, Test_accy 72.88
2024-09-25 16:39:57,413 [lwf.py] => Task 1, Epoch 95/150 => Loss 0.496, Train_accy 62.68, Test_accy 72.90
2024-09-25 16:40:02,695 [lwf.py] => Task 1, Epoch 100/150 => Loss 0.496, Train_accy 62.55, Test_accy 72.71
2024-09-25 16:40:07,869 [lwf.py] => Task 1, Epoch 105/150 => Loss 0.497, Train_accy 62.28, Test_accy 72.60
2024-09-25 16:40:13,098 [lwf.py] => Task 1, Epoch 110/150 => Loss 0.496, Train_accy 62.18, Test_accy 72.95
2024-09-25 16:40:18,211 [lwf.py] => Task 1, Epoch 115/150 => Loss 0.497, Train_accy 62.12, Test_accy 72.79
2024-09-25 16:40:23,442 [lwf.py] => Task 1, Epoch 120/150 => Loss 0.495, Train_accy 62.08, Test_accy 72.60
2024-09-25 16:40:28,685 [lwf.py] => Task 1, Epoch 125/150 => Loss 0.495, Train_accy 62.70, Test_accy 72.81
2024-09-25 16:40:33,823 [lwf.py] => Task 1, Epoch 130/150 => Loss 0.497, Train_accy 61.45, Test_accy 72.71
2024-09-25 16:40:38,911 [lwf.py] => Task 1, Epoch 135/150 => Loss 0.495, Train_accy 61.75, Test_accy 72.67
2024-09-25 16:40:44,173 [lwf.py] => Task 1, Epoch 140/150 => Loss 0.495, Train_accy 62.58, Test_accy 72.74
2024-09-25 16:40:49,506 [lwf.py] => Task 1, Epoch 145/150 => Loss 0.496, Train_accy 61.75, Test_accy 72.69
2024-09-25 16:40:54,853 [lwf.py] => Task 1, Epoch 150/150 => Loss 0.496, Train_accy 61.85, Test_accy 72.79
2024-09-25 16:40:54,854 [lwf.py] => Task 1, Epoch 150/150 => Loss 0.496, Train_accy 61.85, Test_accy 72.79
2024-09-25 16:40:55,270 [trainer.py] => No NME accuracy.
2024-09-25 16:40:55,271 [trainer.py] => CNN: {'total': 72.79, '00-04': 86.0, '05-06': 39.75, 'old': 86.0, 'new': 39.75}
2024-09-25 16:40:55,271 [trainer.py] => CNN top1 curve: [89.93, 72.79]
2024-09-25 16:40:55,271 [trainer.py] => CNN top5 curve: [100.0, 99.26]

2024-09-25 16:40:55,271 [trainer.py] => Average Accuracy (CNN): 81.36000000000001
2024-09-25 16:40:55,271 [trainer.py] => All params: 3847495
2024-09-25 16:40:55,272 [trainer.py] => Trainable params: 3847495
2024-09-25 16:40:55,273 [lwf.py] => Learning on 7-9
2024-09-25 16:41:00,358 [lwf.py] => Task 2, Epoch 5/150 => Loss 0.656, Train_accy 20.90, Test_accy 58.35
2024-09-25 16:41:05,546 [lwf.py] => Task 2, Epoch 10/150 => Loss 0.643, Train_accy 30.82, Test_accy 58.81
2024-09-25 16:41:10,823 [lwf.py] => Task 2, Epoch 15/150 => Loss 0.646, Train_accy 35.72, Test_accy 61.87
2024-09-25 16:41:15,944 [lwf.py] => Task 2, Epoch 20/150 => Loss 0.640, Train_accy 40.25, Test_accy 61.20
2024-09-25 16:41:21,202 [lwf.py] => Task 2, Epoch 25/150 => Loss 0.646, Train_accy 41.28, Test_accy 61.65
2024-09-25 16:41:26,493 [lwf.py] => Task 2, Epoch 30/150 => Loss 0.642, Train_accy 44.98, Test_accy 55.65
2024-09-25 16:41:31,668 [lwf.py] => Task 2, Epoch 35/150 => Loss 0.641, Train_accy 41.02, Test_accy 61.87
2024-09-25 16:41:36,981 [lwf.py] => Task 2, Epoch 40/150 => Loss 0.640, Train_accy 43.72, Test_accy 61.76
2024-09-25 16:41:42,225 [lwf.py] => Task 2, Epoch 45/150 => Loss 0.639, Train_accy 44.62, Test_accy 61.78
2024-09-25 16:41:47,246 [lwf.py] => Task 2, Epoch 50/150 => Loss 0.640, Train_accy 44.90, Test_accy 61.26
2024-09-25 16:41:52,383 [lwf.py] => Task 2, Epoch 55/150 => Loss 0.638, Train_accy 45.55, Test_accy 61.24
2024-09-25 16:41:57,702 [lwf.py] => Task 2, Epoch 60/150 => Loss 0.639, Train_accy 45.40, Test_accy 61.30
2024-09-25 16:42:02,793 [lwf.py] => Task 2, Epoch 65/150 => Loss 0.638, Train_accy 45.30, Test_accy 61.65
2024-09-25 16:42:08,021 [lwf.py] => Task 2, Epoch 70/150 => Loss 0.639, Train_accy 45.58, Test_accy 61.52
2024-09-25 16:42:13,137 [lwf.py] => Task 2, Epoch 75/150 => Loss 0.639, Train_accy 46.45, Test_accy 61.44
2024-09-25 16:42:18,285 [lwf.py] => Task 2, Epoch 80/150 => Loss 0.640, Train_accy 46.18, Test_accy 61.33
2024-09-25 16:42:23,543 [lwf.py] => Task 2, Epoch 85/150 => Loss 0.639, Train_accy 45.62, Test_accy 61.63
2024-09-25 16:42:28,850 [lwf.py] => Task 2, Epoch 90/150 => Loss 0.640, Train_accy 45.00, Test_accy 61.09
2024-09-25 16:42:34,103 [lwf.py] => Task 2, Epoch 95/150 => Loss 0.638, Train_accy 46.22, Test_accy 61.65
2024-09-25 16:42:39,320 [lwf.py] => Task 2, Epoch 100/150 => Loss 0.639, Train_accy 45.50, Test_accy 61.50
2024-09-25 16:42:44,647 [lwf.py] => Task 2, Epoch 105/150 => Loss 0.639, Train_accy 46.55, Test_accy 61.48
2024-09-25 16:42:49,743 [lwf.py] => Task 2, Epoch 110/150 => Loss 0.638, Train_accy 45.62, Test_accy 61.54
2024-09-25 16:42:54,924 [lwf.py] => Task 2, Epoch 115/150 => Loss 0.639, Train_accy 45.62, Test_accy 61.57
2024-09-25 16:43:00,173 [lwf.py] => Task 2, Epoch 120/150 => Loss 0.639, Train_accy 46.35, Test_accy 61.78
2024-09-25 16:43:05,335 [lwf.py] => Task 2, Epoch 125/150 => Loss 0.638, Train_accy 46.15, Test_accy 61.93
2024-09-25 16:43:10,414 [lwf.py] => Task 2, Epoch 130/150 => Loss 0.638, Train_accy 45.68, Test_accy 61.30
2024-09-25 16:43:15,556 [lwf.py] => Task 2, Epoch 135/150 => Loss 0.638, Train_accy 46.48, Test_accy 61.48
2024-09-25 16:43:20,741 [lwf.py] => Task 2, Epoch 140/150 => Loss 0.638, Train_accy 46.22, Test_accy 61.94
2024-09-25 16:43:25,842 [lwf.py] => Task 2, Epoch 145/150 => Loss 0.638, Train_accy 46.32, Test_accy 61.83
2024-09-25 16:43:31,124 [lwf.py] => Task 2, Epoch 150/150 => Loss 0.637, Train_accy 45.75, Test_accy 61.37
2024-09-25 16:43:31,126 [lwf.py] => Task 2, Epoch 150/150 => Loss 0.637, Train_accy 45.75, Test_accy 61.37
2024-09-25 16:43:31,616 [trainer.py] => No NME accuracy.
2024-09-25 16:43:31,617 [trainer.py] => CNN: {'total': 61.37, '00-04': 81.87, '05-06': 30.0, '07-08': 41.5, 'old': 67.05, 'new': 41.5}
2024-09-25 16:43:31,617 [trainer.py] => CNN top1 curve: [89.93, 72.79, 61.37]
2024-09-25 16:43:31,617 [trainer.py] => CNN top5 curve: [100.0, 99.26, 98.33]

2024-09-25 16:43:31,617 [trainer.py] => Average Accuracy (CNN): 74.69666666666667
2024-09-25 16:43:31,618 [trainer.py] => Forgetting (CNN): 8.905000000000001
